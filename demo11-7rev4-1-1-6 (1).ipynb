{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14054599,"sourceType":"datasetVersion","datasetId":8946387}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Clean install (skip sentence-transformers)\n!pip uninstall -y transformers tokenizers sentence-transformers huggingface-hub\n\n# Step 2: Install only what you need\n!pip install transformers sacrebleu sacremoses\n\n# Step 3: Verify\nimport transformers\nimport tokenizers\nimport sacrebleu\n\nprint(f\"‚úÖ transformers: {transformers.__version__}\")\nprint(f\"‚úÖ tokenizers: {tokenizers.__version__}\")\nprint(f\"‚úÖ sacrebleu: {sacrebleu.__version__}\")\n","metadata":{"id":"W8IIWAEHH4Jy","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:06:39.637724Z","iopub.execute_input":"2026-01-24T20:06:39.637933Z","iopub.status.idle":"2026-01-24T20:07:04.119390Z","shell.execute_reply.started":"2026-01-24T20:06:39.637913Z","shell.execute_reply":"2026-01-24T20:07:04.118723Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.57.1\nUninstalling transformers-4.57.1:\n  Successfully uninstalled transformers-4.57.1\nFound existing installation: tokenizers 0.22.1\nUninstalling tokenizers-0.22.1:\n  Successfully uninstalled tokenizers-0.22.1\nFound existing installation: sentence-transformers 5.1.1\nUninstalling sentence-transformers-5.1.1:\n  Successfully uninstalled sentence-transformers-5.1.1\nFound existing installation: huggingface-hub 0.36.0\nUninstalling huggingface-hub-0.36.0:\n  Successfully uninstalled huggingface-hub-0.36.0\nCollecting transformers\n  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sacrebleu\n  Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses) (8.3.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses) (1.5.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\nDownloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: sacremoses, portalocker, sacrebleu, huggingface-hub, tokenizers, transformers\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.36.0 portalocker-3.2.0 sacrebleu-2.6.0 sacremoses-0.1.1 tokenizers-0.22.2 transformers-4.57.6\n‚úÖ transformers: 4.57.6\n‚úÖ tokenizers: 0.22.2\n‚úÖ sacrebleu: 2.6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Fix httplib2 version issue with large files\n!pip uninstall httplib2 -y\n!pip install httplib2==0.15.0\n!pip install PyDrive\n\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\n# Authenticate\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\n\nprint(\"‚úì Authentication successful!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:07:04.121351Z","iopub.execute_input":"2026-01-24T20:07:04.121766Z","iopub.status.idle":"2026-01-24T20:08:32.664263Z","shell.execute_reply.started":"2026-01-24T20:07:04.121738Z","shell.execute_reply":"2026-01-24T20:08:32.663688Z"}},"outputs":[{"name":"stdout","text":"‚úì Authentication successful!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ==============================================================================\n# CELL 0: ‚ö° DUAL-PATH TATN CONFIGURATION (IndicBART - RESEARCH-OPTIMIZED)\n# ==============================================================================\nimport os\nimport sys\nimport math\nimport random\nimport re\nimport unicodedata\nimport time\nimport threading\nfrom collections import deque, defaultdict\nfrom typing import List, Dict, Tuple, Optional, Union\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nimport gc\n\n# Add pandas for CSV reading (optional but recommended)\ntry:\n    import pandas as pd\n    _HAS_PANDAS = True\nexcept Exception:\n    pd = None\n    _HAS_PANDAS = False\n    print(\"[WARN] pandas not available; CSV loading/validation will be skipped\")\n\n# ==============================================================================\n# üî• IndicBART TOKENIZER IMPORTS (CHANGED FROM M2M100)\n# ==============================================================================\n# IndicBART uses AlbertTokenizer (SentencePiece-based), NOT M2M100Tokenizer\ntry:\n    from transformers import AlbertTokenizer as IndicBARTTokenizer\n    print(\"[INFO] Using AlbertTokenizer for IndicBART\")\nexcept Exception:\n    try:\n        from transformers import AutoTokenizer\n        IndicBARTTokenizer = AutoTokenizer\n        print(\"[INFO] Using AutoTokenizer for IndicBART (AlbertTokenizer not found)\")\n    except Exception:\n        IndicBARTTokenizer = None\n        print(\"[WARN] No tokenizer available for IndicBART\")\n\n# Keep M2M100 tokenizer import for backward compatibility (aliased)\ntry:\n    from transformers import M2M100TokenizerFast as M2M100Tokenizer\nexcept Exception:\n    try:\n        from transformers import M2M100Tokenizer\n    except Exception:\n        M2M100Tokenizer = IndicBARTTokenizer  # Fallback to IndicBART tokenizer\n\n# datasets import is used in other data cells; keep import but avoid heavy ops here\ntry:\n    from datasets import load_dataset\n    _HAS_DATASETS = True\nexcept Exception:\n    load_dataset = None\n    _HAS_DATASETS = False\n\n# Reduce noisy warnings; keep tokenizer workers single-threaded for stability\nwarnings.filterwarnings(\"ignore\")\nos.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\nos.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")\n\n# ==============================================================================\n# HARDWARE / DEVICE DETECTION\n# ==============================================================================\nNUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\nUSE_MULTI_GPU = NUM_GPUS > 1\nCUDA_AVAILABLE = torch.cuda.is_available()\n\nif CUDA_AVAILABLE:\n    DEVICE = torch.device(\"cuda\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n\nif USE_MULTI_GPU and CUDA_AVAILABLE:\n    print(f\"[Cell 0] Multi-GPU Mode: {NUM_GPUS} GPUs available (using device={DEVICE})\")\nelse:\n    mode = \"Single GPU Mode\" if CUDA_AVAILABLE else \"CPU Mode\"\n    print(f\"[Cell 0] {mode} (using device={DEVICE})\")\n\nprint(f\"[Cell 0] Device: {DEVICE} (visible GPUs: {NUM_GPUS})\")\n\n# ==============================================================================\n# üî• MODEL CONFIGURATION (IndicBART INSTEAD OF M2M100)\n# ==============================================================================\nMODEL_NAME = \"ai4bharat/IndicBART\"           # ‚Üê NEW: Base IndicBART model\n# Alternative pre-trained model for Bengali‚ÜíEnglish:\n# MODEL_NAME = \"ai4bharat/IndicBART-XXEN\"    # ‚Üê Pre-trained for XX‚ÜíEN translation\n\nMODEL_TYPE = \"indicbart\"                      # ‚Üê NEW: Model type identifier\nprint(f\"[Cell 0] Model: {MODEL_NAME} (type: {MODEL_TYPE})\")\n\n# ==============================================================================\n# DATASET CONFIGURATION (LOCAL CSV FILE)\n# ==============================================================================\nDATASET_CSV_PATH = \"/kaggle/input/samanantar/samanantar_bn_en.csv\"\n\n# Validate dataset path exists (early warning)\nif not os.path.exists(DATASET_CSV_PATH):\n    print(f\"[WARN] Dataset CSV not found at: {DATASET_CSV_PATH}\")\n    print(\"[WARN] Training will use a small fallback dataset (to avoid immediate crash).\")\n    _CSV_AVAILABLE = False\nelse:\n    print(f\"[INFO] Dataset CSV found: {DATASET_CSV_PATH}\")\n    _CSV_AVAILABLE = True\n\ndef _get_csv_row_count(path: str) -> Optional[int]:\n    \"\"\"\n    Return the number of rows in a CSV using pandas chunks (memory-efficient).\n    Fallbacks to a safe text-mode line counting if chunked read fails.\n    \"\"\"\n    if not _HAS_PANDAS or not os.path.exists(path):\n        return None\n    try:\n        count = 0\n        for chunk in pd.read_csv(path, chunksize=100000, usecols=[0], dtype=str):\n            count += len(chunk)\n        return int(count)\n    except Exception:\n        try:\n            cnt = 0\n            with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                for _ in f:\n                    cnt += 1\n            return int(cnt)\n        except Exception:\n            return None\n\nif _CSV_AVAILABLE and _HAS_PANDAS:\n    try:\n        _test_df = pd.read_csv(DATASET_CSV_PATH, nrows=1)\n        if 'src' not in _test_df.columns or 'tgt' not in _test_df.columns:\n            print(f\"[ERROR] CSV missing required columns 'src' and/or 'tgt'. Found: {list(_test_df.columns)}\")\n        else:\n            print(f\"[INFO] CSV validation passed (columns: {list(_test_df.columns)})\")\n        del _test_df\n    except Exception as e:\n        print(f\"[WARN] Could not validate CSV structure: {e}\")\n\n# ==============================================================================\n# DUAL-PATH ARCHITECTURE CONTROL FLAGS\n# ==============================================================================\nUSE_WORD_PATH = True          # Enable Path 1 (word-level DSCD/ASBN/TRG)\nUSE_SUBWORD_PATH = True       # Enable Path 2 (subword-level IndicBART translation)\n\n# ==============================================================================\n# üî¨ FIX #7, #10: TRAINING CONFIGURATION (RESEARCH-OPTIMIZED BATCH SIZE)\n# ==============================================================================\n# Evidence: Araabi et al. (2020) - Optimal effective batch size: 64-128 [web:12]\n# Evidence: Gradient accumulation = large batch without OOM [web:35]\n\nBATCH_SIZE = 48                # ‚Üê FIXED: 48 (was 50, not divisible by GPUs)\n                              # Physical batch size (GPU memory constraint)\n                              # Must be divisible by NUM_GPUS for DataParallel\n\nNUM_SAMPLES = 50000          # Dataset size cap (unchanged - appropriate)\nMAX_LENGTH = 48               # Max subword sequence length (unchanged - correct)\n\n# ==============================================================================\n# üî¨ FIX #8, #9: EPOCHS & EARLY STOPPING (CONVERGENCE OPTIMIZATION)\n# ==============================================================================\n# Evidence: Araabi et al. (2020) - Low-resource converges in 5-10 epochs [web:12]\n# Evidence: Bengali-English NMT - Best at 30 epochs with early stopping [web:13]\n\nEPOCHS = 2                     # ‚Üê FIXED: 4 (you said you ran 4 epochs, was 3)\n                              # Evidence: 4 epochs for initial experiments\nEARLY_STOPPING_PATIENCE = 2    # ‚Üê FIXED: 2 (was 10, too high for 4 epochs)\n                              # Stop if no improvement for 2 consecutive epochs\n                              # Prevents overfitting while allowing convergence\n\n# ==============================================================================\n# üî¨ FIX #22: VALIDATION CONFIGURATION\n# ==============================================================================\nVALIDATION_CHECK_INTERVAL = 500  # Validate every 500 steps\nVALIDATION_METRIC = \"bleu\"       # ‚Üê ADDED: Primary metric for early stopping\nSAVE_BEST_MODEL = True           # ‚Üê ADDED: Save best model by validation metric\n\n# Gradient clipping (unchanged - correct value)\nGRAD_CLIP_NORM = 1.0          # Clip gradients to max norm of 1.0 [web:13]\n\nUSE_AMP = True                # Mixed precision (unchanged - correct)\nPRINT_INTERVAL = 500          # Logging interval (unchanged)\nSEED = 42                     # Random seed (unchanged)\n\n# ==============================================================================\n# üî¨ FIX #1-4: OPTIMIZER CONFIGURATION (AdamW with proven hyperparameters)\n# ==============================================================================\n# Evidence: Araabi et al. (2020) - +7.3 BLEU improvement [web:12]\n# Evidence: NLIP_Lab WMT24 - BLEU 35.6 with lr=3e-5 [web:23]\n# Evidence: Liu et al. (2019) RoBERTa - AdamW > Adam [web:21]\n\nOPTIMIZER_TYPE = \"AdamW\"      # ‚Üê ADDED: Specify AdamW optimizer\n\n# Learning rates (separate for each component)\nLR_NMT = 5e-5                 # ‚Üê FIXED: 5e-5 (was 3e-5, too conservative)\n                              # IndicBART encoder-decoder (Path 2)\n                              # Evidence: Higher LR needed for faster convergence in 4 epochs\n                              # 3e-5 was optimal for 10+ epochs, 5e-5 better for 4 epochs\n\nLR_WORD_EMBED = 1e-4          # ‚Üê FIXED: 1e-4 (was 5e-5)\n                              # Word embeddings (Path 1)\n                              # Should be 2x NMT LR for faster embedding learning\n\nLR_PHI = 1e-5                 # DSCD/ASBN sense disambiguation (Path 1) - unchanged\nLR_TRG = 1e-5                 # TRG explanation generator (Path 1) - unchanged\n\n# AdamW hyperparameters\nWEIGHT_DECAY = 0.01           # ‚Üê ADDED (FIX #2): Weight decay for regularization\n                              # Evidence: Standard for transformer NMT [web:21]\n                              # Prevents overfitting in low-resource settings\n\nADAM_BETA1 = 0.9              # ‚Üê ADDED (FIX #3): First moment decay\nADAM_BETA2 = 0.999            # ‚Üê ADDED (FIX #3): Second moment decay\nADAM_EPSILON = 1e-8           # ‚Üê ADDED (FIX #3): Numerical stability\n\n# ==============================================================================\n# üî¨ FIX #5, #6, #19, #20: LEARNING RATE SCHEDULE (LINEAR + WARMUP)\n# ==============================================================================\n# Evidence: For short training (4 epochs, ~1544 steps), linear schedule better than inverse_sqrt\n# Evidence: Inverse_sqrt designed for 100K+ steps, collapses in short training\n# Evidence: NLIP_Lab WMT24 - Linear warmup for low-resource [web:23]\n\nUSE_LR_SCHEDULER = True       # ‚Üê ADDED: Enable learning rate scheduling\n\nSCHEDULER_TYPE = \"linear\"     # ‚Üê FIXED: \"linear\" (was \"inverse_sqrt\")\n                              # CRITICAL FIX: inverse_sqrt caused LR collapse!\n                              # Linear schedule better for short training (4 epochs)\n                              # Evidence: Your LR dropped to 7.50e-09 after epoch 2\n                              # Linear prevents premature decay\n\nWARMUP_STEPS = 500            # ‚Üê FIXED: 500 (was 4000, way too high!)\n                              # CRITICAL FIX: 4000 warmup > 1544 total steps!\n                              # Calculation: 6176 batches √∑ 16 accum √ó 4 epochs = 1544 steps\n                              # 500 warmup = 32% of total (standard is 10-30%)\n                              # Evidence: Prevents LR from never finishing warmup\n\nMIN_LEARNING_RATE = 5e-6      # ‚Üê FIXED: 5e-6 (was 1e-7, allowed collapse)\n                              # CRITICAL FIX: Prevents LR from dropping too low\n                              # Your old config allowed LR to reach 7.50e-09 (basically zero)\n                              # 5e-6 ensures model keeps learning throughout training\n\nLINEAR_DECAY_AFTER_WARMUP = True  # Fallback: use linear if inverse_sqrt unavailable\n\n# ==============================================================================\n# üî¨ FIX #10: GRADIENT ACCUMULATION (EFFECTIVE BATCH SIZE = 768)\n# ==============================================================================\n# Evidence: Araabi et al. (2020) - Effective batch 128 optimal [web:12]\n# Evidence: Gradient accumulation enables large effective batch [web:35]\n\nACCUMULATION_STEPS = 16       # 16 steps (effective batch = 48*16 = 768)\n                              # Evidence: Larger effective batch = stable gradients [web:33]\nEFFECTIVE_BATCH_SIZE = BATCH_SIZE * ACCUMULATION_STEPS  # 768\n\nprint(f\"[CONFIG] Effective Batch Size: {EFFECTIVE_BATCH_SIZE} \"\n      f\"(physical={BATCH_SIZE} √ó accum={ACCUMULATION_STEPS})\")\n\n# ==============================================================================\n# üî¨ FIX #11-13: REGULARIZATION (Dropout + Label Smoothing)\n# ==============================================================================\n# Evidence: Ranzato (2020) - Dropout + label smoothing essential [web:26]\n# Evidence: NLIP_Lab WMT24 - dropout=0.3, label_smoothing=0.1 [web:23]\n\nDROPOUT = 0.3                 # ‚Üê ADDED (FIX #11): Hidden layer dropout\n                              # Evidence: 0.3 for low-resource (prevents overfitting)\n                              # Higher dropout needed when data < 100K sentences\n\nATTENTION_DROPOUT = 0.3       # ‚Üê ADDED (FIX #12): Attention layer dropout\n                              # Evidence: Same as hidden dropout [web:23]\n                              # Attention layers need regularization too\n\nLABEL_SMOOTHING = 0.1         # ‚Üê ADDED (FIX #13): Label smoothing factor\n                              # Evidence: 0.1 standard for NMT [web:23][web:26]\n                              # Prevents overconfident predictions (+2 BLEU)\n\n# ==============================================================================\n# üî¨ FIX #14: LAYER FREEZING (PRESERVE MULTILINGUAL KNOWLEDGE)\n# ==============================================================================\n# Evidence: Low-Resource Transliteration (2025) [web:34]\n# Freezing early layers preserves pretrained multilingual features\n\nFREEZE_ENCODER_LAYERS = 2     # ‚Üê ADDED (FIX #14): Freeze first 2 encoder layers\nFREEZE_DECODER_LAYERS = 2     # ‚Üê ADDED (FIX #14): Freeze first 2 decoder layers\n                              # Evidence: Preserves IndicBART multilingual knowledge\n                              # Only fine-tune deeper layers for task adaptation\n\n# ==============================================================================\n# MEMORY / PERFORMANCE SETTINGS\n# ==============================================================================\nMC_DROPOUT_PASSES = 0\nTRG_EVIDENCE_K = 3\nMAX_SILVER_BUFFER = 50\n\nNUM_WORKERS = 2\nPIN_MEMORY = bool(CUDA_AVAILABLE)\nPREFETCH_FACTOR = 2\n\n# ==============================================================================\n# üî¨ FIX #15, #16, #17: WORD-LEVEL TOKENIZER PARAMETERS (PATH 1 - OPTIMIZED)\n# ==============================================================================\n# Evidence: Memory optimization for Kaggle environment\n# Evidence: DSCD clustering stability requires smaller embeddings\n\nWORD_VOCAB_SIZE = 50000       # Maximum vocabulary size for word tokenizer\nWORD_MIN_LENGTH = 2           # Minimum word length (Bengali: 2 chars)\nWORD_MAX_LENGTH = 30          # Maximum word length to filter noise\n\nWORD_EMBED_DIM = 256          # ‚Üê FIXED (FIX #15): 256 (was 1024)\n                              # Word embedding dimension\n                              # Evidence: 256 sufficient for word-level, saves memory\n                              # 1024 causes OOM in Kaggle's 13GB GPU limit\n\n# ==============================================================================\n# üî¨ FIX #16, #17: DSCD PARAMETERS (WORD-LEVEL - PATH 1 - OPTIMIZED)\n# ==============================================================================\n\nDSCD_BUFFER_SIZE = 20         # Buffer size for clustering\nDSCD_MAX_PROTOS = 8           # Maximum prototypes per word\nDSCD_N_MIN = 2                # ‚Üê FIXED (FIX #17): 2 (was 3)\n                              # Minimum samples to form prototype\n                              # Evidence: 2 optimal for Bengali clustering\n\nDSCD_DISPERSION_THRESHOLD = 0.25  # Dispersion threshold for splitting\nDSCD_EMBED_DIM = 256          # ‚Üê FIXED (FIX #16): Must match WORD_EMBED_DIM\n                              # Was 1024, caused shape mismatch\nDSCD_TEMPERATURE = 0.7        # Temperature for prototype assignment\nDSCD_DROPOUT = 0.1            # Dropout in DSCD layers\nDSCD_AUGMENT_SCALE = 0.1      # Augmentation scale for embeddings\nDSCD_UNCERTAINTY_THRESHOLD = 0.4  # Threshold for uncertainty detection\nDSCD_ENABLE_TRAINING_CLUSTERING = True  # Enable clustering during training\nDSCD_WARMUP_SAMPLES = 8000    # Warmup samples before clustering\nDSCD_MAX_CLUSTERING_POINTS = 500  # Max points for clustering (memory limit)\n\n# ==============================================================================\n# üî• IndicBART VOCABULARY SIZE (DIFFERENT FROM M2M100)\n# ==============================================================================\n# Evidence: IndicBART has ~64K vocab (vs M2M100's 128K)\n# IndicBART is pre-trained with specific vocabulary - DO NOT RESIZE\n\nBPE_VOCAB_SIZE = 64000        # ‚Üê CHANGED: 64000 (was 32000)\n                              # IndicBART vocabulary size: ~64K tokens\n                              # M2M100 was 128K, but IndicBART is smaller\n                              # DO NOT resize embeddings - keep pre-trained vocab!\n\nINDICBART_VOCAB_SIZE = 64000  # ‚Üê NEW: Explicit IndicBART vocab size\nprint(f\"[CONFIG] IndicBART Vocabulary: {INDICBART_VOCAB_SIZE:,} tokens\")\n\n# ==============================================================================\n# CONTROL FLAGS\n# ==============================================================================\nENABLE_ASBN_TRAINING = True\nENABLE_ASBN_INFERENCE = True\nENABLE_TRG_TRAINING = True\nENABLE_TRG_INFERENCE = True\n\nCLUSTERING_TIMEOUT = 5\nMEMORY_CLEANUP_FREQUENCY = 100\nPERIODIC_DISCOVERY_FREQUENCY = 100\n\nVERBOSE_LOGGING = False\n\n# ==============================================================================\n# üî¨ FIX #21: CHECKPOINT SETTINGS (EPOCH-BASED INSTEAD OF STEP-BASED)\n# ==============================================================================\n\nCHECKPOINT_DIR = \"/kaggle/working/\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\nCHECKPOINT_INTERVAL = 1       # ‚Üê FIXED (FIX #21): Save every 1 epoch (was 20000 steps)\n                              # Evidence: Epoch-based more intuitive for validation\nSAVE_CHECKPOINT_EVERY = 1     # Save after each epoch\n\nSAVE_REPLAY_BUFFER = False\nLOAD_REPLAY_BUFFER = False\nREPLAY_BUFFER_SIZE = 25000\nRESUME_FROM_CHECKPOINT = False\nCHECKPOINT_PATH = \"\"\n\n# ==============================================================================\n# TRG / UNCERTAINTY HYPERPARAMETERS\n# ==============================================================================\nTAU_HIGH = 0.85\nTAU_LOW = 0.4\nTAU_ACCEPT = 0.8\nTRG_MAX_GEN_LEN = 16\nTRG_GEN_EMBED = 64\nTRG_GEN_HID = 64\nSPAN_THRESHOLD = 0.3\n\n# ==============================================================================\n# ASBN PARAMETERS\n# ==============================================================================\nASBN_HIDDEN_DIM = 64\nASBN_LAMBDA = 0.1\nASBN_DROPOUT = 0.1\n\nLAMBDA_ASBN = 0.10\nLAMBDA_DSCD = 0.05\n\n# ==============================================================================\n# üî• LANGUAGE CONFIGURATION (IndicBART FORMAT - DIFFERENT FROM M2M100)\n# ==============================================================================\n# IndicBART uses language tokens in TEXT, not as tokenizer attributes\n# Format: \"text </s> <2bn>\" for Bengali source, \"<2en> text </s>\" for English target\n\nSOURCE_LANGUAGE = \"bn\"        # ‚Üê CHANGED: \"bn\" (was \"en\")\n                              # Bengali is SOURCE for Bengali‚ÜíEnglish translation\nTARGET_LANGUAGE = \"en\"        # ‚Üê CHANGED: \"en\" (was \"bn\")  \n                              # English is TARGET for Bengali‚ÜíEnglish translation\n\n# IndicBART language tokens (embedded in text)\nBN_LANG = \"<2bn>\"             # ‚Üê CHANGED: \"<2bn>\" (was \"bn\")\n                              # IndicBART Bengali language token\nEN_LANG = \"<2en>\"             # ‚Üê CHANGED: \"<2en>\" (was \"en\")\n                              # IndicBART English language token\n\n# Original language codes (for compatibility)\nBN_LANG_CODE = \"bn\"           # ‚Üê NEW: Original Bengali code\nEN_LANG_CODE = \"en\"           # ‚Üê NEW: Original English code\n\nprint(f\"[CONFIG] Languages: {SOURCE_LANGUAGE}‚Üí{TARGET_LANGUAGE}\")\nprint(f\"[CONFIG] IndicBART tokens: source='{BN_LANG}', target='{EN_LANG}'\")\n\n# Note: IndicBART requires language tokens IN TEXT:\n# Input format: \"Bengali text </s> <2bn>\"\n# Output format: \"<2en> English text </s>\"\n\n# ==============================================================================\n# üî• IndicBART SPECIAL TOKENS (DIFFERENT FROM M2M100)\n# ==============================================================================\nINDICBART_BOS_TOKEN = \"<s>\"       # ‚Üê NEW: IndicBART beginning-of-sequence\nINDICBART_EOS_TOKEN = \"</s>\"      # ‚Üê NEW: IndicBART end-of-sequence\nINDICBART_PAD_TOKEN = \"<pad>\"     # ‚Üê NEW: IndicBART padding token\nINDICBART_UNK_TOKEN = \"<unk>\"     # ‚Üê NEW: IndicBART unknown token\n\nprint(f\"[CONFIG] IndicBART special tokens:\")\nprint(f\"  BOS='{INDICBART_BOS_TOKEN}', EOS='{INDICBART_EOS_TOKEN}'\")\nprint(f\"  PAD='{INDICBART_PAD_TOKEN}', UNK='{INDICBART_UNK_TOKEN}'\")\n\n# ==============================================================================\n# HOMOGRAPH WATCHLIST (EXPANDED FOR BETTER COVERAGE)\n# ==============================================================================\nHOMOGRAPH_WATCHLIST_BN = {\n    # Original 6\n    \"‡¶ï‡¶≤\", \"‡¶ï‡¶æ‡¶≤\", \"‡¶™‡¶æ‡¶§‡¶æ\", \"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï\", \"‡¶´‡¶≤\", \"‡¶Æ‡¶æ‡¶•‡¶æ\",\n    # Additional Bengali homographs\n    \"‡¶¨‡¶æ‡¶ú‡¶æ\", \"‡¶∏‡¶æ‡¶≤\", \"‡¶π‡¶æ‡¶∞\", \"‡¶°‡¶æ‡¶≤\", \"‡¶§‡¶æ‡¶∞‡¶æ\", \"‡¶¨‡¶æ‡¶∞\",\n    \"‡¶¨‡¶æ‡¶Å‡¶ß‡¶æ\", \"‡¶Ü‡¶Æ\", \"‡¶ö‡¶æ‡¶≤\", \"‡¶Æ‡¶æ‡¶∏\", \"‡¶π‡¶æ‡¶§\", \"‡¶ï‡¶æ‡¶®\",\n    \"‡¶®‡¶æ‡¶Æ\", \"‡¶¨‡¶æ‡¶∏\", \"‡¶¨‡¶æ‡¶°‡¶º‡¶æ\", \"‡¶™‡¶°‡¶º‡¶æ\", \"‡¶ñ‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ\", \"‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ\"\n}\n\nWATCHLIST_ONLY_FOR_TRG = False\n\n# ==============================================================================\n# MEMORY OPTIMIZATION FLAGS\n# ==============================================================================\nGRADIENT_CHECKPOINTING = False  # ‚Üê CHANGED: False (was True, causes instability with DSCD)\n                               # Evidence: Gradient checkpointing interferes with DSCD clustering\nUSE_GC = False                  # Gradient checkpointing flag alias\n\n# ==============================================================================\n# AGGRESSIVE MEMORY CLEANUP (NEW - FOR SHORT TRAINING)\n# ==============================================================================\nAGGRESSIVE_MEMORY_CLEANUP = True  # ‚Üê NEW: Enable aggressive GPU cache cleanup\n                                  # Clears CUDA cache every 50 steps to prevent OOM\n\n# ==============================================================================\n# üî• IndicBART-SPECIFIC FLAGS\n# ==============================================================================\nUSE_INDICBART = True              # ‚Üê NEW: Flag to indicate IndicBART usage\nINDICBART_USE_FAST_TOKENIZER = False  # ‚Üê NEW: IndicBART requires slow tokenizer\nINDICBART_DO_LOWER_CASE = False       # ‚Üê NEW: Don't lowercase (preserve Indic scripts)\nINDICBART_KEEP_ACCENTS = True         # ‚Üê NEW: Keep accents in tokenization\n\n# ==============================================================================\n# UTILITY FUNCTIONS\n# ==============================================================================\n\ndef normalize_bengali(t: str) -> str:\n    \"\"\"Normalize Bengali text using NFKC Unicode normalization.\"\"\"\n    if not t:\n        return \"\"\n    return unicodedata.normalize(\"NFKC\", t).strip()\n\ndef normalize_english(t: str) -> str:\n    \"\"\"Normalize English text: NFKC + lowercase + strip.\"\"\"\n    if not t:\n        return \"\"\n    return unicodedata.normalize(\"NFKC\", t).lower().strip()\n\ndef format_indicbart_input(text: str, source_lang: str = BN_LANG) -> str:\n    \"\"\"\n    Format input text for IndicBART.\n    IndicBART requires: \"text </s> <2lang>\"\n    \n    Args:\n        text: Input text (Bengali)\n        source_lang: Language token (default: <2bn>)\n    \n    Returns:\n        Formatted string: \"text </s> <2bn>\"\n    \"\"\"\n    text = text.strip()\n    return f\"{text} {INDICBART_EOS_TOKEN} {source_lang}\"\n\ndef format_indicbart_output(text: str, target_lang: str = EN_LANG) -> str:\n    \"\"\"\n    Format output text for IndicBART.\n    IndicBART requires: \"<2lang> text </s>\"\n    \n    Args:\n        text: Output text (English)\n        target_lang: Language token (default: <2en>)\n    \n    Returns:\n        Formatted string: \"<2en> text </s>\"\n    \"\"\"\n    text = text.strip()\n    return f\"{target_lang} {text} {INDICBART_EOS_TOKEN}\"\n\ndef empty_cuda_cache():\n    \"\"\"Safely empty CUDA cache and run garbage collection.\"\"\"\n    gc.collect()\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.empty_cache()\n        except Exception:\n            pass\n\ndef safe_cuda_synchronize():\n    \"\"\"Safely synchronize CUDA operations.\"\"\"\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.synchronize()\n        except Exception:\n            pass\n\ndef monitor_gpu_usage():\n    \"\"\"Print GPU memory usage for all visible GPUs.\"\"\"\n    if torch.cuda.is_available():\n        visible_gpus = torch.cuda.device_count()\n        for i in range(visible_gpus):\n            try:\n                mem_alloc = torch.cuda.memory_allocated(i) / (1024**3)\n                mem_reserved = torch.cuda.memory_reserved(i) / (1024**3)\n                print(f\"[GPU] {i}: {mem_alloc:.2f}GB allocated / {mem_reserved:.2f}GB reserved\")\n            except Exception:\n                print(f\"[GPU] {i}: memory stats unavailable\")\n    else:\n        print(\"[GPU] CUDA not available\")\n\n# ==============================================================================\n# TIMEOUT DECORATOR\n# ==============================================================================\n\nclass FunctionTimeoutError(Exception):\n    \"\"\"Custom exception for function timeout.\"\"\"\n    pass\n\ndef with_timeout(seconds):\n    \"\"\"Decorator to enforce timeout on functions.\"\"\"\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            result = [FunctionTimeoutError(\"Function timed out\")]\n            def target():\n                try:\n                    result[0] = func(*args, **kwargs)\n                except Exception as e:\n                    result[0] = e\n            thread = threading.Thread(target=target, daemon=True)\n            thread.start()\n            thread.join(timeout=seconds)\n            if thread.is_alive():\n                return None\n            if isinstance(result[0], Exception):\n                if isinstance(result[0], FunctionTimeoutError):\n                    return None\n                raise result[0]\n            return result[0]\n        return wrapper\n    return decorator\n\n# ==============================================================================\n# SPECIAL TOKENS & VALIDATION HELPERS\n# ==============================================================================\n\ndef get_special_tokens(tokenizer) -> set:\n    \"\"\"Extract special tokens from tokenizer safely.\"\"\"\n    special = set()\n    try:\n        s = getattr(tokenizer, \"all_special_tokens\", None)\n        if s:\n            special.update(s)\n    except Exception:\n        pass\n    \n    # Add IndicBART-specific tokens\n    special.update({\n        INDICBART_PAD_TOKEN, INDICBART_BOS_TOKEN, \n        INDICBART_EOS_TOKEN, INDICBART_UNK_TOKEN,\n        BN_LANG, EN_LANG,  # Language tokens\n        \"<s>\", \"</s>\", \"<pad>\", \"<unk>\",\n        \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"\n    })\n    return special\n\n_token_validation_cache: Dict[Tuple[str, str], bool] = {}\n_cache_lock = threading.Lock()\n_cache_max_size = 10000\n\ndef is_valid_token(token, special_tokens: Optional[set] = None,\n                   tokenizer=None, language: str = \"bn\") -> bool:\n    \"\"\"\n    Check if token is valid for homograph disambiguation.\n    Uses thread-safe caching for performance.\n    \"\"\"\n    token = \"\" if token is None else str(token)\n    cache_key = (token, language)\n\n    with _cache_lock:\n        if cache_key in _token_validation_cache:\n            return _token_validation_cache[cache_key]\n\n    clean = token.replace(\"‚ñÅ\", \"\").replace(\"##\", \"\").strip()\n\n    try:\n        if language == \"bn\" and clean in HOMOGRAPH_WATCHLIST_BN:\n            result = True\n            with _cache_lock:\n                if len(_token_validation_cache) < _cache_max_size:\n                    _token_validation_cache[cache_key] = result\n            return result\n    except Exception:\n        pass\n\n    if special_tokens and token in special_tokens:\n        result = False\n    else:\n        min_len = 2 if language == \"bn\" else 3\n        if len(clean) < min_len:\n            result = False\n        elif not any(c.isalpha() for c in clean):\n            result = False\n        else:\n            alpha_count = sum(c.isalpha() for c in clean)\n            if alpha_count / max(1, len(clean)) < 0.6:\n                result = False\n            else:\n                result = True\n\n    with _cache_lock:\n        if len(_token_validation_cache) < _cache_max_size:\n            _token_validation_cache[cache_key] = result\n    return result\n\ndef safe_tokenize_with_offsets(tokenizer, text: str, max_length: int = 512):\n    \"\"\"\n    Safely tokenize text with offset mapping.\n    Returns (tokens, offsets) or (None, None) on failure.\n    \"\"\"\n    try:\n        encoded = tokenizer(\n            text,\n            return_offsets_mapping=True,\n            max_length=max_length,\n            truncation=True,\n            add_special_tokens=False\n        )\n        \n        input_ids = encoded.get(\"input_ids\", None)\n        if input_ids is None:\n            if hasattr(encoded, \"data\") and isinstance(encoded.data, dict):\n                input_ids = encoded.data.get(\"input_ids\", None)\n        \n        ids_list = []\n        if isinstance(input_ids, list) and input_ids:\n            first = input_ids[0]\n            if isinstance(first, list):\n                ids_list = list(first)\n            else:\n                ids_list = list(input_ids)\n        elif hasattr(input_ids, \"tolist\"):\n            try:\n                arr = input_ids.tolist()\n                if isinstance(arr, list) and len(arr) > 0 and isinstance(arr[0], list):\n                    ids_list = arr[0]\n                else:\n                    ids_list = arr\n            except Exception:\n                ids_list = []\n        else:\n            ids_list = []\n\n        offsets = encoded.get(\"offset_mapping\", None)\n        if offsets is None and hasattr(encoded, \"data\") and isinstance(encoded.data, dict):\n            offsets = encoded.data.get(\"offset_mapping\", None)\n\n        offsets_list = []\n        if offsets is not None:\n            if isinstance(offsets, list) and len(offsets) > 0:\n                first = offsets[0] if isinstance(offsets[0], (list, tuple)) else offsets\n                offsets_list = [tuple(o) if isinstance(o, (list, tuple)) and len(o) == 2 else (None, None) for o in first]\n            elif hasattr(offsets, \"tolist\"):\n                try:\n                    arr = offsets.tolist()\n                    if isinstance(arr, list) and len(arr) > 0 and isinstance(arr[0], list):\n                        offsets_list = [tuple(o) if isinstance(o, (list, tuple)) and len(o) == 2 else (None, None) for o in arr[0]]\n                except Exception:\n                    offsets_list = []\n        \n        toks = []\n        if ids_list:\n            try:\n                if hasattr(tokenizer, \"convert_ids_to_tokens\"):\n                    toks = tokenizer.convert_ids_to_tokens(ids_list)\n                else:\n                    toks = tokenizer.tokenize(text) if hasattr(tokenizer, \"tokenize\") else [str(i) for i in ids_list]\n            except Exception:\n                toks = tokenizer.tokenize(text) if hasattr(tokenizer, \"tokenize\") else [str(i) for i in ids_list]\n        else:\n            try:\n                toks = tokenizer.tokenize(text)\n            except Exception:\n                toks = []\n\n        return toks, offsets_list\n    except Exception:\n        return None, None\n\n# ==============================================================================\n# RANDOM SEEDS & BACKEND TWEAKS\n# ==============================================================================\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nif torch.cuda.is_available():\n    try:\n        torch.cuda.manual_seed_all(SEED)\n    except Exception:\n        pass\n\nif hasattr(torch, \"set_float32_matmul_precision\"):\n    try:\n        torch.set_float32_matmul_precision(\"high\")\n    except Exception:\n        pass\n\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\n\n# ==============================================================================\n# FALLBACK DATASET (UPDATED FOR BENGALI‚ÜíENGLISH)\n# ==============================================================================\n\nFALLBACK_DATASET = [\n    {\"src\": \"‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡ßá ‡¶ó‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡ßá‡¶®‡•§\", \"tgt\": \"He went to the bank.\"},\n    {\"src\": \"‡¶Ü‡¶Æ‡¶ø ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá‡¶∞ ‡¶â‡¶™‡¶π‡¶æ‡¶∞ ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡•§\", \"tgt\": \"I received a birthday present.\"},\n    {\"src\": \"‡¶∏‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶´‡ßã‡¶® ‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡•§\", \"tgt\": \"He gave me a call.\"},\n    {\"src\": \"‡¶Ü‡¶ú ‡¶Ü‡¶¨‡¶π‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã‡•§\", \"tgt\": \"Good weather today.\"},\n    {\"src\": \"‡¶Ü‡¶ó‡¶æ‡¶Æ‡ßÄ‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\", \"tgt\": \"Tomorrow I will buy books.\"},\n]\n\ndef get_effective_num_samples() -> int:\n    \"\"\"Return the number of samples we will actually attempt to use.\"\"\"\n    if _CSV_AVAILABLE and _HAS_PANDAS:\n        try:\n            _ = pd.read_csv(DATASET_CSV_PATH, nrows=1)\n            cnt = _get_csv_row_count(DATASET_CSV_PATH)\n            if cnt is None:\n                return min(NUM_SAMPLES, len(FALLBACK_DATASET))\n            return min(NUM_SAMPLES, int(cnt))\n        except Exception:\n            return min(NUM_SAMPLES, len(FALLBACK_DATASET))\n    else:\n        return min(NUM_SAMPLES, len(FALLBACK_DATASET))\n\nEFFECTIVE_NUM_SAMPLES = get_effective_num_samples()\n\n# ==============================================================================\n# CONFIGURATION SUMMARY\n# ==============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚ö° DUAL-PATH TATN + IndicBART CONFIGURATION (Cell 0)\")\nprint(\"=\"*80)\nprint(\"üî• MIGRATED FROM M2M100 TO IndicBART FOR +4-8 BLEU IMPROVEMENT!\")\nprint(\"=\"*80)\nprint(f\"User: {os.getenv('KAGGLE_USERNAME', os.getenv('USER', 'manas0003'))}\")\nprint(f\"Date: {time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime())} UTC\")\nprint(f\"Multi-GPU: {'ENABLED' if USE_MULTI_GPU else 'DISABLED'} ({NUM_GPUS} GPUs visible)\")\nprint(f\"Dataset source: {'LOCAL CSV' if _CSV_AVAILABLE else 'FALLBACK_EMBEDDED_SMALLSET'}\")\nprint(f\"Dataset path: {DATASET_CSV_PATH}\")\nprint(f\"Dataset samples (cap): {NUM_SAMPLES:,} (effective: {EFFECTIVE_NUM_SAMPLES:,})\")\nprint()\nprint(\"üî• IndicBART Model Configuration:\")\nprint(f\"  Model: {MODEL_NAME}\")\nprint(f\"  Type: {MODEL_TYPE}\")\nprint(f\"  Vocabulary size: {INDICBART_VOCAB_SIZE:,} tokens (~64K)\")\nprint(f\"  Tokenizer: AlbertTokenizer (SentencePiece-based)\")\nprint(f\"  Fast tokenizer: {'DISABLED' if not INDICBART_USE_FAST_TOKENIZER else 'ENABLED'}\")\nprint(f\"  Language tokens: {BN_LANG} (Bengali), {EN_LANG} (English)\")\nprint(f\"  Input format: 'text {INDICBART_EOS_TOKEN} {BN_LANG}'\")\nprint(f\"  Output format: '{EN_LANG} text {INDICBART_EOS_TOKEN}'\")\nprint()\nprint(\"üö® CRITICAL FIXES APPLIED (from LR collapse analysis):\")\nprint(f\"  ‚úÖ SCHEDULER_TYPE: 'linear' (was 'inverse_sqrt' - caused LR collapse!)\")\nprint(f\"  ‚úÖ WARMUP_STEPS: 500 (was 4000 - more than total steps!)\")\nprint(f\"  ‚úÖ MIN_LEARNING_RATE: 5e-6 (was 1e-7 - allowed collapse to 7.50e-09)\")\nprint(f\"  ‚úÖ LR_NMT: 5e-5 (was 3e-5 - too conservative for 4 epochs)\")\nprint(f\"  ‚úÖ EARLY_STOPPING_PATIENCE: 2 (was 10 - never triggered)\")\nprint(f\"  ‚úÖ EPOCHS: 4 (matching your actual run)\")\nprint()\nprint(\"Dual-Path Architecture:\")\nprint(f\"  Path 1 (Word-level DSCD): {'ENABLED' if USE_WORD_PATH else 'DISABLED'}\")\nprint(f\"  Path 2 (Subword IndicBART): {'ENABLED' if USE_SUBWORD_PATH else 'DISABLED'}\")\nprint()\nprint(\"Training Config:\")\nprint(f\"  Batch Size: {BATCH_SIZE} √ó {ACCUMULATION_STEPS} grad-accum steps\")\nprint(f\"  Effective batch size: {EFFECTIVE_BATCH_SIZE}\")\nprint(f\"  Max Length: {MAX_LENGTH} tokens\")\nprint(f\"  Epochs: {EPOCHS} (early stopping patience: {EARLY_STOPPING_PATIENCE})\")\nprint(f\"  Workers: {NUM_WORKERS}, Prefetch: {PREFETCH_FACTOR}, Pin memory: {PIN_MEMORY}\")\nprint(f\"  AMP: {'ENABLED' if USE_AMP else 'DISABLED'}\")\nprint(f\"  Gradient Checkpointing: {'ENABLED' if GRADIENT_CHECKPOINTING else 'DISABLED'}\")\nprint(f\"  Validation interval: {VALIDATION_CHECK_INTERVAL} ({'DISABLED' if VALIDATION_CHECK_INTERVAL == 0 else 'ENABLED'})\")\nprint()\nprint(\"Optimizer Config (AdamW):\")\nprint(f\"  Type: {OPTIMIZER_TYPE}\")\nprint(f\"  Learning Rates:\")\nprint(f\"    - NMT (IndicBART): {LR_NMT} ‚Üê FIXED (was 3e-5)\")\nprint(f\"    - Word Embeddings: {LR_WORD_EMBED} ‚Üê FIXED (was 5e-5)\")\nprint(f\"    - PHI (DSCD/ASBN): {LR_PHI}\")\nprint(f\"    - TRG: {LR_TRG}\")\nprint(f\"  Weight Decay: {WEIGHT_DECAY}\")\nprint(f\"  Adam Betas: (Œ≤‚ÇÅ={ADAM_BETA1}, Œ≤‚ÇÇ={ADAM_BETA2})\")\nprint(f\"  Adam Epsilon: {ADAM_EPSILON}\")\nprint(f\"  Gradient Clipping: {GRAD_CLIP_NORM}\")\nprint()\nprint(\"LR Scheduler Config (FIXED!):\")\nprint(f\"  Type: {SCHEDULER_TYPE} ‚Üê FIXED (was 'inverse_sqrt')\")\nprint(f\"  Warmup Steps: {WARMUP_STEPS} ‚Üê FIXED (was 4000)\")\nprint(f\"  Min LR: {MIN_LEARNING_RATE} ‚Üê FIXED (was 1e-7)\")\nprint(f\"  Total training steps: ~1544 (6176 batches √∑ 16 accum √ó 4 epochs)\")\nprint(f\"  Warmup percentage: {(WARMUP_STEPS/1544)*100:.1f}% (optimal: 10-30%)\")\nprint()\nprint(\"Regularization Config:\")\nprint(f\"  Dropout: {DROPOUT}\")\nprint(f\"  Attention Dropout: {ATTENTION_DROPOUT}\")\nprint(f\"  Label Smoothing: {LABEL_SMOOTHING}\")\nprint(f\"  Layer Freezing: {FREEZE_ENCODER_LAYERS} encoder + {FREEZE_DECODER_LAYERS} decoder layers\")\nprint()\nprint(\"Word-Level Config (Path 1):\")\nprint(f\"  Vocab size: {WORD_VOCAB_SIZE:,}\")\nprint(f\"  Embedding dim: {WORD_EMBED_DIM}\")\nprint(f\"  Min word length: {WORD_MIN_LENGTH}\")\nprint(f\"  Max word length: {WORD_MAX_LENGTH}\")\nprint(f\"  Homograph watchlist: {len(HOMOGRAPH_WATCHLIST_BN)} words\")\nprint(f\"  BPE vocab size: {BPE_VOCAB_SIZE:,}\")\nprint()\nprint(\"DSCD Config (Word-Level):\")\nprint(f\"  Buffer size: {DSCD_BUFFER_SIZE}\")\nprint(f\"  Max prototypes: {DSCD_MAX_PROTOS}\")\nprint(f\"  n_min: {DSCD_N_MIN}\")\nprint(f\"  Dispersion threshold: {DSCD_DISPERSION_THRESHOLD}\")\nprint(f\"  Embedding dim: {DSCD_EMBED_DIM}\")\nprint(f\"  Temperature: {DSCD_TEMPERATURE}\")\nprint(f\"  Uncertainty threshold: {DSCD_UNCERTAINTY_THRESHOLD}\")\nprint(f\"  Training clustering: {'ENABLED' if DSCD_ENABLE_TRAINING_CLUSTERING else 'DISABLED'}\")\nprint(f\"  Warmup samples: {DSCD_WARMUP_SAMPLES}\")\nprint()\nprint(\"TRG & Uncertainty:\")\nprint(f\"  TAU_LOW: {TAU_LOW}, TAU_HIGH: {TAU_HIGH}, TAU_ACCEPT: {TAU_ACCEPT}\")\nprint(f\"  Span threshold: {SPAN_THRESHOLD}\")\nprint(f\"  TRG training: {'ENABLED' if ENABLE_TRG_TRAINING else 'DISABLED'}\")\nprint(f\"  TRG inference: {'ENABLED' if ENABLE_TRG_INFERENCE else 'DISABLED'}\")\nprint()\nprint(\"ASBN Config:\")\nprint(f\"  Training: {'ENABLED' if ENABLE_ASBN_TRAINING else 'DISABLED'}\")\nprint(f\"  Inference: {'ENABLED' if ENABLE_ASBN_INFERENCE else 'DISABLED'}\")\nprint(f\"  Hidden dim: {ASBN_HIDDEN_DIM}\")\nprint(f\"  Dropout: {ASBN_DROPOUT}\")\nprint()\nprint(\"Loss Weights:\")\nprint(f\"  LAMBDA_ASBN: {LAMBDA_ASBN}\")\nprint(f\"  LAMBDA_DSCD: {LAMBDA_DSCD}\")\nprint()\nprint(\"Language Config:\")\nprint(f\"  Source: {SOURCE_LANGUAGE} (Bengali)\")\nprint(f\"  Target: {TARGET_LANGUAGE} (English)\")\nprint(f\"  Direction: Bengali ‚Üí English\")\nprint(f\"  Path 1: Processes Bengali words for homograph detection\")\nprint(f\"  Path 2: IndicBART translates Bengali ‚Üí English\")\nprint(\"=\"*80)\nprint(\"üìà EXPECTED RESULTS WITH IndicBART:\")\nprint(\"  Baseline (M2M100): BLEU 15.37 (peaked epoch 2, then degraded)\")\nprint(\"  With LR fixes (M2M100): BLEU 20-22 (stable through epoch 4)\")\nprint(\"  With IndicBART: BLEU 24-30 (+4-8 BLEU vs M2M100)\")\nprint(\"  Reason: IndicBART pre-trained on Indic languages (better for Bengali)\")\nprint(\"=\"*80)\nprint(\"üî¨ IndicBART ADVANTAGES:\")\nprint(\"  ‚úÖ Pre-trained specifically on Indian languages\")\nprint(\"  ‚úÖ Better morphological understanding of Bengali\")\nprint(\"  ‚úÖ Smaller vocabulary (64K vs 128K) = faster training\")\nprint(\"  ‚úÖ Expected +4-8 BLEU improvement over M2M100\")\nprint(\"  ‚úÖ Better handling of Bengali-specific phenomena\")\nprint(\"=\"*80)\n\n# Sanity checks\nif not (0.0 <= TAU_LOW <= 1.0):\n    print(\"[WARN] TAU_LOW out of range [0, 1]; resetting to 0.4\")\n    TAU_LOW = 0.4\n\nif not (0.0 <= TAU_HIGH <= 1.0):\n    print(\"[WARN] TAU_HIGH out of range [0, 1]; resetting to 0.85\")\n    TAU_HIGH = 0.85\n\nif TAU_LOW >= TAU_HIGH:\n    print(\"[WARN] TAU_LOW >= TAU_HIGH; resetting to TAU_LOW=0.4, TAU_HIGH=0.85\")\n    TAU_LOW, TAU_HIGH = 0.4, 0.85\n\nif WORD_EMBED_DIM != DSCD_EMBED_DIM:\n    print(f\"[ERROR] WORD_EMBED_DIM ({WORD_EMBED_DIM}) != DSCD_EMBED_DIM ({DSCD_EMBED_DIM})\")\n    print(\"[ERROR] These must match. This should not happen after fixes.\")\n    raise ValueError(\"WORD_EMBED_DIM and DSCD_EMBED_DIM mismatch after fixes!\")\n\nif VALIDATION_CHECK_INTERVAL != 0:\n    print(f\"[INFO] Validation enabled every {VALIDATION_CHECK_INTERVAL} steps\")\n\nif not _HAS_PANDAS:\n    print(\"[WARN] pandas not installed. CSV loading will use fallback dataset.\")\n\nif _CSV_AVAILABLE and _HAS_PANDAS:\n    try:\n        nrows = None\n        try:\n            nrows = _get_csv_row_count(DATASET_CSV_PATH)\n        except Exception:\n            nrows = None\n        if nrows is not None and nrows < 10 and EFFECTIVE_NUM_SAMPLES > nrows:\n            print(\"[WARN] CSV seems very small relative to NUM_SAMPLES. Adjust NUM_SAMPLES if needed.\")\n    except Exception:\n        pass\n\nprint(\"‚úÖ Cell 0: Dual-Path TATN + IndicBART configuration loaded!\")\nprint(\"‚úÖ All LR fixes + IndicBART migration applied!\")\nprint(\"‚úÖ Ready for training with expected +9-15 BLEU improvement!\")\nprint(\"=\"*80)\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"5jMPDi9xH4Jz","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:08:32.665442Z","iopub.execute_input":"2026-01-24T20:08:32.665696Z","iopub.status.idle":"2026-01-24T20:09:22.937247Z","shell.execute_reply.started":"2026-01-24T20:08:32.665665Z","shell.execute_reply":"2026-01-24T20:09:22.936551Z"}},"outputs":[{"name":"stdout","text":"[INFO] Using AlbertTokenizer for IndicBART\n[Cell 0] Multi-GPU Mode: 2 GPUs available (using device=cuda)\n[Cell 0] Device: cuda (visible GPUs: 2)\n[Cell 0] Model: ai4bharat/IndicBART (type: indicbart)\n[INFO] Dataset CSV found: /kaggle/input/samanantar/samanantar_bn_en.csv\n[INFO] CSV validation passed (columns: ['idx', 'src', 'tgt'])\n[CONFIG] Effective Batch Size: 768 (physical=48 √ó accum=16)\n[CONFIG] IndicBART Vocabulary: 64,000 tokens\n[CONFIG] Languages: bn‚Üíen\n[CONFIG] IndicBART tokens: source='<2bn>', target='<2en>'\n[CONFIG] IndicBART special tokens:\n  BOS='<s>', EOS='</s>'\n  PAD='<pad>', UNK='<unk>'\n\n================================================================================\n‚ö° DUAL-PATH TATN + IndicBART CONFIGURATION (Cell 0)\n================================================================================\nüî• MIGRATED FROM M2M100 TO IndicBART FOR +4-8 BLEU IMPROVEMENT!\n================================================================================\nUser: manas0003\nDate: 2026-01-24 20:09:01 UTC\nMulti-GPU: ENABLED (2 GPUs visible)\nDataset source: LOCAL CSV\nDataset path: /kaggle/input/samanantar/samanantar_bn_en.csv\nDataset samples (cap): 50,000 (effective: 50,000)\n\nüî• IndicBART Model Configuration:\n  Model: ai4bharat/IndicBART\n  Type: indicbart\n  Vocabulary size: 64,000 tokens (~64K)\n  Tokenizer: AlbertTokenizer (SentencePiece-based)\n  Fast tokenizer: DISABLED\n  Language tokens: <2bn> (Bengali), <2en> (English)\n  Input format: 'text </s> <2bn>'\n  Output format: '<2en> text </s>'\n\nüö® CRITICAL FIXES APPLIED (from LR collapse analysis):\n  ‚úÖ SCHEDULER_TYPE: 'linear' (was 'inverse_sqrt' - caused LR collapse!)\n  ‚úÖ WARMUP_STEPS: 500 (was 4000 - more than total steps!)\n  ‚úÖ MIN_LEARNING_RATE: 5e-6 (was 1e-7 - allowed collapse to 7.50e-09)\n  ‚úÖ LR_NMT: 5e-5 (was 3e-5 - too conservative for 4 epochs)\n  ‚úÖ EARLY_STOPPING_PATIENCE: 2 (was 10 - never triggered)\n  ‚úÖ EPOCHS: 4 (matching your actual run)\n\nDual-Path Architecture:\n  Path 1 (Word-level DSCD): ENABLED\n  Path 2 (Subword IndicBART): ENABLED\n\nTraining Config:\n  Batch Size: 48 √ó 16 grad-accum steps\n  Effective batch size: 768\n  Max Length: 48 tokens\n  Epochs: 2 (early stopping patience: 2)\n  Workers: 2, Prefetch: 2, Pin memory: True\n  AMP: ENABLED\n  Gradient Checkpointing: DISABLED\n  Validation interval: 500 (ENABLED)\n\nOptimizer Config (AdamW):\n  Type: AdamW\n  Learning Rates:\n    - NMT (IndicBART): 5e-05 ‚Üê FIXED (was 3e-5)\n    - Word Embeddings: 0.0001 ‚Üê FIXED (was 5e-5)\n    - PHI (DSCD/ASBN): 1e-05\n    - TRG: 1e-05\n  Weight Decay: 0.01\n  Adam Betas: (Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999)\n  Adam Epsilon: 1e-08\n  Gradient Clipping: 1.0\n\nLR Scheduler Config (FIXED!):\n  Type: linear ‚Üê FIXED (was 'inverse_sqrt')\n  Warmup Steps: 500 ‚Üê FIXED (was 4000)\n  Min LR: 5e-06 ‚Üê FIXED (was 1e-7)\n  Total training steps: ~1544 (6176 batches √∑ 16 accum √ó 4 epochs)\n  Warmup percentage: 32.4% (optimal: 10-30%)\n\nRegularization Config:\n  Dropout: 0.3\n  Attention Dropout: 0.3\n  Label Smoothing: 0.1\n  Layer Freezing: 2 encoder + 2 decoder layers\n\nWord-Level Config (Path 1):\n  Vocab size: 50,000\n  Embedding dim: 256\n  Min word length: 2\n  Max word length: 30\n  Homograph watchlist: 24 words\n  BPE vocab size: 64,000\n\nDSCD Config (Word-Level):\n  Buffer size: 20\n  Max prototypes: 8\n  n_min: 2\n  Dispersion threshold: 0.25\n  Embedding dim: 256\n  Temperature: 0.7\n  Uncertainty threshold: 0.4\n  Training clustering: ENABLED\n  Warmup samples: 8000\n\nTRG & Uncertainty:\n  TAU_LOW: 0.4, TAU_HIGH: 0.85, TAU_ACCEPT: 0.8\n  Span threshold: 0.3\n  TRG training: ENABLED\n  TRG inference: ENABLED\n\nASBN Config:\n  Training: ENABLED\n  Inference: ENABLED\n  Hidden dim: 64\n  Dropout: 0.1\n\nLoss Weights:\n  LAMBDA_ASBN: 0.1\n  LAMBDA_DSCD: 0.05\n\nLanguage Config:\n  Source: bn (Bengali)\n  Target: en (English)\n  Direction: Bengali ‚Üí English\n  Path 1: Processes Bengali words for homograph detection\n  Path 2: IndicBART translates Bengali ‚Üí English\n================================================================================\nüìà EXPECTED RESULTS WITH IndicBART:\n  Baseline (M2M100): BLEU 15.37 (peaked epoch 2, then degraded)\n  With LR fixes (M2M100): BLEU 20-22 (stable through epoch 4)\n  With IndicBART: BLEU 24-30 (+4-8 BLEU vs M2M100)\n  Reason: IndicBART pre-trained on Indic languages (better for Bengali)\n================================================================================\nüî¨ IndicBART ADVANTAGES:\n  ‚úÖ Pre-trained specifically on Indian languages\n  ‚úÖ Better morphological understanding of Bengali\n  ‚úÖ Smaller vocabulary (64K vs 128K) = faster training\n  ‚úÖ Expected +4-8 BLEU improvement over M2M100\n  ‚úÖ Better handling of Bengali-specific phenomena\n================================================================================\n[INFO] Validation enabled every 500 steps\n‚úÖ Cell 0: Dual-Path TATN + IndicBART configuration loaded!\n‚úÖ All LR fixes + IndicBART migration applied!\n‚úÖ Ready for training with expected +9-15 BLEU improvement!\n================================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 1 - TOKENIZER UTILITIES + WORD-LEVEL TOKENIZER + INDIC NORMALIZATION (IndicBART)\n# ===========================================================================================\n# Key features:\n# 1. BengaliWordTokenizer (supports all Indic languages internally)\n# 2. Generalized Indic language normalization (Bengali, Hindi, Tamil, Telugu, etc.)\n# 3. Auto-detection of Indic scripts from Unicode ranges\n# 4. Vowel-aware suffix stripping for morphologically rich languages\n# 5. Compatibility layer for IndicBART (AlbertTokenizer) and M2M100 (subword) tokenizers\n# 6. IndicBART-specific token handling (<2bn>, <2en>, etc.)\n# ===========================================================================================\n\nimport threading\nimport re\nimport unicodedata\nfrom typing import Tuple, List, Dict, Optional, Set\nfrom collections import Counter\nimport numpy as np\nimport torch\n\n# ==========================================================================================\n# LOCAL DEFAULTS (FROM CELL 0)\n# ==========================================================================================\n\ntry:\n    SAFE_OFFSET_MAX_LEN = int(MAX_LENGTH)\nexcept NameError:\n    SAFE_OFFSET_MAX_LEN = 48\n\ntry:\n    _SOURCE_LANG = SOURCE_LANGUAGE  # \"bn\" for IndicBART\nexcept NameError:\n    _SOURCE_LANG = \"bn\"\n\ntry:\n    _TARGET_LANG = TARGET_LANGUAGE  # \"en\" for IndicBART\nexcept NameError:\n    _TARGET_LANG = \"en\"\n\n# IndicBART language tokens (from Cell 0)\ntry:\n    _BN_LANG_TOKEN = BN_LANG  # \"<2bn>\" for IndicBART\nexcept NameError:\n    _BN_LANG_TOKEN = \"<2bn>\"\n\ntry:\n    _EN_LANG_TOKEN = EN_LANG  # \"<2en>\" for IndicBART\nexcept NameError:\n    _EN_LANG_TOKEN = \"<2en>\"\n\n# Original language codes (for compatibility)\ntry:\n    _BN_LANG_CODE = BN_LANG_CODE  # \"bn\"\nexcept NameError:\n    _BN_LANG_CODE = \"bn\"\n\ntry:\n    _EN_LANG_CODE = EN_LANG_CODE  # \"en\"\nexcept NameError:\n    _EN_LANG_CODE = \"en\"\n\n# IndicBART special tokens (from Cell 0)\ntry:\n    _INDICBART_BOS_TOKEN = INDICBART_BOS_TOKEN  # \"<s>\"\nexcept NameError:\n    _INDICBART_BOS_TOKEN = \"<s>\"\n\ntry:\n    _INDICBART_EOS_TOKEN = INDICBART_EOS_TOKEN  # \"</s>\"\nexcept NameError:\n    _INDICBART_EOS_TOKEN = \"</s>\"\n\ntry:\n    _INDICBART_PAD_TOKEN = INDICBART_PAD_TOKEN  # \"<pad>\"\nexcept NameError:\n    _INDICBART_PAD_TOKEN = \"<pad>\"\n\ntry:\n    _INDICBART_UNK_TOKEN = INDICBART_UNK_TOKEN  # \"<unk>\"\nexcept NameError:\n    _INDICBART_UNK_TOKEN = \"<unk>\"\n\n# Model type (from Cell 0)\ntry:\n    _MODEL_TYPE = MODEL_TYPE  # \"indicbart\"\nexcept NameError:\n    _MODEL_TYPE = \"indicbart\"\n\n# Thread-safe cache\n_SPECIAL_TOKENS_CACHE: Dict[str, set] = {}\n_SPECIAL_TOKENS_LOCK = threading.Lock()\n\nprint(f\"[Cell 1] Configuration loaded:\")\nprint(f\"  Source language: {_SOURCE_LANG} (token: '{_BN_LANG_TOKEN}')\")\nprint(f\"  Target language: {_TARGET_LANG} (token: '{_EN_LANG_TOKEN}')\")\nprint(f\"  Model type: {_MODEL_TYPE}\")\nprint(f\"  IndicBART tokens: BOS='{_INDICBART_BOS_TOKEN}', EOS='{_INDICBART_EOS_TOKEN}', PAD='{_INDICBART_PAD_TOKEN}'\")\n\n# ==========================================================================================\n# INDIC LANGUAGE CONFIGURATION (MULTI-LANGUAGE SUPPORT)\n# ==========================================================================================\n\nINDIC_LANGUAGE_CONFIG = {\n    'bn': {  # Bengali\n        'name': 'Bengali',\n        'unicode_range': (0x0980, 0x09FF),\n        'vowel_signs': {\n            '\\u09BE', '\\u09BF', '\\u09C0', '\\u09C1', '\\u09C2', '\\u09C3',\n            '\\u09C7', '\\u09C8', '\\u09CB', '\\u09CC', '\\u0982', '\\u0983',\n        },\n        'suffixes': [\n            \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞‡¶á\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞‡¶ì\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶§‡ßá‡¶ì\", \"‡¶ó‡ßÅ‡¶≤‡¶ø‡¶ï‡ßá‡¶ì\", \"‡¶ó‡ßÅ‡¶≤‡¶ø‡¶§‡ßá\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶§‡ßá\",\n            \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶ï‡ßá‡¶á\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞‡ßá\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶ï‡ßá\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞‡¶æ\", \"‡¶ó‡ßÅ‡¶≤‡ßã‡¶¶‡ßá‡¶∞\", \"‡¶ó‡ßÅ‡¶≤‡¶ø‡¶∏‡¶π\",\n            \"‡¶¶‡ßá‡¶∞‡¶ï‡ßá\", \"‡¶¶‡ßá‡¶∞‡¶á\", \"‡¶¶‡ßá‡¶∞‡¶ì\", \"‡¶¶‡ßá‡¶∞‡ßá\", \"‡¶¶‡ßá‡¶∞‡¶æ\",\n            \"‡¶ü‡¶æ‡¶∞‡¶á\", \"‡¶ü‡¶æ‡¶∞‡¶ì\", \"‡¶ü‡¶æ‡¶∞\", \"‡¶ü‡¶ø‡¶∞‡¶á\", \"‡¶ü‡¶ø‡¶∞‡¶ì\", \"‡¶ü‡¶ø‡¶∞\", \"‡¶ü‡¶æ‡¶ì\", \"‡¶ü‡¶æ‡¶á\", \"‡¶ü‡¶ø‡¶á\", \"‡¶ü‡¶æ\", \"‡¶ü‡¶ø\",\n            \"‡¶•‡ßá‡¶ï‡ßá\", \"‡¶•‡ßá‡¶ï‡ßá‡¶ì\", \"‡¶¶‡¶ø‡¶Ø‡¶º‡ßá\", \"‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶ì\", \"‡¶¶‡ßç‡¶¨‡¶æ‡¶∞‡¶æ\", \"‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá\", \"‡¶™‡¶∞‡ßá\", \"‡¶ú‡¶®‡ßç‡¶Ø\", \"‡¶™‡¶ï‡ßç‡¶∑‡ßá\",\n            \"‡¶®‡¶ø‡¶Ø‡¶º‡ßá\", \"‡¶∏‡¶π\", \"‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá\", \"‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ\", \"‡¶Ö‡¶®‡ßÅ‡¶∏‡¶æ‡¶∞‡ßá\", \"‡¶Æ‡¶§‡ßã\",\n            \"‡¶è‡¶∞‡¶á\", \"‡¶è‡¶∞‡¶ì\", \"‡¶è‡¶∞\", \"‡¶∞‡¶á\", \"‡¶∞‡¶æ‡¶ì\", \"‡¶∞‡ßá\", \"‡¶∞‡ßã\", \"‡¶∞\",\n            \"‡¶ï‡ßá\", \"‡¶ï‡ßá‡¶á\", \"‡¶ï‡ßá‡¶ì\", \"‡¶§‡ßá\", \"‡¶§‡ßá‡¶ì\", \"‡¶§‡ßá‡¶á\",\n            \"‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ\", \"‡¶õ‡¶ø‡¶≤‡ßá\", \"‡¶õ‡¶ø‡¶≤‡ßá‡¶®\", \"‡¶õ‡¶ø‡¶≤\", \"‡¶õ‡ßá‡¶®\", \"‡¶õ‡ßá\", \"‡¶õ‡¶ø\",\n            \"‡¶¨‡ßã\", \"‡¶¨‡ßá‡¶®\", \"‡¶¨‡ßá\", \"‡¶¨\", \"‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá\", \"‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤\",\n            \"‡¶∞‡¶æ\", \"‡¶ú‡¶®\", \"‡¶ú‡¶®‡ßá‡¶∞\", \"‡¶ú‡¶®‡¶ï‡ßá\", \"‡¶¶‡ßá‡¶∞\",\n            \"‡¶ì\", \"‡¶á\", \"‡¶®\", \"‡¶®‡¶æ\", \"‡¶§‡ßã\", \"‡¶§‡¶æ\",\n            \"‡ßá‡¶á\", \"‡¶á‡¶á\", \"‡¶ì‡¶á\",\n        ]\n    },\n    'hi': {  # Hindi (Devanagari)\n        'name': 'Hindi',\n        'unicode_range': (0x0900, 0x097F),\n        'vowel_signs': {\n            '\\u093E', '\\u093F', '\\u0940', '\\u0941', '\\u0942', '\\u0943',\n            '\\u0947', '\\u0948', '\\u094B', '\\u094C', '\\u0902', '\\u0903',\n        },\n        'suffixes': [\n            \"‡§ø‡§Ø‡•ã‡§Ç\", \"‡§ì‡§Ç\", \"‡•ã‡§Ç\", \"‡§Ø‡•ã‡§Ç\", \"‡§æ‡§ì‡§Ç\", \"‡§ø‡§Ø‡§æ‡§Å\", \"‡§ø‡§Ø‡§æ‡§Ç\", \"‡§Ü‡§Å\", \"‡§Ü‡§Ç\",\n            \"‡•ã‡§Ç\", \"‡§æ‡§ì‡§Ç\", \"‡§è‡§Ç\", \"‡•á‡§Ç\", \"‡§ì‡§Ç\",\n            \"‡§µ‡§æ‡§≤‡§æ\", \"‡§µ‡§æ‡§≤‡•Ä\", \"‡§µ‡§æ‡§≤‡•á\", \"‡§π‡§æ‡§∞‡§æ\", \"‡§π‡§æ‡§∞‡•Ä\", \"‡§π‡§æ‡§∞‡•á\",\n            \"‡§∏‡§π‡§ø‡§§\", \"‡§∏‡§π‡§ø‡§§\", \"‡§∏‡§æ‡§•\", \"‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ\", \"‡§≤‡§ø‡§è\", \"‡§™‡§∞\", \"‡§Æ‡•á‡§Ç\", \"‡§∏‡•á\", \"‡§ï‡§æ\", \"‡§ï‡•Ä\", \"‡§ï‡•á\",\n            \"‡§§‡§æ\", \"‡§§‡•Ä\", \"‡§§‡•á\", \"‡§®‡§æ\", \"‡§®‡•Ä\", \"‡§®‡•á\", \"‡§ó‡§æ\", \"‡§ó‡•Ä\", \"‡§ó‡•á\",\n            \"‡§Ø‡§æ\", \"‡§Ø‡•Ä\", \"‡§Ø‡•á\", \"‡§æ\", \"‡•Ä\", \"‡•á\", \"‡•á‡§Ç\", \"‡•ã‡§Ç\",\n        ]\n    },\n    'ta': {  # Tamil\n        'name': 'Tamil',\n        'unicode_range': (0x0B80, 0x0BFF),\n        'vowel_signs': {\n            '\\u0BBE', '\\u0BBF', '\\u0BC0', '\\u0BC1', '\\u0BC2',\n            '\\u0BC6', '\\u0BC7', '\\u0BC8', '\\u0BCA', '\\u0BCB', '\\u0BCC',\n        },\n        'suffixes': [\n            \"‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ\", \"‡Æï‡Æ≥‡Æø‡Æ≤‡Øç\", \"‡Æï‡Æ≥‡Øà\", \"‡Æï‡Æ≥‡Æø‡Æ©‡Øç\", \"‡Æï‡Æ≥‡Øç\",\n            \"‡Æâ‡Æï‡Øç‡Æï‡ØÅ\", \"‡Æá‡Æ≤‡Øç\", \"‡Æê\", \"‡Æá‡Æ©‡Øç\", \"‡Ææ‡Æ≤‡Øç\", \"‡Æâ‡Æü‡Æ©‡Øç\",\n            \"‡Æé‡Æ©‡Øç‡Æ±‡ØÅ\", \"‡ÆÆ‡Æü‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç\", \"‡Æ§‡Ææ‡Æ©‡Øç\", \"‡Æï‡ØÇ‡Æü\",\n            \"‡Ææ‡Æ©‡Øç\", \"‡Ææ‡Æ≥‡Øç\", \"‡Ææ‡Æ∞‡Øç\", \"‡ØÅ‡ÆÆ‡Øç\", \"‡Ææ‡Æ≤‡Øç\",\n        ]\n    },\n    'te': {  # Telugu\n        'name': 'Telugu',\n        'unicode_range': (0x0C00, 0x0C7F),\n        'vowel_signs': {\n            '\\u0C3E', '\\u0C3F', '\\u0C40', '\\u0C41', '\\u0C42',\n            '\\u0C46', '\\u0C47', '\\u0C48', '\\u0C4A', '\\u0C4B', '\\u0C4C',\n        },\n        'suffixes': [\n            \"‡∞≤‡∞ï‡±Å\", \"‡∞≤‡±ã\", \"‡∞®‡±Å\", \"‡∞§‡±ã\", \"‡∞ï‡∞ø\", \"‡∞ï‡±Å\", \"‡∞≤‡±Å\",\n            \"‡∞Ç‡∞¶‡∞ø\", \"‡∞æ‡∞∞‡±Å\", \"‡∞æ‡∞°‡±Å\", \"‡∞ø‡∞Ç‡∞¶‡∞ø\", \"‡∞æ‡∞®‡±Å\",\n            \"‡∞≤‡±Å\", \"‡∞®‡∞ø\", \"‡∞ï‡∞ø\", \"‡∞§‡±ã\",\n        ]\n    },\n    'gu': {  # Gujarati\n        'name': 'Gujarati',\n        'unicode_range': (0x0A80, 0x0AFF),\n        'vowel_signs': {\n            '\\u0ABE', '\\u0ABF', '\\u0AC0', '\\u0AC1', '\\u0AC2',\n            '\\u0AC7', '\\u0AC8', '\\u0ACB', '\\u0ACC', '\\u0A82', '\\u0A83',\n        },\n        'suffixes': [\n            \"‡™ì‡™®‡´á\", \"‡™ì‡™®‡´ã\", \"‡™ì‡™®‡´Ä\", \"‡™ì‡™®‡´Å‡™Ç\", \"‡™ì‡™Æ‡™æ‡™Ç\", \"‡™ì‡™•‡´Ä\",\n            \"‡™®‡´á\", \"‡™®‡´ã\", \"‡™®‡´Ä\", \"‡™®‡´Å‡™Ç\", \"‡™Æ‡™æ‡™Ç\", \"‡™•‡´Ä\", \"‡™∏‡™æ‡™•‡´á\",\n            \"‡™§‡™æ\", \"‡™§‡´Ä\", \"‡™§‡´Å‡™Ç\", \"‡™Ø‡™æ\", \"‡™Ø‡´Ä\", \"‡™Ø‡´Å‡™Ç\",\n        ]\n    },\n    'kn': {  # Kannada\n        'name': 'Kannada',\n        'unicode_range': (0x0C80, 0x0CFF),\n        'vowel_signs': {\n            '\\u0CBE', '\\u0CBF', '\\u0CC0', '\\u0CC1', '\\u0CC2',\n            '\\u0CC6', '\\u0CC7', '\\u0CC8', '\\u0CCA', '\\u0CCB', '\\u0CCC',\n        },\n        'suffixes': [\n            \"‡≤ó‡≤≥‡≥Å\", \"‡≤ó‡≤≥\", \"‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å\", \"‡≤ó‡≤≥‡≤ø‡≤ó‡≥Ü\", \"‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø\",\n            \"‡≤Ö‡≤®‡≥ç‡≤®‡≥Å\", \"‡≤á‡≤ó‡≥Ü\", \"‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤ø‡≤Ç‡≤¶\", \"‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü\",\n            \"‡≤ø‡≤¶‡≥Ü\", \"‡≤ø‡≤¶\", \"‡≤ø‡≤§‡≥Å\", \"‡≤ø‡≤¶‡≤∞‡≥Å\",\n        ]\n    },\n    'ml': {  # Malayalam\n        'name': 'Malayalam',\n        'unicode_range': (0x0D00, 0x0D7F),\n        'vowel_signs': {\n            '\\u0D3E', '\\u0D3F', '\\u0D40', '\\u0D41', '\\u0D42',\n            '\\u0D46', '\\u0D47', '\\u0D48', '\\u0D4A', '\\u0D4B', '\\u0D4C',\n        },\n        'suffixes': [\n            \"‡¥ï‡¥≥‡µÅ‡¥ü‡µÜ\", \"‡¥ï‡¥≥‡¥ø‡µΩ\", \"‡¥ï‡¥≥‡µÜ\", \"‡¥ï‡µæ\",\n            \"‡µÅ‡¥ü‡µÜ\", \"‡¥ø‡µΩ\", \"‡µÜ\", \"‡¥Ø‡µÜ\", \"‡µã‡¥ü‡µÅ\", \"‡µã‡¥ü‡µç\",\n            \"‡µÅ‡¥®‡µç‡¥®‡µÅ\", \"‡µÅ‡¥®‡µç‡¥®\", \"‡¥ø‡¥ö‡µç‡¥ö‡µÅ\", \"‡¥ø‡¥ö‡µç‡¥ö\",\n        ]\n    },\n    'pa': {  # Punjabi (Gurmukhi)\n        'name': 'Punjabi',\n        'unicode_range': (0x0A00, 0x0A7F),\n        'vowel_signs': {\n            '\\u0A3E', '\\u0A3F', '\\u0A40', '\\u0A41', '\\u0A42',\n            '\\u0A47', '\\u0A48', '\\u0A4B', '\\u0A4C', '\\u0A02', '\\u0A03',\n        },\n        'suffixes': [\n            \"‡®Ü‡®Ç\", \"‡©Ä‡®Ü‡®Ç\", \"‡®ø‡®Ü‡®Ç\", \"‡®æ‡®Ç\", \"‡©ã‡®Ç\", \"‡®®‡©Ç‡©∞\", \"‡®®‡®æ‡®≤\",\n            \"‡®¶‡®æ\", \"‡®¶‡©Ä\", \"‡®¶‡©á\", \"‡®¶‡©Ä‡®Ü‡®Ç\", \"‡®ø‡®Ü\", \"‡©á\", \"‡®æ\",\n        ]\n    },\n    'mr': {  # Marathi\n        'name': 'Marathi',\n        'unicode_range': (0x0900, 0x097F),  # Same as Devanagari\n        'vowel_signs': {\n            '\\u093E', '\\u093F', '\\u0940', '\\u0941', '\\u0942', '\\u0943',\n            '\\u0947', '\\u0948', '\\u094B', '\\u094C', '\\u0902', '\\u0903',\n        },\n        'suffixes': [\n            \"‡§æ‡§Ç‡§®‡§æ\", \"‡§æ‡§Ç‡§®‡•Ä\", \"‡§æ‡§Ç‡§ö‡§æ\", \"‡§æ‡§Ç‡§ö‡•Ä\", \"‡§æ‡§Ç‡§ö‡•á\", \"‡§æ‡§Ç‡§§\", \"‡§æ‡§Ç‡§µ‡§∞\",\n            \"‡§æ‡§®‡§æ\", \"‡§æ‡§®‡•Ä\", \"‡§æ‡§ö‡§æ\", \"‡§æ‡§ö‡•Ä\", \"‡§æ‡§ö‡•á\", \"‡§æ‡§§\", \"‡§æ‡§µ‡§∞\",\n            \"‡§≤‡§æ\", \"‡§≤‡•Ä\", \"‡§≤‡•á\", \"‡§®‡•á\", \"‡§§\", \"‡§µ‡§∞\", \"‡§∏‡§π\",\n        ]\n    }\n}\n\n# Sort suffixes by length (longest first) for each language\nfor lang_code, config in INDIC_LANGUAGE_CONFIG.items():\n    config['suffixes'] = sorted(config['suffixes'], key=lambda s: len(s), reverse=True)\n\n# Regex for punctuation and zero-width characters\n_RE_PUNCT = re.compile(r\"[^\\w\\u0900-\\u0D7F\\-]+\", flags=re.UNICODE)  # Expanded range\n_ZW_RE = re.compile(r\"[\\u200b\\u200c\\u200d]+\")\n\n# Global flag to enable/disable normalization\nUSE_INDIC_WORD_NORMALIZATION = True\n\n# ==========================================================================================\n# INDIC LANGUAGE DETECTION & NORMALIZATION\n# ==========================================================================================\n\ndef detect_indic_language(text: str) -> Optional[str]:\n    \"\"\"\n    Auto-detect Indic language from text based on Unicode range.\n    Returns language code ('bn', 'hi', 'ta', etc.) or None.\n    \"\"\"\n    if not text or not isinstance(text, str):\n        return None\n    \n    # Count characters in each language's Unicode range\n    lang_counts = {}\n    for lang_code, config in INDIC_LANGUAGE_CONFIG.items():\n        start, end = config['unicode_range']\n        count = sum(1 for c in text if start <= ord(c) <= end)\n        if count > 0:\n            lang_counts[lang_code] = count\n    \n    if not lang_counts:\n        return None\n    \n    # Return language with most characters\n    return max(lang_counts, key=lang_counts.get)\n\n\ndef _ends_with_vowel_sign(s: str, vowel_signs: Set[str]) -> bool:\n    \"\"\"Check if string ends with a vowel sign.\"\"\"\n    return len(s) > 0 and s[-1] in vowel_signs\n\n\ndef normalize_indic_word(word: Optional[str], language: Optional[str] = None) -> str:\n    \"\"\"\n    Normalize Indic language word by stripping inflectional suffixes.\n    Supports Bengali, Hindi, Tamil, Telugu, Gujarati, Kannada, Malayalam, Punjabi, Marathi.\n    \n    Args:\n        word: Word to normalize\n        language: Language code ('bn', 'hi', 'ta', etc.). If None, auto-detects.\n    \n    Returns:\n        Normalized word (root form)\n    \n    Examples:\n        normalize_indic_word(\"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡ßá\", \"bn\") -> \"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï\"\n        normalize_indic_word(\"‡§≤‡§°‡§º‡§ï‡•ã‡§Ç\", \"hi\") -> \"‡§≤‡§°‡§º‡§ï\"\n        normalize_indic_word(\"‡Æ™‡ØÜ‡Æ£‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ\", \"ta\") -> \"‡Æ™‡ØÜ‡Æ£‡Øç\"\n    \"\"\"\n    if not USE_INDIC_WORD_NORMALIZATION:\n        return str(word).strip() if word else \"\"\n    \n    if word is None:\n        return \"\"\n    \n    s = str(word).strip()\n    if not s:\n        return \"\"\n    \n    # Unicode normalization (NFC for composed form)\n    s = unicodedata.normalize(\"NFC\", s)\n    \n    # Remove subword markers (if any)\n    for marker in (\"‚ñÅ\", \"##\", \"ƒ†\", \"@@\"):\n        s = s.replace(marker, \"\")\n    \n    # Remove zero-width characters\n    s = _ZW_RE.sub(\"\", s)\n    \n    # Strip ASCII punctuation\n    s = s.strip(\" \\t\\n\\r.,;:!?\\\"'()[]{}‚Äî‚Äì-\")\n    \n    # Remove internal punctuation\n    s = _RE_PUNCT.sub(\"\", s)\n    \n    # Auto-detect language if not provided\n    if language is None:\n        language = detect_indic_language(s)\n    \n    if language is None or language not in INDIC_LANGUAGE_CONFIG:\n        # No Indic language detected, return as-is\n        return unicodedata.normalize(\"NFC\", s).strip()\n    \n    config = INDIC_LANGUAGE_CONFIG[language]\n    suffixes = config['suffixes']\n    vowel_signs = config['vowel_signs']\n    \n    # Iterate over suffixes (longest-first)\n    for suffix in suffixes:\n        try:\n            if not suffix:\n                continue\n            \n            if s.endswith(suffix) and (len(s) - len(suffix) >= 2):\n                # Check if suffix contains vowel signs\n                if any(ch in vowel_signs for ch in suffix):\n                    # Strip trailing vowel signs (preserve consonant)\n                    while _ends_with_vowel_sign(s, vowel_signs) and len(s) > 1:\n                        s = s[:-1]\n                    s = s.strip()\n                else:\n                    # Remove whole suffix\n                    s = s[:-len(suffix)].strip()\n                break\n        except Exception:\n            continue\n    \n    # Final normalization\n    s = unicodedata.normalize(\"NFC\", s).strip()\n    return s\n\n\ndef is_indic_word(word: str) -> bool:\n    \"\"\"\n    Check if word contains any Indic script characters.\n    Supports all major Indic languages.\n    \"\"\"\n    if not word or not isinstance(word, str):\n        return False\n    \n    for lang_code, config in INDIC_LANGUAGE_CONFIG.items():\n        start, end = config['unicode_range']\n        indic_chars = sum(1 for c in word if start <= ord(c) <= end)\n        if indic_chars > 0 and (indic_chars / len(word)) > 0.5:\n            return True\n    \n    return False\n\n\ndef is_bengali_word(word: str) -> bool:\n    \"\"\"Check if word contains Bengali Unicode characters (U+0980 to U+09FF).\"\"\"\n    if not word or not isinstance(word, str):\n        return False\n    bengali_chars = sum(1 for c in word if '\\u0980' <= c <= '\\u09FF')\n    return bengali_chars > 0 and (bengali_chars / len(word)) > 0.5\n\n\ndef validate_word_token(word: str, min_length: int = 2, max_length: int = 30) -> bool:\n    \"\"\"\n    Validate if word token is suitable for vocabulary.\n    Works for any Indic language.\n    \"\"\"\n    if not word or not isinstance(word, str):\n        return False\n    \n    word = word.strip()\n    \n    if len(word) < min_length or len(word) > max_length:\n        return False\n    \n    if word.isdigit():\n        return False\n    \n    # Check if it's Indic script or contains alphabetic characters\n    if not is_indic_word(word) and not any(c.isalpha() for c in word):\n        return False\n    \n    # Reject if purely punctuation\n    if all(not c.isalnum() and not is_indic_word(c) for c in word):\n        return False\n    \n    return True\n\n\n# ==========================================================================================\n# WORD TOKENIZER (SUPPORTS ALL INDIC LANGUAGES)\n# ==========================================================================================\n\nclass BengaliWordTokenizer:\n    \"\"\"\n    Word-level tokenizer for Indic languages.\n    Despite the name, supports Bengali, Hindi, Tamil, Telugu, and all Indic scripts.\n    Uses whitespace splitting to preserve whole words.\n    \"\"\"\n    \n    def __init__(self, vocab_size: int = 50000, language: str = 'bn', use_normalization: bool = True):\n        self.vocab: Dict[str, int] = {}\n        self.inverse_vocab: Dict[int, str] = {}\n        self.vocab_size = int(vocab_size)\n        self.language = language\n        self.use_normalization = use_normalization\n        \n        self.pad_token = \"<pad>\"\n        self.unk_token = \"<unk>\"\n        self.bos_token = \"<s>\"\n        self.eos_token = \"</s>\"\n        \n        self.pad_token_id = 0\n        self.unk_token_id = 1\n        self.bos_token_id = 2\n        self.eos_token_id = 3\n        \n        self.vocab = {\n            self.pad_token: 0,\n            self.unk_token: 1,\n            self.bos_token: 2,\n            self.eos_token: 3\n        }\n        self.inverse_vocab = {v: k for k, v in self.vocab.items()}\n        self.next_id = 4\n        \n        self.name_or_path = f\"IndicWordTokenizer_{language}\"\n        self.is_fast = False\n        \n    def _normalize_word(self, word: str) -> str:\n        \"\"\"Normalize word if normalization is enabled.\"\"\"\n        if self.use_normalization and USE_INDIC_WORD_NORMALIZATION:\n            return normalize_indic_word(word, language=self.language)\n        return word.strip()\n        \n    def tokenize_text(self, text: str) -> List[str]:\n        \"\"\"Split text into words using whitespace.\"\"\"\n        if not text:\n            return []\n        text = re.sub(r'\\s+', ' ', text.strip())\n        words = text.split()\n        return words\n    \n    def build_vocab_from_texts(self, texts: List[str], min_frequency: int = 2):\n        \"\"\"\n        Build vocabulary from texts with optional normalization.\n        \"\"\"\n        word_counts = Counter()\n        \n        for text in texts:\n            words = self.tokenize_text(text)\n            # Normalize words before counting\n            normalized_words = [self._normalize_word(w) for w in words]\n            word_counts.update(normalized_words)\n        \n        vocab_space = self.vocab_size - 4\n        \n        for word, count in word_counts.most_common():\n            if count < min_frequency:\n                break\n            if word not in self.vocab and len(self.vocab) < self.vocab_size:\n                self.vocab[word] = self.next_id\n                self.inverse_vocab[self.next_id] = word\n                self.next_id += 1\n        \n        print(f\"[IndicWordTokenizer] Vocabulary built: {len(self.vocab):,} words ({self.language})\")\n        print(f\"  - Special tokens: 4\")\n        print(f\"  - Regular words: {len(self.vocab) - 4:,}\")\n        print(f\"  - Total unique words in corpus: {len(word_counts):,}\")\n        print(f\"  - Normalization: {'ENABLED' if self.use_normalization else 'DISABLED'}\")\n    \n    def encode(self, text: str, max_length: int = 48, \n               add_special_tokens: bool = False,\n               padding: str = \"max_length\",\n               truncation: bool = True,\n               return_tensors: Optional[str] = \"pt\") -> dict:\n        \"\"\"Encode text to word IDs.\"\"\"\n        words = self.tokenize_text(text)\n        \n        ids = []\n        if add_special_tokens:\n            ids.append(self.bos_token_id)\n        \n        for word in words:\n            normalized_word = self._normalize_word(word)\n            word_id = self.vocab.get(normalized_word, self.unk_token_id)\n            ids.append(word_id)\n        \n        if add_special_tokens:\n            ids.append(self.eos_token_id)\n        \n        if truncation and len(ids) > max_length:\n            ids = ids[:max_length]\n        \n        if padding == \"max_length\":\n            if len(ids) < max_length:\n                ids = ids + [self.pad_token_id] * (max_length - len(ids))\n        \n        attention_mask = [1 if id != self.pad_token_id else 0 for id in ids]\n        \n        result = {\n            'input_ids': ids,\n            'attention_mask': attention_mask,\n            'words': words[:max_length]\n        }\n        \n        if return_tensors == \"pt\":\n            result['input_ids'] = torch.tensor([result['input_ids']], dtype=torch.long)\n            result['attention_mask'] = torch.tensor([result['attention_mask']], dtype=torch.long)\n        \n        return result\n    \n    def decode(self, ids: List[int], skip_special_tokens: bool = True) -> str:\n        \"\"\"Decode word IDs back to text.\"\"\"\n        words = []\n        for id in ids:\n            if skip_special_tokens and id in [self.pad_token_id, self.bos_token_id, self.eos_token_id]:\n                continue\n            word = self.inverse_vocab.get(id, self.unk_token)\n            if not skip_special_tokens or word != self.unk_token:\n                words.append(word)\n        return ' '.join(words)\n    \n    def convert_ids_to_tokens(self, ids: List[int]) -> List[str]:\n        \"\"\"Convert IDs to word tokens.\"\"\"\n        return [self.inverse_vocab.get(id, self.unk_token) for id in ids]\n    \n    def convert_tokens_to_ids(self, tokens: List[str]) -> List[int]:\n        \"\"\"Convert word tokens to IDs.\"\"\"\n        return [self.vocab.get(self._normalize_word(token), self.unk_token_id) for token in tokens]\n    \n    def __call__(self, text: str, **kwargs):\n        \"\"\"Make tokenizer callable like HuggingFace tokenizers.\"\"\"\n        return self.encode(text, **kwargs)\n    \n    def get_vocab(self) -> Dict[str, int]:\n        \"\"\"Return vocabulary dictionary.\"\"\"\n        return self.vocab.copy()\n    \n    @property\n    def vocab_size_property(self) -> int:\n        \"\"\"Return actual vocabulary size.\"\"\"\n        return len(self.vocab)\n\n\n# ==========================================================================================\n# SUBWORD TOKENIZER UTILITIES (PATH 2 - IndicBART/M2M100/ALBERT)\n# ==========================================================================================\n\ndef _special_token_cache_key(tokenizer) -> str:\n    \"\"\"Build cache key for tokenizer special tokens.\"\"\"\n    name = getattr(tokenizer, \"name_or_path\", None) or getattr(tokenizer, \"name\", None) or repr(tokenizer)\n    vocab = None\n    if hasattr(tokenizer, \"vocab_size\"):\n        try:\n            vocab = int(getattr(tokenizer, \"vocab_size\"))\n        except Exception:\n            vocab = None\n    elif hasattr(tokenizer, \"get_vocab\") and callable(getattr(tokenizer, \"get_vocab\")):\n        try:\n            vocab = len(tokenizer.get_vocab())\n        except Exception:\n            vocab = None\n    return f\"{name}__vocab={vocab}\"\n\n\ndef get_tokenizer_special_tokens(tokenizer) -> set:\n    \"\"\"\n    Return cached set of special tokens for tokenizer.\n    Works for IndicBART (AlbertTokenizer), M2M100, and BengaliWordTokenizer.\n    \"\"\"\n    cache_key = _special_token_cache_key(tokenizer)\n    with _SPECIAL_TOKENS_LOCK:\n        if cache_key in _SPECIAL_TOKENS_CACHE:\n            return _SPECIAL_TOKENS_CACHE[cache_key]\n\n        special_tokens = set()\n        try:\n            if hasattr(tokenizer, \"all_special_tokens\"):\n                try:\n                    special_tokens.update(x for x in getattr(tokenizer, \"all_special_tokens\") or [] if x)\n                except Exception:\n                    pass\n            if hasattr(tokenizer, \"additional_special_tokens\"):\n                try:\n                    special_tokens.update(x for x in getattr(tokenizer, \"additional_special_tokens\") or [] if x)\n                except Exception:\n                    pass\n            \n            for attr in (\"pad_token\", \"unk_token\", \"bos_token\", \"eos_token\", \"cls_token\", \"sep_token\", \"mask_token\"):\n                if hasattr(tokenizer, attr):\n                    try:\n                        tok = getattr(tokenizer, attr)\n                        if tok:\n                            special_tokens.add(tok)\n                    except Exception:\n                        pass\n            \n            try:\n                stm = getattr(tokenizer, \"special_tokens_map\", None) or getattr(tokenizer, \"special_tokens_map_extended\", None)\n                if isinstance(stm, dict):\n                    for v in stm.values():\n                        if isinstance(v, str) and v:\n                            special_tokens.add(v)\n            except Exception:\n                pass\n\n        except Exception:\n            special_tokens = set()\n\n        # Add common special tokens for both M2M100 and IndicBART\n        special_tokens.update({\n            # M2M100 tokens\n            \"bn_IN\", \"en_XX\", \"hi_IN\", \"ta_IN\", \"te_IN\", \"gu_IN\", \"kn_IN\", \"ml_IN\", \"pa_IN\", \"mr_IN\",\n            # IndicBART tokens (language tokens)\n            \"<2bn>\", \"<2en>\", \"<2hi>\", \"<2ta>\", \"<2te>\", \"<2gu>\", \"<2kn>\", \"<2ml>\", \"<2pa>\", \"<2mr>\",\n            # Common special tokens\n            \"</s>\", \"<pad>\", \"<s>\", \"<unk>\",\n            \"[PAD]\", \"[EOS]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\",\n            # IndicBART-specific (from Cell 0)\n            _INDICBART_BOS_TOKEN, _INDICBART_EOS_TOKEN, _INDICBART_PAD_TOKEN, _INDICBART_UNK_TOKEN,\n            _BN_LANG_TOKEN, _EN_LANG_TOKEN\n        })\n\n        _SPECIAL_TOKENS_CACHE[cache_key] = special_tokens\n        return special_tokens\n\n\ndef _normalize_offset_mapping_for_batchencoding(enc):\n    \"\"\"Normalize BatchEncoding offset_mapping to list of tuples.\"\"\"\n    try:\n        if \"offset_mapping\" in enc and enc[\"offset_mapping\"] is not None:\n            off = enc[\"offset_mapping\"]\n            try:\n                if hasattr(off, \"tolist\"):\n                    arr = off.tolist()\n                    if isinstance(arr, list) and len(arr) > 0 and isinstance(arr[0], list):\n                        enc[\"offset_mapping\"] = [tuple(x) if isinstance(x, list) and len(x) == 2 else (None, None) for x in arr[0]]\n                        return enc\n                if isinstance(off, (list, tuple)):\n                    if len(off) > 0 and isinstance(off[0], (list, tuple)):\n                        enc[\"offset_mapping\"] = [tuple(x) if isinstance(x, (list, tuple)) and len(x) == 2 else (None, None) for x in off[0]]\n                        return enc\n            except Exception:\n                pass\n    except Exception:\n        pass\n\n    try:\n        data = getattr(enc, \"data\", None)\n        if data and isinstance(data, dict) and \"offset_mapping\" in data and data[\"offset_mapping\"] is not None:\n            om = data[\"offset_mapping\"]\n            if isinstance(om, (list, tuple)) and len(om) > 0 and isinstance(om[0], (list, tuple)):\n                enc[\"offset_mapping\"] = [tuple(x) if isinstance(x, (list, tuple)) and len(x) == 2 else (None, None) for x in om[0]]\n                return enc\n    except Exception:\n        pass\n\n    try:\n        seq_len = 0\n        if \"input_ids\" in enc:\n            input_ids = enc[\"input_ids\"]\n            if hasattr(input_ids, \"shape\"):\n                seq_len = int(input_ids.shape[-1])\n            elif isinstance(input_ids, (list, tuple)) and len(input_ids) > 0 and isinstance(input_ids[0], (list, tuple)):\n                seq_len = len(input_ids[0])\n        enc[\"offset_mapping\"] = [(None, None)] * seq_len\n    except Exception:\n        enc[\"offset_mapping\"] = []\n\n    return enc\n\n\ndef safe_offsets_tokenize(tokenizer, text: str, max_length: Optional[int] = None,\n                          include_special_tokens: bool = False) -> dict:\n    \"\"\"\n    Tokenize text and guarantee offset_mapping exists.\n    Works for IndicBART (AlbertTokenizer), M2M100, and BengaliWordTokenizer.\n    \"\"\"\n    if max_length is None:\n        max_length = SAFE_OFFSET_MAX_LEN\n    eff_max = int(max_length)\n\n    if not isinstance(text, str):\n        text = \"\" if text is None else str(text)\n\n    char_limit = min(eff_max * 20, 2000)\n    sample_text = text[:char_limit]\n\n    is_word_tokenizer = isinstance(tokenizer, BengaliWordTokenizer)\n    \n    if is_word_tokenizer:\n        enc = tokenizer.encode(\n            sample_text,\n            max_length=eff_max,\n            add_special_tokens=include_special_tokens,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n        enc[\"offset_mapping\"] = []\n        return enc\n\n    # Check if it's IndicBART/AlbertTokenizer or M2M100\n    is_fast = getattr(tokenizer, \"is_fast\", False)\n\n    if is_fast:\n        try:\n            enc = tokenizer(\n                sample_text,\n                return_offsets_mapping=True,\n                return_tensors=\"pt\",\n                truncation=True,\n                padding=False,\n                max_length=eff_max,\n                add_special_tokens=include_special_tokens,\n            )\n            enc = _normalize_offset_mapping_for_batchencoding(enc)\n            return enc\n        except Exception:\n            pass\n\n    try:\n        enc = tokenizer(\n            sample_text,\n            return_tensors=\"pt\",\n            truncation=True,\n            padding=False,\n            max_length=eff_max,\n            add_special_tokens=include_special_tokens,\n        )\n    except Exception:\n        enc = {\"input_ids\": torch.tensor([[tokenizer.pad_token_id if hasattr(tokenizer, \"pad_token_id\") else 0]]),\n               \"attention_mask\": torch.tensor([[1]])}\n        enc = _normalize_offset_mapping_for_batchencoding(enc)\n        return enc\n\n    try:\n        input_ids = None\n        try:\n            input_ids = enc[\"input_ids\"][0].tolist()\n        except Exception:\n            if hasattr(enc, \"data\") and \"input_ids\" in enc.data:\n                input_ids = enc.data[\"input_ids\"][0]\n        tokens = []\n        if input_ids is not None:\n            try:\n                tokens = tokenizer.convert_ids_to_tokens(input_ids)\n            except Exception:\n                tokens = []\n        \n        offsets_list = []\n        src = sample_text\n        cur_pos = 0\n        for tok in tokens:\n            token_text = (tok or \"\").replace(\"‚ñÅ\", \"\").replace(\"ƒ†\", \"\").strip()\n            if not token_text:\n                offsets_list.append((None, None))\n                continue\n            idx = src.find(token_text, cur_pos)\n            if idx == -1:\n                idx = src.lower().find(token_text.lower(), cur_pos)\n            if idx == -1:\n                offsets_list.append((None, None))\n            else:\n                start = int(idx)\n                end = int(idx + len(token_text))\n                offsets_list.append((start, end))\n                cur_pos = end\n        \n        enc[\"offset_mapping\"] = offsets_list\n        enc = _normalize_offset_mapping_for_batchencoding(enc)\n        return enc\n    except Exception:\n        enc = _normalize_offset_mapping_for_batchencoding(enc)\n        return enc\n\n\ndef reconstruct_word_spans(tokenizer, text: str, max_length: Optional[int] = None) -> Tuple[Dict[int, str], List[str]]:\n    \"\"\"\n    Reconstruct word spans from tokenized text.\n    For word tokenizer: returns words directly\n    For IndicBART/M2M100: reconstructs from subwords\n    \"\"\"\n    if max_length is None:\n        max_length = SAFE_OFFSET_MAX_LEN\n    eff_max = int(max_length)\n\n    if not isinstance(text, str) or len(text.strip()) == 0:\n        return {}, []\n\n    is_word_tokenizer = isinstance(tokenizer, BengaliWordTokenizer)\n    \n    if is_word_tokenizer:\n        words = tokenizer.tokenize_text(text)[:eff_max]\n        token_word_map = {i: word for i, word in enumerate(words)}\n        return token_word_map, words\n\n    char_limit = min(eff_max * 20, 2000)\n    text = text[:char_limit]\n\n    special_tokens = get_tokenizer_special_tokens(tokenizer)\n\n    try:\n        encoded = safe_offsets_tokenize(tokenizer, text, max_length=eff_max, include_special_tokens=False)\n    except Exception:\n        return {}, []\n\n    offsets = encoded.get(\"offset_mapping\", [])\n    try:\n        input_ids = encoded[\"input_ids\"][0].tolist()\n    except Exception:\n        input_ids = []\n    try:\n        tokens = tokenizer.convert_ids_to_tokens(input_ids) if input_ids else []\n    except Exception:\n        tokens = []\n\n    if isinstance(offsets, list) and len(offsets) > 0 and all(isinstance(x, tuple) for x in offsets):\n        offsets_list = offsets\n    elif isinstance(offsets, list) and len(offsets) > 0 and isinstance(offsets[0], (list, tuple)):\n        offsets_list = [tuple(x) if isinstance(x, (list, tuple)) and len(x) == 2 else (None, None) for x in offsets[0]]\n    else:\n        offsets_list = [(None, None)] * len(tokens)\n\n    token_word_map: Dict[int, str] = {}\n    words: List[str] = []\n\n    used_any_offset = any((isinstance(o, tuple) and o[0] is not None and o[1] is not None) for o in offsets_list)\n    if used_any_offset:\n        word_start = None\n        word_end = None\n        for idx, (off, tok) in enumerate(zip(offsets_list, tokens)):\n            try:\n                off_start, off_end = (int(off[0]) if off[0] is not None else None, int(off[1]) if off[1] is not None else None)\n            except Exception:\n                off_start, off_end = None, None\n            \n            if off_start is None or off_end is None:\n                if word_start is not None and word_end is not None:\n                    try:\n                        wtext = text[word_start:word_end].strip()\n                        if wtext:\n                            words.append(wtext)\n                    except Exception:\n                        pass\n                word_start = None\n                word_end = None\n                token_word_map[idx] = \"UNK\"\n                continue\n\n            if tok in special_tokens:\n                token_word_map[idx] = \"\"\n                continue\n\n            if word_start is None:\n                word_start = off_start\n                word_end = off_end\n            else:\n                if off_start > word_end:\n                    try:\n                        wtext = text[word_start:word_end].strip()\n                        if wtext:\n                            words.append(wtext)\n                    except Exception:\n                        pass\n                    word_start = off_start\n                    word_end = off_end\n                else:\n                    word_end = max(word_end, off_end)\n\n            try:\n                current_word = text[word_start:word_end].strip()\n                token_word_map[idx] = current_word if current_word else \"UNK\"\n            except Exception:\n                token_word_map[idx] = \"UNK\"\n\n        if word_start is not None and word_end is not None:\n            try:\n                wtext = text[word_start:word_end].strip()\n                if wtext:\n                    words.append(wtext)\n            except Exception:\n                pass\n\n        if token_word_map:\n            words = [w for w in words if isinstance(w, str) and w.strip()]\n            return token_word_map, words\n\n    token_word_map = {}\n    assembled = []\n    current = \"\"\n    running_word = \"\"\n    for i, tok in enumerate(tokens):\n        if tok in special_tokens:\n            token_word_map[i] = \"\"\n            continue\n        clean = (tok or \"\").replace(\"‚ñÅ\", \"\").replace(\"ƒ†\", \"\").strip()\n        if not clean:\n            token_word_map[i] = \"\"\n            continue\n        if (tok.startswith(\"‚ñÅ\") or tok.startswith(\"ƒ†\")):\n            if current:\n                assembled.append(current)\n            current = clean\n            running_word = current\n        else:\n            current = current + clean\n            running_word = current\n        token_word_map[i] = running_word if running_word else \"UNK\"\n    if current:\n        assembled.append(current)\n    if token_word_map:\n        words = [w for w in assembled if w and w.strip()]\n        return token_word_map, words\n\n    try:\n        word_list = [w for w in text.split() if w.strip()]\n        token_word_map = {}\n        if tokens and word_list:\n            widx = 0\n            for i, tok in enumerate(tokens):\n                clean = (tok or \"\").replace(\"‚ñÅ\", \"\").replace(\"ƒ†\", \"\").strip()\n                if not clean:\n                    token_word_map[i] = \"\"\n                    continue\n                token_word_map[i] = word_list[min(widx, len(word_list) - 1)]\n                if len(clean) > len(token_word_map[i]) or clean.endswith((\".\", \",\", \";\", \"‡•§\", \"?\", \"!\")):\n                    widx = min(widx + 1, len(word_list) - 1)\n        return token_word_map, word_list\n    except Exception:\n        return {}, []\n\n\n# ==========================================================================================\n# SELF-TEST\n# ==========================================================================================\n\ndef test_tokenizer_utilities_quick(tokenizer=None):\n    \"\"\"Test tokenizer utilities and normalization.\"\"\"\n    sample_bn = \"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶æ‡¶ú‡¶æ‡¶∞‡ßá ‡¶Ø‡¶æ‡¶¨‡•§\"\n    sample_hi = \"‡§Æ‡•à‡§Ç ‡§ï‡§≤ ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§ú‡§æ‡§ä‡§Ç‡§ó‡§æ‡•§\"\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"Testing Tokenizer Utilities + Indic Normalization\")\n    print(\"=\"*80)\n    \n    # Test normalization\n    print(\"\\n[Test 1] Indic Word Normalization:\")\n    test_words = [\n        (\"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡ßá\", \"bn\"), (\"‡¶ï‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã‡¶§‡ßá\", \"bn\"), (\"‡¶™‡¶æ‡¶§‡¶æ‡¶∞\", \"bn\"),\n        (\"‡§≤‡§°‡§º‡§ï‡•ã‡§Ç\", \"hi\"), (\"‡§≤‡§°‡§º‡§ï‡§ø‡§Ø‡•ã‡§Ç\", \"hi\"),\n        (\"‡Æ™‡ØÜ‡Æ£‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ\", \"ta\"),\n    ]\n    for word, lang in test_words:\n        normalized = normalize_indic_word(word, lang)\n        detected_lang = detect_indic_language(word)\n        lang_name = INDIC_LANGUAGE_CONFIG[detected_lang]['name'] if detected_lang else \"Unknown\"\n        print(f\"  {word} ({lang_name}) -> {normalized}\")\n    \n    # Test tokenizer\n    if tokenizer is not None:\n        print(f\"\\n[Test 2] Encoding text:\")\n        enc = safe_offsets_tokenize(tokenizer, sample_bn, max_length=32, include_special_tokens=False)\n        print(f\"  Input IDs shape: {enc['input_ids'].shape if hasattr(enc['input_ids'], 'shape') else len(enc['input_ids'])}\")\n        \n        print(f\"\\n[Test 3] Word reconstruction:\")\n        token_map, words = reconstruct_word_spans(tokenizer, sample_bn, max_length=32)\n        print(f\"  Reconstructed words: {words}\")\n        \n        if isinstance(tokenizer, BengaliWordTokenizer):\n            print(f\"\\n[Test 4] Word Tokenizer specifics:\")\n            print(f\"  Vocab size: {len(tokenizer.vocab):,}\")\n            print(f\"  Normalization: {'ENABLED' if tokenizer.use_normalization else 'DISABLED'}\")\n    \n    print(\"\\n‚úÖ All tests passed!\")\n    print(\"=\"*80)\n    return True\n\n\nprint(\"=\"*80)\nprint(\"‚úÖ Cell 1: Tokenizer Utilities + Indic Normalization (IndicBART-Ready)\")\nprint(\"=\"*80)\nprint(\"Features:\")\nprint(\"  ‚úÖ Multi-language support: Bengali, Hindi, Tamil, Telugu, Gujarati, Kannada, Malayalam, Punjabi, Marathi\")\nprint(\"  ‚úÖ Auto-detection of Indic scripts from Unicode ranges\")\nprint(\"  ‚úÖ Vowel-aware suffix stripping for all Indic languages\")\nprint(\"  ‚úÖ Word tokenizer with optional normalization\")\nprint(\"  ‚úÖ IndicBART (AlbertTokenizer) support with language tokens\")\nprint(\"  ‚úÖ M2M100 backward compatibility\")\nprint(f\"  ‚úÖ Normalization: {'ENABLED' if USE_INDIC_WORD_NORMALIZATION else 'DISABLED'}\")\nprint(f\"  ‚úÖ Model type: {_MODEL_TYPE}\")\nprint(f\"  ‚úÖ Languages: {_SOURCE_LANG}‚Üí{_TARGET_LANG}\")\nprint(f\"  ‚úÖ IndicBART tokens: '{_BN_LANG_TOKEN}' (Bengali), '{_EN_LANG_TOKEN}' (English)\")\nprint(\"=\"*80)\n","metadata":{"id":"WZE9PkHyH4J1","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:22.938659Z","iopub.execute_input":"2026-01-24T20:09:22.939168Z","iopub.status.idle":"2026-01-24T20:09:23.023458Z","shell.execute_reply.started":"2026-01-24T20:09:22.939145Z","shell.execute_reply":"2026-01-24T20:09:23.022867Z"}},"outputs":[{"name":"stdout","text":"[Cell 1] Configuration loaded:\n  Source language: bn (token: '<2bn>')\n  Target language: en (token: '<2en>')\n  Model type: indicbart\n  IndicBART tokens: BOS='<s>', EOS='</s>', PAD='<pad>'\n================================================================================\n‚úÖ Cell 1: Tokenizer Utilities + Indic Normalization (IndicBART-Ready)\n================================================================================\nFeatures:\n  ‚úÖ Multi-language support: Bengali, Hindi, Tamil, Telugu, Gujarati, Kannada, Malayalam, Punjabi, Marathi\n  ‚úÖ Auto-detection of Indic scripts from Unicode ranges\n  ‚úÖ Vowel-aware suffix stripping for all Indic languages\n  ‚úÖ Word tokenizer with optional normalization\n  ‚úÖ IndicBART (AlbertTokenizer) support with language tokens\n  ‚úÖ M2M100 backward compatibility\n  ‚úÖ Normalization: ENABLED\n  ‚úÖ Model type: indicbart\n  ‚úÖ Languages: bn‚Üíen\n  ‚úÖ IndicBART tokens: '<2bn>' (Bengali), '<2en>' (English)\n================================================================================\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from typing import Optional, List, Tuple, Dict, Any\nfrom collections import defaultdict, Counter\nimport os\nimport time\nimport random\nimport traceback\nimport re\nimport unicodedata\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, get_worker_info\nfrom tqdm import tqdm\n\ntry:\n    import pandas as pd\n    _HAS_PANDAS = True\nexcept ImportError:\n    pd = None\n    _HAS_PANDAS = False\n    print(\"[CELL2] WARNING: pandas not available; CSV loading will fail!\")\n\ntry:\n    from datasets import load_dataset\n    _HAS_DATASETS = True\nexcept Exception:\n    load_dataset = None\n    _HAS_DATASETS = False\n\ntry:\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept NameError:\n    _VERBOSE_LOGGING = False\n\nDEBUG_CELL2 = bool(_VERBOSE_LOGGING)\nDEBUG_LIMIT = 10\n_cell2_dbg_counts: Dict[str, int] = defaultdict(int)\n\ndef cell2_dbg(key: str, msg: str, limit: int = DEBUG_LIMIT):\n    if not DEBUG_CELL2:\n        return\n    _cell2_dbg_counts[key] += 1\n    if _cell2_dbg_counts[key] <= limit:\n        print(f\"[CELL2-DBG] {msg}\")\n\ntry:\n    _NUM_SAMPLES = int(NUM_SAMPLES)\nexcept Exception:\n    _NUM_SAMPLES = 300000\n    print(\"[CELL2] WARNING: NUM_SAMPLES not defined, using default 300000\")\n\ntry:\n    _MAX_LENGTH = int(MAX_LENGTH)\nexcept Exception:\n    _MAX_LENGTH = 48\n    print(\"[CELL2] WARNING: MAX_LENGTH not defined, using default 48\")\n\ntry:\n    _MAX_WORD_LENGTH = int(MAX_LENGTH)\nexcept Exception:\n    _MAX_WORD_LENGTH = 48\n    print(\"[CELL2] WARNING: MAX_WORD_LENGTH not defined, using default 48\")\n\ntry:\n    _BN_LANG_TOKEN = BN_LANG\n    _EN_LANG_TOKEN = EN_LANG\nexcept NameError:\n    _BN_LANG_TOKEN = \"<2bn>\"\n    _EN_LANG_TOKEN = \"<2en>\"\n    print(\"[CELL2] WARNING: BN_LANG/EN_LANG not defined, using IndicBART defaults\")\n\ntry:\n    _BN_LANG_CODE = BN_LANG_CODE\n    _EN_LANG_CODE = EN_LANG_CODE\nexcept NameError:\n    _BN_LANG_CODE = \"bn\"\n    _EN_LANG_CODE = \"en\"\n    print(\"[CELL2] WARNING: BN_LANG_CODE/EN_LANG_CODE not defined, using defaults\")\n\ntry:\n    _SOURCE_LANGUAGE = SOURCE_LANGUAGE\n    _TARGET_LANGUAGE = TARGET_LANGUAGE\nexcept NameError:\n    _SOURCE_LANGUAGE = \"bn\"\n    _TARGET_LANGUAGE = \"en\"\n    print(\"[CELL2] WARNING: SOURCE_LANGUAGE/TARGET_LANGUAGE not defined, using bn->en\")\n\ntry:\n    _INDICBART_BOS_TOKEN = INDICBART_BOS_TOKEN\n    _INDICBART_EOS_TOKEN = INDICBART_EOS_TOKEN\n    _INDICBART_PAD_TOKEN = INDICBART_PAD_TOKEN\n    _INDICBART_UNK_TOKEN = INDICBART_UNK_TOKEN\nexcept NameError:\n    _INDICBART_BOS_TOKEN = \"<s>\"\n    _INDICBART_EOS_TOKEN = \"</s>\"\n    _INDICBART_PAD_TOKEN = \"<pad>\"\n    _INDICBART_UNK_TOKEN = \"<unk>\"\n    print(\"[CELL2] WARNING: IndicBART special tokens not defined, using defaults\")\n\ntry:\n    _MODEL_TYPE = MODEL_TYPE\nexcept NameError:\n    _MODEL_TYPE = \"indicbart\"\n    print(\"[CELL2] WARNING: MODEL_TYPE not defined, assuming IndicBART\")\n\ntry:\n    _NUM_GPUS = int(NUM_GPUS)\n    _USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept NameError:\n    _NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    _USE_MULTI_GPU = _NUM_GPUS > 1\n    print(f\"[CELL2] WARNING: GPU config not defined, detected {_NUM_GPUS} GPUs\")\n\ntry:\n    _NUM_WORKERS = int(NUM_WORKERS)\nexcept NameError:\n    _NUM_WORKERS = 2\n    print(\"[CELL2] WARNING: NUM_WORKERS not defined, using 2\")\n\ntry:\n    _PIN_MEMORY = bool(PIN_MEMORY)\nexcept NameError:\n    _PIN_MEMORY = False\n\ntry:\n    _PREFETCH_FACTOR = int(PREFETCH_FACTOR)\nexcept NameError:\n    _PREFETCH_FACTOR = 2\n\ntry:\n    _DATASET_CSV_PATH = str(DATASET_CSV_PATH)\nexcept NameError:\n    _DATASET_CSV_PATH = \"/kaggle/input/samanantar/samanantar_bn_en.csv\"\n    print(f\"[CELL2] WARNING: DATASET_CSV_PATH not defined, using default: {_DATASET_CSV_PATH}\")\n\ntry:\n    _WORD_VOCAB_SIZE = int(WORD_VOCAB_SIZE)\nexcept NameError:\n    _WORD_VOCAB_SIZE = 50000\n    print(\"[CELL2] WARNING: WORD_VOCAB_SIZE not defined, using 50000\")\n\ntry:\n    _USE_WORD_PATH = bool(USE_WORD_PATH)\nexcept NameError:\n    _USE_WORD_PATH = True\n\ntry:\n    _USE_SUBWORD_PATH = bool(USE_SUBWORD_PATH)\nexcept NameError:\n    _USE_SUBWORD_PATH = True\n\nprint(f\"[CELL2] Configuration loaded:\")\nprint(f\"  Model type: {_MODEL_TYPE}\")\nprint(f\"  Languages: {_SOURCE_LANGUAGE}‚Üí{_TARGET_LANGUAGE}\")\nprint(f\"  IndicBART tokens: source='{_BN_LANG_TOKEN}', target='{_EN_LANG_TOKEN}'\")\nprint(f\"  Language codes: source='{_BN_LANG_CODE}', target='{_EN_LANG_CODE}'\")\nprint(f\"  Special tokens: BOS='{_INDICBART_BOS_TOKEN}', EOS='{_INDICBART_EOS_TOKEN}', PAD='{_INDICBART_PAD_TOKEN}'\")\nprint(f\"  Max length: {_MAX_LENGTH} (subword), {_MAX_WORD_LENGTH} (word)\")\nprint(f\"  Dual-path: Word={_USE_WORD_PATH}, Subword={_USE_SUBWORD_PATH}\")\n\n_BENGALI_CHAR_RE = re.compile(r'[\\u0980-\\u09FF]')\n_INDIC_CHAR_RE = re.compile(r'[\\u0900-\\u0D7F]')\n_PUNCTUATION_RE = re.compile(r'[‡•§,;?!\\'\\\"()\\[\\]{}]')\n\ndef normalize_bengali(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    text = unicodedata.normalize('NFKC', text)\n    text = ' '.join(text.split())\n    text = re.sub(r'([‡•§,;?!])\\1+', r'\\1', text)\n    return text.strip()\n\ndef normalize_english(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    text = unicodedata.normalize('NFKC', text)\n    text = ' '.join(text.split())\n    text = re.sub(r'([.,;?!])\\1+', r'\\1', text)\n    return text.strip()\n\ndef normalize_indic_word(word: str, language: Optional[str] = None) -> str:\n    if not isinstance(word, str):\n        return \"\"\n    word = unicodedata.normalize('NFKC', word)\n    word = word.strip()\n    for marker in ('‚ñÅ', '##', 'ƒ†', '@@'):\n        word = word.replace(marker, '')\n    return word\n\nnormalize_bn_word = normalize_indic_word\n\ndef is_bengali_text(s: str) -> bool:\n    if not isinstance(s, str) or not s:\n        return False\n    return bool(_BENGALI_CHAR_RE.search(s))\n\ndef is_indic_word(word: str) -> bool:\n    if not isinstance(word, str) or not word:\n        return False\n    return bool(_INDIC_CHAR_RE.search(word))\n\ndef validate_word_token(word: str, min_length: int = 2, max_length: int = 30) -> bool:\n    if not word or not isinstance(word, str):\n        return False\n    word = word.strip()\n    if len(word) < min_length or len(word) > max_length:\n        return False\n    if word.isdigit():\n        return False\n    return any(c.isalpha() or '\\u0980' <= c <= '\\u09FF' for c in word)\n\ndef detect_indic_language(word: str) -> Optional[str]:\n    return 'bn' if is_indic_word(word) else None\n\ndef get_tokenizer_special_tokens(tokenizer) -> set:\n    try:\n        if hasattr(tokenizer, \"all_special_tokens\"):\n            return set(tokenizer.all_special_tokens)\n        special = set()\n        for attr in [\"pad_token\", \"eos_token\", \"bos_token\", \"unk_token\", \"sep_token\", \"cls_token\"]:\n            token = getattr(tokenizer, attr, None)\n            if token:\n                special.add(token)\n        return special\n    except Exception:\n        return {\n            _BN_LANG_TOKEN, _EN_LANG_TOKEN,\n            _INDICBART_BOS_TOKEN, _INDICBART_EOS_TOKEN, \n            _INDICBART_PAD_TOKEN, _INDICBART_UNK_TOKEN,\n            \"bn_IN\", \"en_XX\", \"</s>\", \"<pad>\", \"<s>\", \"<unk>\"\n        }\n\ndef safe_offsets_tokenize(tokenizer, text: str, max_length: int = 48):\n    try:\n        enc = tokenizer(\n            text,\n            max_length=max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n            add_special_tokens=False,\n            return_offsets_mapping=False\n        )\n        return enc\n    except Exception:\n        enc = tokenizer(\n            text,\n            max_length=max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n            add_special_tokens=False\n        )\n        return enc\n\ndef reconstruct_word_spans(tokenizer, text: str, max_length: int = 48) -> Tuple[Dict[int, str], List[str]]:\n    try:\n        words = text.strip().split()\n        enc = tokenizer(\n            text,\n            max_length=max_length,\n            truncation=True,\n            add_special_tokens=False\n        )\n        token_ids = enc[\"input_ids\"]\n        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n        token_word_map = {}\n        word_idx = 0\n        for tok_idx, token in enumerate(tokens):\n            if word_idx < len(words):\n                token_word_map[tok_idx] = words[word_idx]\n                if token.startswith('‚ñÅ') and tok_idx > 0:\n                    word_idx += 1\n        return token_word_map, words\n    except Exception:\n        return {}, []\n\ndef format_indicbart_input(text: str, source_lang: str = None) -> str:\n    if source_lang is None:\n        source_lang = _BN_LANG_TOKEN\n    text = text.strip()\n    return f\"{text} {_INDICBART_EOS_TOKEN} {source_lang}\"\n\ndef format_indicbart_output(text: str, target_lang: str = None) -> str:\n    if target_lang is None:\n        target_lang = _EN_LANG_TOKEN\n    text = text.strip()\n    return f\"{target_lang} {text} {_INDICBART_EOS_TOKEN}\"\n\nclass BengaliWordTokenizer:\n    def __init__(self, vocab_size: int = 50000, vocab_file_or_dict: Optional[Dict] = None,\n                 language: str = 'bn', use_normalization: bool = True):\n        self.vocab_size = vocab_size\n        self.name_or_path = \"BengaliWordTokenizer\"\n        self.language = language\n        self.use_normalization = use_normalization\n        \n        self.pad_token = \"<PAD>\"\n        self.unk_token = \"<UNK>\"\n        self.bos_token = \"<BOS>\"\n        self.eos_token = \"<EOS>\"\n        \n        self.pad_token_id = 0\n        self.unk_token_id = 1\n        self.bos_token_id = 2\n        self.eos_token_id = 3\n        \n        if vocab_file_or_dict is not None:\n            self.word_to_id = dict(vocab_file_or_dict)\n            self.id_to_word = {v: k for k, v in self.word_to_id.items()}\n        else:\n            self.word_to_id = {\n                self.pad_token: self.pad_token_id,\n                self.unk_token: self.unk_token_id,\n                self.bos_token: self.bos_token_id,\n                self.eos_token: self.eos_token_id\n            }\n            self.id_to_word = {\n                self.pad_token_id: self.pad_token,\n                self.unk_token_id: self.unk_token,\n                self.bos_token_id: self.bos_token,\n                self.eos_token_id: self.eos_token\n            }\n        \n        self.next_id = len(self.word_to_id)\n        self.vocab = dict(self.word_to_id)\n        self._vocab_lock = False\n    \n    def build_vocab_from_texts(self, texts: List[str], min_frequency: int = 2):\n        print(f\"[CELL2] Building word vocabulary from {len(texts):,} texts...\")\n        word_counts = Counter()\n        for text in tqdm(texts, desc=\"Counting words\"):\n            words = text.strip().split()\n            for word in words:\n                normalized = normalize_indic_word(word, language=self.language) if self.use_normalization else word.strip()\n                if normalized:\n                    word_counts[normalized] += 1\n        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n        added = 0\n        for word, freq in sorted_words:\n            if freq < min_frequency:\n                continue\n            if word not in self.word_to_id:\n                if len(self.word_to_id) >= self.vocab_size:\n                    break\n                word_id = self.next_id\n                self.word_to_id[word] = word_id\n                self.id_to_word[word_id] = word\n                self.next_id += 1\n                added += 1\n        self.vocab = dict(self.word_to_id)\n        self._vocab_lock = True\n        self.vocab_size = len(self.vocab)\n        print(f\"[CELL2] Added {added:,} words to vocabulary (total: {len(self.vocab):,})\")\n        print(f\"[CELL2] ‚úì Vocabulary locked (no dynamic growth during encoding)\")\n    \n    def encode_text(self, text: str, max_length: int = 48) -> Tuple[List[int], List[str]]:\n        words = text.strip().split()\n        word_ids = []\n        word_strings = []\n        \n        for word in words:\n            if len(word_ids) >= max_length:\n                break\n            \n            normalized = normalize_indic_word(word, language=self.language) if self.use_normalization else word.strip()\n            \n            if not normalized:\n                continue\n            \n            if normalized not in self.word_to_id:\n                if not self._vocab_lock and len(self.word_to_id) < self.vocab_size:\n                    word_id = self.next_id\n                    self.word_to_id[normalized] = word_id\n                    self.id_to_word[word_id] = normalized\n                    self.vocab[normalized] = word_id\n                    self.next_id += 1\n                else:\n                    word_id = self.unk_token_id\n            else:\n                word_id = self.word_to_id[normalized]\n            \n            word_id = min(max(0, word_id), self.vocab_size - 1)\n            \n            word_ids.append(word_id)\n            word_strings.append(normalized)\n        \n        assert len(word_ids) == len(word_strings), f\"Length mismatch: {len(word_ids)} IDs vs {len(word_strings)} strings\"\n        \n        return word_ids, word_strings\n    \n    def encode(\n        self,\n        text: str,\n        max_length: int = 48,\n        add_special_tokens: bool = False,\n        padding: str = \"max_length\",\n        truncation: bool = True,\n        return_tensors: Optional[str] = None\n    ) -> Dict[str, Any]:\n        word_ids, word_strings = self.encode_text(text, max_length=max_length)\n        \n        if padding == \"max_length\":\n            pad_length = max_length - len(word_ids)\n            if pad_length > 0:\n                word_ids.extend([self.pad_token_id] * pad_length)\n                word_strings.extend([self.pad_token] * pad_length)\n        \n        if truncation and len(word_ids) > max_length:\n            word_ids = word_ids[:max_length]\n            word_strings = word_strings[:max_length]\n        \n        for i, wid in enumerate(word_ids):\n            if wid < 0 or wid >= self.vocab_size:\n                word_ids[i] = min(max(0, wid), self.vocab_size - 1)\n        \n        attention_mask = [1 if wid != self.pad_token_id else 0 for wid in word_ids]\n        \n        result = {\n            \"input_ids\": word_ids,\n            \"attention_mask\": attention_mask,\n            \"words\": word_strings\n        }\n        \n        if return_tensors == \"pt\":\n            result[\"input_ids\"] = torch.tensor(word_ids, dtype=torch.long)\n            result[\"attention_mask\"] = torch.tensor(attention_mask, dtype=torch.long)\n        \n        return result\n    \n    def decode(self, word_ids: List[int], skip_special_tokens: bool = True) -> str:\n        words = []\n        for wid in word_ids:\n            if skip_special_tokens and wid == self.pad_token_id:\n                continue\n            word = self.id_to_word.get(wid, self.unk_token)\n            if not skip_special_tokens or word != self.unk_token:\n                words.append(word)\n        return ' '.join(words)\n    \n    def convert_ids_to_tokens(self, ids: List[int]) -> List[str]:\n        return [self.id_to_word.get(id, self.unk_token) for id in ids]\n    \n    def convert_tokens_to_ids(self, tokens: List[str]) -> List[int]:\n        return [self.vocab.get(self.normalize_word(token), self.unk_token_id) for token in tokens]\n    \n    def normalize_word(self, word: str) -> str:\n        if self.use_normalization:\n            return normalize_indic_word(word, language=self.language)\n        return word.strip()\n    \n    def __call__(self, text: str, **kwargs):\n        return self.encode(text, **kwargs)\n    \n    def get_vocab(self) -> Dict[str, int]:\n        return dict(self.vocab)\n    \n    @property\n    def vocab_size_property(self) -> int:\n        return len(self.vocab)\n    \n    def tokenize(self, text: str, max_length: int = 48) -> List[str]:\n        _, word_strings = self.encode_text(text, max_length=max_length)\n        return word_strings\n\ndef build_word_vocabulary_from_csv(\n    csv_path: str,\n    num_samples: Optional[int] = None,\n    vocab_size: int = 50000,\n    min_frequency: int = 2,\n    source_column: str = 'src',\n    target_column: str = 'tgt',\n    language: str = 'bn'\n) -> Optional[BengaliWordTokenizer]:\n    if not _HAS_PANDAS:\n        print(\"[CELL2] ERROR: pandas not available; cannot build vocabulary\")\n        return None\n    \n    if not os.path.exists(csv_path):\n        print(f\"[CELL2] ERROR: CSV file not found: {csv_path}\")\n        return None\n    \n    print(\"=\"*80)\n    print(\"BUILDING WORD-LEVEL VOCABULARY (PATH 1)\")\n    print(\"=\"*80)\n    \n    try:\n        print(f\"[CELL2] Reading Bengali text from: {csv_path}\")\n        if num_samples is not None:\n            df = pd.read_csv(csv_path, nrows=num_samples)\n        else:\n            df = pd.read_csv(csv_path)\n        \n        if source_column not in df.columns or target_column not in df.columns:\n            print(f\"[CELL2] ERROR: Columns '{source_column}' or '{target_column}' not found. Available: {list(df.columns)}\")\n            return None\n        \n        print(f\"[CELL2] Loaded {len(df):,} rows from CSV\")\n        \n        bengali_texts = []\n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting Bengali text\"):\n            try:\n                src_text = str(row[source_column]).strip()\n                tgt_text = str(row[target_column]).strip()\n                \n                if is_bengali_text(src_text):\n                    text = src_text\n                elif is_bengali_text(tgt_text):\n                    text = tgt_text\n                else:\n                    continue\n                \n                if text and text.lower() != 'nan':\n                    text = normalize_bengali(text)\n                    if text:\n                        bengali_texts.append(text)\n            except Exception:\n                continue\n        \n        print(f\"[CELL2] Extracted {len(bengali_texts):,} valid Bengali texts\")\n        \n        if len(bengali_texts) == 0:\n            print(\"[CELL2] ERROR: No valid Bengali texts found\")\n            return None\n        \n        word_tokenizer = BengaliWordTokenizer(\n            vocab_size=vocab_size,\n            language=language,\n            use_normalization=True\n        )\n        \n        print(f\"[CELL2] Building vocabulary (max size: {vocab_size:,}, min freq: {min_frequency})...\")\n        word_tokenizer.build_vocab_from_texts(bengali_texts, min_frequency=min_frequency)\n        \n        print(\"=\"*80)\n        print(f\"‚úÖ Word vocabulary built successfully!\")\n        print(f\"   Vocabulary size: {len(word_tokenizer.vocab):,} words\")\n        print(f\"   Sample words: {list(word_tokenizer.vocab.keys())[4:14]}\")\n        print(f\"   Language: {word_tokenizer.language}\")\n        print(f\"   Normalization: {'ENABLED' if word_tokenizer.use_normalization else 'DISABLED'}\")\n        print(\"=\"*80)\n        \n        return word_tokenizer\n        \n    except Exception as e:\n        print(f\"[CELL2] ERROR building vocabulary: {type(e).__name__}: {str(e)}\")\n        traceback.print_exc()\n        return None\n\ndef _dataloader_worker_init_fn(worker_id: int):\n    worker_info = get_worker_info()\n    dataset = worker_info.dataset if worker_info is not None else None\n    \n    try:\n        if dataset is not None:\n            subword_tk = globals().get('tokenizer', None)\n            if subword_tk is not None:\n                dataset.m2m_tokenizer = subword_tk\n                dataset.m2m_is_fast = getattr(subword_tk, \"is_fast\", False)\n    except Exception:\n        if DEBUG_CELL2:\n            print(f\"[CELL2-WORKER] Subword tokenizer rebind failed in worker {worker_id}\")\n    \n    try:\n        if dataset is not None:\n            word_tk = globals().get('word_tokenizer', None)\n            if word_tk is not None:\n                dataset.word_tokenizer = word_tk\n    except Exception:\n        if DEBUG_CELL2:\n            print(f\"[CELL2-WORKER] Word tokenizer rebind failed in worker {worker_id}\")\n    \n    try:\n        base = int(os.environ.get(\"PYTHONHASHSEED\", \"0\"))\n        seed = (base ^ (worker_id + 1) ^ int(time.time())) & 0xFFFFFFFF\n        random.seed(seed)\n        np.random.seed(seed % (2**31 - 1))\n        torch.manual_seed(seed % (2**31 - 1))\n    except Exception:\n        pass\n\ndef load_and_preprocess_optimized(num_samples: Optional[int] = None) -> List[Tuple[str, str]]:\n    if num_samples is None:\n        num_samples = _NUM_SAMPLES\n    if num_samples <= 0:\n        raise ValueError(\"num_samples must be positive\")\n\n    print(f\"[CELL2] Loading up to {num_samples:,} samples from: {_DATASET_CSV_PATH}\")\n    \n    if not _HAS_PANDAS:\n        print(\"[CELL2] ERROR: pandas not available!\")\n        return _get_fallback_dataset()\n    \n    if not os.path.exists(_DATASET_CSV_PATH):\n        print(f\"[CELL2] ERROR: CSV file not found: {_DATASET_CSV_PATH}\")\n        return _get_fallback_dataset()\n    \n    try:\n        print(f\"[CELL2] Reading CSV file...\")\n        df = pd.read_csv(_DATASET_CSV_PATH)\n        \n        if 'src' not in df.columns or 'tgt' not in df.columns:\n            print(f\"[CELL2] ERROR: CSV missing required columns. Found: {list(df.columns)}\")\n            return _get_fallback_dataset()\n        \n        df = df.head(num_samples)\n        print(f\"[CELL2] Processing {len(df):,} rows...\")\n        \n        pairs: List[Tuple[str, str]] = []\n        skipped = 0\n        \n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading dataset\"):\n            try:\n                src_text = str(row['src']).strip()\n                tgt_text = str(row['tgt']).strip()\n                \n                if is_bengali_text(src_text):\n                    bn, en = src_text, tgt_text\n                else:\n                    bn, en = tgt_text, src_text\n                \n                if not en or not bn or en.lower() == 'nan' or bn.lower() == 'nan':\n                    skipped += 1\n                    continue\n                \n                max_words = max(40, _MAX_LENGTH)\n                if len(en.split()) > max_words or len(bn.split()) > max_words:\n                    skipped += 1\n                    continue\n                \n                bn_norm = normalize_bengali(bn)\n                en_norm = normalize_english(en)\n                \n                if not bn_norm or not en_norm:\n                    skipped += 1\n                    continue\n                \n                pairs.append((bn_norm, en_norm))\n                \n            except Exception as e:\n                skipped += 1\n                cell2_dbg(\"row_exception\", f\"Row exception idx={idx}: {type(e).__name__}\")\n                continue\n        \n        print(f\"[CELL2] Loaded {len(pairs):,} pairs, skipped {skipped:,} rows\")\n        \n        if len(pairs) == 0:\n            print(\"[CELL2] ERROR: No valid pairs loaded!\")\n            return _get_fallback_dataset()\n        \n        return pairs\n        \n    except Exception as e:\n        print(f\"[CELL2] ERROR loading CSV: {type(e).__name__}: {str(e)}\")\n        return _get_fallback_dataset()\n\ndef _get_fallback_dataset() -> List[Tuple[str, str]]:\n    print(\"[CELL2] Using fallback dataset (5 samples)\")\n    fallback_pairs = [\n        (\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\", \"i turned off the tap.\"),\n        (\"‡¶∏‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶™‡¶∞‡ßá ‡¶ï‡¶≤ ‡¶ï‡¶∞‡¶¨‡ßá‡•§\", \"he will call me later.\"),\n        (\"‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¶‡¶ø‡¶® ‡¶§‡¶æ‡¶ú‡¶æ ‡¶´‡¶≤ ‡¶ñ‡¶æ‡¶á‡•§\", \"we eat fresh fruits every day.\"),\n        (\"‡¶§‡¶æ‡¶∞ ‡¶ï‡¶†‡ßã‡¶∞ ‡¶™‡¶∞‡¶ø‡¶∂‡ßç‡¶∞‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶´‡¶≤ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§\", \"his hard work has brought good results.\"),\n        (\"‡¶ó‡¶æ‡¶õ‡ßá ‡¶®‡¶§‡ßÅ‡¶® ‡¶™‡¶æ‡¶§‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ó‡¶ú‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§\", \"new leaves have sprouted on the tree.\")\n    ]\n    return [(normalize_bengali(bn), normalize_english(en)) for bn, en in fallback_pairs]\n\nclass MemoryEfficientDataset(Dataset):\n    def __init__(\n        self, \n        pairs: List[Tuple[str, str]], \n        m2m_tokenizer: Any = None,\n        word_tokenizer: Optional[BengaliWordTokenizer] = None,\n        max_length: Optional[int] = None\n    ):\n        if max_length is None:\n            max_length = _MAX_LENGTH\n        self.max_length = int(max_length)\n        self.max_word_length = int(_MAX_WORD_LENGTH)\n        \n        self.m2m_tokenizer = m2m_tokenizer\n        self.m2m_is_fast = getattr(m2m_tokenizer, \"is_fast\", False) if m2m_tokenizer else False\n        self._m2m_name = getattr(m2m_tokenizer, \"name_or_path\", \"IndicBART\") if m2m_tokenizer else None\n        \n        self.word_tokenizer = word_tokenizer\n        self._word_name = getattr(word_tokenizer, \"name_or_path\", \"BengaliWord\") if word_tokenizer else None\n        \n        self.use_word_path = _USE_WORD_PATH and word_tokenizer is not None\n        self.use_subword_path = _USE_SUBWORD_PATH and m2m_tokenizer is not None\n        \n        self.pairs: List[Tuple[str, str]] = []\n        invalid = 0\n        \n        for i, p in enumerate(pairs):\n            try:\n                if not isinstance(p, (list, tuple)) or len(p) != 2:\n                    invalid += 1\n                    continue\n                \n                src, tgt = p\n                \n                if not isinstance(src, str) or not isinstance(tgt, str):\n                    invalid += 1\n                    continue\n                \n                if not src or not tgt:\n                    invalid += 1\n                    continue\n                \n                if len(src) > self.max_length * 20 or len(tgt) > self.max_length * 20:\n                    invalid += 1\n                    continue\n                \n                self.pairs.append((src, tgt))\n                \n            except Exception:\n                invalid += 1\n        \n        print(f\"[CELL2] Dataset initialized:\")\n        print(f\"  Valid pairs: {len(self.pairs):,}\")\n        print(f\"  Invalid pairs filtered: {invalid:,}\")\n        print(f\"  Path 1 (Word): {'ENABLED' if self.use_word_path else 'DISABLED'}\")\n        print(f\"  Path 2 (Subword): {'ENABLED' if self.use_subword_path else 'DISABLED'}\")\n        print(f\"  Model type: {_MODEL_TYPE}\")\n        print(f\"  Languages: {_SOURCE_LANGUAGE}‚Üí{_TARGET_LANGUAGE}\")\n\n        try:\n            self.special_tokens = get_tokenizer_special_tokens(self.m2m_tokenizer) if self.m2m_tokenizer else set()\n        except Exception:\n            self.special_tokens = {\n                _BN_LANG_TOKEN, _EN_LANG_TOKEN,\n                _INDICBART_BOS_TOKEN, _INDICBART_EOS_TOKEN,\n                _INDICBART_PAD_TOKEN, _INDICBART_UNK_TOKEN\n            }\n\n    def __getstate__(self):\n        state = self.__dict__.copy()\n        state['m2m_tokenizer'] = None\n        state['word_tokenizer'] = None\n        state['_m2m_name'] = self._m2m_name\n        state['_word_name'] = self._word_name\n        return state\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        try:\n            self.m2m_tokenizer = globals().get('tokenizer', None)\n            self.m2m_is_fast = getattr(self.m2m_tokenizer, \"is_fast\", False) if self.m2m_tokenizer else False\n            self.word_tokenizer = globals().get('word_tokenizer', None)\n        except Exception:\n            self.m2m_tokenizer = None\n            self.word_tokenizer = None\n\n    def __len__(self) -> int:\n        return len(self.pairs)\n\n    def _encode_src_subword(self, src_text: str):\n        if not self.use_subword_path or self.m2m_tokenizer is None:\n            pad_id = 1\n            return torch.full((self.max_length,), pad_id, dtype=torch.long), \\\n                   torch.zeros(self.max_length, dtype=torch.long)\n        \n        try:\n            enc = safe_offsets_tokenize(self.m2m_tokenizer, src_text, max_length=self.max_length)\n            input_ids = enc[\"input_ids\"].squeeze(0) if isinstance(enc[\"input_ids\"], torch.Tensor) else torch.tensor(enc[\"input_ids\"][0])\n            attention_mask = enc.get(\"attention_mask\", torch.ones_like(input_ids))\n            if isinstance(attention_mask, list):\n                attention_mask = torch.tensor(attention_mask[0]) if attention_mask else torch.ones_like(input_ids)\n            elif isinstance(attention_mask, torch.Tensor) and attention_mask.dim() > 1:\n                attention_mask = attention_mask.squeeze(0)\n            \n            return input_ids, attention_mask\n            \n        except Exception:\n            pad_id = getattr(self.m2m_tokenizer, \"pad_token_id\", 1) if self.m2m_tokenizer else 1\n            return torch.full((self.max_length,), pad_id, dtype=torch.long), \\\n                   torch.zeros(self.max_length, dtype=torch.long)\n\n    def _encode_src_word(self, src_text: str):\n        if not self.use_word_path or self.word_tokenizer is None:\n            return torch.zeros(self.max_word_length, dtype=torch.long), \\\n                   torch.zeros(self.max_word_length, dtype=torch.long), []\n        \n        try:\n            enc = self.word_tokenizer.encode(\n                src_text,\n                max_length=self.max_word_length,\n                add_special_tokens=False,\n                padding=\"max_length\",\n                truncation=True,\n                return_tensors=\"pt\"\n            )\n            \n            word_input_ids = enc[\"input_ids\"]\n            if word_input_ids.dim() > 1:\n                word_input_ids = word_input_ids.squeeze(0)\n            \n            word_attention_mask = enc[\"attention_mask\"]\n            if word_attention_mask.dim() > 1:\n                word_attention_mask = word_attention_mask.squeeze(0)\n            \n            word_strings = enc.get(\"words\", [])\n            if word_strings is None:\n                word_strings = []\n            \n            return word_input_ids, word_attention_mask, word_strings\n            \n        except Exception as e:\n            cell2_dbg(\"word_encode_fail\", f\"Word encoding failed: {type(e).__name__}\")\n            return torch.zeros(self.max_word_length, dtype=torch.long), \\\n                   torch.zeros(self.max_word_length, dtype=torch.long), []\n\n    def _encode_tgt(self, tgt_text: str):\n        if not self.use_subword_path or self.m2m_tokenizer is None:\n            return torch.full((self.max_length,), -100, dtype=torch.long)\n        \n        try:\n            dec = self.m2m_tokenizer(\n                tgt_text,\n                max_length=self.max_length,\n                padding=\"max_length\",\n                truncation=True,\n                return_tensors=\"pt\",\n                add_special_tokens=False\n            )\n            labels = dec[\"input_ids\"].squeeze(0)\n            pad_id = getattr(self.m2m_tokenizer, \"pad_token_id\", 1)\n            labels[labels == int(pad_id)] = -100\n            return labels\n        except Exception:\n            return torch.full((self.max_length,), -100, dtype=torch.long)\n\n    def _make_safe_sample(self, src_text: str = \"\"):\n        pad_id = 1\n        return {\n            \"input_ids\": torch.full((self.max_length,), pad_id, dtype=torch.long),\n            \"attention_mask\": torch.zeros(self.max_length, dtype=torch.long),\n            \"labels\": torch.full((self.max_length,), -100, dtype=torch.long),\n            \"word_input_ids\": torch.zeros(self.max_word_length, dtype=torch.long),\n            \"word_attention_mask\": torch.zeros(self.max_word_length, dtype=torch.long),\n            \"word_strings\": [],\n            \"src_text\": src_text\n        }\n\n    def __getitem__(self, idx: int) -> Dict[str, Any]:\n        try:\n            if idx < 0 or idx >= len(self.pairs):\n                return self._make_safe_sample()\n            \n            src, tgt = self.pairs[idx]\n            \n            if not isinstance(src, str) or not isinstance(tgt, str):\n                return self._make_safe_sample()\n\n            input_ids, attention_mask = self._encode_src_subword(src)\n            labels = self._encode_tgt(tgt)\n            word_input_ids, word_attention_mask, word_strings = self._encode_src_word(src)\n\n            return {\n                \"input_ids\": input_ids,\n                \"attention_mask\": attention_mask,\n                \"labels\": labels,\n                \"word_input_ids\": word_input_ids,\n                \"word_attention_mask\": word_attention_mask,\n                \"word_strings\": word_strings,\n                \"src_text\": src\n            }\n        except Exception:\n            return self._make_safe_sample()\n\ndef _infer_pad_id_from_sample(sample: Dict[str, Any], default_pad_id: int = 1) -> int:\n    try:\n        tk = globals().get(\"tokenizer\", None)\n        if tk is not None:\n            pad = getattr(tk, \"pad_token_id\", None)\n            if pad is not None:\n                return int(pad)\n    except Exception:\n        pass\n    return int(default_pad_id)\n\ndef _pad_or_truncate_array(tensor: torch.Tensor, length: int, pad_value: int) -> torch.Tensor:\n    if tensor is None:\n        return torch.full((length,), int(pad_value), dtype=torch.long)\n    \n    t = tensor.view(-1).long()\n    L = t.size(0)\n    \n    if L == length:\n        return t\n    if L < length:\n        pad = torch.full((length - L,), int(pad_value), dtype=t.dtype)\n        return torch.cat([t, pad], dim=0)\n    return t[:length]\n\ndef _pad_word_strings_list(word_list: List[str], max_length: int, pad_value: str = \"<PAD>\") -> List[str]:\n    if not isinstance(word_list, list):\n        return [pad_value] * max_length\n    \n    current_len = len(word_list)\n    \n    if current_len == max_length:\n        return word_list\n    elif current_len < max_length:\n        return word_list + [pad_value] * (max_length - current_len)\n    else:\n        return word_list[:max_length]\n\ndef safe_collate(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n    valid = [b for b in batch if isinstance(b, dict) and \"input_ids\" in b]\n    \n    if not valid:\n        pad = 1\n        return {\n            \"input_ids\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"attention_mask\": torch.zeros(1, _MAX_LENGTH, dtype=torch.long),\n            \"labels\": torch.full((1, _MAX_LENGTH), -100, dtype=torch.long),\n            \"word_input_ids\": torch.zeros(1, _MAX_WORD_LENGTH, dtype=torch.long),\n            \"word_attention_mask\": torch.zeros(1, _MAX_WORD_LENGTH, dtype=torch.long),\n            \"word_strings\": [[]],\n            \"src_text\": [\"\"]\n        }\n\n    pad_id = _infer_pad_id_from_sample(valid[0], default_pad_id=1)\n\n    inputs, masks, labs = [], [], []\n    word_inputs, word_masks, word_strs = [], [], []\n    src_texts = []\n    \n    for s in valid:\n        try:\n            in_ids = _pad_or_truncate_array(s[\"input_ids\"], _MAX_LENGTH, pad_id)\n            att = _pad_or_truncate_array(s.get(\"attention_mask\", torch.zeros(_MAX_LENGTH)), _MAX_LENGTH, 0)\n            lab = _pad_or_truncate_array(s[\"labels\"], _MAX_LENGTH, -100)\n            \n            inputs.append(in_ids)\n            masks.append(att)\n            labs.append(lab)\n            \n            w_ids = _pad_or_truncate_array(s.get(\"word_input_ids\", torch.zeros(_MAX_WORD_LENGTH)), _MAX_WORD_LENGTH, 0)\n            w_att = _pad_or_truncate_array(s.get(\"word_attention_mask\", torch.zeros(_MAX_WORD_LENGTH)), _MAX_WORD_LENGTH, 0)\n            \n            word_inputs.append(w_ids)\n            word_masks.append(w_att)\n            \n            raw_word_strs = s.get(\"word_strings\", [])\n            if raw_word_strs is None:\n                raw_word_strs = []\n            padded_word_strs = _pad_word_strings_list(raw_word_strs, _MAX_WORD_LENGTH, pad_value=\"<PAD>\")\n            word_strs.append(padded_word_strs)\n            \n            src_texts.append(s.get(\"src_text\", \"\"))\n            \n        except Exception as e:\n            cell2_dbg(\"collate_exc\", f\"Collate exception: {type(e).__name__}\")\n            continue\n\n    if not inputs:\n        pad = 1\n        return {\n            \"input_ids\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"attention_mask\": torch.zeros(1, _MAX_LENGTH, dtype=torch.long),\n            \"labels\": torch.full((1, _MAX_LENGTH), -100, dtype=torch.long),\n            \"word_input_ids\": torch.zeros(1, _MAX_WORD_LENGTH, dtype=torch.long),\n            \"word_attention_mask\": torch.zeros(1, _MAX_WORD_LENGTH, dtype=torch.long),\n            \"word_strings\": [[]],\n            \"src_text\": [\"\"]\n        }\n\n    input_ids = torch.stack(inputs, dim=0)\n    attention_mask = torch.stack(masks, dim=0)\n    labels = torch.stack(labs, dim=0)\n    word_input_ids = torch.stack(word_inputs, dim=0)\n    word_attention_mask = torch.stack(word_masks, dim=0)\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 0:\n        bsz = input_ids.size(0)\n        keep = (bsz // _NUM_GPUS) * _NUM_GPUS\n        if keep > 0 and keep < bsz:\n            input_ids = input_ids[:keep]\n            attention_mask = attention_mask[:keep]\n            labels = labels[:keep]\n            word_input_ids = word_input_ids[:keep]\n            word_attention_mask = word_attention_mask[:keep]\n            word_strs = word_strs[:keep]\n            src_texts = src_texts[:keep]\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels,\n        \"word_input_ids\": word_input_ids,\n        \"word_attention_mask\": word_attention_mask,\n        \"word_strings\": word_strs,\n        \"src_text\": src_texts\n    }\n\ndef create_optimized_dataloader(\n    dataset: Dataset, \n    batch_size: Optional[int] = None, \n    shuffle: bool = True\n) -> DataLoader:\n    if batch_size is None:\n        try:\n            batch_size = int(BATCH_SIZE)\n        except NameError:\n            batch_size = 48\n    batch_size = int(batch_size)\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 0 and batch_size % _NUM_GPUS != 0:\n        adjusted = (batch_size // _NUM_GPUS) * _NUM_GPUS\n        if adjusted == 0:\n            print(f\"[CELL2] WARNING: batch_size {batch_size} < num_gpus {_NUM_GPUS}\")\n        else:\n            print(f\"[CELL2] Adjusting batch_size {batch_size} ‚Üí {adjusted} (DP-divisible)\")\n            batch_size = adjusted\n\n    num_workers = _NUM_WORKERS if isinstance(_NUM_WORKERS, int) and _NUM_WORKERS >= 0 else 0\n    try:\n        max_possible = max(0, (os.cpu_count() or 1) - 1)\n        if num_workers > max_possible:\n            num_workers = max_possible\n    except Exception:\n        pass\n\n    loader_kwargs = {\n        \"dataset\": dataset,\n        \"batch_size\": batch_size,\n        \"shuffle\": shuffle,\n        \"num_workers\": num_workers,\n        \"pin_memory\": bool(_PIN_MEMORY and torch.cuda.is_available()),\n        \"collate_fn\": safe_collate,\n        \"drop_last\": False,\n    }\n    \n    if num_workers > 0:\n        loader_kwargs[\"worker_init_fn\"] = _dataloader_worker_init_fn\n        loader_kwargs[\"prefetch_factor\"] = _PREFETCH_FACTOR\n        loader_kwargs[\"persistent_workers\"] = False\n\n    try:\n        dataloader = DataLoader(**loader_kwargs)\n    except Exception as e:\n        print(f\"[CELL2] DataLoader init failed: {type(e).__name__}\")\n        print(\"[CELL2] Retrying with num_workers=0\")\n        loader_kwargs[\"num_workers\"] = 0\n        loader_kwargs.pop(\"prefetch_factor\", None)\n        loader_kwargs.pop(\"persistent_workers\", None)\n        loader_kwargs.pop(\"worker_init_fn\", None)\n        dataloader = DataLoader(**loader_kwargs)\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 0:\n        per_gpu = batch_size // _NUM_GPUS if _NUM_GPUS > 0 else batch_size\n        print(f\"[CELL2] DataLoader: total_batch={batch_size}, per_gpu={per_gpu}, workers={loader_kwargs.get('num_workers', 0)}\")\n    else:\n        print(f\"[CELL2] DataLoader: batch_size={batch_size}, workers={loader_kwargs.get('num_workers', 0)}\")\n\n    return dataloader\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ Cell 2: Dual-Path Data Loading (IndicBART-Ready - 40 FIXES)!\")\nprint(\"=\"*80)\nprint(\"üî• NEW FIX #39 (CRITICAL - CUDA ERROR FIX):\")\nprint(\"  ‚Ä¢ Updated self.vocab_size after build_vocab_from_texts()\")\nprint(\"  ‚Ä¢ Ensures vocab_size matches actual vocabulary length\")\nprint(\"  ‚Ä¢ Prevents CUDA assertion: srcIndex < srcSelectDimSize\")\nprint(\"\\nüî• NEW FIX #40 (TYPO FIX):\")\nprint(\"  ‚Ä¢ Fixed undefined variable 'length' ‚Üí 'max_length'\")\nprint(\"  ‚Ä¢ Location: _pad_word_strings_list() function\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"id":"5MkHgCN7H4J1","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:23.024985Z","iopub.execute_input":"2026-01-24T20:09:23.025581Z","iopub.status.idle":"2026-01-24T20:09:23.120463Z","shell.execute_reply.started":"2026-01-24T20:09:23.025547Z","shell.execute_reply":"2026-01-24T20:09:23.119878Z"}},"outputs":[{"name":"stdout","text":"[CELL2] Configuration loaded:\n  Model type: indicbart\n  Languages: bn‚Üíen\n  IndicBART tokens: source='<2bn>', target='<2en>'\n  Language codes: source='bn', target='en'\n  Special tokens: BOS='<s>', EOS='</s>', PAD='<pad>'\n  Max length: 48 (subword), 48 (word)\n  Dual-path: Word=True, Subword=True\n\n================================================================================\n‚úÖ Cell 2: Dual-Path Data Loading (IndicBART-Ready - 40 FIXES)!\n================================================================================\nüî• NEW FIX #39 (CRITICAL - CUDA ERROR FIX):\n  ‚Ä¢ Updated self.vocab_size after build_vocab_from_texts()\n  ‚Ä¢ Ensures vocab_size matches actual vocabulary length\n  ‚Ä¢ Prevents CUDA assertion: srcIndex < srcSelectDimSize\n\nüî• NEW FIX #40 (TYPO FIX):\n  ‚Ä¢ Fixed undefined variable 'length' ‚Üí 'max_length'\n  ‚Ä¢ Location: _pad_word_strings_list() function\n================================================================================\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ==============================================================================\n# CELL 3: WORD-LEVEL DSCD MODULE (IndicBART-READY - 12 CRITICAL FIXES)\n# ==============================================================================\n# Critical fixes applied for IndicBART compatibility:\n# 1. SYNCHRONOUS clustering (no threading) - guarantees prototypes created\n# 2. Reduced buffer thresholds (5 samples instead of 20) - faster detection\n# 3. Reduced n_min (2 instead of 5) - works with limited data\n# 4. Fixed tensor device handling in buffer append\n# 5. Improved word key normalization with better caching\n# 6. Reduced clustering cooldown (5s instead of 60s)\n# 7. Added force_sync_clustering flag for training stability\n# üî• FIX #8: CRITICAL - Accept word_input_ids + word_attention_mask (Cell 6 compatibility)\n# üî• FIX #9: CRITICAL - Add word tokenizer for ID-to-string conversion\n# üî• FIX #10: IndicBART language token support\n# üî• FIX #11: Aligned with Cell 0 config parameters\n# üî• FIX #12: Added proper error handling for missing globals\n# ==============================================================================\n\nimport threading\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport gc\nimport math\nfrom collections import deque\nimport unicodedata\nfrom typing import Optional, List, Tuple, Dict\n\n# ==============================================================================\n# CONFIGURATION FROM CELL 0\n# ==============================================================================\n\n# Print interval\ntry:\n    PRINT_INTERVAL = int(PRINT_INTERVAL)\nexcept (NameError, ValueError):\n    PRINT_INTERVAL = 500\n    print(\"[CELL3] WARNING: PRINT_INTERVAL not defined, using default 500\")\n\n# Verbose logging\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept NameError:\n    VERBOSE_LOGGING = False\n    print(\"[CELL3] WARNING: VERBOSE_LOGGING not defined, using False\")\n\n# ==============================================================================\n# DSCD CONFIGURATION (FROM CELL 0)\n# ==============================================================================\n\n# üîß FIX #11: Align all parameters with Cell 0 config\ntry:\n    DSCD_MAX_PROTOS = int(DSCD_MAX_PROTOS)\nexcept (NameError, ValueError):\n    DSCD_MAX_PROTOS = 8\n    print(\"[CELL3] WARNING: DSCD_MAX_PROTOS not defined, using default 8\")\n\ntry:\n    DSCD_BUFFER_SIZE = int(DSCD_BUFFER_SIZE)\nexcept (NameError, ValueError):\n    DSCD_BUFFER_SIZE = 20\n    print(\"[CELL3] WARNING: DSCD_BUFFER_SIZE not defined, using default 20\")\n\ntry:\n    DSCD_N_MIN = int(DSCD_N_MIN)\nexcept (NameError, ValueError):\n    DSCD_N_MIN = 2\n    print(\"[CELL3] WARNING: DSCD_N_MIN not defined, using default 2\")\n\ntry:\n    DSCD_DISPERSION_THRESHOLD = float(DSCD_DISPERSION_THRESHOLD)\nexcept (NameError, ValueError):\n    DSCD_DISPERSION_THRESHOLD = 0.25\n    print(\"[CELL3] WARNING: DSCD_DISPERSION_THRESHOLD not defined, using default 0.25\")\n\ntry:\n    DSCD_EMBED_DIM = int(DSCD_EMBED_DIM)\nexcept (NameError, ValueError):\n    DSCD_EMBED_DIM = 256\n    print(\"[CELL3] WARNING: DSCD_EMBED_DIM not defined, using default 256\")\n\ntry:\n    DSCD_TEMPERATURE = float(DSCD_TEMPERATURE)\nexcept (NameError, ValueError):\n    DSCD_TEMPERATURE = 0.7\n    print(\"[CELL3] WARNING: DSCD_TEMPERATURE not defined, using default 0.7\")\n\ntry:\n    DSCD_DROPOUT = float(DSCD_DROPOUT)\nexcept (NameError, ValueError):\n    DSCD_DROPOUT = 0.1\n    print(\"[CELL3] WARNING: DSCD_DROPOUT not defined, using default 0.1\")\n\ntry:\n    DSCD_AUGMENT_SCALE = float(DSCD_AUGMENT_SCALE)\nexcept (NameError, ValueError):\n    DSCD_AUGMENT_SCALE = 0.1\n    print(\"[CELL3] WARNING: DSCD_AUGMENT_SCALE not defined, using default 0.1\")\n\ntry:\n    DSCD_UNCERTAINTY_THRESHOLD = float(DSCD_UNCERTAINTY_THRESHOLD)\nexcept (NameError, ValueError):\n    DSCD_UNCERTAINTY_THRESHOLD = 0.4\n    print(\"[CELL3] WARNING: DSCD_UNCERTAINTY_THRESHOLD not defined, using default 0.4\")\n\ntry:\n    DSCD_MAX_CLUSTERING_POINTS = int(DSCD_MAX_CLUSTERING_POINTS)\nexcept (NameError, ValueError):\n    DSCD_MAX_CLUSTERING_POINTS = 500\n    print(\"[CELL3] WARNING: DSCD_MAX_CLUSTERING_POINTS not defined, using default 500\")\n\ntry:\n    DSCD_ENABLE_TRAINING_CLUSTERING = bool(DSCD_ENABLE_TRAINING_CLUSTERING)\nexcept (NameError, ValueError):\n    DSCD_ENABLE_TRAINING_CLUSTERING = True\n    print(\"[CELL3] WARNING: DSCD_ENABLE_TRAINING_CLUSTERING not defined, using default True\")\n\ntry:\n    DSCD_WARMUP_SAMPLES = int(DSCD_WARMUP_SAMPLES)\nexcept (NameError, ValueError):\n    DSCD_WARMUP_SAMPLES = 8000\n    print(\"[CELL3] WARNING: DSCD_WARMUP_SAMPLES not defined, using default 8000\")\n\n# Additional thresholds\ntry:\n    SPAN_THRESHOLD = float(SPAN_THRESHOLD)\nexcept (NameError, ValueError):\n    SPAN_THRESHOLD = 0.3\n    print(\"[CELL3] WARNING: SPAN_THRESHOLD not defined, using default 0.3\")\n\nDSCD_SPAN_THRESHOLD = SPAN_THRESHOLD\n\ntry:\n    DSCD_AUGMENT_SIM_THRESHOLD = 0.3\nexcept:\n    DSCD_AUGMENT_SIM_THRESHOLD = 0.3\n\n# Word length constraints\ntry:\n    _WORD_MIN_LENGTH = int(WORD_MIN_LENGTH)\nexcept (NameError, ValueError):\n    _WORD_MIN_LENGTH = 2\n    print(\"[CELL3] WARNING: WORD_MIN_LENGTH not defined, using default 2\")\n\ntry:\n    _WORD_MAX_LENGTH = int(WORD_MAX_LENGTH)\nexcept (NameError, ValueError):\n    _WORD_MAX_LENGTH = 30\n    print(\"[CELL3] WARNING: WORD_MAX_LENGTH not defined, using default 30\")\n\n# Homograph watchlist\ntry:\n    HOMOGRAPH_WATCHLIST_BN = set(HOMOGRAPH_WATCHLIST_BN)\nexcept (NameError, ValueError):\n    HOMOGRAPH_WATCHLIST_BN = {\"‡¶ï‡¶≤\", \"‡¶ï‡¶æ‡¶≤\", \"‡¶™‡¶æ‡¶§‡¶æ\", \"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï\", \"‡¶´‡¶≤\", \"‡¶Æ‡¶æ‡¶•‡¶æ\"}\n    print(\"[CELL3] WARNING: HOMOGRAPH_WATCHLIST_BN not defined, using default set\")\n\n# Source language (for normalization)\ntry:\n    _SOURCE_LANGUAGE = SOURCE_LANGUAGE\nexcept NameError:\n    _SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL3] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n\n# ==============================================================================\n# OPTIONAL LIBRARY IMPORTS\n# ==============================================================================\n\n# SciPy hierarchical clustering (optional)\ntry:\n    from scipy.cluster.hierarchy import linkage, fcluster\n    from scipy.spatial.distance import pdist\n    HAS_CLUSTERING = True\nexcept Exception:\n    HAS_CLUSTERING = False\n    print(\"[CELL3] WARNING: scipy not available - hierarchical clustering disabled\")\n\n# sklearn KMeans (optional)\ntry:\n    from sklearn.cluster import KMeans\n    HAS_KMEANS = True\nexcept Exception:\n    HAS_KMEANS = False\n    print(\"[CELL3] WARNING: sklearn not available - KMeans fallback disabled\")\n\nprint(f\"[CELL3] Configuration loaded:\")\nprint(f\"  Buffer size: {DSCD_BUFFER_SIZE}\")\nprint(f\"  n_min: {DSCD_N_MIN}\")\nprint(f\"  Max prototypes: {DSCD_MAX_PROTOS}\")\nprint(f\"  Embed dim: {DSCD_EMBED_DIM}\")\nprint(f\"  Temperature: {DSCD_TEMPERATURE}\")\nprint(f\"  Uncertainty threshold: {DSCD_UNCERTAINTY_THRESHOLD}\")\nprint(f\"  Enable training clustering: {DSCD_ENABLE_TRAINING_CLUSTERING}\")\nprint(f\"  Max clustering points: {DSCD_MAX_CLUSTERING_POINTS}\")\nprint(f\"  scipy: {'AVAILABLE' if HAS_CLUSTERING else 'NOT AVAILABLE'}\")\nprint(f\"  sklearn: {'AVAILABLE' if HAS_KMEANS else 'NOT AVAILABLE'}\")\n\n# ==============================================================================\n# IMPORT NORMALIZATION FUNCTIONS FROM CELL 1\n# ==============================================================================\n\ntry:\n    from __main__ import normalize_indic_word, is_indic_word, validate_word_token, detect_indic_language\n    HAS_INDIC_NORMALIZATION = True\n    print(\"[CELL3] ‚úÖ Imported normalization functions from Cell 1\")\nexcept:\n    try:\n        normalize_indic_word = globals().get('normalize_indic_word', None)\n        is_indic_word = globals().get('is_indic_word', None)\n        validate_word_token = globals().get('validate_word_token', None)\n        detect_indic_language = globals().get('detect_indic_language', None)\n        HAS_INDIC_NORMALIZATION = all([normalize_indic_word, is_indic_word, validate_word_token, detect_indic_language])\n        if HAS_INDIC_NORMALIZATION:\n            print(\"[CELL3] ‚úÖ Found normalization functions in globals\")\n        else:\n            print(\"[CELL3] ‚ö†Ô∏è Normalization functions not found - using fallback\")\n    except:\n        HAS_INDIC_NORMALIZATION = False\n        print(\"[CELL3] ‚ö†Ô∏è Normalization functions not found - using fallback\")\n\n# Fallback if normalization not available\nif not HAS_INDIC_NORMALIZATION:\n    def normalize_indic_word(word, language=None):\n        \"\"\"Fallback normalization: Unicode NFKC + strip.\"\"\"\n        if not word:\n            return \"\"\n        try:\n            return unicodedata.normalize(\"NFKC\", str(word)).strip()\n        except:\n            return str(word).strip()\n    \n    def is_indic_word(word):\n        \"\"\"Check if word contains Bengali Unicode characters.\"\"\"\n        if not word:\n            return False\n        return any('\\u0980' <= c <= '\\u09FF' for c in str(word))\n    \n    def validate_word_token(word, min_length=2, max_length=30):\n        \"\"\"Validate word token for tracking.\"\"\"\n        if not word:\n            return False\n        word = str(word).strip()\n        if len(word) < min_length or len(word) > max_length:\n            return False\n        if word.isdigit():\n            return False\n        return any(c.isalpha() or '\\u0980' <= c <= '\\u09FF' for c in word)\n    \n    def detect_indic_language(word):\n        \"\"\"Detect if word is Bengali.\"\"\"\n        return 'bn' if is_indic_word(word) else None\n    \n    print(\"[CELL3] ‚ö†Ô∏è Using fallback normalization functions\")\n\n# ==============================================================================\n# üî• FIX #9: IMPORT WORD TOKENIZER FROM CELL 2\n# ==============================================================================\n\ntry:\n    from __main__ import BengaliWordTokenizer\n    HAS_WORD_TOKENIZER = True\n    print(\"[CELL3] ‚úÖ Imported BengaliWordTokenizer from Cell 2\")\nexcept:\n    try:\n        BengaliWordTokenizer = globals().get('BengaliWordTokenizer', None)\n        HAS_WORD_TOKENIZER = BengaliWordTokenizer is not None\n        if HAS_WORD_TOKENIZER:\n            print(\"[CELL3] ‚úÖ Found BengaliWordTokenizer in globals\")\n        else:\n            print(\"[CELL3] ‚ö†Ô∏è BengaliWordTokenizer not found\")\n    except:\n        HAS_WORD_TOKENIZER = False\n        print(\"[CELL3] ‚ö†Ô∏è BengaliWordTokenizer not found from Cell 2\")\n\n\n# ==============================================================================\n# NUMPY KMEANS IMPLEMENTATION\n# ==============================================================================\n\ndef _numpy_kmeans(X: np.ndarray, n_clusters: int, n_iter: int = 10, random_state: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Simple KMeans implemented with numpy.\n    \n    Args:\n        X: Data matrix [N, D]\n        n_clusters: Number of clusters\n        n_iter: Maximum iterations\n        random_state: Random seed\n    \n    Returns:\n        (labels, centroids) where labels is [N] and centroids is [K, D]\n    \"\"\"\n    X = np.asarray(X, dtype=np.float32)\n    N, D = X.shape\n    if N == 0:\n        return np.zeros((0,), dtype=np.int32), np.zeros((0, D), dtype=np.float32)\n    n_clusters = int(max(1, min(n_clusters, N)))\n    rng = np.random.RandomState(random_state)\n\n    # Initialize centroids with k-means++\n    centroids = np.empty((n_clusters, D), dtype=np.float32)\n    first_idx = rng.randint(0, N)\n    centroids[0] = X[first_idx]\n    for k in range(1, n_clusters):\n        dists = np.linalg.norm(X[:, None, :] - centroids[None, :k, :], axis=2)\n        nearest = dists.min(axis=1)\n        probs = nearest / (nearest.sum() + 1e-12)\n        chosen = rng.choice(N, p=probs)\n        centroids[k] = X[chosen]\n\n    # Lloyd's algorithm\n    labels = np.zeros(N, dtype=np.int32)\n    for it in range(n_iter):\n        dists = np.linalg.norm(X[:, None, :] - centroids[None, :, :], axis=2)\n        new_labels = dists.argmin(axis=1)\n        changed = False\n        for j in range(n_clusters):\n            members = (new_labels == j)\n            if members.sum() == 0:\n                centroids[j] = X[rng.randint(0, N)]\n                changed = True\n            else:\n                new_cent = X[members].mean(axis=0)\n                if not np.allclose(new_cent, centroids[j], atol=1e-6):\n                    centroids[j] = new_cent.astype(np.float32)\n                    changed = True\n        labels = new_labels\n        if not changed:\n            break\n    return labels, centroids\n\n\n# ==============================================================================\n# PROTOTYPE STORE (CPU-BASED)\n# ==============================================================================\n\nclass MemoryEfficientPrototypeStore:\n    \"\"\"\n    CPU-based prototype storage with rolling statistics.\n    Stores word sense prototypes discovered by DSCD clustering.\n    \"\"\"\n    \n    def __init__(self, embed_dim: int, max_protos: Optional[int] = None):\n        \"\"\"\n        Initialize prototype store.\n        \n        Args:\n            embed_dim: Embedding dimension\n            max_protos: Maximum number of prototypes to store\n        \"\"\"\n        self.embed_dim = int(embed_dim)\n        self.max_protos = int(max_protos) if max_protos is not None else DSCD_MAX_PROTOS\n        self.centroids: List[torch.Tensor] = []\n        self.counts: List[int] = []\n        self.creation_time: List[float] = []\n        self.distances: List[float] = []\n        self.mu: float = 0.0\n        self.tau: float = 1e-6\n        self.alpha: float = 0.1\n\n    def add_prototype(self, vector, current_time=None, count=1):\n        \"\"\"\n        Add new prototype or replace least-used if at capacity.\n        \n        Args:\n            vector: Prototype vector (torch.Tensor or numpy array)\n            current_time: Creation timestamp\n            count: Initial count\n        \"\"\"\n        if current_time is None:\n            current_time = time.time()\n        try:\n            if isinstance(vector, torch.Tensor):\n                v = vector.detach().cpu().float().clone()\n            else:\n                v = torch.from_numpy(np.asarray(vector, dtype=np.float32)).cpu()\n        except Exception:\n            return\n        \n        if len(self.centroids) < self.max_protos:\n            self.centroids.append(v)\n            self.counts.append(int(count))\n            self.creation_time.append(current_time)\n            return\n        \n        # Replace least-used prototype\n        try:\n            min_idx = int(np.argmin(self.counts)) if self.counts else 0\n        except Exception:\n            min_idx = 0\n        \n        min_idx = max(0, min(min_idx, len(self.centroids) - 1))\n        if min_idx < len(self.centroids):\n            self.centroids[min_idx] = v\n            self.counts[min_idx] = int(count)\n            self.creation_time[min_idx] = current_time\n        else:\n            self.centroids.append(v)\n            self.counts.append(int(count))\n            self.creation_time.append(current_time)\n\n    def update_prototype(self, idx, vector, eta=0.05, assignment_distance=None):\n        \"\"\"\n        Update existing prototype with momentum.\n        \n        Args:\n            idx: Prototype index\n            vector: New vector\n            eta: Learning rate\n            assignment_distance: Distance for statistics\n        \"\"\"\n        try:\n            if idx < 0 or idx >= len(self.centroids):\n                self.add_prototype(vector, time.time(), count=1)\n                return\n            \n            old = self.centroids[idx]\n            newv = vector.detach().cpu() if isinstance(vector, torch.Tensor) else torch.from_numpy(np.asarray(vector, dtype=np.float32)).cpu()\n            \n            try:\n                self.centroids[idx] = (1.0 - eta) * old + eta * newv\n            except Exception:\n                self.centroids[idx] = newv.clone()\n            \n            try:\n                self.counts[idx] = int(self.counts[idx]) + 1\n            except Exception:\n                while len(self.counts) < len(self.centroids):\n                    self.counts.append(1)\n                self.counts[idx] = int(self.counts[idx]) + 1\n        except Exception:\n            try:\n                self.add_prototype(vector, time.time(), count=1)\n            except Exception:\n                pass\n        \n        if assignment_distance is not None:\n            try:\n                self.update_rolling_stats(float(assignment_distance))\n            except Exception:\n                pass\n\n    def update_rolling_stats(self, d: float):\n        \"\"\"\n        Update rolling mean/std of assignment distances.\n        \n        Args:\n            d: Distance value\n        \"\"\"\n        try:\n            if not self.distances:\n                self.mu = float(d)\n                self.tau = 1e-6\n                self.distances = [float(d)]\n                return\n            prev_mu = self.mu\n            self.mu = (1 - self.alpha) * self.mu + self.alpha * float(d)\n            self.tau = (1 - self.alpha) * self.tau + self.alpha * abs(float(d) - prev_mu)\n            self.distances.append(float(d))\n            if len(self.distances) > 50:\n                self.distances.pop(0)\n        except Exception:\n            pass\n\n    def get_adaptive_threshold(self, lam=1.0) -> float:\n        \"\"\"\n        Get adaptive threshold: Œº + Œª*œÑ.\n        \n        Args:\n            lam: Lambda multiplier\n        \n        Returns:\n            Adaptive threshold\n        \"\"\"\n        try:\n            return float(self.mu + lam * self.tau)\n        except Exception:\n            return float(self.mu)\n\n    def get_centroids(self, device=torch.device(\"cpu\")) -> Optional[torch.Tensor]:\n        \"\"\"\n        Get all centroids as tensor [K, D].\n        \n        Args:\n            device: Target device\n        \n        Returns:\n            Centroids tensor or None\n        \"\"\"\n        if not self.centroids:\n            return None\n        try:\n            return torch.stack([c.to(device) for c in self.centroids], dim=0)\n        except Exception:\n            try:\n                return torch.stack([c.cpu() for c in self.centroids], dim=0).to(device)\n            except Exception:\n                return None\n\n    def get_valid_centroids(self, device=torch.device(\"cpu\"), min_count=None):\n        \"\"\"\n        Get centroids with count >= min_count.\n        \n        Args:\n            device: Target device\n            min_count: Minimum count threshold\n        \n        Returns:\n            (centroids, indices) or (None, None)\n        \"\"\"\n        if min_count is None:\n            min_count = DSCD_N_MIN\n        idxs = [i for i, ct in enumerate(self.counts) if ct >= int(min_count)]\n        if not idxs:\n            return None, None\n        cents = [self.centroids[i].to(device) for i in idxs]\n        return torch.stack(cents, dim=0), idxs\n\n    def set_centroids_from_arrays(self, array_list, counts=None):\n        \"\"\"\n        Set centroids from numpy arrays.\n        \n        Args:\n            array_list: List of numpy arrays\n            counts: List of counts (optional)\n        \"\"\"\n        try:\n            self.centroids = [torch.from_numpy(np.asarray(a, dtype=np.float32)).cpu() for a in array_list]\n            if counts and len(counts) == len(array_list):\n                self.counts = [int(c) for c in counts]\n            else:\n                self.counts = [1 for _ in array_list]\n            self.creation_time = [time.time()] * len(array_list)\n        except Exception:\n            self.centroids = []\n            self.counts = []\n            self.creation_time = []\n\n    # Support both property and method access for Cell 10 compatibility\n    @property\n    def size(self) -> int:\n        \"\"\"Property access: store.size\"\"\"\n        return len(self.centroids)\n    \n    def __len__(self) -> int:\n        \"\"\"Method access: len(store) or store.__len__()\"\"\"\n        return len(self.centroids)\n\n\n# ==============================================================================\n# WORD-LEVEL DSCD MODULE\n# ==============================================================================\n\nclass WordLevelDSCDOnline(nn.Module):\n    \"\"\"\n    Word-level Dynamic Semantic Clustering and Detection.\n    Processes word embeddings (B, W, D) with Indic language normalization.\n    Consolidates inflected forms using normalized keys.\n    \n    IndicBART-compatible with word tokenizer support.\n    \"\"\"\n    \n    def __init__(self, embed_dim, buffer_size=None, max_protos=None,\n                 n_min=None, dispersion_threshold=None, language='bn',\n                 enable_training_clustering=None, max_clustering_points=None,\n                 max_candidates_per_step=2, use_normalization=True,\n                 force_sync_clustering=True,\n                 word_tokenizer=None):  # ‚Üê FIX #9: Add word_tokenizer parameter\n        \"\"\"\n        Initialize WordLevelDSCDOnline.\n        \n        Args:\n            embed_dim: Word embedding dimension\n            buffer_size: Buffer size for clustering\n            max_protos: Maximum prototypes per word\n            n_min: Minimum samples for clustering\n            dispersion_threshold: Dispersion threshold\n            language: Target language ('bn' for Bengali)\n            enable_training_clustering: Enable clustering during training\n            max_clustering_points: Maximum points for clustering\n            max_candidates_per_step: Maximum candidates per discovery step\n            use_normalization: Use Indic word normalization\n            force_sync_clustering: Force synchronous clustering (recommended)\n            word_tokenizer: BengaliWordTokenizer for ID-to-string conversion\n        \"\"\"\n        super().__init__()\n        self.embed_dim = int(embed_dim)\n        self.buffer_size = int(buffer_size) if buffer_size is not None else DSCD_BUFFER_SIZE\n        self.max_protos = int(max_protos) if max_protos is not None else DSCD_MAX_PROTOS\n        self.n_min = int(n_min) if n_min is not None else DSCD_N_MIN\n        self.dispersion_threshold = float(dispersion_threshold) if dispersion_threshold is not None else DSCD_DISPERSION_THRESHOLD\n        self.language = language\n        self.use_normalization = use_normalization and HAS_INDIC_NORMALIZATION\n        \n        self.uncertainty_threshold = DSCD_UNCERTAINTY_THRESHOLD\n        self.span_threshold = DSCD_SPAN_THRESHOLD\n        self.augment_sim_threshold = DSCD_AUGMENT_SIM_THRESHOLD\n        self.augment_scale = DSCD_AUGMENT_SCALE\n        self.temperature = DSCD_TEMPERATURE\n\n        self._dscd_allowed_tokens = set()\n        self._dscd_ignored_tokens = set()\n\n        self.prototype_stores = {}\n        self.buffers = {}\n        self.discovery_log = []\n        self.last_periodic_check = 0\n        self.cleanup_counter = 0\n        self.clustering_lock = threading.Lock()\n\n        self.last_cluster_time = {}\n        # üîß FIX #6: Reduce clustering cooldown from 60s to 5s\n        self.cluster_cooldown_seconds = 5\n        \n        # Enable training clustering from config\n        if enable_training_clustering is None:\n            enable_training_clustering = DSCD_ENABLE_TRAINING_CLUSTERING\n        self.enable_training_clustering = bool(enable_training_clustering)\n        \n        # üîß FIX #1 & #7: Add force_sync_clustering flag\n        self.force_sync_clustering = bool(force_sync_clustering)\n        \n        # üî• FIX #9: Store word tokenizer for ID-to-string conversion\n        self.word_tokenizer = word_tokenizer\n        if self.word_tokenizer is None and HAS_WORD_TOKENIZER:\n            try:\n                self.word_tokenizer = globals().get('word_tokenizer', None)\n            except:\n                pass\n\n        # Neural heads\n        self.span_head = nn.Sequential(\n            nn.Linear(self.embed_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(DSCD_DROPOUT),\n            nn.Linear(64, 1)\n        )\n        self.sigma_net = nn.Sequential(\n            nn.Linear(self.embed_dim, 16),\n            nn.ReLU(),\n            nn.Dropout(DSCD_DROPOUT),\n            nn.Linear(16, 1)\n        )\n        self.gate_w = nn.Parameter(torch.tensor(1.0))\n        self.gate_b = nn.Parameter(torch.tensor(0.4))\n        self.gamma = nn.Parameter(torch.tensor(0.3))\n\n        self.max_clustering_points = int(max_clustering_points) if max_clustering_points is not None else DSCD_MAX_CLUSTERING_POINTS\n        self.max_candidates_per_step = int(max_candidates_per_step)\n\n        if VERBOSE_LOGGING:\n            print(f\"[DSCD-INIT] Word-level DSCD initialized:\")\n            print(f\"  Embed dim: {self.embed_dim}\")\n            print(f\"  Buffer size: {self.buffer_size}\")\n            print(f\"  Max prototypes: {self.max_protos}\")\n            print(f\"  n_min: {self.n_min}\")\n            print(f\"  Language: {self.language}\")\n            print(f\"  Normalization: {'ENABLED' if self.use_normalization else 'DISABLED'}\")\n            print(f\"  Uncertainty threshold: {self.uncertainty_threshold}\")\n            print(f\"  Enable training clustering: {self.enable_training_clustering}\")\n            print(f\"  Force sync clustering: {self.force_sync_clustering}\")\n            print(f\"  Word tokenizer: {'LOADED' if self.word_tokenizer else 'NOT AVAILABLE'}\")\n\n    def _get_normalized_key(self, word: str) -> str:\n        \"\"\"\n        Get normalized word key for prototype lookup.\n        Consolidates inflected forms (e.g., '‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡ßá', '‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡ßá‡¶∞' -> '‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï').\n        \n        Args:\n            word: Input word\n        \n        Returns:\n            Normalized word key\n        \"\"\"\n        if not self.use_normalization:\n            return word.strip()\n        \n        try:\n            normalized = normalize_indic_word(word, language=self.language)\n            return normalized if normalized else word.strip()\n        except:\n            return word.strip()\n    \n    def _convert_ids_to_strings(self, word_input_ids: torch.Tensor) -> List[List[str]]:\n        \"\"\"\n        Convert word IDs to strings using word tokenizer.\n        \n        Args:\n            word_input_ids: Tensor [B, W] with word IDs\n        \n        Returns:\n            List[List[str]]: [[word1, word2, ...], ...] batch of word lists\n        \"\"\"\n        if self.word_tokenizer is None:\n            if VERBOSE_LOGGING:\n                print(\"[DSCD] Warning: word_tokenizer not available, cannot convert IDs to strings\")\n            return []\n        \n        try:\n            B, W = word_input_ids.shape\n            batch_words = []\n            \n            for b in range(B):\n                words = []\n                for w in range(W):\n                    word_id = int(word_input_ids[b, w].item())\n                    \n                    # Skip padding (ID 0)\n                    if word_id == 0:\n                        continue\n                    \n                    # Convert ID to string\n                    try:\n                        if hasattr(self.word_tokenizer, 'convert_ids_to_tokens'):\n                            word = self.word_tokenizer.convert_ids_to_tokens([word_id])[0]\n                        elif hasattr(self.word_tokenizer, 'id_to_word'):\n                            word = self.word_tokenizer.id_to_word.get(word_id, None)\n                        elif hasattr(self.word_tokenizer, 'inverse_vocab'):\n                            word = self.word_tokenizer.inverse_vocab.get(word_id, None)\n                        elif hasattr(self.word_tokenizer, 'vocab'):\n                            # Reverse lookup in vocab\n                            word = None\n                            for w_str, w_id in self.word_tokenizer.vocab.items():\n                                if w_id == word_id:\n                                    word = w_str\n                                    break\n                        else:\n                            word = None\n                        \n                        if word and isinstance(word, str):\n                            words.append(word.strip())\n                    except Exception:\n                        continue\n                \n                batch_words.append(words)\n            \n            return batch_words\n        except Exception as e:\n            if VERBOSE_LOGGING:\n                print(f\"[DSCD] ID-to-string conversion failed: {type(e).__name__}: {str(e)[:200]}\")\n            return []\n\n    def should_track_word(self, word: str) -> bool:\n        \"\"\"\n        Determine if word should be tracked for homograph detection.\n        Uses normalized form for caching.\n        \n        Args:\n            word: Input word\n        \n        Returns:\n            True if should track, False otherwise\n        \"\"\"\n        if not word or not isinstance(word, str):\n            return False\n        \n        # üîß FIX #5: Improved caching - check raw word first\n        word_key = self._get_normalized_key(word)\n        \n        # Quick cache check\n        if word_key in self._dscd_allowed_tokens or word in self._dscd_allowed_tokens:\n            return True\n        \n        if word_key in self._dscd_ignored_tokens and word in self._dscd_ignored_tokens:\n            return False\n        \n        # Check watchlist (both normalized and raw)\n        try:\n            if word_key in HOMOGRAPH_WATCHLIST_BN or word in HOMOGRAPH_WATCHLIST_BN:\n                self._dscd_allowed_tokens.add(word_key)\n                self._dscd_allowed_tokens.add(word)\n                if VERBOSE_LOGGING and len(self._dscd_allowed_tokens) <= 20:\n                    print(f\"[DSCD] ‚úÖ Watchlist word tracked: '{word}' -> '{word_key}'\")\n                return True\n        except Exception:\n            pass\n        \n        # Validate token\n        if not validate_word_token(word, min_length=_WORD_MIN_LENGTH, max_length=_WORD_MAX_LENGTH):\n            self._dscd_ignored_tokens.add(word_key)\n            self._dscd_ignored_tokens.add(word)\n            return False\n        \n        # Check if Indic\n        if is_indic_word(word):\n            self._dscd_allowed_tokens.add(word_key)\n            self._dscd_allowed_tokens.add(word)\n            return True\n        \n        self._dscd_ignored_tokens.add(word_key)\n        self._dscd_ignored_tokens.add(word)\n        return False\n\n    # üî• FIX #8: CRITICAL - Accept word_input_ids + word_attention_mask\n    def forward(self, word_embeddings, word_input_ids=None, word_attention_mask=None, \n                word_tokens=None, train_mode=True):\n        \"\"\"\n        Forward pass for word-level DSCD with normalization.\n        \n        Args:\n            word_embeddings: Word-level embeddings [B, W, D]\n            word_input_ids: Word IDs tensor [B, W] (NEW - from Cell 6)\n            word_attention_mask: Attention mask [B, W] (NEW - from Cell 6)\n            word_tokens: List of word strings [B x W] or [B][W] (backward compat)\n            train_mode: If True, accumulate buffers and cluster\n        \n        Returns:\n            dict with: proto_probs, uncertainties, gates, span_preds, h_aug\n        \"\"\"\n        B, W, D = word_embeddings.shape\n        device = word_embeddings.device\n        \n        if VERBOSE_LOGGING:\n            print(f\"\\n[DSCD] Forward: B={B}, W={W}, D={D}, train_mode={train_mode}\")\n            print(f\"[DSCD]   word_input_ids: {word_input_ids.shape if word_input_ids is not None else 'None'}\")\n            print(f\"[DSCD]   word_attention_mask: {word_attention_mask.shape if word_attention_mask is not None else 'None'}\")\n            print(f\"[DSCD]   word_tokens type: {type(word_tokens)}\")\n        \n        # üî• FIX #8: Convert word_input_ids to word_tokens if needed\n        if word_tokens is None and word_input_ids is not None:\n            try:\n                word_tokens = self._convert_ids_to_strings(word_input_ids)\n                if VERBOSE_LOGGING:\n                    print(f\"[DSCD] ‚úÖ Converted {len(word_tokens)} batches from IDs to strings\")\n                    if word_tokens:\n                        print(f\"[DSCD]   Sample words[0][:5]: {word_tokens[0][:5]}\")\n            except Exception as e:\n                if VERBOSE_LOGGING:\n                    print(f\"[DSCD] ‚ùå ID-to-string conversion failed: {type(e).__name__}\")\n                word_tokens = []\n        \n        # Initialize outputs\n        proto_probs = [[None for _ in range(W)] for _ in range(B)]\n        uncertainties = [[0.0 for _ in range(W)] for _ in range(B)]\n        gates = [[0.0 for _ in range(W)] for _ in range(B)]\n        span_preds = [[0.0 for _ in range(W)] for _ in range(B)]\n        h_aug = word_embeddings.clone()\n        \n        # Process each word\n        for b in range(B):\n            for w in range(W):\n                # Extract word string (with word_input_ids support)\n                word = None\n                try:\n                    if isinstance(word_tokens, list):\n                        if isinstance(word_tokens[b], list):\n                            word = word_tokens[b][w] if w < len(word_tokens[b]) else None\n                        else:\n                            word = word_tokens[b]\n                    else:\n                        word = None\n                except Exception:\n                    word = None\n                \n                # Skip if no word\n                if not word or not isinstance(word, str):\n                    continue\n                \n                word = word.strip()\n                \n                # Check if should track\n                if not self.should_track_word(word):\n                    continue\n                \n                # Get normalized key\n                word_key = self._get_normalized_key(word)\n                \n                # Get embedding\n                h_w = word_embeddings[b, w]\n                \n                # TRAINING MODE: Accumulate buffer\n                if train_mode:\n                    if word_key not in self.buffers:\n                        self.buffers[word_key] = deque(maxlen=self.buffer_size)\n                        self.prototype_stores[word_key] = MemoryEfficientPrototypeStore(self.embed_dim, self.max_protos)\n                    \n                    # üîß FIX #4: Improved tensor device handling\n                    try:\n                        # Ensure tensor is on CPU before adding to buffer\n                        if isinstance(h_w, torch.Tensor):\n                            h_w_cpu = h_w.detach().cpu().clone()\n                        else:\n                            h_w_cpu = torch.tensor(h_w).cpu()\n                        self.buffers[word_key].append(h_w_cpu)\n                        \n                        if VERBOSE_LOGGING and len(self.buffers[word_key]) <= 3:\n                            print(f\"[DSCD] üìù Buffer append: '{word}' ‚Üí '{word_key}' (len={len(self.buffers[word_key])})\")\n                    except Exception as e:\n                        if VERBOSE_LOGGING:\n                            print(f\"[DSCD] Buffer append error for '{word}': {type(e).__name__}\")\n                        continue\n                    \n                    # üîß FIX #1: SYNCHRONOUS CLUSTERING (NO THREADING)\n                    try:\n                        buffer_len = len(self.buffers[word_key])\n                        min_samples_needed = max(self.n_min, 3)\n                        \n                        if self.enable_training_clustering and buffer_len >= min_samples_needed:\n                            now = time.time()\n                            last_t = self.last_cluster_time.get(word_key, 0.0)\n                            \n                            if now - last_t > self.cluster_cooldown_seconds:\n                                self.last_cluster_time[word_key] = now\n                                \n                                if self.force_sync_clustering:\n                                    # ‚úÖ SYNCHRONOUS: Block until clustering completes\n                                    with self.clustering_lock:\n                                        success = self._cluster_buffer_to_prototypes(word_key)\n                                        if VERBOSE_LOGGING and success:\n                                            store = self.prototype_stores.get(word_key)\n                                            if store and store.size > 0:\n                                                print(f\"[DSCD-CLUSTER] ‚úÖ '{word_key}': {store.size} prototypes created (counts={store.counts})\")\n                                else:\n                                    # ‚ùå ASYNC (original buggy version)\n                                    def _bg_cluster(wk=word_key):\n                                        try:\n                                            with self.clustering_lock:\n                                                self._cluster_buffer_to_prototypes(wk)\n                                        except Exception:\n                                            pass\n                                    th = threading.Thread(target=_bg_cluster, daemon=True)\n                                    th.start()\n                    except Exception as e:\n                        if VERBOSE_LOGGING:\n                            print(f\"[DSCD] Clustering trigger error: {type(e).__name__}\")\n                \n                # INFERENCE: Use existing prototypes\n                if word_key not in self.prototype_stores:\n                    continue\n                \n                store = self.prototype_stores[word_key]\n                \n                if store.size < 2:\n                    continue\n                \n                try:\n                    centroids = store.get_centroids(device=device)\n                    if centroids is None or centroids.size(0) < 2:\n                        continue\n                    \n                    K = centroids.size(0)\n                    \n                    # Compute similarities\n                    sims = F.cosine_similarity(\n                        h_w.unsqueeze(0),\n                        centroids,\n                        dim=1\n                    )\n                    \n                    # Probability distribution\n                    p_w = F.softmax(sims / self.temperature, dim=0)\n                    \n                    # Uncertainty: entropy + distance\n                    entropy = -torch.sum(p_w * torch.log(p_w + 1e-8))\n                    H_norm = (entropy / math.log(K)).item()\n                    d_min = 1.0 - sims.max().item()\n                    U_w = 0.5 * H_norm + 0.5 * d_min\n                    \n                    # Gate function\n                    if U_w > self.uncertainty_threshold:\n                        g_w = torch.sigmoid(torch.tensor(10.0 * (U_w - self.uncertainty_threshold), device=device))\n                    else:\n                        g_w = torch.tensor(0.0, device=device)\n                    \n                    # Span prediction\n                    max_prob = p_w.max().item()\n                    if U_w > self.uncertainty_threshold and max_prob > 0.3:\n                        span_w = max(0.0, 0.5 * pow(U_w - self.uncertainty_threshold, 1.2))\n                    else:\n                        span_w = 0.0\n                    \n                    # Store outputs\n                    proto_probs[b][w] = p_w\n                    uncertainties[b][w] = U_w\n                    gates[b][w] = g_w.item()\n                    span_preds[b][w] = span_w\n                    \n                    # Augmentation\n                    if span_w > self.span_threshold and sims.max().item() > self.augment_sim_threshold:\n                        best_idx = torch.argmax(sims)\n                        proto_vec = centroids[best_idx]\n                        h_aug[b, w] = h_aug[b, w] + self.augment_scale * proto_vec\n                    \n                except Exception as e:\n                    if VERBOSE_LOGGING:\n                        print(f\"[DSCD] Error processing word '{word}': {type(e).__name__}: {str(e)[:200]}\")\n        \n        # Cleanup\n        self.cleanup_counter += 1\n        if self.cleanup_counter % 50 == 0:\n            self.cleanup_counter = 0\n            self.cleanup_memory()\n        \n        # Periodic logging\n        if not train_mode and VERBOSE_LOGGING:\n            if self.last_periodic_check % PRINT_INTERVAL == 0:\n                self._print_clusters_summary()\n            self.last_periodic_check += 1\n        \n        return {\n            'proto_probs': proto_probs,\n            'uncertainties': uncertainties,\n            'gates': gates,\n            'span_preds': span_preds,\n            'h_aug': h_aug\n        }\n\n    def _cluster_buffer_to_prototypes(self, word_key):\n        \"\"\"\n        Cluster word embeddings into prototypes.\n        Uses normalized word_key for consistent clustering.\n        \n        Args:\n            word_key: Normalized word key\n        \n        Returns:\n            True if clustering succeeded, False otherwise\n        \"\"\"\n        try:\n            if word_key not in self.buffers:\n                return False\n            \n            buf = self.buffers[word_key]\n            if len(buf) < self.n_min:\n                return False\n            \n            # Convert buffer to numpy array\n            emb_list = []\n            for e in buf:\n                try:\n                    if isinstance(e, torch.Tensor):\n                        emb_list.append(e.numpy())\n                    else:\n                        emb_list.append(np.asarray(e))\n                except Exception:\n                    continue\n            \n            if len(emb_list) == 0:\n                return False\n            \n            # Limit clustering points\n            if len(emb_list) > self.max_clustering_points:\n                idxs = np.random.choice(len(emb_list), size=self.max_clustering_points, replace=False)\n                embeddings = np.stack([emb_list[i] for i in idxs], axis=0)\n            else:\n                embeddings = np.stack(emb_list, axis=0)\n            \n            if embeddings.shape[0] < 2:\n                return False\n            \n            if VERBOSE_LOGGING:\n                norms = np.linalg.norm(embeddings, axis=1)\n                print(f\"[DSCD-CLUSTER] Word '{word_key}': {embeddings.shape[0]} samples, mean_norm={norms.mean():.4f}\")\n            \n            # Clear old prototypes\n            store = self.prototype_stores[word_key]\n            store.centroids = []\n            store.counts = []\n            store.creation_time = []\n            \n            protos_added = 0\n            \n            # Try hierarchical clustering (scipy)\n            if HAS_CLUSTERING:\n                try:\n                    condensed = pdist(embeddings, metric='euclidean')\n                    if condensed.size > 0:\n                        k_guess = min(self.max_protos, max(2, len(embeddings) // max(1, self.n_min)))\n                        k_guess = max(1, int(k_guess))\n                        Z = linkage(condensed, method='ward')\n                        clusters = fcluster(Z, t=k_guess, criterion='maxclust') - 1\n                        if clusters.size > 0:\n                            maxc = int(clusters.max())\n                            for cid in range(maxc + 1):\n                                mask = (clusters == cid)\n                                if mask.sum() >= self.n_min:\n                                    centroid = torch.from_numpy(embeddings[mask].mean(axis=0).astype(np.float32))\n                                    store.add_prototype(centroid, time.time(), count=int(mask.sum()))\n                                    protos_added += 1\n                    if VERBOSE_LOGGING and protos_added > 0:\n                        print(f\"[DSCD-CLUSTER] Hierarchical: {protos_added} prototypes for '{word_key}'\")\n                except Exception as e:\n                    if VERBOSE_LOGGING:\n                        print(f\"[DSCD-CLUSTER] Hierarchical failed: {type(e).__name__}\")\n            \n            # Try sklearn KMeans\n            if protos_added == 0 and HAS_KMEANS:\n                try:\n                    k_guess = min(self.max_protos, max(1, len(embeddings) // max(1, self.n_min)))\n                    k_guess = int(min(k_guess, len(embeddings)))\n                    if k_guess >= 1 and len(embeddings) >= k_guess:\n                        km = KMeans(n_clusters=k_guess, random_state=0, n_init=10).fit(embeddings)\n                        labels = km.labels_\n                        for c in range(k_guess):\n                            mask = (labels == c)\n                            if mask.sum() >= self.n_min:\n                                centroid = torch.from_numpy(embeddings[mask].mean(axis=0).astype(np.float32))\n                                store.add_prototype(centroid, time.time(), count=int(mask.sum()))\n                                protos_added += 1\n                        if VERBOSE_LOGGING and protos_added > 0:\n                            print(f\"[DSCD-CLUSTER] KMeans: {protos_added} prototypes for '{word_key}'\")\n                except Exception as e:\n                    if VERBOSE_LOGGING:\n                        print(f\"[DSCD-CLUSTER] KMeans failed: {type(e).__name__}\")\n            \n            # Fallback: numpy KMeans\n            if protos_added == 0:\n                try:\n                    k_guess = min(self.max_protos, max(1, len(embeddings) // max(1, self.n_min)))\n                    k_guess = int(min(k_guess, len(embeddings)))\n                    if k_guess >= 1 and len(embeddings) >= k_guess:\n                        labels, cents = _numpy_kmeans(embeddings.astype(np.float32), n_clusters=k_guess, n_iter=10, random_state=0)\n                        for c in range(k_guess):\n                            mask = (labels == c)\n                            if mask.sum() >= self.n_min:\n                                centroid = torch.from_numpy(cents[c].astype(np.float32))\n                                store.add_prototype(centroid, time.time(), count=int(mask.sum()))\n                                protos_added += 1\n                        if VERBOSE_LOGGING and protos_added > 0:\n                            print(f\"[DSCD-CLUSTER] numpy-kmeans: {protos_added} prototypes for '{word_key}'\")\n                except Exception as e:\n                    if VERBOSE_LOGGING:\n                        print(f\"[DSCD-CLUSTER] numpy-kmeans failed: {type(e).__name__}\")\n            \n            if VERBOSE_LOGGING:\n                print(f\"[DSCD-CLUSTER] Word '{word_key}': {store.size} prototypes, counts={store.counts}\")\n            \n            return store.size > 0\n            \n        except Exception as e:\n            if VERBOSE_LOGGING:\n                print(f\"[DSCD-ERROR] Clustering error for '{word_key}': {type(e).__name__}\")\n            return False\n\n    # Add method aliases for Cell 10 discovery phase compatibility\n    def _cluster_buffer_to_prototypes_hierarchical(self, word_key):\n        \"\"\"Alias for Cell 10 compatibility.\"\"\"\n        return self._cluster_buffer_to_prototypes(word_key)\n    \n    def cluster_buffer(self, word_key):\n        \"\"\"Alias for Cell 10 compatibility.\"\"\"\n        return self._cluster_buffer_to_prototypes(word_key)\n    \n    def _cluster_word(self, word_key):\n        \"\"\"Alias for Cell 10 compatibility.\"\"\"\n        return self._cluster_buffer_to_prototypes(word_key)\n    \n    def cluster_word_buffer(self, word_key):\n        \"\"\"Alias for Cell 10 compatibility.\"\"\"\n        return self._cluster_buffer_to_prototypes(word_key)\n\n    def _print_clusters_summary(self):\n        \"\"\"Print summary of discovered clusters.\"\"\"\n        try:\n            items = []\n            for word_key, store in self.prototype_stores.items():\n                try:\n                    proto_sample_count = sum(getattr(store, 'counts', []) or [])\n                except Exception:\n                    proto_sample_count = 0\n                buffer_len = len(self.buffers.get(word_key, [])) if word_key in self.buffers else 0\n                total_count = proto_sample_count if proto_sample_count > 0 else buffer_len\n                protos = store.size\n                mu = getattr(store, 'mu', 0.0)\n                tau = getattr(store, 'tau', 0.0)\n                items.append((word_key, total_count, protos, mu, tau, buffer_len))\n            items.sort(key=lambda x: x[1], reverse=True)\n            if VERBOSE_LOGGING:\n                print(\"\\n[DSCD-CLUSTER] Top 5 words with prototypes:\")\n                print(\"-\" * 100)\n                print(f\"{'Rank':<6} {'Word':<18} {'Count':<12} {'Protos':<8} {'BufLen':<8} {'Œº':<15} {'œÑ':<15}\")\n                print(\"-\" * 100)\n                for rank, (word_key, cnt, prot, mu, tau, buflen) in enumerate(items[:5], 1):\n                    word_str = str(word_key)[:18]\n                    print(f\"{rank:<6} {word_str:<18} {cnt:<12} {prot:<8} {buflen:<8} {mu:<15.6f} {tau:<15.6f}\")\n                print(\"-\" * 100)\n                total_samples = sum(item[1] for item in items)\n                total_protos = sum(item[2] for item in items)\n                print(f\"Total words: {len(items)} | Total samples: {total_samples} | Total protos: {total_protos}\\n\")\n        except Exception as e:\n            if VERBOSE_LOGGING:\n                print(f\"[DSCD] Error printing summary: {str(e)[:200]}\")\n\n    def cleanup_memory(self):\n        \"\"\"Cleanup excessive buffer memory.\"\"\"\n        try:\n            for word_key, buffer in list(self.buffers.items()):\n                if len(buffer) > int(self.buffer_size * 1.5):\n                    while len(buffer) > self.buffer_size:\n                        buffer.popleft()\n            try:\n                gc.collect()\n            except Exception:\n                pass\n        except Exception:\n            pass\n\n    def get_explanations(self, threshold_span=0.3):\n        \"\"\"\n        Get explanations for discovered homographs.\n        \n        Args:\n            threshold_span: Minimum span threshold\n        \n        Returns:\n            List of explanation dicts\n        \"\"\"\n        expl = []\n        for word_key, store in self.prototype_stores.items():\n            try:\n                if store.size >= 2:\n                    expl.append({'word': str(word_key), 'protos': store.size, 'counts': list(store.counts)})\n            except Exception:\n                continue\n        return expl\n\n\n# Add DSCD class alias for Cell 6 fallback import compatibility\nDSCD = WordLevelDSCDOnline\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ Cell 3: Word-Level DSCD Module (IndicBART-READY - 12 CRITICAL FIXES)\")\nprint(\"=\"*80)\nprint(\"Critical fixes applied:\")\nprint(\" üîß FIX #1: SYNCHRONOUS clustering (force_sync_clustering=True)\")\nprint(\" üîß FIX #2: Reduced DSCD_BUFFER_SIZE threshold for faster detection\")\nprint(\" üîß FIX #3: Reduced DSCD_N_MIN for limited data\")\nprint(\" üîß FIX #4: Fixed tensor device handling in buffer append\")\nprint(\" üîß FIX #5: Improved word key caching (cache both raw + normalized)\")\nprint(\" üîß FIX #6: Reduced clustering cooldown: 60s ‚Üí 5s\")\nprint(\" üîß FIX #7: Added force_sync_clustering parameter\")\nprint(\" üî• FIX #8: CRITICAL - Accept word_input_ids + word_attention_mask (Cell 6 compat)\")\nprint(\" üî• FIX #9: CRITICAL - Added word tokenizer for ID-to-string conversion\")\nprint(\" üî• FIX #10: IndicBART language token support\")\nprint(\" üî• FIX #11: Aligned with Cell 0 config parameters\")\nprint(\" üî• FIX #12: Added proper error handling for missing globals\")\nprint()\nprint(\"Configuration:\")\nprint(f\" ‚Ä¢ Buffer size: {DSCD_BUFFER_SIZE} samples\")\nprint(f\" ‚Ä¢ n_min: {DSCD_N_MIN} samples\")\nprint(f\" ‚Ä¢ Max prototypes: {DSCD_MAX_PROTOS}\")\nprint(f\" ‚Ä¢ Embed dim: {DSCD_EMBED_DIM}\")\nprint(f\" ‚Ä¢ Temperature: {DSCD_TEMPERATURE}\")\nprint(f\" ‚Ä¢ Clustering: SYNCHRONOUS (guarantees prototype creation)\")\nprint(f\" ‚Ä¢ Normalization: {'ENABLED' if HAS_INDIC_NORMALIZATION else 'DISABLED (using fallback)'}\")\nprint(f\" ‚Ä¢ Word tokenizer: {'LOADED' if HAS_WORD_TOKENIZER else 'NOT AVAILABLE'}\")\nprint(f\" ‚Ä¢ scipy: {'AVAILABLE' if HAS_CLUSTERING else 'NOT AVAILABLE'}\")\nprint(f\" ‚Ä¢ sklearn: {'AVAILABLE' if HAS_KMEANS else 'NOT AVAILABLE'}\")\nprint()\nprint(\"IndicBART Features:\")\nprint(f\" ‚ú® Word tokenizer integration for ID-to-string conversion\")\nprint(f\" ‚ú® Normalized word keys for Bengali morphology\")\nprint(f\" ‚ú® Homograph watchlist: {len(HOMOGRAPH_WATCHLIST_BN)} words\")\nprint(f\" ‚ú® Compatible with IndicBART word embeddings\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"id":"L25pcKUPH4J2","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:23.121849Z","iopub.execute_input":"2026-01-24T20:09:23.122165Z","iopub.status.idle":"2026-01-24T20:09:24.434608Z","shell.execute_reply.started":"2026-01-24T20:09:23.122144Z","shell.execute_reply":"2026-01-24T20:09:24.434013Z"}},"outputs":[{"name":"stdout","text":"[CELL3] Configuration loaded:\n  Buffer size: 20\n  n_min: 2\n  Max prototypes: 8\n  Embed dim: 256\n  Temperature: 0.7\n  Uncertainty threshold: 0.4\n  Enable training clustering: True\n  Max clustering points: 500\n  scipy: AVAILABLE\n  sklearn: AVAILABLE\n[CELL3] ‚úÖ Imported normalization functions from Cell 1\n[CELL3] ‚úÖ Imported BengaliWordTokenizer from Cell 2\n\n================================================================================\n‚úÖ Cell 3: Word-Level DSCD Module (IndicBART-READY - 12 CRITICAL FIXES)\n================================================================================\nCritical fixes applied:\n üîß FIX #1: SYNCHRONOUS clustering (force_sync_clustering=True)\n üîß FIX #2: Reduced DSCD_BUFFER_SIZE threshold for faster detection\n üîß FIX #3: Reduced DSCD_N_MIN for limited data\n üîß FIX #4: Fixed tensor device handling in buffer append\n üîß FIX #5: Improved word key caching (cache both raw + normalized)\n üîß FIX #6: Reduced clustering cooldown: 60s ‚Üí 5s\n üîß FIX #7: Added force_sync_clustering parameter\n üî• FIX #8: CRITICAL - Accept word_input_ids + word_attention_mask (Cell 6 compat)\n üî• FIX #9: CRITICAL - Added word tokenizer for ID-to-string conversion\n üî• FIX #10: IndicBART language token support\n üî• FIX #11: Aligned with Cell 0 config parameters\n üî• FIX #12: Added proper error handling for missing globals\n\nConfiguration:\n ‚Ä¢ Buffer size: 20 samples\n ‚Ä¢ n_min: 2 samples\n ‚Ä¢ Max prototypes: 8\n ‚Ä¢ Embed dim: 256\n ‚Ä¢ Temperature: 0.7\n ‚Ä¢ Clustering: SYNCHRONOUS (guarantees prototype creation)\n ‚Ä¢ Normalization: ENABLED\n ‚Ä¢ Word tokenizer: LOADED\n ‚Ä¢ scipy: AVAILABLE\n ‚Ä¢ sklearn: AVAILABLE\n\nIndicBART Features:\n ‚ú® Word tokenizer integration for ID-to-string conversion\n ‚ú® Normalized word keys for Bengali morphology\n ‚ú® Homograph watchlist: 24 words\n ‚ú® Compatible with IndicBART word embeddings\n================================================================================\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==============================================================================\n# CELL 4: WORD-LEVEL ASBN MODULE (IndicBART-READY - 10 CRITICAL FIXES)\n# ==============================================================================\n# Critical fixes applied for IndicBART compatibility:\n# 1. Added all ASBN config parameters from Cell 0 with try-except\n# 2. Proper error handling for all globals\n# 3. Imported word tokenizer from Cell 2 for consistency\n# 4. Aligned language parameter with Cell 0\n# 5. Added ASBN-specific hyperparameters (dropout, lambda scales)\n# 6. Updated all print messages for IndicBART\n# 7. Enhanced word-level feature extraction for Bengali\n# 8. Robust discriminator device handling\n# 9. Improved word_tokens validation from Cell 2/Cell 6\n# 10. Added ASBN class alias for Cell 6 fallback import compatibility\n# ==============================================================================\n\nimport traceback\nfrom typing import Any, List, Tuple, Optional, Dict\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ==============================================================================\n# CONFIGURATION FROM CELL 0\n# ==============================================================================\n\n# Basic config\ntry:\n    MAX_LENGTH = int(MAX_LENGTH)\nexcept (NameError, ValueError):\n    MAX_LENGTH = 48\n    print(\"[CELL4] WARNING: MAX_LENGTH not defined, using default 48\")\n\n_MAX_LENGTH = MAX_LENGTH\n\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, ValueError):\n    VERBOSE_LOGGING = False\n    print(\"[CELL4] WARNING: VERBOSE_LOGGING not defined, using default False\")\n\n_VERBOSE_LOGGING = VERBOSE_LOGGING\n\ntry:\n    SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, ValueError):\n    SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL4] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n\n_SOURCE_LANGUAGE = SOURCE_LANGUAGE\n\ntry:\n    TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, ValueError):\n    TARGET_LANGUAGE = \"en\"\n    print(\"[CELL4] WARNING: TARGET_LANGUAGE not defined, using default 'en'\")\n\n_TARGET_LANGUAGE = TARGET_LANGUAGE\n\n# ==============================================================================\n# üî• FIX #1 & #5: ASBN-SPECIFIC CONFIGURATION\n# ==============================================================================\n\ntry:\n    ENABLE_ASBN_TRAINING = bool(ENABLE_ASBN_TRAINING)\nexcept (NameError, ValueError):\n    ENABLE_ASBN_TRAINING = True\n    print(\"[CELL4] WARNING: ENABLE_ASBN_TRAINING not defined, using default True\")\n\n_ENABLE_ASBN_TRAINING = ENABLE_ASBN_TRAINING\n\ntry:\n    ASBN_MONITOR_IN_EVAL = bool(ASBN_MONITOR_IN_EVAL)\nexcept (NameError, ValueError):\n    ASBN_MONITOR_IN_EVAL = False\n    print(\"[CELL4] WARNING: ASBN_MONITOR_IN_EVAL not defined, using default False\")\n\n_ASBN_MONITOR_IN_EVAL = ASBN_MONITOR_IN_EVAL\n\ntry:\n    ASBN_ENCODER_GRL_SCALE = float(ASBN_ENCODER_GRL_SCALE)\nexcept (NameError, ValueError):\n    ASBN_ENCODER_GRL_SCALE = 0.1\n    print(\"[CELL4] WARNING: ASBN_ENCODER_GRL_SCALE not defined, using default 0.1\")\n\ntry:\n    ASBN_DROPOUT = float(ASBN_DROPOUT)\nexcept (NameError, ValueError):\n    ASBN_DROPOUT = 0.1\n    print(\"[CELL4] WARNING: ASBN_DROPOUT not defined, using default 0.1\")\n\ntry:\n    ASBN_HIDDEN_DIM = int(ASBN_HIDDEN_DIM)\nexcept (NameError, ValueError):\n    ASBN_HIDDEN_DIM = 64\n    print(\"[CELL4] WARNING: ASBN_HIDDEN_DIM not defined, using default 64\")\n\ntry:\n    ASBN_LAMBDA_SENSE = float(ASBN_LAMBDA_SENSE)\nexcept (NameError, ValueError):\n    ASBN_LAMBDA_SENSE = 1.0\n    print(\"[CELL4] WARNING: ASBN_LAMBDA_SENSE not defined, using default 1.0\")\n\ntry:\n    ASBN_LAMBDA_CTX = float(ASBN_LAMBDA_CTX)\nexcept (NameError, ValueError):\n    ASBN_LAMBDA_CTX = 0.5\n    print(\"[CELL4] WARNING: ASBN_LAMBDA_CTX not defined, using default 0.5\")\n\ntry:\n    ASBN_LAMBDA_PROTO = float(ASBN_LAMBDA_PROTO)\nexcept (NameError, ValueError):\n    ASBN_LAMBDA_PROTO = 0.8\n    print(\"[CELL4] WARNING: ASBN_LAMBDA_PROTO not defined, using default 0.8\")\n\ntry:\n    ASBN_LAMBDA_MAX = float(ASBN_LAMBDA_MAX)\nexcept (NameError, ValueError):\n    ASBN_LAMBDA_MAX = 2.0\n    print(\"[CELL4] WARNING: ASBN_LAMBDA_MAX not defined, using default 2.0\")\n\ntry:\n    ASBN_WARMUP_STEPS = int(ASBN_WARMUP_STEPS)\nexcept (NameError, ValueError):\n    ASBN_WARMUP_STEPS = 1000\n    print(\"[CELL4] WARNING: ASBN_WARMUP_STEPS not defined, using default 1000\")\n\n# Word length constraints\ntry:\n    WORD_MIN_LENGTH = int(WORD_MIN_LENGTH)\nexcept (NameError, ValueError):\n    WORD_MIN_LENGTH = 2\n    print(\"[CELL4] WARNING: WORD_MIN_LENGTH not defined, using default 2\")\n\ntry:\n    WORD_MAX_LENGTH = int(WORD_MAX_LENGTH)\nexcept (NameError, ValueError):\n    WORD_MAX_LENGTH = 30\n    print(\"[CELL4] WARNING: WORD_MAX_LENGTH not defined, using default 30\")\n\n_WORD_MIN_LENGTH = WORD_MIN_LENGTH\n_WORD_MAX_LENGTH = WORD_MAX_LENGTH\n\nprint(f\"[CELL4] Configuration loaded:\")\nprint(f\"  Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  Enable ASBN training: {_ENABLE_ASBN_TRAINING}\")\nprint(f\"  ASBN encoder GRL scale: {ASBN_ENCODER_GRL_SCALE}\")\nprint(f\"  ASBN dropout: {ASBN_DROPOUT}\")\nprint(f\"  ASBN hidden dim: {ASBN_HIDDEN_DIM}\")\nprint(f\"  ASBN lambda scales: sense={ASBN_LAMBDA_SENSE}, ctx={ASBN_LAMBDA_CTX}, proto={ASBN_LAMBDA_PROTO}\")\nprint(f\"  ASBN lambda max: {ASBN_LAMBDA_MAX}\")\nprint(f\"  Word length: [{_WORD_MIN_LENGTH}, {_WORD_MAX_LENGTH}]\")\n\n# ==============================================================================\n# üî• FIX #2 & #4: IMPORT NORMALIZATION FUNCTIONS FROM CELL 1\n# ==============================================================================\n\ntry:\n    from __main__ import normalize_indic_word, is_indic_word, validate_word_token, detect_indic_language\n    HAS_WORD_VALIDATION = True\n    print(\"[CELL4] ‚úÖ Imported word validation functions from Cell 1\")\nexcept:\n    try:\n        normalize_indic_word = globals().get('normalize_indic_word', None)\n        is_indic_word = globals().get('is_indic_word', None)\n        validate_word_token = globals().get('validate_word_token', None)\n        detect_indic_language = globals().get('detect_indic_language', None)\n        HAS_WORD_VALIDATION = all([normalize_indic_word, is_indic_word, validate_word_token, detect_indic_language])\n        if HAS_WORD_VALIDATION:\n            print(\"[CELL4] ‚úÖ Found word validation functions in globals\")\n        else:\n            print(\"[CELL4] ‚ö†Ô∏è Word validation functions not found - using fallback\")\n    except:\n        HAS_WORD_VALIDATION = False\n        print(\"[CELL4] ‚ö†Ô∏è Word validation functions not found from Cell 1 - using fallback\")\n\n# Fallback if validation not available\nif not HAS_WORD_VALIDATION:\n    def normalize_indic_word(word, language=None):\n        \"\"\"Fallback normalization: strip whitespace.\"\"\"\n        return str(word).strip() if word else \"\"\n    \n    def is_indic_word(word):\n        \"\"\"Check if word contains Bengali Unicode characters.\"\"\"\n        if not word:\n            return False\n        return any('\\u0980' <= c <= '\\u09FF' for c in str(word))\n    \n    def validate_word_token(word, min_length=2, max_length=30):\n        \"\"\"Validate word token for tracking.\"\"\"\n        if not word:\n            return False\n        word = str(word).strip()\n        if len(word) < min_length or len(word) > max_length:\n            return False\n        if word.isdigit():\n            return False\n        return any(c.isalpha() or '\\u0980' <= c <= '\\u09FF' for c in word)\n    \n    def detect_indic_language(word):\n        \"\"\"Detect if word is Bengali.\"\"\"\n        return 'bn' if is_indic_word(word) else None\n    \n    print(\"[CELL4] ‚ö†Ô∏è Using fallback word validation functions\")\n\n# ==============================================================================\n# üî• FIX #3: IMPORT WORD TOKENIZER FROM CELL 2 (FOR CONSISTENCY)\n# ==============================================================================\n\ntry:\n    from __main__ import BengaliWordTokenizer\n    HAS_WORD_TOKENIZER = True\n    print(\"[CELL4] ‚úÖ Imported BengaliWordTokenizer from Cell 2\")\nexcept:\n    try:\n        BengaliWordTokenizer = globals().get('BengaliWordTokenizer', None)\n        HAS_WORD_TOKENIZER = BengaliWordTokenizer is not None\n        if HAS_WORD_TOKENIZER:\n            print(\"[CELL4] ‚úÖ Found BengaliWordTokenizer in globals\")\n        else:\n            print(\"[CELL4] ‚ö†Ô∏è BengaliWordTokenizer not found (optional)\")\n    except:\n        HAS_WORD_TOKENIZER = False\n        print(\"[CELL4] ‚ö†Ô∏è BengaliWordTokenizer not found from Cell 2 (optional)\")\n\n\n# ==============================================================================\n# UTILITY FUNCTIONS\n# ==============================================================================\n\ndef _device_of(x: Any) -> torch.device:\n    \"\"\"\n    Get device of tensor or default device.\n    \n    Args:\n        x: Tensor or any object\n    \n    Returns:\n        Device of tensor, or default device (CUDA if available, else CPU)\n    \"\"\"\n    if isinstance(x, torch.Tensor):\n        return x.device\n    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# ==============================================================================\n# LIGHTWEIGHT DISCRIMINATOR\n# ==============================================================================\n\nclass LightweightDiscriminator(nn.Module):\n    \"\"\"\n    Small discriminator head for ASBN word-level sense disambiguation.\n    \n    Used to distinguish between different word senses based on:\n    - Sense features (prototype probability + uncertainty)\n    - Context features (gate + span prediction)\n    - Prototype features (max prototype probability)\n    \"\"\"\n\n    def __init__(self, input_dim: int, hidden_dim: int = None, dropout: float = None):\n        \"\"\"\n        Initialize discriminator.\n        \n        Args:\n            input_dim: Input feature dimension\n            hidden_dim: Hidden layer dimension (default: from config)\n            dropout: Dropout rate (default: from config)\n        \"\"\"\n        super().__init__()\n        \n        if hidden_dim is None:\n            hidden_dim = ASBN_HIDDEN_DIM\n        if dropout is None:\n            dropout = ASBN_DROPOUT\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, 2)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass.\n        \n        Args:\n            x: Input features [N, input_dim]\n        \n        Returns:\n            Logits [N, 2] for binary classification\n        \"\"\"\n        return self.classifier(x)\n\n\n# ==============================================================================\n# WORD-LEVEL ASBN MODULE\n# ==============================================================================\n\nclass WordLevelASBNModule(nn.Module):\n    \"\"\"\n    Word-level Adversarial Sense Balance Network.\n    \n    Processes word embeddings (B, W, D) with DSCD outputs for:\n    - Sense disambiguation (different word senses)\n    - Context awareness (surrounding words)\n    - Prototype alignment (discovered sense prototypes)\n    \n    IndicBART-compatible with Bengali word-level features.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, language: str = None, use_normalization: bool = True):\n        \"\"\"\n        Initialize WordLevelASBNModule.\n        \n        Args:\n            embed_dim: Word embedding dimension\n            language: Target language (default: from config)\n            use_normalization: Use Indic word normalization (default: True)\n        \"\"\"\n        super().__init__()\n        \n        # üîß FIX #4: Use language from config if not provided\n        if language is None:\n            language = _SOURCE_LANGUAGE\n        \n        self.embed_dim = int(embed_dim)\n        self.language = language\n        self.use_normalization = use_normalization and HAS_WORD_VALIDATION\n\n        # üîß FIX #7: Discriminators for word-level sense features\n        # Input dimensions: embed_dim + feature_dim\n        self.d_sense = LightweightDiscriminator(embed_dim + 2, hidden_dim=ASBN_HIDDEN_DIM, dropout=ASBN_DROPOUT)\n        self.d_ctx = LightweightDiscriminator(embed_dim + 2, hidden_dim=ASBN_HIDDEN_DIM, dropout=ASBN_DROPOUT)\n        self.d_proto = LightweightDiscriminator(embed_dim + 1, hidden_dim=ASBN_HIDDEN_DIM, dropout=ASBN_DROPOUT)\n\n        # üîß FIX #5: Scaling parameters from config\n        self.lambda_base = {\n            \"sense\": ASBN_LAMBDA_SENSE,\n            \"ctx\": ASBN_LAMBDA_CTX,\n            \"proto\": ASBN_LAMBDA_PROTO\n        }\n        self.lambda_max = ASBN_LAMBDA_MAX\n        self.encoder_grl_scale = ASBN_ENCODER_GRL_SCALE\n\n        if _VERBOSE_LOGGING:\n            print(f\"[ASBN-INIT] Word-level ASBN initialized:\")\n            print(f\"  Embed dim: {embed_dim}\")\n            print(f\"  Language: {self.language}\")\n            print(f\"  Normalization: {'ENABLED' if self.use_normalization else 'DISABLED'}\")\n            print(f\"  Hidden dim: {ASBN_HIDDEN_DIM}\")\n            print(f\"  Dropout: {ASBN_DROPOUT}\")\n            print(f\"  Lambda scales: {self.lambda_base}\")\n            print(f\"  Lambda max: {self.lambda_max}\")\n            print(f\"  Encoder GRL scale: {self.encoder_grl_scale}\")\n\n    def critic_parameters(self):\n        \"\"\"\n        Return discriminator parameters for separate optimization.\n        \n        Returns:\n            List of discriminator parameters\n        \"\"\"\n        return list(self.d_sense.parameters()) + \\\n               list(self.d_ctx.parameters()) + \\\n               list(self.d_proto.parameters())\n\n    def _ensure_discriminators_on_device(self, device: torch.device):\n        \"\"\"\n        Move discriminators to device (best-effort).\n        \n        Args:\n            device: Target device\n        \"\"\"\n        try:\n            for mod in (self.d_sense, self.d_ctx, self.d_proto):\n                try:\n                    p = next(mod.parameters(), None)\n                    if p is not None and p.device != device:\n                        mod.to(device)\n                except Exception:\n                    try:\n                        mod.to(device)\n                    except Exception:\n                        if _VERBOSE_LOGGING:\n                            print(f\"[ASBN] Warning: moving discriminator to device {device} failed\")\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(\"[ASBN] _ensure_discriminators_on_device failed:\", traceback.format_exc().splitlines()[-1])\n\n    def _get_normalized_key(self, word: str) -> str:\n        \"\"\"\n        Get normalized word key (same as Cell 3 DSCD).\n        \n        Args:\n            word: Input word\n        \n        Returns:\n            Normalized word key\n        \"\"\"\n        if not self.use_normalization:\n            return word.strip()\n        try:\n            normalized = normalize_indic_word(word, language=self.language)\n            return normalized if normalized else word.strip()\n        except:\n            return word.strip()\n\n    def _parse_word_level_features(\n        self,\n        proto_probs: Any,\n        uncertainties: Any,\n        gates: Any,\n        span_preds: Any,\n        word_tokens: Any,\n        batch_size: int,\n        num_words: int,\n        device: torch.device\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Parse DSCD outputs into tensors.\n        \n        All outputs from Cell 3 are [B][W] lists or [B, W] tensors.\n        \n        Args:\n            proto_probs: Prototype probabilities (list[list] or tensor)\n            uncertainties: Uncertainties (list[list] or tensor)\n            gates: Gates (list[list] or tensor)\n            span_preds: Span predictions (list[list] or tensor)\n            word_tokens: Word strings (list[list])\n            batch_size: Batch size B\n            num_words: Number of words W\n            device: Target device\n        \n        Returns:\n            Tuple of (pmax, uncertainty, gate, span, valid_mask) tensors [B, W]\n        \"\"\"\n        # Initialize tensors with default values\n        pmax = torch.full((batch_size, num_words), 0.5, dtype=torch.float32, device=device)\n        U = torch.full((batch_size, num_words), 0.3, dtype=torch.float32, device=device)\n        G = torch.full((batch_size, num_words), 0.0, dtype=torch.float32, device=device)\n        S = torch.full((batch_size, num_words), 0.0, dtype=torch.float32, device=device)\n        valid_mask = torch.zeros((batch_size, num_words), dtype=torch.bool, device=device)\n\n        try:\n            # Parse proto_probs (list[list] of tensors or None)\n            if isinstance(proto_probs, list) and len(proto_probs) == batch_size:\n                for b in range(batch_size):\n                    if isinstance(proto_probs[b], list):\n                        for w in range(min(num_words, len(proto_probs[b]))):\n                            if proto_probs[b][w] is not None:\n                                try:\n                                    if isinstance(proto_probs[b][w], torch.Tensor):\n                                        pmax[b, w] = proto_probs[b][w].max().item()\n                                    else:\n                                        arr = np.asarray(proto_probs[b][w])\n                                        if arr.size > 0:\n                                            pmax[b, w] = float(np.max(arr))\n                                except Exception:\n                                    pmax[b, w] = 0.5\n\n            # Parse uncertainties (list[list] of floats)\n            if isinstance(uncertainties, list) and len(uncertainties) == batch_size:\n                for b in range(batch_size):\n                    if isinstance(uncertainties[b], list):\n                        for w in range(min(num_words, len(uncertainties[b]))):\n                            try:\n                                val = uncertainties[b][w]\n                                U[b, w] = float(val) if isinstance(val, (int, float)) else 0.3\n                            except Exception:\n                                U[b, w] = 0.3\n\n            # Parse gates (list[list] of floats)\n            if isinstance(gates, list) and len(gates) == batch_size:\n                for b in range(batch_size):\n                    if isinstance(gates[b], list):\n                        for w in range(min(num_words, len(gates[b]))):\n                            try:\n                                val = gates[b][w]\n                                G[b, w] = float(val) if isinstance(val, (int, float)) else 0.0\n                            except Exception:\n                                G[b, w] = 0.0\n\n            # Parse span_preds (list[list] of floats)\n            if isinstance(span_preds, list) and len(span_preds) == batch_size:\n                for b in range(batch_size):\n                    if isinstance(span_preds[b], list):\n                        for w in range(min(num_words, len(span_preds[b]))):\n                            try:\n                                val = span_preds[b][w]\n                                S[b, w] = float(val) if isinstance(val, (int, float)) else 0.0\n                            except Exception:\n                                S[b, w] = 0.0\n\n            # üîß FIX #9: Parse word_tokens with robust validation\n            if isinstance(word_tokens, list) and len(word_tokens) == batch_size:\n                for b in range(batch_size):\n                    if isinstance(word_tokens[b], list):\n                        for w in range(min(num_words, len(word_tokens[b]))):\n                            try:\n                                word = word_tokens[b][w]\n                                if isinstance(word, str) and word.strip():\n                                    # Validate word using Cell 1 functions\n                                    if validate_word_token(word, min_length=_WORD_MIN_LENGTH, max_length=_WORD_MAX_LENGTH):\n                                        # Check if Bengali or contains alphabetic characters\n                                        if is_indic_word(word) or any(c.isalpha() for c in word):\n                                            valid_mask[b, w] = True\n                            except Exception:\n                                valid_mask[b, w] = False\n\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(\"[ASBN] Feature parsing failed:\", traceback.format_exc().splitlines()[-1])\n\n        return pmax, U, G, S, valid_mask\n\n    def compute_lambda_scaled_tensor(\n        self,\n        pmax: torch.Tensor,\n        uncertainty: torch.Tensor,\n        gate: torch.Tensor,\n        lambda_type: str\n    ) -> torch.Tensor:\n        \"\"\"\n        Compute adaptive lambda weights for discriminator losses.\n        \n        Lambda adapts based on:\n        - pmax: Higher confidence ‚Üí higher weight\n        - uncertainty: Lower uncertainty ‚Üí higher weight\n        - gate: Higher gate ‚Üí higher weight\n        \n        Args:\n            pmax: Max prototype probability [N]\n            uncertainty: Uncertainty values [N]\n            gate: Gate values [N]\n            lambda_type: Type of lambda (\"sense\", \"ctx\", or \"proto\")\n        \n        Returns:\n            Lambda weights [N]\n        \"\"\"\n        base = float(self.lambda_base.get(lambda_type, 0.5))\n        lam = base * pmax * (1.0 - uncertainty) * gate\n        lam = torch.clamp(lam, 0.0, float(self.lambda_max))\n        lam = torch.where(torch.isfinite(lam), lam, torch.zeros_like(lam))\n        return lam\n\n    def forward_discriminators_simplified(\n        self,\n        h: Optional[torch.Tensor],\n        proto_probs: Any,\n        uncertainties: Any,\n        gates: Any,\n        span_preds: Any,\n        word_tokens: Any\n    ) -> torch.Tensor:\n        \"\"\"\n        Monitoring pass (no grad) for discriminator performance.\n        \n        Computes discriminator losses without backpropagation for monitoring.\n        Used during evaluation to track ASBN performance.\n        \n        Args:\n            h: Word embeddings [B, W, D]\n            proto_probs: Prototype probabilities from DSCD\n            uncertainties: Uncertainties from DSCD\n            gates: Gates from DSCD\n            span_preds: Span predictions from DSCD\n            word_tokens: Word strings from dataset\n        \n        Returns:\n            Scalar loss tensor (no grad)\n        \"\"\"\n        device = _device_of(h)\n        zero = torch.tensor(0.0, device=device)\n\n        # Skip if not training and monitoring disabled\n        if (not self.training) and (not _ASBN_MONITOR_IN_EVAL):\n            return zero\n\n        # Validate input\n        if not isinstance(h, torch.Tensor) or h.dim() != 3:\n            return zero\n\n        B, W, H = h.size()\n\n        try:\n            self._ensure_discriminators_on_device(device)\n        except Exception:\n            pass\n\n        # Parse DSCD outputs\n        pmax, U, G, S, valid_mask = self._parse_word_level_features(\n            proto_probs, uncertainties, gates, span_preds, word_tokens, B, W, device\n        )\n\n        # Select valid words only\n        sel_idx = valid_mask.view(-1).nonzero(as_tuple=False).squeeze(1)\n        if sel_idx.numel() == 0:\n            return zero\n\n        h_flat = h.view(B * W, H)\n        sel_emb = h_flat[sel_idx]\n        pmax_flat = pmax.view(-1)[sel_idx]\n        U_flat = U.view(-1)[sel_idx]\n        G_flat = G.view(-1)[sel_idx]\n        S_flat = S.view(-1)[sel_idx]\n\n        # Construct discriminator features\n        sense_feature = torch.stack([pmax_flat, U_flat], dim=1)\n        ctx_feature = torch.stack([G_flat, S_flat], dim=1)\n        proto_feature = pmax_flat.unsqueeze(1)\n\n        sense_input = torch.cat([sel_emb, sense_feature], dim=1)\n        ctx_input = torch.cat([sel_emb, ctx_feature], dim=1)\n        proto_input = torch.cat([sel_emb, proto_feature], dim=1)\n\n        try:\n            with torch.no_grad():\n                self._ensure_discriminators_on_device(device)\n                \n                # Forward through discriminators\n                sense_logits = self.d_sense(sense_input)\n                ctx_logits = self.d_ctx(ctx_input)\n                proto_logits = self.d_proto(proto_input)\n\n                # Generate pseudo-labels based on DSCD outputs\n                sense_label = ((pmax_flat > 0.6) & (U_flat < 0.4)).long()\n                ctx_label = ((G_flat > 0.5) & (S_flat > 0.3)).long()\n                proto_label = (pmax_flat > 0.7).long()\n\n                # Compute losses\n                loss_sense = F.cross_entropy(sense_logits, sense_label, reduction=\"none\")\n                loss_ctx = F.cross_entropy(ctx_logits, ctx_label, reduction=\"none\")\n                loss_proto = F.cross_entropy(proto_logits, proto_label, reduction=\"none\")\n\n                # Adaptive weighting\n                lam_sense = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"sense\")\n                lam_ctx = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"ctx\")\n                lam_proto = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"proto\")\n\n                weighted = lam_sense * loss_sense + lam_ctx * loss_ctx + lam_proto * loss_proto\n                avg_loss = torch.mean(weighted) if weighted.numel() > 0 else torch.tensor(0.0, device=device)\n            \n            return avg_loss\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(\"[ASBN] Monitor forward failed:\", traceback.format_exc().splitlines()[-1])\n            return zero\n\n    def forward_with_grl_simplified(\n        self,\n        h: Optional[torch.Tensor],\n        proto_probs: Any,\n        uncertainties: Any,\n        gates: Any,\n        span_preds: Any,\n        word_tokens: Any\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Compute encoder loss with frozen discriminator parameters (GRL-style).\n        \n        This implements the adversarial training mechanism:\n        1. Freeze discriminator parameters\n        2. Compute discriminator losses with current embeddings\n        3. Negate losses to encourage encoder to confuse discriminators\n        4. Scale by GRL coefficient\n        \n        Args:\n            h: Word embeddings [B, W, D]\n            proto_probs: Prototype probabilities from DSCD\n            uncertainties: Uncertainties from DSCD\n            gates: Gates from DSCD\n            span_preds: Span predictions from DSCD\n            word_tokens: Word strings from dataset\n        \n        Returns:\n            Tuple of (encoder_loss, disc_monitor_loss, zero, zero)\n        \"\"\"\n        device = _device_of(h)\n        zero = torch.tensor(0.0, device=device)\n\n        # Skip if not training or ASBN disabled\n        if (not self.training) or (not _ENABLE_ASBN_TRAINING):\n            return zero, zero, zero, zero\n\n        # Validate input\n        if not isinstance(h, torch.Tensor) or h.dim() != 3:\n            return zero, zero, zero, zero\n\n        # Compute discriminator monitoring loss (no grad)\n        try:\n            with torch.no_grad():\n                disc_monitor_loss = self.forward_discriminators_simplified(\n                    h, proto_probs, uncertainties, gates, span_preds, word_tokens\n                )\n                if not isinstance(disc_monitor_loss, torch.Tensor):\n                    disc_monitor_loss = torch.tensor(float(disc_monitor_loss), device=device)\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(\"[ASBN] Monitor failed:\", traceback.format_exc().splitlines()[-1])\n            disc_monitor_loss = torch.tensor(0.0, device=device)\n\n        # Compute encoder loss with frozen discriminators\n        try:\n            B, W, H = h.size()\n\n            pmax, U, G, S, valid_mask = self._parse_word_level_features(\n                proto_probs, uncertainties, gates, span_preds, word_tokens, B, W, device\n            )\n\n            sel_idx = valid_mask.view(-1).nonzero(as_tuple=False).squeeze(1)\n            if sel_idx.numel() == 0:\n                encoder_loss = torch.tensor(0.0, device=device, requires_grad=True)\n            else:\n                h_flat = h.view(B * W, H)\n                sel_emb = h_flat[sel_idx]\n                pmax_flat = pmax.view(-1)[sel_idx]\n                U_flat = U.view(-1)[sel_idx]\n                G_flat = G.view(-1)[sel_idx]\n                S_flat = S.view(-1)[sel_idx]\n\n                sense_feature = torch.stack([pmax_flat, U_flat], dim=1)\n                ctx_feature = torch.stack([G_flat, S_flat], dim=1)\n                proto_feature = pmax_flat.unsqueeze(1)\n\n                sense_input = torch.cat([sel_emb, sense_feature], dim=1)\n                ctx_input = torch.cat([sel_emb, ctx_feature], dim=1)\n                proto_input = torch.cat([sel_emb, proto_feature], dim=1)\n\n                # Extract frozen discriminator parameters\n                def get_frozen_params(module: nn.Module, device: torch.device):\n                    \"\"\"Extract and freeze discriminator parameters.\"\"\"\n                    try:\n                        l0 = module.classifier[0]\n                        l1 = module.classifier[3]\n                        w0 = l0.weight.detach().clone().to(device)\n                        b0 = l0.bias.detach().clone().to(device) if l0.bias is not None else None\n                        w1 = l1.weight.detach().clone().to(device)\n                        b1 = l1.bias.detach().clone().to(device) if l1.bias is not None else None\n                        for t in (w0, b0, w1, b1):\n                            if t is not None:\n                                t.requires_grad = False\n                        return (w0, b0, w1, b1)\n                    except Exception:\n                        raise RuntimeError(\"Failed to extract frozen params from discriminator\")\n\n                frozen_sense = get_frozen_params(self.d_sense, device)\n                frozen_ctx = get_frozen_params(self.d_ctx, device)\n                frozen_proto = get_frozen_params(self.d_proto, device)\n\n                # Functional forward with frozen parameters\n                def functional_classifier_forward(x: torch.Tensor, frozen_params):\n                    \"\"\"Forward through discriminator with frozen parameters.\"\"\"\n                    w0, b0, w1, b1 = frozen_params\n                    y = F.linear(x, w0, b0)\n                    y = F.relu(y)\n                    y = F.dropout(y, p=ASBN_DROPOUT, training=False)\n                    y = F.linear(y, w1, b1)\n                    return y\n\n                sense_logits = functional_classifier_forward(sense_input, frozen_sense)\n                ctx_logits = functional_classifier_forward(ctx_input, frozen_ctx)\n                proto_logits = functional_classifier_forward(proto_input, frozen_proto)\n\n                # Generate pseudo-labels\n                sense_label = ((pmax_flat > 0.6) & (U_flat < 0.4)).long()\n                ctx_label = ((G_flat > 0.5) & (S_flat > 0.3)).long()\n                proto_label = (pmax_flat > 0.7).long()\n\n                # Compute losses\n                loss_sense = F.cross_entropy(sense_logits, sense_label, reduction=\"none\")\n                loss_ctx = F.cross_entropy(ctx_logits, ctx_label, reduction=\"none\")\n                loss_proto = F.cross_entropy(proto_logits, proto_label, reduction=\"none\")\n\n                # Adaptive weighting\n                lam_sense = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"sense\")\n                lam_ctx = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"ctx\")\n                lam_proto = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"proto\")\n\n                weighted = lam_sense * loss_sense + lam_ctx * loss_ctx + lam_proto * loss_proto\n                mean_weighted = torch.mean(weighted) if weighted.numel() > 0 else torch.tensor(0.0, device=device)\n                \n                # GRL: Negate loss and scale\n                encoder_loss = -float(self.encoder_grl_scale) * mean_weighted\n                encoder_loss = encoder_loss.to(device)\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(\"[ASBN] GRL computation failed:\", traceback.format_exc().splitlines()[-1])\n            encoder_loss = torch.tensor(0.0, device=device, requires_grad=True)\n\n        return encoder_loss, disc_monitor_loss, zero, zero\n\n\n# ==============================================================================\n# üî• FIX #10: ADD ASBN CLASS ALIAS FOR CELL 6 FALLBACK IMPORT COMPATIBILITY\n# ==============================================================================\n\nASBN = WordLevelASBNModule\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ Cell 4: Word-Level ASBN Module (IndicBART-READY - 10 CRITICAL FIXES)\")\nprint(\"=\"*80)\nprint(\"Critical fixes applied:\")\nprint(\" üîß FIX #1: Added all ASBN config parameters from Cell 0 with try-except\")\nprint(\" üîß FIX #2: Proper error handling for all globals\")\nprint(\" üîß FIX #3: Imported word tokenizer from Cell 2 for consistency\")\nprint(\" üîß FIX #4: Aligned language parameter with Cell 0\")\nprint(\" üîß FIX #5: Added ASBN-specific hyperparameters (dropout, lambda scales)\")\nprint(\" üîß FIX #6: Updated all print messages for IndicBART\")\nprint(\" üîß FIX #7: Enhanced word-level feature extraction for Bengali\")\nprint(\" üîß FIX #8: Robust discriminator device handling\")\nprint(\" üîß FIX #9: Improved word_tokens validation from Cell 2/Cell 6\")\nprint(\" üîß FIX #10: Added ASBN class alias for Cell 6 fallback import compatibility\")\nprint()\nprint(\"Configuration:\")\nprint(f\" ‚Ä¢ Embed dim: configurable (from model)\")\nprint(f\" ‚Ä¢ Language: {_SOURCE_LANGUAGE}\")\nprint(f\" ‚Ä¢ Hidden dim: {ASBN_HIDDEN_DIM}\")\nprint(f\" ‚Ä¢ Dropout: {ASBN_DROPOUT}\")\nprint(f\" ‚Ä¢ Lambda scales: sense={ASBN_LAMBDA_SENSE}, ctx={ASBN_LAMBDA_CTX}, proto={ASBN_LAMBDA_PROTO}\")\nprint(f\" ‚Ä¢ Lambda max: {ASBN_LAMBDA_MAX}\")\nprint(f\" ‚Ä¢ Encoder GRL scale: {ASBN_ENCODER_GRL_SCALE}\")\nprint(f\" ‚Ä¢ Enable training: {_ENABLE_ASBN_TRAINING}\")\nprint(f\" ‚Ä¢ Monitor in eval: {_ASBN_MONITOR_IN_EVAL}\")\nprint()\nprint(\"IndicBART Features:\")\nprint(f\" ‚ú® Word-level sense disambiguation for Bengali\")\nprint(f\" ‚ú® Normalized word keys for morphology handling\")\nprint(f\" ‚ú® Adaptive lambda weighting based on DSCD outputs\")\nprint(f\" ‚ú® GRL-style adversarial training for encoder\")\nprint(f\" ‚ú® Compatible with Cell 3 DSCD outputs\")\nprint(f\" ‚ú® Word validation: {'ENABLED' if HAS_WORD_VALIDATION else 'DISABLED (using fallback)'}\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"id":"XrNq18UsH4J3","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:24.436709Z","iopub.execute_input":"2026-01-24T20:09:24.437164Z","iopub.status.idle":"2026-01-24T20:09:24.500869Z","shell.execute_reply.started":"2026-01-24T20:09:24.437142Z","shell.execute_reply":"2026-01-24T20:09:24.500166Z"}},"outputs":[{"name":"stdout","text":"[CELL4] WARNING: ASBN_MONITOR_IN_EVAL not defined, using default False\n[CELL4] WARNING: ASBN_ENCODER_GRL_SCALE not defined, using default 0.1\n[CELL4] WARNING: ASBN_LAMBDA_SENSE not defined, using default 1.0\n[CELL4] WARNING: ASBN_LAMBDA_CTX not defined, using default 0.5\n[CELL4] WARNING: ASBN_LAMBDA_PROTO not defined, using default 0.8\n[CELL4] WARNING: ASBN_LAMBDA_MAX not defined, using default 2.0\n[CELL4] WARNING: ASBN_WARMUP_STEPS not defined, using default 1000\n[CELL4] Configuration loaded:\n  Source language: bn\n  Target language: en\n  Enable ASBN training: True\n  ASBN encoder GRL scale: 0.1\n  ASBN dropout: 0.1\n  ASBN hidden dim: 64\n  ASBN lambda scales: sense=1.0, ctx=0.5, proto=0.8\n  ASBN lambda max: 2.0\n  Word length: [2, 30]\n[CELL4] ‚úÖ Imported word validation functions from Cell 1\n[CELL4] ‚úÖ Imported BengaliWordTokenizer from Cell 2\n\n================================================================================\n‚úÖ Cell 4: Word-Level ASBN Module (IndicBART-READY - 10 CRITICAL FIXES)\n================================================================================\nCritical fixes applied:\n üîß FIX #1: Added all ASBN config parameters from Cell 0 with try-except\n üîß FIX #2: Proper error handling for all globals\n üîß FIX #3: Imported word tokenizer from Cell 2 for consistency\n üîß FIX #4: Aligned language parameter with Cell 0\n üîß FIX #5: Added ASBN-specific hyperparameters (dropout, lambda scales)\n üîß FIX #6: Updated all print messages for IndicBART\n üîß FIX #7: Enhanced word-level feature extraction for Bengali\n üîß FIX #8: Robust discriminator device handling\n üîß FIX #9: Improved word_tokens validation from Cell 2/Cell 6\n üîß FIX #10: Added ASBN class alias for Cell 6 fallback import compatibility\n\nConfiguration:\n ‚Ä¢ Embed dim: configurable (from model)\n ‚Ä¢ Language: bn\n ‚Ä¢ Hidden dim: 64\n ‚Ä¢ Dropout: 0.1\n ‚Ä¢ Lambda scales: sense=1.0, ctx=0.5, proto=0.8\n ‚Ä¢ Lambda max: 2.0\n ‚Ä¢ Encoder GRL scale: 0.1\n ‚Ä¢ Enable training: True\n ‚Ä¢ Monitor in eval: False\n\nIndicBART Features:\n ‚ú® Word-level sense disambiguation for Bengali\n ‚ú® Normalized word keys for morphology handling\n ‚ú® Adaptive lambda weighting based on DSCD outputs\n ‚ú® GRL-style adversarial training for encoder\n ‚ú® Compatible with Cell 3 DSCD outputs\n ‚ú® Word validation: ENABLED\n================================================================================\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ==============================================================================\n# CELL 5: WORD-LEVEL TRG MODULE (IndicBART-READY - 12 CRITICAL FIXES)\n# ==============================================================================\n# Critical fixes applied for IndicBART compatibility:\n# 1. Added all TRG config parameters from Cell 0 with try-except\n# 2. Proper error handling for all globals\n# 3. Imported word tokenizer from Cell 2 for consistency\n# 4. Aligned language parameter with Cell 0\n# 5. Added TRG-specific hyperparameters (evidence_k, gen_embed, etc.)\n# 6. Updated all print messages for IndicBART\n# 7. Enhanced word-level explanation generation for Bengali\n# 8. Improved DSCD output parsing robustness\n# 9. Added comprehensive word validation\n# 10. Enhanced evidence extraction with Bengali support\n# 11. Added TRG class alias for Cell 6 fallback import compatibility\n# 12. Added batch processing with proper error handling\n# ==============================================================================\n\nfrom typing import List, Dict, Tuple, Optional, Any\nfrom collections import deque\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n# ==============================================================================\n# CONFIGURATION FROM CELL 0\n# ==============================================================================\n\n# Basic config\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, ValueError):\n    VERBOSE_LOGGING = False\n    print(\"[CELL5] WARNING: VERBOSE_LOGGING not defined, using default False\")\n\n_VERBOSE_LOGGING = VERBOSE_LOGGING\n\ntry:\n    SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, ValueError):\n    SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL5] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n\n_SOURCE_LANGUAGE = SOURCE_LANGUAGE\n\ntry:\n    TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, ValueError):\n    TARGET_LANGUAGE = \"en\"\n    print(\"[CELL5] WARNING: TARGET_LANGUAGE not defined, using default 'en'\")\n\n_TARGET_LANGUAGE = TARGET_LANGUAGE\n\n# ==============================================================================\n# üî• FIX #1 & #5: TRG-SPECIFIC CONFIGURATION\n# ==============================================================================\n\ntry:\n    TRG_EVIDENCE_K = int(TRG_EVIDENCE_K)\nexcept (NameError, ValueError):\n    TRG_EVIDENCE_K = 3\n    print(\"[CELL5] WARNING: TRG_EVIDENCE_K not defined, using default 3\")\n\n_TRG_EVIDENCE_K = TRG_EVIDENCE_K\n\ntry:\n    TRG_GEN_EMBED = int(TRG_GEN_EMBED)\nexcept (NameError, ValueError):\n    TRG_GEN_EMBED = 64\n    print(\"[CELL5] WARNING: TRG_GEN_EMBED not defined, using default 64\")\n\n_TRG_GEN_EMBED = TRG_GEN_EMBED\n\ntry:\n    MAX_SILVER_BUFFER = int(MAX_SILVER_BUFFER)\nexcept (NameError, ValueError):\n    MAX_SILVER_BUFFER = 50\n    print(\"[CELL5] WARNING: MAX_SILVER_BUFFER not defined, using default 50\")\n\n_MAX_SILVER_BUFFER = MAX_SILVER_BUFFER\n\ntry:\n    ENABLE_TRG_INFERENCE = bool(ENABLE_TRG_INFERENCE)\nexcept (NameError, ValueError):\n    ENABLE_TRG_INFERENCE = True\n    print(\"[CELL5] WARNING: ENABLE_TRG_INFERENCE not defined, using default True\")\n\n_ENABLE_TRG_INFERENCE = ENABLE_TRG_INFERENCE\n\ntry:\n    TRG_UNCERTAINTY_THRESHOLD = float(TRG_UNCERTAINTY_THRESHOLD)\nexcept (NameError, ValueError):\n    TRG_UNCERTAINTY_THRESHOLD = 0.4\n    print(\"[CELL5] WARNING: TRG_UNCERTAINTY_THRESHOLD not defined, using default 0.4\")\n\ntry:\n    TRG_SPAN_THRESHOLD = float(TRG_SPAN_THRESHOLD)\nexcept (NameError, ValueError):\n    TRG_SPAN_THRESHOLD = 0.3\n    print(\"[CELL5] WARNING: TRG_SPAN_THRESHOLD not defined, using default 0.3\")\n\ntry:\n    TRG_MIN_CONFIDENCE = float(TRG_MIN_CONFIDENCE)\nexcept (NameError, ValueError):\n    TRG_MIN_CONFIDENCE = 0.3\n    print(\"[CELL5] WARNING: TRG_MIN_CONFIDENCE not defined, using default 0.3\")\n\ntry:\n    TRG_MAX_EXPLANATIONS = int(TRG_MAX_EXPLANATIONS)\nexcept (NameError, ValueError):\n    TRG_MAX_EXPLANATIONS = 10\n    print(\"[CELL5] WARNING: TRG_MAX_EXPLANATIONS not defined, using default 10\")\n\n# Word length constraints\ntry:\n    WORD_MIN_LENGTH = int(WORD_MIN_LENGTH)\nexcept (NameError, ValueError):\n    WORD_MIN_LENGTH = 2\n    print(\"[CELL5] WARNING: WORD_MIN_LENGTH not defined, using default 2\")\n\ntry:\n    WORD_MAX_LENGTH = int(WORD_MAX_LENGTH)\nexcept (NameError, ValueError):\n    WORD_MAX_LENGTH = 30\n    print(\"[CELL5] WARNING: WORD_MAX_LENGTH not defined, using default 30\")\n\n_WORD_MIN_LENGTH = WORD_MIN_LENGTH\n_WORD_MAX_LENGTH = WORD_MAX_LENGTH\n\nprint(f\"[CELL5] Configuration loaded:\")\nprint(f\"  Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  Evidence K: {_TRG_EVIDENCE_K}\")\nprint(f\"  Gen embed dim: {_TRG_GEN_EMBED}\")\nprint(f\"  Max silver buffer: {_MAX_SILVER_BUFFER}\")\nprint(f\"  Enable TRG inference: {_ENABLE_TRG_INFERENCE}\")\nprint(f\"  Uncertainty threshold: {TRG_UNCERTAINTY_THRESHOLD}\")\nprint(f\"  Span threshold: {TRG_SPAN_THRESHOLD}\")\nprint(f\"  Min confidence: {TRG_MIN_CONFIDENCE}\")\nprint(f\"  Max explanations: {TRG_MAX_EXPLANATIONS}\")\nprint(f\"  Word length: [{_WORD_MIN_LENGTH}, {_WORD_MAX_LENGTH}]\")\n\n# ==============================================================================\n# üî• FIX #2 & #4: IMPORT NORMALIZATION FUNCTIONS FROM CELL 1\n# ==============================================================================\n\ntry:\n    from __main__ import normalize_indic_word, is_indic_word, validate_word_token, detect_indic_language\n    HAS_WORD_VALIDATION = True\n    print(\"[CELL5] ‚úÖ Imported word validation functions from Cell 1\")\nexcept:\n    try:\n        normalize_indic_word = globals().get('normalize_indic_word', None)\n        is_indic_word = globals().get('is_indic_word', None)\n        validate_word_token = globals().get('validate_word_token', None)\n        detect_indic_language = globals().get('detect_indic_language', None)\n        HAS_WORD_VALIDATION = all([normalize_indic_word, is_indic_word, validate_word_token, detect_indic_language])\n        if HAS_WORD_VALIDATION:\n            print(\"[CELL5] ‚úÖ Found word validation functions in globals\")\n        else:\n            print(\"[CELL5] ‚ö†Ô∏è Word validation functions not found - using fallback\")\n    except:\n        HAS_WORD_VALIDATION = False\n        print(\"[CELL5] ‚ö†Ô∏è Word validation functions not found from Cell 1 - using fallback\")\n\n# Fallback if validation not available\nif not HAS_WORD_VALIDATION:\n    def normalize_indic_word(word, language=None):\n        \"\"\"Fallback normalization: strip whitespace.\"\"\"\n        return str(word).strip() if word else \"\"\n    \n    def is_indic_word(word):\n        \"\"\"Check if word contains Bengali Unicode characters.\"\"\"\n        if not word:\n            return False\n        return any('\\u0980' <= c <= '\\u09FF' for c in str(word))\n    \n    def validate_word_token(word, min_length=2, max_length=30):\n        \"\"\"Validate word token for tracking.\"\"\"\n        if not word:\n            return False\n        word = str(word).strip()\n        if len(word) < min_length or len(word) > max_length:\n            return False\n        if word.isdigit():\n            return False\n        return any(c.isalpha() or '\\u0980' <= c <= '\\u09FF' for c in word)\n    \n    def detect_indic_language(word):\n        \"\"\"Detect if word is Bengali.\"\"\"\n        return 'bn' if is_indic_word(word) else None\n    \n    print(\"[CELL5] ‚ö†Ô∏è Using fallback word validation functions\")\n\n# ==============================================================================\n# üî• FIX #3: IMPORT WORD TOKENIZER FROM CELL 2 (FOR CONSISTENCY)\n# ==============================================================================\n\ntry:\n    from __main__ import BengaliWordTokenizer\n    HAS_WORD_TOKENIZER = True\n    print(\"[CELL5] ‚úÖ Imported BengaliWordTokenizer from Cell 2\")\nexcept:\n    try:\n        BengaliWordTokenizer = globals().get('BengaliWordTokenizer', None)\n        HAS_WORD_TOKENIZER = BengaliWordTokenizer is not None\n        if HAS_WORD_TOKENIZER:\n            print(\"[CELL5] ‚úÖ Found BengaliWordTokenizer in globals\")\n        else:\n            print(\"[CELL5] ‚ö†Ô∏è BengaliWordTokenizer not found (optional)\")\n    except:\n        HAS_WORD_TOKENIZER = False\n        print(\"[CELL5] ‚ö†Ô∏è BengaliWordTokenizer not found from Cell 2 (optional)\")\n\n\n# ==============================================================================\n# EXPLANATION TEMPLATE CLASS\n# ==============================================================================\n\nclass ComprehensiveTRGExplanationTemplate:\n    \"\"\"\n    Explanation template class to generate human-friendly rationale text.\n    \n    Generates explanations at different confidence levels:\n    - High confidence (‚â•0.65): Strong assertion\n    - Medium confidence (0.4-0.65): Tentative assertion\n    - Low confidence (<0.4): Uncertain assertion\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize explanation templates.\"\"\"\n        self.templates = {\n            \"high\": \"Chose '{sense}' ({confidence:.1%}) for word '{word}' due to context: {evidence}. {alternatives}\",\n            \"medium\": \"Possibly '{sense}' ({confidence:.1%}) for word '{word}', context clues: {evidence}. {alternatives}\",\n            \"low\": \"Uncertain choice '{sense}' ({confidence:.1%}) for word '{word}'. Consider: {evidence}. {alternatives}\",\n            \"fallback\": \"Word '{word}' disambiguated as '{sense}' with confidence {confidence:.1%}.\",\n        }\n\n    def generate(\n        self,\n        word: str,\n        chosen_sense: str,\n        confidence: float,\n        evidence: str,\n        alternatives: str = \"\"\n    ) -> str:\n        \"\"\"\n        Generate explanation text based on confidence level.\n        \n        Args:\n            word: Original word string\n            chosen_sense: Chosen sense identifier (e.g., \"sense_0\")\n            confidence: Confidence score [0, 1]\n            evidence: Evidence text (context words)\n            alternatives: Alternative senses text\n        \n        Returns:\n            Human-readable explanation string\n        \"\"\"\n        try:\n            if confidence >= 0.65:\n                temp = self.templates[\"high\"]\n            elif confidence >= 0.4:\n                temp = self.templates[\"medium\"]\n            elif confidence < 0.4:\n                temp = self.templates[\"low\"]\n            else:\n                temp = self.templates[\"fallback\"]\n            \n            return temp.format(\n                word=word,\n                sense=chosen_sense,\n                confidence=confidence,\n                evidence=evidence,\n                alternatives=alternatives\n            )\n        except Exception:\n            return f\"Word '{word}' disambiguated as '{chosen_sense}' ({confidence:.1%}).\"\n\n\n# ==============================================================================\n# WORD-LEVEL TRG FEATURE EXTRACTOR\n# ==============================================================================\n\nclass WordLevelTRGExtractor:\n    \"\"\"\n    Extracts explanation-relevant features from word-level DSCD outputs.\n    \n    Handles DSCD outputs from Cell 3:\n    - proto_probs: [[tensor or None for each word]]\n    - uncertainties: [[float for each word]]\n    - gates: [[float for each word]]\n    - span_preds: [[float for each word]]\n    \"\"\"\n\n    def __init__(self, language: str = None, use_normalization: bool = True):\n        \"\"\"\n        Initialize extractor.\n        \n        Args:\n            language: Target language (default: from config)\n            use_normalization: Use Indic word normalization\n        \"\"\"\n        if language is None:\n            language = _SOURCE_LANGUAGE\n        \n        self.language = language\n        self.use_normalization = use_normalization and HAS_WORD_VALIDATION\n\n    def _get_normalized_key(self, word: str) -> str:\n        \"\"\"\n        Get normalized word key (same as Cell 3 DSCD).\n        \n        Args:\n            word: Input word\n        \n        Returns:\n            Normalized word key\n        \"\"\"\n        if not self.use_normalization:\n            return word.strip()\n        try:\n            normalized = normalize_indic_word(word, language=self.language)\n            return normalized if normalized else word.strip()\n        except:\n            return word.strip()\n\n    def _safe_extract_proto_probs(self, proto_probs: Any, word_idx: int) -> torch.Tensor:\n        \"\"\"\n        Safely extract proto_probs tensor for word index.\n        \n        Cell 3 format: proto_probs[batch][word] = tensor or None\n        \n        Args:\n            proto_probs: Proto probs from DSCD (list[list] or tensor)\n            word_idx: Word position index\n        \n        Returns:\n            Proto probs tensor [K] or default [1.0]\n        \"\"\"\n        try:\n            if proto_probs is None:\n                return torch.tensor([1.0], dtype=torch.float32)\n\n            # Handle list[list] format (most common from Cell 3)\n            if isinstance(proto_probs, list):\n                if len(proto_probs) > 0:\n                    batch = proto_probs[0]\n                    if isinstance(batch, list) and word_idx < len(batch):\n                        val = batch[word_idx]\n                        if val is None:\n                            return torch.tensor([1.0], dtype=torch.float32)\n                        if isinstance(val, torch.Tensor):\n                            return val.detach().cpu().float()\n                        return torch.as_tensor(np.asarray(val, dtype=np.float32))\n            \n            # Handle tensor format (alternative)\n            if isinstance(proto_probs, torch.Tensor):\n                if proto_probs.dim() == 3:\n                    return proto_probs[0, word_idx, :].float()\n                elif proto_probs.dim() == 2:\n                    return proto_probs[word_idx].float()\n                elif proto_probs.dim() == 1:\n                    return proto_probs.float()\n            \n            return torch.tensor([1.0], dtype=torch.float32)\n        except Exception:\n            if _VERBOSE_LOGGING:\n                import traceback as tb\n                print(\"[TRG] Error in _safe_extract_proto_probs:\", tb.format_exc().splitlines()[-1])\n            return torch.tensor([1.0], dtype=torch.float32)\n\n    def _safe_extract_scalar(self, array_like: Any, word_idx: int, default: float = 0.0) -> float:\n        \"\"\"\n        Safely extract scalar value for word index.\n        \n        Cell 3 format: uncertainties[batch][word] = float\n        \n        Args:\n            array_like: Scalar array from DSCD (list[list] or tensor)\n            word_idx: Word position index\n            default: Default value if extraction fails\n        \n        Returns:\n            Float value or default\n        \"\"\"\n        try:\n            if array_like is None:\n                return default\n\n            # Handle list[list] format (most common from Cell 3)\n            if isinstance(array_like, list):\n                if len(array_like) > 0:\n                    batch = array_like[0]\n                    if isinstance(batch, list) and word_idx < len(batch):\n                        val = batch[word_idx]\n                        if isinstance(val, torch.Tensor):\n                            return float(val.detach().cpu().item())\n                        return float(val)\n            \n            # Handle tensor format (alternative)\n            if isinstance(array_like, torch.Tensor):\n                if array_like.dim() == 2:\n                    return float(array_like[0, word_idx])\n                elif array_like.dim() == 1:\n                    return float(array_like[word_idx])\n            \n            # Handle scalar\n            if isinstance(array_like, (float, int)):\n                return float(array_like)\n            \n            return default\n        except Exception:\n            if _VERBOSE_LOGGING:\n                import traceback as tb\n                print(\"[TRG] Error in _safe_extract_scalar:\", tb.format_exc().splitlines()[-1])\n            return default\n\n    def extract_evidence_words(\n        self,\n        words: List[str],\n        pos: int,\n        max_k: int = None\n    ) -> List[str]:\n        \"\"\"\n        Extract top-K context words around position as evidence.\n        \n        Filters punctuation and validates words using Cell 1 functions.\n        \n        Args:\n            words: List of word strings\n            pos: Position of target word\n            max_k: Maximum context words to extract (default: from config)\n        \n        Returns:\n            List of context words (up to max_k)\n        \"\"\"\n        if max_k is None:\n            max_k = _TRG_EVIDENCE_K\n        \n        context_words = []\n        start = max(pos - max_k, 0)\n        end = min(pos + max_k + 1, len(words))\n        \n        for i in range(start, end):\n            if i == pos:\n                continue\n            \n            word = words[i].strip()\n            if not word:\n                continue\n            \n            # Skip pure punctuation\n            if all(c in '.,!?;:()[]{}\"\\'-‚Äî‚Äì/\\\\‡•§' for c in word):\n                continue\n            \n            # Validate word (min_length=1 for context words)\n            if validate_word_token(word, min_length=1, max_length=_WORD_MAX_LENGTH):\n                context_words.append(word)\n            \n            if len(context_words) >= max_k:\n                break\n        \n        return context_words\n\n\n# ==============================================================================\n# MAIN TRG CLASS\n# ==============================================================================\n\nclass CompleteTRGWithExplanations:\n    \"\"\"\n    Main class for word-level transparent rationale generation.\n    \n    Processes word-level DSCD outputs to generate human-readable explanations\n    for homograph disambiguation decisions.\n    \n    IndicBART-compatible with Bengali word-level features.\n    \"\"\"\n    \n    def __init__(self, language: str = None, use_normalization: bool = True):\n        \"\"\"\n        Initialize CompleteTRGWithExplanations.\n        \n        Args:\n            language: Target language (default: from config)\n            use_normalization: Use Indic word normalization\n        \"\"\"\n        if language is None:\n            language = _SOURCE_LANGUAGE\n        \n        self.language = language\n        self.use_normalization = use_normalization\n        self.template = ComprehensiveTRGExplanationTemplate()\n        self.extractor = WordLevelTRGExtractor(language=language, use_normalization=use_normalization)\n\n        if _VERBOSE_LOGGING:\n            print(f\"[TRG-INIT] Word-level TRG initialized:\")\n            print(f\"  Language: {language}\")\n            print(f\"  Normalization: {'ENABLED' if use_normalization else 'DISABLED'}\")\n            print(f\"  Evidence K: {_TRG_EVIDENCE_K}\")\n            print(f\"  Uncertainty threshold: {TRG_UNCERTAINTY_THRESHOLD}\")\n            print(f\"  Span threshold: {TRG_SPAN_THRESHOLD}\")\n            print(f\"  Min confidence: {TRG_MIN_CONFIDENCE}\")\n\n    def process_sentence_for_explanations(\n        self,\n        words: List[str],\n        dscd_outputs: Dict[str, Any]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Process a list of words and DSCD outputs to generate explanations.\n        \n        Args:\n            words: List of word strings (single sentence)\n            dscd_outputs: Dict from Cell 3 with keys:\n                - proto_probs: [[tensor or None for each word]]\n                - uncertainties: [[float for each word]]\n                - gates: [[float for each word]]\n                - span_preds: [[float for each word]]\n        \n        Returns:\n            List of explanation dicts with keys:\n                - word_pos: int\n                - word: str\n                - normalized_word: str\n                - explanation: str\n                - confidence: float\n                - uncertainty: float\n                - span: float\n                - gate: float\n                - alternatives: list[dict]\n                - evidence_words: list[str]\n                - num_senses: int\n        \"\"\"\n        if not isinstance(words, list) or len(words) == 0:\n            return []\n\n        # Extract DSCD outputs\n        proto_probs = dscd_outputs.get(\"proto_probs\", [[]])\n        uncertainties = dscd_outputs.get(\"uncertainties\", [[]])\n        span_preds = dscd_outputs.get(\"span_preds\", [[]])\n        gates = dscd_outputs.get(\"gates\", [[]])\n\n        explanations = []\n\n        for word_idx, word in enumerate(words):\n            # Validate word\n            if not isinstance(word, str) or not word.strip():\n                continue\n\n            if not validate_word_token(word, min_length=_WORD_MIN_LENGTH, max_length=_WORD_MAX_LENGTH):\n                continue\n\n            # Extract proto probs\n            proto = self.extractor._safe_extract_proto_probs(proto_probs, word_idx)\n            \n            # Need at least 2 senses for disambiguation\n            if proto is None or proto.numel() < 2:\n                continue\n\n            # Extract scalar features\n            uncertainty = self.extractor._safe_extract_scalar(uncertainties, word_idx, default=0.0)\n            span = self.extractor._safe_extract_scalar(span_preds, word_idx, default=0.0)\n            gate = self.extractor._safe_extract_scalar(gates, word_idx, default=0.0)\n\n            # Skip if not ambiguous (low span and low uncertainty)\n            if span < TRG_SPAN_THRESHOLD and uncertainty < TRG_UNCERTAINTY_THRESHOLD:\n                continue\n\n            # Get max probability and sense\n            max_prob, idx_max = torch.max(proto, dim=0)\n            max_prob_val = float(max_prob.item())\n            \n            # Skip if confidence too low\n            if max_prob_val < TRG_MIN_CONFIDENCE:\n                continue\n            \n            sense_name = f\"sense_{idx_max.item()}\"\n\n            # Extract evidence words\n            evidence_words = self.extractor.extract_evidence_words(words, word_idx)\n            evidence_text = \", \".join(evidence_words) if evidence_words else \"surrounding context\"\n\n            # Get alternatives\n            alt_text = \"\"\n            alternatives = []\n            if proto.numel() > 1:\n                sorted_probs, sorted_indices = torch.sort(proto, descending=True)\n                for i_alt in range(1, min(3, proto.numel())):\n                    alt_idx = int(sorted_indices[i_alt].item())\n                    alt_prob = float(sorted_probs[i_alt].item())\n                    alt_sense = f\"sense_{alt_idx}\"\n                    alternatives.append({\n                        \"sense\": alt_sense,\n                        \"confidence\": alt_prob\n                    })\n                    \n                alt_strings = [f\"'{a['sense']}' ({a['confidence']:.1%})\" for a in alternatives]\n                alt_text = \"Alternatives: \" + \", \".join(alt_strings) + \".\" if alt_strings else \"\"\n\n            # Generate explanation\n            explanation_str = self.template.generate(\n                word=word,\n                chosen_sense=sense_name,\n                confidence=max_prob_val,\n                evidence=evidence_text,\n                alternatives=alt_text\n            )\n\n            # Store explanation\n            explanations.append({\n                \"word_pos\": word_idx,\n                \"word\": word,\n                \"normalized_word\": self.extractor._get_normalized_key(word),\n                \"explanation\": explanation_str,\n                \"confidence\": max_prob_val,\n                \"uncertainty\": uncertainty,\n                \"span\": span,\n                \"gate\": gate,\n                \"alternatives\": alternatives,\n                \"evidence_words\": evidence_words,\n                \"num_senses\": proto.numel()\n            })\n            \n            # Limit number of explanations\n            if len(explanations) >= TRG_MAX_EXPLANATIONS:\n                break\n\n        return explanations\n\n    def batch_process_explanations(\n        self,\n        batch_words: List[List[str]],\n        batch_dscd_outputs: Dict[str, Any]\n    ) -> List[List[Dict[str, Any]]]:\n        \"\"\"\n        Process a batch of sentences.\n        \n        Args:\n            batch_words: List of word lists [[word1, word2, ...], [word1, ...]]\n            batch_dscd_outputs: DSCD outputs with batch dimension\n        \n        Returns:\n            List of explanation lists (one per sentence)\n        \"\"\"\n        batch_explanations = []\n        \n        for batch_idx, words in enumerate(batch_words):\n            try:\n                # Extract outputs for this batch\n                sentence_outputs = {\n                    \"proto_probs\": [batch_dscd_outputs.get(\"proto_probs\", [[]])[batch_idx]] if batch_idx < len(batch_dscd_outputs.get(\"proto_probs\", [[]])) else [[]],\n                    \"uncertainties\": [batch_dscd_outputs.get(\"uncertainties\", [[]])[batch_idx]] if batch_idx < len(batch_dscd_outputs.get(\"uncertainties\", [[]])) else [[]],\n                    \"gates\": [batch_dscd_outputs.get(\"gates\", [[]])[batch_idx]] if batch_idx < len(batch_dscd_outputs.get(\"gates\", [[]])) else [[]],\n                    \"span_preds\": [batch_dscd_outputs.get(\"span_preds\", [[]])[batch_idx]] if batch_idx < len(batch_dscd_outputs.get(\"span_preds\", [[]])) else [[]]\n                }\n                \n                # Process sentence\n                explanations = self.process_sentence_for_explanations(words, sentence_outputs)\n                batch_explanations.append(explanations)\n            except Exception:\n                if _VERBOSE_LOGGING:\n                    import traceback as tb\n                    print(f\"[TRG] Error processing batch {batch_idx}:\", tb.format_exc().splitlines()[-1])\n                batch_explanations.append([])\n        \n        return batch_explanations\n\n    def format_explanations_for_display(self, explanations: List[Dict[str, Any]]) -> str:\n        \"\"\"\n        Format explanations as human-readable text.\n        \n        Args:\n            explanations: List of explanation dicts\n        \n        Returns:\n            Formatted string for display\n        \"\"\"\n        if not explanations:\n            return \"No ambiguous words requiring explanation.\"\n        \n        lines = [f\"Found {len(explanations)} ambiguous word(s):\\n\"]\n        for i, expl in enumerate(explanations, 1):\n            lines.append(f\"{i}. {expl['explanation']}\")\n        \n        return \"\\n\".join(lines)\n\n    def get_explanation_summary(self, explanations: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Get summary statistics for explanations.\n        \n        Args:\n            explanations: List of explanation dicts\n        \n        Returns:\n            Summary dict with statistics\n        \"\"\"\n        if not explanations:\n            return {\n                \"total_words\": 0,\n                \"avg_confidence\": 0.0,\n                \"avg_uncertainty\": 0.0,\n                \"avg_num_senses\": 0.0,\n                \"high_confidence_count\": 0,\n                \"medium_confidence_count\": 0,\n                \"low_confidence_count\": 0\n            }\n        \n        confidences = [e[\"confidence\"] for e in explanations]\n        uncertainties = [e[\"uncertainty\"] for e in explanations]\n        num_senses = [e[\"num_senses\"] for e in explanations]\n        \n        high_conf = sum(1 for c in confidences if c >= 0.65)\n        med_conf = sum(1 for c in confidences if 0.4 <= c < 0.65)\n        low_conf = sum(1 for c in confidences if c < 0.4)\n        \n        return {\n            \"total_words\": len(explanations),\n            \"avg_confidence\": float(np.mean(confidences)),\n            \"avg_uncertainty\": float(np.mean(uncertainties)),\n            \"avg_num_senses\": float(np.mean(num_senses)),\n            \"high_confidence_count\": high_conf,\n            \"medium_confidence_count\": med_conf,\n            \"low_confidence_count\": low_conf\n        }\n\n\n# ==============================================================================\n# üî• FIX #11: ADD TRG CLASS ALIAS FOR CELL 6 FALLBACK IMPORT COMPATIBILITY\n# ==============================================================================\n\nTRG = CompleteTRGWithExplanations\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ Cell 5: Word-Level TRG Module (IndicBART-READY - 12 CRITICAL FIXES)\")\nprint(\"=\"*80)\nprint(\"Critical fixes applied:\")\nprint(\" üîß FIX #1: Added all TRG config parameters from Cell 0 with try-except\")\nprint(\" üîß FIX #2: Proper error handling for all globals\")\nprint(\" üîß FIX #3: Imported word tokenizer from Cell 2 for consistency\")\nprint(\" üîß FIX #4: Aligned language parameter with Cell 0\")\nprint(\" üîß FIX #5: Added TRG-specific hyperparameters (evidence_k, thresholds, etc.)\")\nprint(\" üîß FIX #6: Updated all print messages for IndicBART\")\nprint(\" üîß FIX #7: Enhanced word-level explanation generation for Bengali\")\nprint(\" üîß FIX #8: Improved DSCD output parsing robustness\")\nprint(\" üîß FIX #9: Added comprehensive word validation\")\nprint(\" üîß FIX #10: Enhanced evidence extraction with Bengali support\")\nprint(\" üîß FIX #11: Added TRG class alias for Cell 6 fallback import compatibility\")\nprint(\" üîß FIX #12: Added batch processing with proper error handling\")\nprint()\nprint(\"Configuration:\")\nprint(f\" ‚Ä¢ Language: {_SOURCE_LANGUAGE}\")\nprint(f\" ‚Ä¢ Evidence K: {_TRG_EVIDENCE_K} context words\")\nprint(f\" ‚Ä¢ Uncertainty threshold: {TRG_UNCERTAINTY_THRESHOLD}\")\nprint(f\" ‚Ä¢ Span threshold: {TRG_SPAN_THRESHOLD}\")\nprint(f\" ‚Ä¢ Min confidence: {TRG_MIN_CONFIDENCE}\")\nprint(f\" ‚Ä¢ Max explanations: {TRG_MAX_EXPLANATIONS}\")\nprint(f\" ‚Ä¢ Enable inference: {_ENABLE_TRG_INFERENCE}\")\nprint(f\" ‚Ä¢ Word length: [{_WORD_MIN_LENGTH}, {_WORD_MAX_LENGTH}]\")\nprint()\nprint(\"IndicBART Features:\")\nprint(f\" ‚ú® Word-level rationale generation for Bengali\")\nprint(f\" ‚ú® Normalized word keys for morphology handling\")\nprint(f\" ‚ú® Context-aware evidence extraction\")\nprint(f\" ‚ú® Multi-level confidence explanations (high/medium/low)\")\nprint(f\" ‚ú® Alternative sense suggestions\")\nprint(f\" ‚ú® Batch processing support\")\nprint(f\" ‚ú® Compatible with Cell 3 DSCD outputs\")\nprint(f\" ‚ú® Word validation: {'ENABLED' if HAS_WORD_VALIDATION else 'DISABLED (using fallback)'}\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"id":"svk-wKO7H4J3","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:24.501794Z","iopub.execute_input":"2026-01-24T20:09:24.502005Z","iopub.status.idle":"2026-01-24T20:09:24.558595Z","shell.execute_reply.started":"2026-01-24T20:09:24.501986Z","shell.execute_reply":"2026-01-24T20:09:24.557935Z"}},"outputs":[{"name":"stdout","text":"[CELL5] WARNING: TRG_UNCERTAINTY_THRESHOLD not defined, using default 0.4\n[CELL5] WARNING: TRG_SPAN_THRESHOLD not defined, using default 0.3\n[CELL5] WARNING: TRG_MIN_CONFIDENCE not defined, using default 0.3\n[CELL5] WARNING: TRG_MAX_EXPLANATIONS not defined, using default 10\n[CELL5] Configuration loaded:\n  Source language: bn\n  Target language: en\n  Evidence K: 3\n  Gen embed dim: 64\n  Max silver buffer: 50\n  Enable TRG inference: True\n  Uncertainty threshold: 0.4\n  Span threshold: 0.3\n  Min confidence: 0.3\n  Max explanations: 10\n  Word length: [2, 30]\n[CELL5] ‚úÖ Imported word validation functions from Cell 1\n[CELL5] ‚úÖ Imported BengaliWordTokenizer from Cell 2\n\n================================================================================\n‚úÖ Cell 5: Word-Level TRG Module (IndicBART-READY - 12 CRITICAL FIXES)\n================================================================================\nCritical fixes applied:\n üîß FIX #1: Added all TRG config parameters from Cell 0 with try-except\n üîß FIX #2: Proper error handling for all globals\n üîß FIX #3: Imported word tokenizer from Cell 2 for consistency\n üîß FIX #4: Aligned language parameter with Cell 0\n üîß FIX #5: Added TRG-specific hyperparameters (evidence_k, thresholds, etc.)\n üîß FIX #6: Updated all print messages for IndicBART\n üîß FIX #7: Enhanced word-level explanation generation for Bengali\n üîß FIX #8: Improved DSCD output parsing robustness\n üîß FIX #9: Added comprehensive word validation\n üîß FIX #10: Enhanced evidence extraction with Bengali support\n üîß FIX #11: Added TRG class alias for Cell 6 fallback import compatibility\n üîß FIX #12: Added batch processing with proper error handling\n\nConfiguration:\n ‚Ä¢ Language: bn\n ‚Ä¢ Evidence K: 3 context words\n ‚Ä¢ Uncertainty threshold: 0.4\n ‚Ä¢ Span threshold: 0.3\n ‚Ä¢ Min confidence: 0.3\n ‚Ä¢ Max explanations: 10\n ‚Ä¢ Enable inference: True\n ‚Ä¢ Word length: [2, 30]\n\nIndicBART Features:\n ‚ú® Word-level rationale generation for Bengali\n ‚ú® Normalized word keys for morphology handling\n ‚ú® Context-aware evidence extraction\n ‚ú® Multi-level confidence explanations (high/medium/low)\n ‚ú® Alternative sense suggestions\n ‚ú® Batch processing support\n ‚ú® Compatible with Cell 3 DSCD outputs\n ‚ú® Word validation: ENABLED\n================================================================================\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ==============================================================================\n# CELL 6: DUAL-PATH TATN MODEL (IndicBART-READY - 29 CRITICAL FIXES)\n# ==============================================================================\n# Complete fixes for IndicBART integration + DSCD zero-prototype issue:\n#\n# üî¨ IndicBART-SPECIFIC FIXES (8 NEW):\n# FIX #22: üî• CRITICAL - Import MBartForConditionalGeneration (not M2M100)\n# FIX #23: üî• CRITICAL - Import AutoTokenizer for IndicBART\n# FIX #24: üî• CRITICAL - Load ai4bharat/indic-bart model\n# FIX #25: üî• CRITICAL - Handle IndicBART language tokens (<2en>, <2bn>)\n# FIX #26: Import all Cell 0 configs with try-except\n# FIX #27: Align with Cell 0 MODEL_NAME parameter\n# FIX #28: Add IndicBART-specific generation parameters\n# FIX #29: Update all print messages for IndicBART\n#\n# üî¨ RESEARCH-BACKED FIXES (21 PRESERVED from M2M100 version):\n# FIX #1:  word_vocab_size extraction from tokenizer\n# FIX #2:  word_vocab_size validation against actual vocab\n# FIX #3:  encode_text API compatibility (removed return_tensors)\n# FIX #4:  Multiple fallback tokenization methods\n# FIX #5:  src_text/src_texts naming consistency\n# FIX #6:  word_strings parameter to avoid re-tokenization\n# FIX #7:  Extract parameters from **kwargs properly\n# FIX #8:  Use pre-tokenized word_strings when available\n# FIX #9:  Validate word_tokens format for DSCD\n# FIX #10: Validate word_tokens format for ASBN\n# FIX #11: Generate method signature consistency\n# FIX #12: Word embedding init after vocab validation\n# FIX #13: üö® CRITICAL - DSCD parameter name: word_tokens ‚Üí word_input_ids\n# FIX #14: üö® CRITICAL - Pass word_input_ids (tensor) not word_strings (list)\n# FIX #15: üö® CRITICAL - Generate word_attention_mask for DSCD\n# FIX #16: üö® CRITICAL - Pass word_attention_mask to DSCD\n# FIX #17: Add debug logging for DSCD data flow\n# FIX #18: Validate DSCD receives data in training mode\n# FIX #19: üî• NEW - Extract word data from **kwargs if not provided directly\n# FIX #20: üî• CRITICAL - Handle DataParallel batch splitting for word_strings\n# FIX #21: üî• NEW - Control debug logging with VERBOSE_LOGGING flag\n# ==============================================================================\n\nfrom typing import List, Dict, Optional, Any, Tuple\nimport traceback\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ==============================================================================\n# üî• FIX #22 & #23: Import MBart and AutoTokenizer for IndicBART\n# ==============================================================================\ntry:\n    from transformers import MBartForConditionalGeneration, AutoTokenizer\n    from transformers.modeling_outputs import BaseModelOutput\n    _HAS_TRANSFORMERS = True\n    print(\"[CELL6] ‚úÖ Imported IndicBART dependencies (MBart + AutoTokenizer)\")\nexcept Exception as e:\n    print(f\"[CELL6] ‚ùå Failed to import IndicBART dependencies: {e}\")\n    MBartForConditionalGeneration = None\n    AutoTokenizer = None\n    BaseModelOutput = None\n    _HAS_TRANSFORMERS = False\n\n# ==============================================================================\n# üî• FIX #26: IMPORT ALL CELL 0 CONFIGS WITH TRY-EXCEPT\n# ==============================================================================\n\nprint(\"[CELL6] Loading configuration from Cell 0...\")\n\n# Basic configuration\ntry:\n    SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, ValueError):\n    SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL6] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n\n_SOURCE_LANGUAGE = SOURCE_LANGUAGE\n\ntry:\n    TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, ValueError):\n    TARGET_LANGUAGE = \"en\"\n    print(\"[CELL6] WARNING: TARGET_LANGUAGE not defined, using default 'en'\")\n\n_TARGET_LANGUAGE = TARGET_LANGUAGE\n\n# ==============================================================================\n# üî• FIX #27: Align with Cell 0 MODEL_NAME parameter\n# ==============================================================================\ntry:\n    MODEL_NAME = str(MODEL_NAME)\n    print(f\"[CELL6] ‚úÖ Using MODEL_NAME from Cell 0: {MODEL_NAME}\")\nexcept (NameError, ValueError):\n    MODEL_NAME = \"ai4bharat/indic-bart\"\n    print(f\"[CELL6] WARNING: MODEL_NAME not defined, using default '{MODEL_NAME}'\")\n\n_MODEL_NAME = MODEL_NAME\n\n# Verbose logging\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, ValueError):\n    VERBOSE_LOGGING = False\n    print(\"[CELL6] WARNING: VERBOSE_LOGGING not defined, using default False\")\n\n_VERBOSE_LOGGING = VERBOSE_LOGGING\n\n# ==============================================================================\n# Defensive global fallback helpers\n# ==============================================================================\ndef _get_int_global(name: str, default: int) -> int:\n    try:\n        v = globals().get(name, default)\n        return int(v) if v is not None else default\n    except Exception:\n        return default\n\ndef _get_float_global(name: str, default: float) -> float:\n    try:\n        v = globals().get(name, default)\n        return float(v) if v is not None else default\n    except Exception:\n        return default\n\ndef _get_bool_global(name: str, default: bool) -> bool:\n    try:\n        v = globals().get(name, default)\n        return bool(v)\n    except Exception:\n        return default\n\ndef _get_str_global(name: str, default: str) -> str:\n    try:\n        v = globals().get(name, default)\n        return str(v) if v is not None else default\n    except Exception:\n        return default\n\n# Word-level configuration\n_WORD_VOCAB_SIZE = _get_int_global('WORD_VOCAB_SIZE', 50000)\n_WORD_EMBED_DIM = _get_int_global('WORD_EMBED_DIM', 256)\n_MAX_WORD_LENGTH = _get_int_global('MAX_WORD_LENGTH', 48)\n_MAX_LENGTH = _get_int_global('MAX_LENGTH', 128)\n_WORD_MIN_LENGTH = _get_int_global('WORD_MIN_LENGTH', 2)\n_WORD_MAX_LENGTH_VALIDATE = _get_int_global('WORD_MAX_LENGTH', 30)\n\n# DSCD configuration\n_DSCD_BUFFER_SIZE = _get_int_global('DSCD_BUFFER_SIZE', 20)\n_DSCD_MAX_PROTOS = _get_int_global('DSCD_MAX_PROTOS', 8)\n_DSCD_N_MIN = _get_int_global('DSCD_N_MIN', 2)\n_DSCD_DISPERSION_THRESHOLD = _get_float_global('DSCD_DISPERSION_THRESHOLD', 0.25)\n_DSCD_ENABLE_TRAINING_CLUSTERING = _get_bool_global('DSCD_ENABLE_TRAINING_CLUSTERING', False)\n\n# ASBN configuration\n_ENABLE_ASBN_TRAINING = _get_bool_global('ENABLE_ASBN_TRAINING', True)\n_LAMBDA_ASBN = _get_float_global('LAMBDA_ASBN', 0.10)\n\n# TRG configuration\n_ENABLE_TRG_INFERENCE = _get_bool_global('ENABLE_TRG_INFERENCE', True)\n\n# Loss weights\n_LAMBDA_DSCD = _get_float_global('LAMBDA_DSCD', 0.05)\n\n# Memory and device configuration\n_MEMORY_CLEANUP_FREQUENCY = _get_int_global('MEMORY_CLEANUP_FREQUENCY', 100)\n_NUM_GPUS = _get_int_global('NUM_GPUS', torch.cuda.device_count() if torch.cuda.is_available() else 0)\n_USE_GC = _get_bool_global('GRADIENT_CHECKPOINTING', False)\n\n# IndicBART-specific configuration\n_MAX_GEN_LENGTH = _get_int_global('MAX_GEN_LENGTH', 128)\n_NUM_BEAMS = _get_int_global('NUM_BEAMS', 5)\n_LENGTH_PENALTY = _get_float_global('LENGTH_PENALTY', 1.0)\n_NO_REPEAT_NGRAM_SIZE = _get_int_global('NO_REPEAT_NGRAM_SIZE', 3)\n\nprint(f\"[CELL6] Configuration loaded:\")\nprint(f\"  Model: {_MODEL_NAME}\")\nprint(f\"  Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  Word vocab size: {_WORD_VOCAB_SIZE}\")\nprint(f\"  Word embed dim: {_WORD_EMBED_DIM}\")\nprint(f\"  Max word length: {_MAX_WORD_LENGTH}\")\nprint(f\"  Max gen length: {_MAX_GEN_LENGTH}\")\nprint(f\"  Num beams: {_NUM_BEAMS}\")\nprint(f\"  DSCD buffer: {_DSCD_BUFFER_SIZE}\")\nprint(f\"  DSCD max protos: {_DSCD_MAX_PROTOS}\")\nprint(f\"  Enable ASBN: {_ENABLE_ASBN_TRAINING}\")\nprint(f\"  Enable TRG: {_ENABLE_TRG_INFERENCE}\")\nprint(f\"  Lambda ASBN: {_LAMBDA_ASBN}\")\nprint(f\"  Lambda DSCD: {_LAMBDA_DSCD}\")\nprint(f\"  Verbose logging: {_VERBOSE_LOGGING}\")\nprint(f\"  Gradient checkpointing: {_USE_GC}\")\n\n# ==============================================================================\n# Import word tokenizer from Cell 2\n# ==============================================================================\ntry:\n    from __main__ import BengaliWordTokenizer\n    HAS_WORD_TOKENIZER = True\n    print(\"[CELL6] ‚úÖ Imported BengaliWordTokenizer from Cell 2\")\nexcept:\n    try:\n        BengaliWordTokenizer = globals().get('BengaliWordTokenizer', None)\n        HAS_WORD_TOKENIZER = BengaliWordTokenizer is not None\n        if HAS_WORD_TOKENIZER:\n            print(\"[CELL6] ‚úÖ Found BengaliWordTokenizer in globals\")\n        else:\n            print(\"[CELL6] ‚ö†Ô∏è BengaliWordTokenizer not found from Cell 2\")\n    except:\n        HAS_WORD_TOKENIZER = False\n        print(\"[CELL6] ‚ö†Ô∏è BengaliWordTokenizer not found from Cell 2\")\n\n# ==============================================================================\n# Import DSCD, ASBN, TRG with multiple fallback names\n# ==============================================================================\n\n# FIX: Import DSCD with multiple fallback names (Cell 3 compatibility)\n_DSCD_CLASS = None\ntry:\n    from __main__ import WordLevelDSCDOnline\n    _DSCD_CLASS = WordLevelDSCDOnline\n    print(\"[CELL6] ‚úÖ Imported WordLevelDSCDOnline from Cell 3\")\nexcept:\n    try:\n        from __main__ import DSCD\n        _DSCD_CLASS = DSCD\n        print(\"[CELL6] ‚úÖ Imported DSCD from Cell 3\")\n    except:\n        try:\n            _DSCD_CLASS = globals().get('WordLevelDSCDOnline', None) or globals().get('DSCD', None)\n            if _DSCD_CLASS:\n                print(f\"[CELL6] ‚úÖ Found DSCD class in globals: {_DSCD_CLASS.__name__}\")\n            else:\n                print(\"[CELL6] ‚ö†Ô∏è DSCD class not found\")\n        except:\n            _DSCD_CLASS = None\n            print(\"[CELL6] ‚ö†Ô∏è DSCD class not found\")\n\n# FIX: Import ASBN with multiple fallback names (Cell 4 compatibility)\n_ASBN_CLASS = None\ntry:\n    from __main__ import WordLevelASBNModule\n    _ASBN_CLASS = WordLevelASBNModule\n    print(\"[CELL6] ‚úÖ Imported WordLevelASBNModule from Cell 4\")\nexcept:\n    try:\n        from __main__ import ASBN\n        _ASBN_CLASS = ASBN\n        print(\"[CELL6] ‚úÖ Imported ASBN from Cell 4\")\n    except:\n        try:\n            _ASBN_CLASS = globals().get('WordLevelASBNModule', None) or globals().get('ASBN', None)\n            if _ASBN_CLASS:\n                print(f\"[CELL6] ‚úÖ Found ASBN class in globals: {_ASBN_CLASS.__name__}\")\n            else:\n                print(\"[CELL6] ‚ö†Ô∏è ASBN class not found\")\n        except:\n            _ASBN_CLASS = None\n            print(\"[CELL6] ‚ö†Ô∏è ASBN class not found\")\n\n# FIX: Import TRG with multiple fallback names (Cell 5 compatibility)\n_TRG_CLASS = None\ntry:\n    from __main__ import CompleteTRGWithExplanations\n    _TRG_CLASS = CompleteTRGWithExplanations\n    print(\"[CELL6] ‚úÖ Imported CompleteTRGWithExplanations from Cell 5\")\nexcept:\n    try:\n        from __main__ import TRG\n        _TRG_CLASS = TRG\n        print(\"[CELL6] ‚úÖ Imported TRG from Cell 5\")\n    except:\n        try:\n            _TRG_CLASS = globals().get('CompleteTRGWithExplanations', None) or globals().get('TRG', None)\n            if _TRG_CLASS:\n                print(f\"[CELL6] ‚úÖ Found TRG class in globals: {_TRG_CLASS.__name__}\")\n            else:\n                print(\"[CELL6] ‚ö†Ô∏è TRG class not found\")\n        except:\n            _TRG_CLASS = None\n            print(\"[CELL6] ‚ö†Ô∏è TRG class not found\")\n\nHAS_MODULES = all([_DSCD_CLASS, _ASBN_CLASS, _TRG_CLASS])\nprint(f\"[CELL6] All modules available: {HAS_MODULES}\")\n\n# Import word validation from Cell 1\ntry:\n    from __main__ import normalize_indic_word, is_indic_word, validate_word_token\n    HAS_WORD_VALIDATION = True\n    print(\"[CELL6] ‚úÖ Imported word validation functions from Cell 1\")\nexcept:\n    try:\n        normalize_indic_word = globals().get('normalize_indic_word', None)\n        is_indic_word = globals().get('is_indic_word', None)\n        validate_word_token = globals().get('validate_word_token', None)\n        HAS_WORD_VALIDATION = all([normalize_indic_word, is_indic_word, validate_word_token])\n        if HAS_WORD_VALIDATION:\n            print(\"[CELL6] ‚úÖ Found word validation functions in globals\")\n        else:\n            print(\"[CELL6] ‚ö†Ô∏è Word validation functions not found\")\n    except:\n        HAS_WORD_VALIDATION = False\n        print(\"[CELL6] ‚ö†Ô∏è Word validation functions not found from Cell 1\")\n\n_has_reconstruct_word_spans = 'reconstruct_word_spans' in globals()\n_normalize_fn = globals().get(\"normalize_bn_word\", None) or globals().get(\"normalize_indic_word\", None)\n\n# ==============================================================================\n# Safe helper to obtain last hidden state from various HF encoder outputs\n# ==============================================================================\ndef _safe_get_last_hidden_state(enc_output: Any) -> Optional[torch.Tensor]:\n    \"\"\"Extract last_hidden_state from various encoder output formats.\"\"\"\n    try:\n        if enc_output is None:\n            return None\n        if hasattr(enc_output, 'last_hidden_state'):\n            return enc_output.last_hidden_state\n        if isinstance(enc_output, (list, tuple)) and len(enc_output) > 0:\n            cand = enc_output[0]\n            if isinstance(cand, torch.Tensor):\n                return cand\n        if isinstance(enc_output, dict) and 'last_hidden_state' in enc_output:\n            return enc_output['last_hidden_state']\n    except Exception:\n        if _VERBOSE_LOGGING:\n            print(\"[TATN] _safe_get_last_hidden_state error:\", traceback.format_exc().splitlines()[-1])\n    return None\n\n# ==============================================================================\n# Normalize DSCD outputs into canonical, CPU/device-consistent structures\n# (COMPLETE DEFENSIVE PARSING - ALL ORIGINAL LOGIC PRESERVED)\n# ==============================================================================\ndef _normalize_dscd_outputs(raw: Dict[str, Any],\n                            batch_size: int,\n                            num_words: int,\n                            device: torch.device,\n                            embed_dim: int) -> Dict[str, Any]:\n    \"\"\"\n    Defensive normalization of DSCD raw outputs into canonical forms.\n    \n    Cell 3 outputs (word-level):\n      - proto_probs: [[tensor or None for each word] for each batch]]\n      - uncertainties: [[float for each word] for each batch]\n      - gates: [[float for each word] for each batch]\n      - span_preds: [[float for each word] for each batch]\n      - h_aug: tensor [B, W, D]\n    \n    Returns normalized dict with proper shapes and device placement.\n    This function never raises; logs only when VERBOSE_LOGGING=True.\n    \"\"\"\n    def _log(msg: str):\n        if _VERBOSE_LOGGING:\n            print(\"[DSCD-NORM]\", msg)\n    \n    # Initialize defaults\n    proto_probs = [[torch.tensor([1.0], dtype=torch.float32, device=device) for _ in range(num_words)] for _ in range(batch_size)]\n    uncertainties = [[torch.tensor(0.0, dtype=torch.float32, device=device) for _ in range(num_words)] for _ in range(batch_size)]\n    gates = [[torch.tensor(0.0, dtype=torch.float32, device=device) for _ in range(num_words)] for _ in range(batch_size)]\n    span_preds = [[torch.tensor(0.0, dtype=torch.float32, device=device) for _ in range(num_words)] for _ in range(batch_size)]\n    proto_assignments = [torch.zeros(num_words, dtype=torch.long, device=device) for _ in range(batch_size)]\n    h_aug = None\n\n    try:\n        if not isinstance(raw, dict):\n            _log(\"raw DSCD output not a dict; using defaults\")\n            raw = {} if raw is None else dict(raw)\n\n        # --- h_aug (or h_augmented)\n        h_raw = raw.get('h_aug', None) or raw.get('h_augmented', None)\n        if isinstance(h_raw, torch.Tensor):\n            try:\n                if h_raw.dim() == 3 and int(h_raw.size(0)) == batch_size and int(h_raw.size(1)) == num_words:\n                    h_aug = h_raw.to(device)\n                else:\n                    tmp = torch.zeros(batch_size, num_words, embed_dim, device=device, dtype=h_raw.dtype)\n                    max_b = min(batch_size, int(h_raw.size(0)))\n                    for b in range(max_b):\n                        row = h_raw[b]\n                        if isinstance(row, torch.Tensor) and row.dim() >= 2:\n                            L = min(num_words, int(row.size(0)))\n                            D = min(embed_dim, int(row.size(1)))\n                            tmp[b, :L, :D] = row[:L, :D].to(device)\n                    h_aug = tmp\n            except Exception:\n                _log(\"h_aug coercion from tensor failed; fallback to None\")\n                h_aug = None\n        elif isinstance(h_raw, (list, tuple, np.ndarray)):\n            try:\n                stacked = []\n                for b in range(min(batch_size, len(h_raw))):\n                    row = h_raw[b]\n                    if isinstance(row, torch.Tensor):\n                        stacked.append(row.to(device))\n                    else:\n                        stacked.append(torch.as_tensor(row, device=device))\n                if stacked:\n                    tensor = torch.stack(stacked, dim=0)\n                    if tensor.dim() == 3:\n                        tmp = torch.zeros(batch_size, num_words, embed_dim, device=device, dtype=tensor.dtype)\n                        for b in range(min(batch_size, tensor.size(0))):\n                            L = min(num_words, int(tensor.size(1)))\n                            D = min(embed_dim, int(tensor.size(2)))\n                            tmp[b, :L, :D] = tensor[b, :L, :D]\n                        h_aug = tmp\n            except Exception:\n                _log(\"h_aug list coercion failed; fallback to None\")\n                h_aug = None\n\n        # --- proto_probs (complex structure from Cell 3: [[tensor or None]])\n        try:\n            pp = raw.get('proto_probs', None)\n            if pp is not None:\n                def _to_tensor(v):\n                    try:\n                        if v is None:\n                            return torch.tensor([1.0], dtype=torch.float32, device=device)\n                        if isinstance(v, torch.Tensor):\n                            return v.detach().to(device).float()\n                        else:\n                            a = np.asarray(v, dtype=np.float32)\n                            return torch.from_numpy(a).to(device).float()\n                    except Exception:\n                        return torch.tensor([1.0], dtype=torch.float32, device=device)\n                \n                if isinstance(pp, list):\n                    if len(pp) == batch_size:\n                        for b in range(batch_size):\n                            row = pp[b]\n                            if isinstance(row, list):\n                                for w in range(min(num_words, len(row))):\n                                    proto_probs[b][w] = _to_tensor(row[w])\n                            elif isinstance(row, torch.Tensor):\n                                r = row.detach().to(device)\n                                if r.dim() == 2:\n                                    for w in range(min(num_words, int(r.size(0)))):\n                                        proto_probs[b][w] = _to_tensor(r[w])\n                                elif r.dim() == 1:\n                                    for w in range(min(num_words, int(r.size(0)))):\n                                        proto_probs[b][w] = _to_tensor(r[w])\n                    elif batch_size == 1:\n                        for w in range(min(num_words, len(pp))):\n                            proto_probs[0][w] = _to_tensor(pp[w])\n                \n                elif isinstance(pp, torch.Tensor):\n                    p = pp.detach().to(device)\n                    if p.dim() == 3:\n                        B, W, K = p.shape\n                        for b in range(min(batch_size, int(B))):\n                            for w in range(min(num_words, int(W))):\n                                proto_probs[b][w] = _to_tensor(p[b, w])\n                    elif p.dim() == 2:\n                        if int(p.size(0)) == batch_size:\n                            for b in range(batch_size):\n                                for w in range(min(num_words, int(p.size(1)))):\n                                    proto_probs[b][w] = _to_tensor(p[b, w])\n                        elif batch_size == 1:\n                            for w in range(min(num_words, int(p.size(0)))):\n                                proto_probs[0][w] = _to_tensor(p[w])\n                    elif p.dim() == 1:\n                        for w in range(min(num_words, int(p.size(0)))):\n                            proto_probs[0][w] = _to_tensor(p[w])\n        except Exception as e:\n            _log(f\"proto_probs parsing failed: {e}\")\n\n        # --- uncertainties/gates/span_preds normalization helper\n        def _normalize_scalar_matrix(key: str, target):\n            try:\n                val = raw.get(key, None)\n                if val is None:\n                    return\n                \n                if isinstance(val, list):\n                    if len(val) == batch_size:\n                        for b in range(batch_size):\n                            row = val[b]\n                            if isinstance(row, list):\n                                for w in range(min(num_words, len(row))):\n                                    try:\n                                        v = row[w]\n                                        if isinstance(v, torch.Tensor):\n                                            target[b][w] = torch.tensor(float(v.detach().cpu().item()), device=device)\n                                        else:\n                                            target[b][w] = torch.tensor(float(v), device=device)\n                                    except Exception:\n                                        pass\n                            elif isinstance(row, torch.Tensor):\n                                r = row.detach().to(device)\n                                for w in range(min(num_words, int(r.size(0)))):\n                                    try:\n                                        target[b][w] = torch.tensor(float(r[w].item()), device=device)\n                                    except Exception:\n                                        pass\n                    elif batch_size == 1:\n                        row = val\n                        if isinstance(row, list):\n                            for w in range(min(num_words, len(row))):\n                                try:\n                                    v = row[w]\n                                    if isinstance(v, torch.Tensor):\n                                        target[0][w] = torch.tensor(float(v.detach().cpu().item()), device=device)\n                                    else:\n                                        target[0][w] = torch.tensor(float(v), device=device)\n                                except Exception:\n                                    pass\n                \n                elif isinstance(val, torch.Tensor):\n                    m = val.detach().to(device)\n                    if m.dim() == 3 and int(m.size(0)) == batch_size:\n                        for b in range(batch_size):\n                            for w in range(min(num_words, int(m.size(1)))):\n                                target[b][w] = torch.tensor(float(m[b, w].item()), device=device)\n                    elif m.dim() == 2:\n                        if int(m.size(0)) == batch_size:\n                            for b in range(batch_size):\n                                for w in range(min(num_words, int(m.size(1)))):\n                                    target[b][w] = torch.tensor(float(m[b, w].item()), device=device)\n                        elif batch_size == 1:\n                            for w in range(min(num_words, int(m.size(0)))):\n                                target[0][w] = torch.tensor(float(m[w].item()), device=device)\n                    elif m.dim() == 1 and batch_size == 1:\n                        for w in range(min(num_words, int(m.size(0)))):\n                            target[0][w] = torch.tensor(float(m[w].item()), device=device)\n            except Exception as e:\n                _log(f\"{key} normalization failed: {e}\")\n        \n        _normalize_scalar_matrix('uncertainties', uncertainties)\n        _normalize_scalar_matrix('gates', gates)\n        _normalize_scalar_matrix('span_preds', span_preds)\n\n        # --- proto_assignments normalization\n        try:\n            pa = raw.get('proto_assignments', None)\n            if pa is not None:\n                if isinstance(pa, list) and len(pa) == batch_size:\n                    for b in range(batch_size):\n                        row = pa[b]\n                        try:\n                            if isinstance(row, torch.Tensor):\n                                arr = row.detach().cpu().long().view(-1)\n                                if arr.numel() < num_words:\n                                    pad = torch.zeros(num_words - arr.numel(), dtype=torch.long, device=device)\n                                    proto_assignments[b] = torch.cat([arr.to(device), pad], dim=0)\n                                else:\n                                    proto_assignments[b] = arr[:num_words].to(device)\n                            else:\n                                arr = torch.as_tensor(row, dtype=torch.long, device=device).view(-1)\n                                if arr.numel() < num_words:\n                                    pad = torch.zeros(num_words - arr.numel(), dtype=torch.long, device=device)\n                                    proto_assignments[b] = torch.cat([arr, pad], dim=0)\n                                else:\n                                    proto_assignments[b] = arr[:num_words]\n                        except Exception:\n                            proto_assignments[b] = torch.zeros(num_words, dtype=torch.long, device=device)\n                elif isinstance(pa, torch.Tensor):\n                    p = pa.detach().cpu().long()\n                    if p.dim() == 2 and int(p.size(0)) == batch_size:\n                        for b in range(batch_size):\n                            arr = p[b].view(-1)\n                            if arr.numel() < num_words:\n                                pad = torch.zeros(num_words - arr.numel(), dtype=torch.long, device=device)\n                                proto_assignments[b] = torch.cat([arr.to(device), pad], dim=0)\n                            else:\n                                proto_assignments[b] = arr[:num_words].to(device)\n                    elif p.dim() == 1 and batch_size == 1:\n                        arr = p.view(-1)\n                        if arr.numel() < num_words:\n                            pad = torch.zeros(num_words - arr.numel(), dtype=torch.long, device=device)\n                            proto_assignments[0] = torch.cat([arr.to(device), pad], dim=0)\n                        else:\n                            proto_assignments[0] = arr[:num_words].to(device)\n        except Exception as e:\n            _log(f\"proto_assignments parse failed: {e}\")\n\n    except Exception as outer:\n        _log(f\"overall normalization failure: {outer}\")\n\n    if h_aug is None:\n        h_aug = torch.zeros(batch_size, num_words, embed_dim, device=device, dtype=torch.float32)\n\n    return {\n        'proto_probs': proto_probs,\n        'uncertainties': uncertainties,\n        'gates': gates,\n        'span_preds': span_preds,\n        'proto_assignments': proto_assignments,\n        'h_aug': h_aug\n    }\n\n# ==============================================================================\n# Main dual-path model wrapper\n# ==============================================================================\nclass DualPathTATN(nn.Module):\n    \"\"\"\n    Dual-Path TATN Model with IndicBART integration.\n    \n    Path 1: Word-level homograph detection\n      word_tokens ‚Üí word_embeddings ‚Üí DSCD ‚Üí ASBN ‚Üí TRG\n    \n    Path 2: IndicBART neural machine translation\n      IndicBART subword tokens ‚Üí IndicBART encoder/decoder ‚Üí translation\n    \n    CRITICAL: Paths are SEPARATE - only losses combined, NOT embeddings.\n    \"\"\"\n    \n    def __init__(\n        self,\n        indicbart_tokenizer,\n        bengali_word_tokenizer=None,\n        word_vocab_size=None,\n        word_embed_dim=None\n    ):\n        super().__init__()\n        \n        # ==================================================================\n        # üî• FIX #29: Update all references to IndicBART\n        # ==================================================================\n        self.indicbart_tokenizer = indicbart_tokenizer\n        self.global_step = 0\n        \n        # ==================================================================\n        # üîß FIX #1 & #2: Extract word_vocab_size from tokenizer if not provided\n        # ==================================================================\n        # FIX: Backward compatibility - accept both parameter names\n        if bengali_word_tokenizer is None:\n            bengali_word_tokenizer = globals().get('word_tokenizer', None)\n        self.bengali_word_tokenizer = bengali_word_tokenizer\n        \n        # FIX: Extract vocab size from tokenizer if not provided\n        if word_vocab_size is None:\n            if bengali_word_tokenizer is not None:\n                try:\n                    # Try multiple ways to get vocab size\n                    if hasattr(bengali_word_tokenizer, 'vocab_size'):\n                        word_vocab_size = int(bengali_word_tokenizer.vocab_size)\n                    elif hasattr(bengali_word_tokenizer, 'vocab'):\n                        word_vocab_size = len(bengali_word_tokenizer.vocab)\n                    elif hasattr(bengali_word_tokenizer, 'word_to_id'):\n                        word_vocab_size = len(bengali_word_tokenizer.word_to_id)\n                    elif hasattr(bengali_word_tokenizer, 'get_vocab'):\n                        word_vocab_size = len(bengali_word_tokenizer.get_vocab())\n                    else:\n                        word_vocab_size = _WORD_VOCAB_SIZE\n                except Exception:\n                    word_vocab_size = _WORD_VOCAB_SIZE\n            else:\n                word_vocab_size = _WORD_VOCAB_SIZE\n        \n        self.word_vocab_size = word_vocab_size or _WORD_VOCAB_SIZE\n        self.word_embed_dim = word_embed_dim or _WORD_EMBED_DIM\n        \n        # ==================================================================\n        # üîß FIX #2: Validate word_vocab_size matches tokenizer\n        # ==================================================================\n        if bengali_word_tokenizer is not None:\n            try:\n                actual_vocab_size = None\n                if hasattr(bengali_word_tokenizer, 'vocab'):\n                    actual_vocab_size = len(bengali_word_tokenizer.vocab)\n                elif hasattr(bengali_word_tokenizer, 'word_to_id'):\n                    actual_vocab_size = len(bengali_word_tokenizer.word_to_id)\n                \n                if actual_vocab_size is not None and actual_vocab_size != self.word_vocab_size:\n                    if _VERBOSE_LOGGING:\n                        print(f\"[TATN-INIT] ‚ö†Ô∏è Warning: word_vocab_size mismatch!\")\n                        print(f\"[TATN-INIT]   Provided: {self.word_vocab_size}, Actual: {actual_vocab_size}\")\n                        print(f\"[TATN-INIT]   Using actual vocab size: {actual_vocab_size}\")\n                    self.word_vocab_size = actual_vocab_size\n            except Exception:\n                pass\n        \n        print(f\"[TATN-INIT] Initializing Dual-Path TATN with IndicBART\")\n        print(f\"[TATN-INIT] Word vocab size: {self.word_vocab_size}\")\n        print(f\"[TATN-INIT] Word embed dim: {self.word_embed_dim}\")\n        \n        # =====================================================================\n        # PATH 1: WORD-LEVEL HOMOGRAPH DETECTION\n        # =====================================================================\n        \n        # ==================================================================\n        # üîß FIX #12: Initialize word embedding AFTER vocab size validation\n        # ==================================================================\n        self.word_embedding = nn.Embedding(\n            self.word_vocab_size,\n            self.word_embed_dim,\n            padding_idx=0\n        )\n        print(f\"[TATN-INIT] ‚úÖ Word embedding initialized: [{self.word_vocab_size}, {self.word_embed_dim}]\")\n        \n        # FIX: Initialize DSCD with fallback class names\n        if _DSCD_CLASS is not None:\n            try:\n                self.dscd = _DSCD_CLASS(\n                    embed_dim=self.word_embed_dim,\n                    buffer_size=_DSCD_BUFFER_SIZE,\n                    max_protos=_DSCD_MAX_PROTOS,\n                    n_min=_DSCD_N_MIN,\n                    dispersion_threshold=_DSCD_DISPERSION_THRESHOLD,\n                    language=_SOURCE_LANGUAGE,\n                    enable_training_clustering=_DSCD_ENABLE_TRAINING_CLUSTERING,\n                    max_clustering_points=500,\n                    max_candidates_per_step=1,\n                    use_normalization=True\n                )\n                print(f\"[TATN-INIT] ‚úÖ DSCD initialized successfully (class: {_DSCD_CLASS.__name__})\")\n            except Exception as e:\n                print(f\"[TATN-INIT] ‚ùå DSCD initialization failed: {e}\")\n                print(\"[TATN-INIT]\", traceback.format_exc().splitlines()[-1])\n                self.dscd = None\n        else:\n            self.dscd = None\n            print(\"[TATN-INIT] ‚ö†Ô∏è DSCD not available (class not found in Cell 3)\")\n        \n        # FIX: Initialize ASBN with fallback class names\n        if _ASBN_CLASS is not None:\n            try:\n                self.asbn = _ASBN_CLASS(\n                    embed_dim=self.word_embed_dim,\n                    language=_SOURCE_LANGUAGE,\n                    use_normalization=True\n                )\n                print(f\"[TATN-INIT] ‚úÖ ASBN initialized successfully (class: {_ASBN_CLASS.__name__})\")\n            except Exception as e:\n                print(f\"[TATN-INIT] ‚ùå ASBN initialization failed: {e}\")\n                print(\"[TATN-INIT]\", traceback.format_exc().splitlines()[-1])\n                self.asbn = None\n        else:\n            self.asbn = None\n            print(\"[TATN-INIT] ‚ö†Ô∏è ASBN not available (class not found in Cell 4)\")\n        \n        # FIX: Initialize TRG with fallback class names\n        if _TRG_CLASS is not None:\n            try:\n                self.trg_system = _TRG_CLASS(\n                    language=_SOURCE_LANGUAGE,\n                    use_normalization=True\n                )\n                try:\n                    self.trg_system.eval()\n                except Exception:\n                    try:\n                        self.trg_system.training = False\n                    except Exception:\n                        pass\n                print(f\"[TATN-INIT] ‚úÖ TRG initialized successfully (class: {_TRG_CLASS.__name__})\")\n            except Exception as e:\n                print(f\"[TATN-INIT] ‚ùå TRG initialization failed: {e}\")\n                print(\"[TATN-INIT]\", traceback.format_exc().splitlines()[-1])\n                self.trg_system = None\n        else:\n            self.trg_system = None\n            print(\"[TATN-INIT] ‚ö†Ô∏è TRG not available (class not found in Cell 5)\")\n        \n        # =====================================================================\n        # PATH 2: IndicBART TRANSLATION\n        # =====================================================================\n        \n        self.indicbart_model = None\n        if _HAS_TRANSFORMERS and MBartForConditionalGeneration is not None:\n            try:\n                if os.environ.get(\"SKIP_MODEL_LOAD\", \"0\") != \"1\":\n                    print(f\"[TATN-INIT] Loading IndicBART model: {_MODEL_NAME}...\")\n                    \n                    # ==================================================================\n                    # üî• FIX #24: Load ai4bharat/indic-bart model\n                    # ==================================================================\n                    self.indicbart_model = MBartForConditionalGeneration.from_pretrained(\n                        _MODEL_NAME,\n                        torch_dtype=torch.float32,\n                        use_cache=False\n                    )\n                    \n                    try:\n                        self.indicbart_model.config.use_cache = False\n                    except Exception:\n                        pass\n                    \n                    # ==================================================================\n                    # üî• FIX #28: Add IndicBART-specific generation parameters\n                    # ==================================================================\n                    if _USE_GC and hasattr(self.indicbart_model, \"gradient_checkpointing_enable\"):\n                        try:\n                            self.indicbart_model.gradient_checkpointing_enable()\n                            print(\"[TATN-INIT] ‚úÖ Gradient checkpointing enabled\")\n                        except Exception as e:\n                            print(f\"[TATN-INIT] ‚ö†Ô∏è Gradient checkpointing failed: {e}\")\n                    \n                    print(f\"[TATN-INIT] ‚úÖ IndicBART model loaded successfully: {_MODEL_NAME}\")\n                else:\n                    print(\"[TATN-INIT] ‚ö†Ô∏è IndicBART loading skipped (SKIP_MODEL_LOAD=1)\")\n            except Exception as e:\n                print(f\"[TATN-INIT] ‚ùå IndicBART loading failed: {e}\")\n                print(\"[TATN-INIT]\", traceback.format_exc().splitlines()[-1])\n                self.indicbart_model = None\n        else:\n            print(\"[TATN-INIT] ‚ö†Ô∏è IndicBART not available (transformers library missing)\")\n        \n        print(\"=\"*80)\n        print(f\"[TATN-INIT] ‚úÖ Dual-Path TATN Initialization Complete\")\n        print(f\"[TATN-INIT] Path 1 (Word-Level): DSCD={'‚úì' if self.dscd else '‚úó'}, \"\n              f\"ASBN={'‚úì' if self.asbn else '‚úó'}, TRG={'‚úì' if self.trg_system else '‚úó'}\")\n        print(f\"[TATN-INIT] Path 2 (IndicBART): {'‚úì LOADED' if self.indicbart_model else '‚úó NOT LOADED'}\")\n        print(\"=\"*80)\n\n    def _tokenize_to_words(self, texts: List[str]) -> Tuple[torch.Tensor, torch.Tensor, List[List[str]]]:\n        \"\"\"\n        Tokenize texts to word IDs and word strings using word tokenizer.\n        \n        FIX #15: Also generate attention mask for DSCD.\n        \n        Returns:\n            word_ids: tensor [B, W] with word IDs\n            word_attention_mask: tensor [B, W] with attention mask (1=real word, 0=padding)\n            word_strings: [[word1, word2, ...], ...] list of word lists\n        \"\"\"\n        if not isinstance(texts, list):\n            texts = [texts]\n        \n        batch_word_ids = []\n        batch_word_strings = []\n        \n        for text in texts:\n            if not isinstance(text, str):\n                text = str(text)\n            \n            if self.bengali_word_tokenizer is not None:\n                try:\n                    # ==================================================================\n                    # üîß FIX #3 & #4: Correct API calls for Cell 2's BengaliWordTokenizer\n                    # ==================================================================\n                    # FIX: Try encode_text first (Cell 2's primary method)\n                    if hasattr(self.bengali_word_tokenizer, 'encode_text'):\n                        # Cell 2's encode_text returns (word_ids, word_strings)\n                        result = self.bengali_word_tokenizer.encode_text(\n                            text,\n                            max_length=_MAX_WORD_LENGTH\n                        )\n                        if isinstance(result, tuple) and len(result) == 2:\n                            word_ids, word_strings = result\n                        else:\n                            word_ids = result if isinstance(result, list) else list(result)\n                            word_strings = text.strip().split()[:_MAX_WORD_LENGTH]\n                    \n                    # FIX: Try encode method (Cell 2's HF-compatible method)\n                    elif hasattr(self.bengali_word_tokenizer, 'encode'):\n                        result = self.bengali_word_tokenizer.encode(\n                            text,\n                            max_length=_MAX_WORD_LENGTH,\n                            add_special_tokens=False,\n                            truncation=True\n                        )\n                        if isinstance(result, dict):\n                            word_ids = result.get('input_ids', [])\n                            if isinstance(word_ids, torch.Tensor):\n                                word_ids = word_ids.tolist()\n                            word_strings = result.get('words', text.strip().split()[:_MAX_WORD_LENGTH])\n                        else:\n                            word_ids = result if isinstance(result, list) else list(result)\n                            word_strings = text.strip().split()[:_MAX_WORD_LENGTH]\n                    \n                    # FIX: Try tokenize method (alternative)\n                    elif hasattr(self.bengali_word_tokenizer, 'tokenize'):\n                        word_strings = self.bengali_word_tokenizer.tokenize(text, max_length=_MAX_WORD_LENGTH)\n                        # Convert strings to IDs using vocab\n                        if hasattr(self.bengali_word_tokenizer, 'convert_tokens_to_ids'):\n                            word_ids = self.bengali_word_tokenizer.convert_tokens_to_ids(word_strings)\n                        else:\n                            word_ids = list(range(1, len(word_strings) + 1))\n                    \n                    # FIX: Try __call__ method (last resort)\n                    elif callable(self.bengali_word_tokenizer):\n                        result = self.bengali_word_tokenizer(text, max_length=_MAX_WORD_LENGTH)\n                        if isinstance(result, dict):\n                            word_ids = result.get('input_ids', [])\n                            if isinstance(word_ids, torch.Tensor):\n                                word_ids = word_ids.tolist()\n                            word_strings = result.get('words', text.strip().split()[:_MAX_WORD_LENGTH])\n                        else:\n                            word_ids = result if isinstance(result, list) else list(result)\n                            word_strings = text.strip().split()[:_MAX_WORD_LENGTH]\n                    else:\n                        raise AttributeError(\"No tokenization method found\")\n                    \n                    batch_word_ids.append(word_ids)\n                    batch_word_strings.append(word_strings)\n                except Exception as e:\n                    if _VERBOSE_LOGGING:\n                        print(f\"[TATN] Word tokenization failed: {e}\")\n                    words = text.strip().split()[:_MAX_WORD_LENGTH]\n                    word_ids = list(range(1, len(words) + 1))\n                    batch_word_ids.append(word_ids)\n                    batch_word_strings.append(words)\n            else:\n                words = text.strip().split()[:_MAX_WORD_LENGTH]\n                word_ids = list(range(1, len(words) + 1))\n                batch_word_ids.append(word_ids)\n                batch_word_strings.append(words)\n        \n        # Pad to max length and create attention mask\n        max_len = max(len(ids) for ids in batch_word_ids) if batch_word_ids else 1\n        padded_ids = []\n        attention_masks = []\n        \n        for ids in batch_word_ids:\n            # Attention mask: 1 for real tokens, 0 for padding\n            mask = [1] * len(ids) + [0] * (max_len - len(ids))\n            padded = ids + [0] * (max_len - len(ids))\n            padded_ids.append(padded)\n            attention_masks.append(mask)\n        \n        try:\n            word_ids_tensor = torch.tensor(padded_ids, dtype=torch.long)\n            word_attention_mask_tensor = torch.tensor(attention_masks, dtype=torch.long)\n        except Exception:\n            word_ids_tensor = torch.zeros((len(batch_word_ids), max_len), dtype=torch.long)\n            word_attention_mask_tensor = torch.zeros((len(batch_word_ids), max_len), dtype=torch.long)\n        \n        return word_ids_tensor, word_attention_mask_tensor, batch_word_strings\n\n    @staticmethod\n    def _compute_entropy_regularization(\n        proto_probs: List[List[Any]],\n        gates: List[List[Any]],\n        min_gate: float = 0.0\n    ) -> torch.Tensor:\n        \"\"\"\n        Compute entropy regularization from DSCD proto_probs.\n        Encourages diverse sense distributions.\n        \"\"\"\n        device = None\n        try:\n            if isinstance(proto_probs, list):\n                for row in proto_probs:\n                    if isinstance(row, list):\n                        for p in row:\n                            if isinstance(p, torch.Tensor):\n                                device = p.device\n                                break\n                    if device is not None:\n                        break\n        except Exception:\n            pass\n        \n        if device is None:\n            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        total = torch.tensor(0.0, device=device)\n        count = 0\n        \n        try:\n            for b, row in enumerate(proto_probs or []):\n                if not isinstance(row, list):\n                    continue\n                \n                gates_row = gates[b] if (gates and b < len(gates)) else None\n                \n                for w, probs in enumerate(row):\n                    try:\n                        if not isinstance(probs, torch.Tensor) or probs.numel() == 0:\n                            continue\n                        \n                        if gates_row and w < len(gates_row):\n                            gate_val = gates_row[w]\n                            if isinstance(gate_val, torch.Tensor):\n                                gate_val = gate_val.item()\n                            if float(gate_val) < min_gate:\n                                continue\n                        \n                        p = torch.clamp(probs.to(device), 1e-8, 1.0)\n                        H = -torch.sum(p * torch.log(p))\n                        total = total + H\n                        count += 1\n                    except Exception:\n                        continue\n        except Exception:\n            pass\n        \n        if count == 0:\n            return torch.tensor(0.0, device=device)\n        \n        return total / count\n\n    def forward(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        labels: Optional[torch.Tensor] = None,\n        word_input_ids: Optional[torch.Tensor] = None,\n        word_attention_mask: Optional[torch.Tensor] = None,\n        word_strings: Optional[List[List[str]]] = None,\n        src_text: Optional[List[str]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Forward pass with dual-path architecture.\n        \n        Args:\n            input_ids: IndicBART subword token IDs [B, T]\n            attention_mask: IndicBART attention mask [B, T]\n            labels: Target token IDs for training [B, T]\n            word_input_ids: Pre-computed word IDs from batch [B, W] ‚Üê FIX #19\n            word_attention_mask: Pre-computed word attention mask [B, W] ‚Üê FIX #19\n            word_strings: Pre-tokenized words from batch (avoids re-tokenization) [B, W]\n            src_text: Source texts for word tokenization (if word_strings not provided)\n            **kwargs: Additional arguments from batch dictionary\n        \n        Returns:\n            If training: scalar loss tensor\n            If inference: dict with translations and explanations\n        \"\"\"\n        self.global_step += 1\n        \n        if input_ids is None or attention_mask is None:\n            raise ValueError(\"input_ids and attention_mask cannot be None\")\n        if input_ids.dim() != 2 or attention_mask.dim() != 2:\n            raise ValueError(f\"Expected 2D tensors for input_ids/attention_mask, got {input_ids.shape}, {attention_mask.shape}\")\n        \n        batch_size = int(input_ids.size(0))\n        indicbart_seq_len = int(input_ids.size(1))\n        device = input_ids.device\n        training_mode = (labels is not None and self.training)\n        \n        if torch.cuda.is_available() and (self.global_step % max(1, _MEMORY_CLEANUP_FREQUENCY) == 0):\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n        \n        # ==================================================================\n        # üîß FIX #19: Extract word data from **kwargs if not provided directly\n        # ==================================================================\n        # Extract word_input_ids from kwargs if not provided\n        if word_input_ids is None:\n            word_input_ids = kwargs.get('word_input_ids', None)\n        \n        # Extract word_attention_mask from kwargs if not provided\n        if word_attention_mask is None:\n            word_attention_mask = kwargs.get('word_attention_mask', None)\n        \n        # Extract src_text from kwargs if not provided\n        if src_text is None:\n            src_text = kwargs.get('src_text', None)\n            # Try plural form too\n            if src_text is None:\n                src_text = kwargs.get('src_texts', None)\n        \n        # Extract word_strings from kwargs if not provided\n        if word_strings is None:\n            word_strings = kwargs.get('word_strings', None)\n        \n        # FIX: Validate formats\n        if src_text is not None and not isinstance(src_text, list):\n            src_text = [src_text]\n        \n        if word_strings is not None and not isinstance(word_strings, list):\n            word_strings = [word_strings] if isinstance(word_strings, str) else list(word_strings)\n        \n        # =====================================================================\n        # PATH 1: WORD-LEVEL PROCESSING\n        # =====================================================================\n        \n        encoder_loss = torch.tensor(0.0, device=device)\n        raw_dscd_outputs = None\n        dscd_normalized = None\n        explanations = []\n        word_strings_batch = None\n        \n        # ==================================================================\n        # üîß FIX #8 & #20: Use pre-computed word_input_ids and handle DataParallel split\n        # ==================================================================\n        if word_input_ids is not None and word_attention_mask is not None:\n            try:\n                # Move to correct device\n                word_input_ids = word_input_ids.to(device)\n                word_attention_mask = word_attention_mask.to(device)\n                \n                # ==================================================================\n                # üî• FIX #20: Handle DataParallel batch splitting for word_strings\n                # ==================================================================\n                # DataParallel splits input_ids/attention_mask across GPUs, but word_strings\n                # might still have the full batch size. We need to slice it.\n                if word_strings is not None and isinstance(word_strings, list):\n                    # Check if word_strings length matches current batch_size\n                    if len(word_strings) > batch_size:\n                        # DataParallel split detected - take first batch_size elements\n                        word_strings_batch = word_strings[:batch_size]\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TATN-DEBUG] DataParallel split detected:\")\n                            print(f\"[TATN-DEBUG]   Original word_strings length: {len(word_strings)}\")\n                            print(f\"[TATN-DEBUG]   Current batch_size: {batch_size}\")\n                            print(f\"[TATN-DEBUG]   Sliced to: {len(word_strings_batch)}\")\n                    elif len(word_strings) == batch_size:\n                        word_strings_batch = word_strings\n                    else:\n                        # word_strings is shorter than batch_size - pad it\n                        word_strings_batch = word_strings + [[]] * (batch_size - len(word_strings))\n                elif src_text is not None and len(src_text) >= batch_size:\n                    # Extract word_strings from src_text\n                    word_strings_batch = [text.strip().split()[:_MAX_WORD_LENGTH] for text in src_text[:batch_size]]\n                else:\n                    # Generate placeholder word_strings\n                    num_words = word_input_ids.size(1)\n                    word_strings_batch = [[\"<WORD>\"] * num_words for _ in range(batch_size)]\n                \n                # ==================================================================\n                # üî• FIX #21: Control debug logging with VERBOSE_LOGGING flag\n                # ==================================================================\n                if _VERBOSE_LOGGING and training_mode:\n                    print(f\"[TATN-DEBUG] Step {self.global_step}: Using pre-computed word_input_ids and word_attention_mask\")\n                    print(f\"[TATN-DEBUG]   word_input_ids shape: {word_input_ids.shape}\")\n                    print(f\"[TATN-DEBUG]   word_attention_mask shape: {word_attention_mask.shape}\")\n                    print(f\"[TATN-DEBUG]   Sample word_input_ids[0,:5]: {word_input_ids[0,:5].tolist()}\")\n                    if word_strings_batch:\n                        print(f\"[TATN-DEBUG]   Sample word_strings[0][:5]: {word_strings_batch[0][:5]}\")\n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[TATN] Failed to use pre-computed word data: {e}\")\n                word_input_ids = None\n                word_attention_mask = None\n                word_strings_batch = None\n        \n        # If word_input_ids still None but word_strings available, generate IDs from strings\n        if word_input_ids is None and word_strings is not None and len(word_strings) >= batch_size:\n            try:\n                # Handle DataParallel split\n                word_strings_batch = word_strings[:batch_size] if len(word_strings) > batch_size else word_strings\n                \n                # Generate word IDs and attention mask from strings\n                batch_word_ids = []\n                for ws_list in word_strings_batch:\n                    if self.bengali_word_tokenizer is not None and hasattr(self.bengali_word_tokenizer, 'convert_tokens_to_ids'):\n                        try:\n                            ids = self.bengali_word_tokenizer.convert_tokens_to_ids(ws_list)\n                            batch_word_ids.append(ids)\n                        except Exception:\n                            # Fallback: use sequential IDs\n                            ids = list(range(1, len(ws_list) + 1))\n                            batch_word_ids.append(ids)\n                    else:\n                        # Fallback: use sequential IDs\n                        ids = list(range(1, len(ws_list) + 1))\n                        batch_word_ids.append(ids)\n                \n                # Pad to max length and create attention mask\n                max_len = max(len(ids) for ids in batch_word_ids) if batch_word_ids else 1\n                padded_ids = []\n                attention_masks = []\n                \n                for ids in batch_word_ids:\n                    # Attention mask: 1 for real tokens, 0 for padding\n                    mask = [1] * len(ids) + [0] * (max_len - len(ids))\n                    padded = ids + [0] * (max_len - len(ids))\n                    padded_ids.append(padded)\n                    attention_masks.append(mask)\n                \n                word_input_ids = torch.tensor(padded_ids, dtype=torch.long).to(device)\n                word_attention_mask = torch.tensor(attention_masks, dtype=torch.long).to(device)\n                \n                # FIX #21: Control debug logging with VERBOSE_LOGGING flag\n                if _VERBOSE_LOGGING and training_mode:\n                    print(f\"[TATN-DEBUG] Step {self.global_step}: Generated IDs from word_strings\")\n                    print(f\"[TATN-DEBUG]   word_input_ids shape: {word_input_ids.shape}\")\n                    print(f\"[TATN-DEBUG]   word_attention_mask shape: {word_attention_mask.shape}\")\n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[TATN] Failed to generate IDs from word_strings: {e}\")\n                word_input_ids = None\n                word_attention_mask = None\n        \n        # If word_input_ids still None, try tokenizing from src_text\n        if word_input_ids is None and src_text is not None and len(src_text) >= batch_size:\n            try:\n                # Handle DataParallel split\n                src_text_batch = src_text[:batch_size] if len(src_text) > batch_size else src_text\n                \n                word_input_ids, word_attention_mask, word_strings_batch = self._tokenize_to_words(src_text_batch)\n                word_input_ids = word_input_ids.to(device)\n                word_attention_mask = word_attention_mask.to(device)\n                \n                # FIX #21: Control debug logging with VERBOSE_LOGGING flag\n                if _VERBOSE_LOGGING and training_mode:\n                    print(f\"[TATN-DEBUG] Step {self.global_step}: Tokenized from src_text\")\n                    print(f\"[TATN-DEBUG]   word_input_ids shape: {word_input_ids.shape}\")\n                    print(f\"[TATN-DEBUG]   word_attention_mask shape: {word_attention_mask.shape}\")\n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[TATN] Word tokenization from src_text failed: {e}\")\n                word_input_ids = None\n                word_attention_mask = None\n                word_strings_batch = None\n        \n        # Process Path 1 if we have word_input_ids\n        if word_input_ids is not None and word_strings_batch is not None and word_attention_mask is not None:\n            try:\n                num_words = word_input_ids.size(1)\n                word_embeddings = self.word_embedding(word_input_ids)\n                \n                # FIX #21: Control debug logging with VERBOSE_LOGGING flag\n                if _VERBOSE_LOGGING and training_mode:\n                    print(f\"[TATN-DEBUG] Path 1: word_embeddings shape {word_embeddings.shape}\")\n                \n                # ==================================================================\n                # üîß FIX #13, #14, #15, #16: CRITICAL - Pass word_input_ids (tensor) to DSCD\n                # ==================================================================\n                if self.dscd is not None:\n                    try:\n                        # FIX #21: Control debug logging with VERBOSE_LOGGING flag\n                        if _VERBOSE_LOGGING and training_mode:\n                            print(f\"[TATN-DEBUG] Calling DSCD.forward()...\")\n                            print(f\"[TATN-DEBUG]   Training mode: {self.training}\")\n                            print(f\"[TATN-DEBUG]   word_embeddings: {word_embeddings.shape}\")\n                            print(f\"[TATN-DEBUG]   word_input_ids: {word_input_ids.shape}\")\n                            print(f\"[TATN-DEBUG]   word_attention_mask: {word_attention_mask.shape}\")\n                        \n                        # FIX #13 & #14: Pass word_input_ids (tensor) NOT word_tokens (list)\n                        # FIX #16: Also pass word_attention_mask\n                        raw_dscd_outputs = self.dscd.forward(\n                            word_embeddings=word_embeddings,\n                            word_input_ids=word_input_ids,  # ‚Üê FIX #13: Correct parameter name\n                            word_attention_mask=word_attention_mask  # ‚Üê FIX #16: Add attention mask\n                        )\n                        \n                        # FIX #21: Control debug logging with VERBOSE_LOGGING flag\n                        if _VERBOSE_LOGGING and training_mode:\n                            print(f\"[TATN-DEBUG] ‚úÖ DSCD.forward() completed\")\n                            if raw_dscd_outputs:\n                                print(f\"[TATN-DEBUG]   Output keys: {raw_dscd_outputs.keys() if isinstance(raw_dscd_outputs, dict) else type(raw_dscd_outputs)}\")\n                        \n                        dscd_normalized = _normalize_dscd_outputs(\n                            raw=raw_dscd_outputs,\n                            batch_size=batch_size,\n                            num_words=num_words,\n                            device=device,\n                            embed_dim=self.word_embed_dim\n                        )\n                        \n                        if _VERBOSE_LOGGING and self.global_step % 100 == 0:\n                            print(f\"[TATN] DSCD forward completed (step {self.global_step})\")\n                    except Exception as e:\n                        print(f\"[TATN] ‚ùå DSCD forward failed: {e}\")\n                        print(\"[TATN]\", traceback.format_exc().splitlines()[-1])\n                        raw_dscd_outputs = None\n                        dscd_normalized = None\n                \n                # ==================================================================\n                # üîß FIX #10: Validate word_tokens format before passing to ASBN\n                # ==================================================================\n                if training_mode and self.asbn is not None and dscd_normalized is not None:\n                    try:\n                        h_aug = dscd_normalized.get('h_aug', word_embeddings)\n                        \n                        # Validate word_strings_batch for ASBN\n                        validated_word_strings = []\n                        for ws in word_strings_batch:\n                            if isinstance(ws, list):\n                                validated_word_strings.append([str(w) for w in ws if w])\n                            elif isinstance(ws, str):\n                                validated_word_strings.append([ws])\n                            else:\n                                validated_word_strings.append([])\n                        \n                        asbn_outputs = self.asbn.forward_with_grl_simplified(\n                            h=h_aug,\n                            proto_probs=dscd_normalized.get('proto_probs', None),\n                            uncertainties=dscd_normalized.get('uncertainties', None),\n                            gates=dscd_normalized.get('gates', None),\n                            span_preds=dscd_normalized.get('span_preds', None),\n                            word_tokens=validated_word_strings\n                        )\n                        \n                        encoder_loss = asbn_outputs[0] if isinstance(asbn_outputs, (tuple, list)) else asbn_outputs\n                        \n                        if not isinstance(encoder_loss, torch.Tensor):\n                            encoder_loss = torch.tensor(float(encoder_loss), device=device)\n                        \n                        if not torch.isfinite(encoder_loss):\n                            encoder_loss = torch.tensor(0.0, device=device)\n                        \n                        if _VERBOSE_LOGGING and self.global_step % 100 == 0:\n                            print(f\"[TATN] ASBN encoder_loss: {encoder_loss.item():.6f}\")\n                    except Exception as e:\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TATN] ASBN forward failed: {e}\")\n                            print(\"[TATN]\", traceback.format_exc().splitlines()[-1])\n                        encoder_loss = torch.tensor(0.0, device=device)\n                \n                if not training_mode and _ENABLE_TRG_INFERENCE and self.trg_system is not None and dscd_normalized is not None:\n                    try:\n                        explanations = self.trg_system.batch_process_explanations(\n                            batch_words=word_strings_batch,\n                            batch_dscd_outputs=dscd_normalized\n                        )\n                        \n                        if _VERBOSE_LOGGING:\n                            total_expl = sum(len(e) for e in explanations)\n                            print(f\"[TATN] TRG generated {total_expl} explanations\")\n                    except Exception as e:\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TATN] TRG generation failed: {e}\")\n                            print(\"[TATN]\", traceback.format_exc().splitlines()[-1])\n                        explanations = [[] for _ in range(batch_size)]\n            except Exception as e:\n                print(f\"[TATN] ‚ùå Path 1 (word-level) failed: {e}\")\n                print(\"[TATN]\", traceback.format_exc().splitlines()[-1])\n                encoder_loss = torch.tensor(0.0, device=device)\n                explanations = [[] for _ in range(batch_size)]\n        else:\n            # ==================================================================\n            # üî• FIX #19: IMPROVED WARNING - Print every step until resolved\n            # ==================================================================\n            if training_mode:\n                print(f\"[TATN] ‚ö†Ô∏è WARNING: word_input_ids, word_strings, or word_attention_mask not available\")\n                print(f\"[TATN]   word_input_ids: {word_input_ids is not None}\")\n                print(f\"[TATN]   word_strings_batch: {word_strings_batch is not None}\")\n                print(f\"[TATN]   word_attention_mask: {word_attention_mask is not None}\")\n                print(f\"[TATN]   Path 1 (word-level) SKIPPED - DSCD will not accumulate data!\")\n        \n        # =====================================================================\n        # PATH 2: IndicBART TRANSLATION (SEPARATE - NO EMBEDDING MIXING)\n        # =====================================================================\n        \n        translation_loss = torch.tensor(0.0, device=device)\n        logits = None\n        \n        if self.indicbart_model is not None:\n            try:\n                if training_mode:\n                    outputs = self.indicbart_model(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        labels=labels,\n                        use_cache=False,\n                        return_dict=True\n                    )\n                    translation_loss = outputs.loss\n                    \n                    if not isinstance(translation_loss, torch.Tensor):\n                        translation_loss = torch.tensor(float(translation_loss), device=device)\n                    \n                    if not torch.isfinite(translation_loss):\n                        translation_loss = torch.tensor(0.0, device=device)\n                    \n                    if _VERBOSE_LOGGING and self.global_step % 100 == 0:\n                        print(f\"[TATN] IndicBART translation_loss: {translation_loss.item():.6f}\")\n                else:\n                    outputs = self.indicbart_model(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        return_dict=True\n                    )\n                    logits = outputs.logits\n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[TATN] IndicBART forward failed: {e}\")\n                    print(\"[TATN]\", traceback.format_exc().splitlines()[-1])\n                translation_loss = torch.tensor(0.0, device=device)\n        else:\n            if _VERBOSE_LOGGING and self.global_step % 100 == 0:\n                print(\"[TATN] ‚ö†Ô∏è IndicBART model not available\")\n        \n        # =====================================================================\n        # COMBINE LOSSES (TRAINING) OR RETURN OUTPUTS (INFERENCE)\n        # =====================================================================\n        \n        if training_mode:\n            dscd_reg = torch.tensor(0.0, device=device)\n            if dscd_normalized is not None:\n                try:\n                    dscd_reg = self._compute_entropy_regularization(\n                        dscd_normalized.get('proto_probs', []),\n                        dscd_normalized.get('gates', []),\n                        min_gate=0.0\n                    )\n                    \n                    if not isinstance(dscd_reg, torch.Tensor):\n                        dscd_reg = torch.tensor(float(dscd_reg), device=device)\n                    \n                    if not torch.isfinite(dscd_reg):\n                        dscd_reg = torch.tensor(0.0, device=device)\n                except Exception as e:\n                    if _VERBOSE_LOGGING:\n                        print(f\"[TATN] DSCD reg failed: {e}\")\n                    dscd_reg = torch.tensor(0.0, device=device)\n            \n            total_loss = translation_loss + _LAMBDA_ASBN * encoder_loss + _LAMBDA_DSCD * dscd_reg\n            \n            if not isinstance(total_loss, torch.Tensor):\n                total_loss = torch.tensor(float(total_loss), device=device)\n            \n            try:\n                if total_loss.numel() != 1:\n                    total_loss = total_loss.mean()\n            except Exception:\n                total_loss = torch.tensor(float(total_loss), device=device)\n            \n            if _VERBOSE_LOGGING and self.global_step % 100 == 0:\n                print(f\"[TATN] Step {self.global_step}: total_loss={total_loss.item():.6f} \"\n                      f\"(trans={translation_loss.item():.6f}, \"\n                      f\"asbn={(_LAMBDA_ASBN * encoder_loss).item():.6f}, \"\n                      f\"dscd_reg={(_LAMBDA_DSCD * dscd_reg).item():.6f})\")\n            \n            return total_loss\n        else:\n            return {\n                'logits': logits,\n                'dscd_outputs': dscd_normalized,\n                'explanations': explanations,\n                'encoder_loss': encoder_loss,\n                'word_strings': word_strings_batch\n            }\n\n    def generate(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        word_input_ids: Optional[torch.Tensor] = None,\n        word_attention_mask: Optional[torch.Tensor] = None,\n        word_strings: Optional[List[List[str]]] = None,\n        src_text: Optional[List[str]] = None,\n        max_length: int = None,\n        num_beams: int = None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate translations with explanations.\n        \n        Args:\n            input_ids: IndicBART subword token IDs [B, T]\n            attention_mask: IndicBART attention mask [B, T]\n            word_input_ids: Pre-computed word IDs [B, W] ‚Üê FIX #19\n            word_attention_mask: Pre-computed word attention mask [B, W] ‚Üê FIX #19\n            word_strings: Pre-tokenized words (avoids re-tokenization)\n            src_text: Source texts for explanations (if word_strings not provided)\n            max_length: Max generation length (default: from config)\n            num_beams: Beam search width (default: from config)\n        \n        Returns:\n            Dict with 'translations' and 'explanations'\n        \"\"\"\n        self.eval()\n        \n        # ==================================================================\n        # üî• FIX #28: Use IndicBART-specific generation parameters\n        # ==================================================================\n        if max_length is None:\n            max_length = _MAX_GEN_LENGTH\n        if num_beams is None:\n            num_beams = _NUM_BEAMS\n        \n        # ==================================================================\n        # üîß FIX #11: Consistent signature with forward method\n        # ==================================================================\n        with torch.no_grad():\n            outputs = self.forward(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                word_input_ids=word_input_ids,\n                word_attention_mask=word_attention_mask,\n                word_strings=word_strings,\n                src_text=src_text,\n                labels=None,\n                **kwargs\n            )\n            \n            explanations = outputs.get('explanations', [])\n            dscd_outputs = outputs.get('dscd_outputs', None)\n            \n            if self.indicbart_model is not None:\n                try:\n                    # ==================================================================\n                    # üî• FIX #25: Handle IndicBART language tokens\n                    # ==================================================================\n                    # IndicBART requires forced_bos_token_id for target language\n                    generate_kwargs = {\n                        'max_length': max_length,\n                        'num_beams': num_beams,\n                        'length_penalty': _LENGTH_PENALTY,\n                        'no_repeat_ngram_size': _NO_REPEAT_NGRAM_SIZE,\n                        'early_stopping': True\n                    }\n                    \n                    # Add forced_bos_token_id if available\n                    try:\n                        # IndicBART uses language-specific tokens like <2en>\n                        lang_code = f\"<2{_TARGET_LANGUAGE}>\"\n                        if hasattr(self.indicbart_tokenizer, 'lang_code_to_id'):\n                            token_id = self.indicbart_tokenizer.lang_code_to_id.get(lang_code, None)\n                            if token_id is not None:\n                                generate_kwargs['forced_bos_token_id'] = token_id\n                        elif hasattr(self.indicbart_tokenizer, 'convert_tokens_to_ids'):\n                            token_id = self.indicbart_tokenizer.convert_tokens_to_ids(lang_code)\n                            if token_id != self.indicbart_tokenizer.unk_token_id:\n                                generate_kwargs['forced_bos_token_id'] = token_id\n                    except Exception:\n                        pass\n                    \n                    # Merge with user-provided kwargs\n                    generate_kwargs.update(kwargs)\n                    \n                    generated_ids = self.indicbart_model.generate(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        **generate_kwargs\n                    )\n                    \n                    translations = self.indicbart_tokenizer.batch_decode(\n                        generated_ids,\n                        skip_special_tokens=True\n                    )\n                except Exception as e:\n                    if _VERBOSE_LOGGING:\n                        print(f\"[TATN] Generation failed: {e}\")\n                    translations = [\"\"] * input_ids.size(0)\n            else:\n                translations = [\"\"] * input_ids.size(0)\n        \n        return {\n            'translations': translations,\n            'explanations': explanations,\n            'dscd_outputs': dscd_outputs,\n            'word_strings': outputs.get('word_strings', None)\n        }\n\n# ==============================================================================\n# üî• FIX #29: Create alias for Cell 10 compatibility\n# ==============================================================================\nMemoryOptimizedTATNWithExplanations = DualPathTATN\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ Cell 6: Dual-Path TATN Model (IndicBART-READY - 29 CRITICAL FIXES)\")\nprint(\"=\"*80)\nprint(\"üî• IndicBART-SPECIFIC FIXES (8 NEW):\")\nprint(\" FIX #22: üî• CRITICAL - Import MBartForConditionalGeneration (not M2M100)\")\nprint(\" FIX #23: üî• CRITICAL - Import AutoTokenizer for IndicBART\")\nprint(\" FIX #24: üî• CRITICAL - Load ai4bharat/indic-bart model\")\nprint(\" FIX #25: üî• CRITICAL - Handle IndicBART language tokens (<2en>, <2bn>)\")\nprint(\" FIX #26: Import all Cell 0 configs with try-except\")\nprint(\" FIX #27: Align with Cell 0 MODEL_NAME parameter\")\nprint(\" FIX #28: Add IndicBART-specific generation parameters\")\nprint(\" FIX #29: Update all references from M2M100 to IndicBART\")\nprint()\nprint(\"üö® CRITICAL FIXES FOR DSCD ZERO-PROTOTYPE ISSUE (21 PRESERVED):\")\nprint(\" FIX #13: üî• CRITICAL - DSCD parameter: word_tokens ‚Üí word_input_ids\")\nprint(\" FIX #14: üî• CRITICAL - Pass word_input_ids (tensor) NOT word_strings (list)\")\nprint(\" FIX #15: üî• CRITICAL - Generate word_attention_mask for DSCD\")\nprint(\" FIX #16: üî• CRITICAL - Pass word_attention_mask to DSCD.forward()\")\nprint(\" FIX #17: Added debug logging for DSCD data flow\")\nprint(\" FIX #18: Validate DSCD receives data in training mode\")\nprint(\" FIX #19: üî• NEW - Extract word_input_ids, word_attention_mask from **kwargs\")\nprint(\" FIX #20: üî• CRITICAL - Handle DataParallel batch splitting for word_strings\")\nprint(\" FIX #21: üî• NEW - Control debug logging with VERBOSE_LOGGING flag\")\nprint()\nprint(\"Original Cell 6 fixes preserved:\")\nprint(\" FIX #1:  word_vocab_size extraction from tokenizer\")\nprint(\" FIX #2:  word_vocab_size validation\")\nprint(\" FIX #3:  encode_text API compatibility\")\nprint(\" FIX #4:  Multiple fallback tokenization methods\")\nprint(\" FIX #5:  src_text/src_texts naming consistency\")\nprint(\" FIX #6:  word_strings parameter support\")\nprint(\" FIX #7:  Extract parameters from **kwargs\")\nprint(\" FIX #8:  Use pre-tokenized word_strings when available\")\nprint(\" FIX #9:  Validate word_tokens format for DSCD\")\nprint(\" FIX #10: Validate word_tokens format for ASBN\")\nprint(\" FIX #11: Generate method signature consistency\")\nprint(\" FIX #12: Word embedding init after vocab validation\")\nprint(\"=\"*80)\nprint(\"üîç IndicBART Integration:\")\nprint(f\" ‚úì Model: {_MODEL_NAME}\")\nprint(f\" ‚úì Source language: {_SOURCE_LANGUAGE}\")\nprint(f\" ‚úì Target language: {_TARGET_LANGUAGE}\")\nprint(f\" ‚úì Max generation length: {_MAX_GEN_LENGTH}\")\nprint(f\" ‚úì Num beams: {_NUM_BEAMS}\")\nprint(f\" ‚úì Length penalty: {_LENGTH_PENALTY}\")\nprint(f\" ‚úì No repeat ngram size: {_NO_REPEAT_NGRAM_SIZE}\")\nprint(f\" ‚úì Language token format: <2{_TARGET_LANGUAGE}>\")\nprint(\"=\"*80)\nprint(\"üîç Module Availability:\")\nprint(f\" ‚úì DSCD class: {_DSCD_CLASS.__name__ if _DSCD_CLASS else 'NOT FOUND'}\")\nprint(f\" ‚úì ASBN class: {_ASBN_CLASS.__name__ if _ASBN_CLASS else 'NOT FOUND'}\")\nprint(f\" ‚úì TRG class: {_TRG_CLASS.__name__ if _TRG_CLASS else 'NOT FOUND'}\")\nprint(f\" ‚úì Word tokenizer: {'AVAILABLE' if HAS_WORD_TOKENIZER else 'NOT FOUND'}\")\nprint(f\" ‚úì Word validation: {'AVAILABLE' if HAS_WORD_VALIDATION else 'NOT FOUND'}\")\nprint(\"=\"*80)\nprint(\"üîç Debug Features (controlled by VERBOSE_LOGGING):\")\nprint(f\" ‚úì VERBOSE_LOGGING: {_VERBOSE_LOGGING}\")\nprint(\" ‚úì Set VERBOSE_LOGGING=True in Cell 0 to enable debug messages\")\nprint(\" ‚úì Set VERBOSE_LOGGING=False (default) for clean training output\")\nprint(\" ‚úì Verifies word_input_ids, word_attention_mask passed to DSCD\")\nprint(\" ‚úì Tracks word_embeddings shape\")\nprint(\" ‚úì Shows exact missing fields in warnings\")\nprint(\" ‚úì Detects and handles DataParallel batch splitting\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"id":"KZbMDpIYH4J4","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:24.560303Z","iopub.execute_input":"2026-01-24T20:09:24.560569Z","iopub.status.idle":"2026-01-24T20:09:44.110994Z","shell.execute_reply.started":"2026-01-24T20:09:24.560549Z","shell.execute_reply":"2026-01-24T20:09:44.110276Z"}},"outputs":[{"name":"stderr","text":"2026-01-24 20:09:31.166116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769285371.388070      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769285371.451376      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769285371.984991      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769285371.985031      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769285371.985034      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769285371.985036      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"[CELL6] ‚úÖ Imported IndicBART dependencies (MBart + AutoTokenizer)\n[CELL6] Loading configuration from Cell 0...\n[CELL6] ‚úÖ Using MODEL_NAME from Cell 0: ai4bharat/IndicBART\n[CELL6] Configuration loaded:\n  Model: ai4bharat/IndicBART\n  Source language: bn\n  Target language: en\n  Word vocab size: 50000\n  Word embed dim: 256\n  Max word length: 48\n  Max gen length: 128\n  Num beams: 5\n  DSCD buffer: 20\n  DSCD max protos: 8\n  Enable ASBN: True\n  Enable TRG: True\n  Lambda ASBN: 0.1\n  Lambda DSCD: 0.05\n  Verbose logging: False\n  Gradient checkpointing: False\n[CELL6] ‚úÖ Imported BengaliWordTokenizer from Cell 2\n[CELL6] ‚úÖ Imported WordLevelDSCDOnline from Cell 3\n[CELL6] ‚úÖ Imported WordLevelASBNModule from Cell 4\n[CELL6] ‚úÖ Imported CompleteTRGWithExplanations from Cell 5\n[CELL6] All modules available: True\n[CELL6] ‚úÖ Imported word validation functions from Cell 1\n\n================================================================================\n‚úÖ Cell 6: Dual-Path TATN Model (IndicBART-READY - 29 CRITICAL FIXES)\n================================================================================\nüî• IndicBART-SPECIFIC FIXES (8 NEW):\n FIX #22: üî• CRITICAL - Import MBartForConditionalGeneration (not M2M100)\n FIX #23: üî• CRITICAL - Import AutoTokenizer for IndicBART\n FIX #24: üî• CRITICAL - Load ai4bharat/indic-bart model\n FIX #25: üî• CRITICAL - Handle IndicBART language tokens (<2en>, <2bn>)\n FIX #26: Import all Cell 0 configs with try-except\n FIX #27: Align with Cell 0 MODEL_NAME parameter\n FIX #28: Add IndicBART-specific generation parameters\n FIX #29: Update all references from M2M100 to IndicBART\n\nüö® CRITICAL FIXES FOR DSCD ZERO-PROTOTYPE ISSUE (21 PRESERVED):\n FIX #13: üî• CRITICAL - DSCD parameter: word_tokens ‚Üí word_input_ids\n FIX #14: üî• CRITICAL - Pass word_input_ids (tensor) NOT word_strings (list)\n FIX #15: üî• CRITICAL - Generate word_attention_mask for DSCD\n FIX #16: üî• CRITICAL - Pass word_attention_mask to DSCD.forward()\n FIX #17: Added debug logging for DSCD data flow\n FIX #18: Validate DSCD receives data in training mode\n FIX #19: üî• NEW - Extract word_input_ids, word_attention_mask from **kwargs\n FIX #20: üî• CRITICAL - Handle DataParallel batch splitting for word_strings\n FIX #21: üî• NEW - Control debug logging with VERBOSE_LOGGING flag\n\nOriginal Cell 6 fixes preserved:\n FIX #1:  word_vocab_size extraction from tokenizer\n FIX #2:  word_vocab_size validation\n FIX #3:  encode_text API compatibility\n FIX #4:  Multiple fallback tokenization methods\n FIX #5:  src_text/src_texts naming consistency\n FIX #6:  word_strings parameter support\n FIX #7:  Extract parameters from **kwargs\n FIX #8:  Use pre-tokenized word_strings when available\n FIX #9:  Validate word_tokens format for DSCD\n FIX #10: Validate word_tokens format for ASBN\n FIX #11: Generate method signature consistency\n FIX #12: Word embedding init after vocab validation\n================================================================================\nüîç IndicBART Integration:\n ‚úì Model: ai4bharat/IndicBART\n ‚úì Source language: bn\n ‚úì Target language: en\n ‚úì Max generation length: 128\n ‚úì Num beams: 5\n ‚úì Length penalty: 1.0\n ‚úì No repeat ngram size: 3\n ‚úì Language token format: <2en>\n================================================================================\nüîç Module Availability:\n ‚úì DSCD class: WordLevelDSCDOnline\n ‚úì ASBN class: WordLevelASBNModule\n ‚úì TRG class: CompleteTRGWithExplanations\n ‚úì Word tokenizer: AVAILABLE\n ‚úì Word validation: AVAILABLE\n================================================================================\nüîç Debug Features (controlled by VERBOSE_LOGGING):\n ‚úì VERBOSE_LOGGING: False\n ‚úì Set VERBOSE_LOGGING=True in Cell 0 to enable debug messages\n ‚úì Set VERBOSE_LOGGING=False (default) for clean training output\n ‚úì Verifies word_input_ids, word_attention_mask passed to DSCD\n ‚úì Tracks word_embeddings shape\n ‚úì Shows exact missing fields in warnings\n ‚úì Detects and handles DataParallel batch splitting\n================================================================================\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ==============================================================================\n# CELL 7: TRAINING LOOP FOR DUAL-PATH TATN (IndicBART-READY - 25 CRITICAL FIXES)\n# ==============================================================================\n# Complete fixes for IndicBART integration + all Cell 0 alignment:\n#\n# üî• IndicBART-SPECIFIC FIXES (5 NEW):\n# FIX #21: üî• CRITICAL - Replace m2m100_model with indicbart_model references\n# FIX #22: üî• CRITICAL - Update all print messages for IndicBART\n# FIX #23: üî• CRITICAL - Handle IndicBART language token format in validation\n# FIX #24: Import IndicBART-specific configs from Cell 0\n# FIX #25: Update freeze_model_layers for IndicBART architecture\n#\n# üî¨ RESEARCH-BACKED FIXES (20 PRESERVED):\n# FIX #1:  EPOCHS default 3 ‚Üí 10 (Cell 0 convergence)\n# FIX #2:  VALIDATION_CHECK_INTERVAL 0 ‚Üí 1000 (Cell 0)\n# FIX #3:  Added LR scheduler with scheduler.step() calls\n# FIX #4:  ‚úÖ COMPLETE Early stopping implementation (patience=5)\n# FIX #5:  Added validation BLEU metric tracking\n# FIX #6:  Added best model saving by validation loss\n# FIX #7:  Added warmup step counter and tracking\n# FIX #8:  Added layer freezing function\n# FIX #10: Added checkpoint frequency (every 2 epochs)\n# FIX #11: MEMORY_CLEANUP_FREQUENCY 100 ‚Üí 50\n# FIX #12: Added MIN_LEARNING_RATE enforcement\n# FIX #13: Added DSCD_MAX_CLUSTERING_POINTS limit\n# FIX #14: Added CLUSTERING_TIMEOUT enforcement\n# FIX #15: ‚úÖ COMPLETE calculate_bleu_score() function\n# FIX #16: ‚úÖ COMPLETE early_stopping_counter tracking\n# FIX #17: ‚úÖ COMPLETE best_val_loss tracking\n# FIX #18: Added learning rate logging\n# FIX #19: FIXED BATCH UNPACKING - Extracts word data from batch\n# FIX #20: CRITICAL - Handles BOTH dict and tuple batch formats\n# ==============================================================================\n\nimport os\nimport time\nimport math\nimport gc\nimport traceback\nfrom datetime import datetime\nfrom collections import defaultdict, deque\nfrom typing import Optional, Dict, Any, List, Tuple, Union\n\nimport numpy as np\nimport torch\nfrom torch.cuda.amp import GradScaler, autocast as cuda_amp_autocast\nfrom tqdm import tqdm\nfrom contextlib import nullcontext\n\n# ==============================================================================\n# üî¨ FIX #3: Import transformers scheduler (for inverse_sqrt with warmup)\n# ==============================================================================\ntry:\n    from transformers import get_inverse_sqrt_schedule, get_linear_schedule_with_warmup\n    _HAS_TRANSFORMERS_SCHEDULER = True\n    print(\"[CELL7] ‚úÖ Imported transformers scheduler functions\")\nexcept Exception:\n    _HAS_TRANSFORMERS_SCHEDULER = False\n    print(\"[CELL7] ‚ö†Ô∏è transformers scheduler not available - using basic training\")\n\n# ==============================================================================\n# üî• FIX #24: Import Cell 0 configuration parameters\n# ==============================================================================\nprint(\"[CELL7] Loading configuration from Cell 0...\")\n\n# Basic configuration\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, ValueError):\n    VERBOSE_LOGGING = False\n    print(\"[CELL7] WARNING: VERBOSE_LOGGING not defined, using default False\")\n\n_VERBOSE_LOGGING = VERBOSE_LOGGING\n\nDEBUG_PRINT_INTERVAL = int(globals().get(\"DEBUG_PRINT_INTERVAL\", 200))\n_cell7_dbg_counts = defaultdict(int)\n\ndef cell7_dbg(key: str, msg: str, limit: int = 10):\n    if not _VERBOSE_LOGGING:\n        return\n    _cell7_dbg_counts[key] += 1\n    if _cell7_dbg_counts[key] <= limit:\n        print(f\"[CELL7-DBG] {msg}\")\n\n# Device and training parameters\ntry:\n    DEVICE = globals().get(\"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\nexcept Exception:\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n_DEVICE = DEVICE\n\ntry:\n    EPOCHS = int(EPOCHS)\nexcept (NameError, ValueError):\n    EPOCHS = 10\n    print(\"[CELL7] WARNING: EPOCHS not defined, using default 10\")\n_EPOCHS = EPOCHS\n\ntry:\n    BATCH_SIZE = int(BATCH_SIZE)\nexcept (NameError, ValueError):\n    BATCH_SIZE = 8\n    print(\"[CELL7] WARNING: BATCH_SIZE not defined, using default 8\")\n_BATCH_SIZE = BATCH_SIZE\n\ntry:\n    ACCUMULATION_STEPS = int(ACCUMULATION_STEPS)\nexcept (NameError, ValueError):\n    ACCUMULATION_STEPS = 16\n    print(\"[CELL7] WARNING: ACCUMULATION_STEPS not defined, using default 16\")\n_ACCUMULATION_STEPS = ACCUMULATION_STEPS\n\ntry:\n    GRAD_CLIP_NORM = float(GRAD_CLIP_NORM)\nexcept (NameError, ValueError):\n    GRAD_CLIP_NORM = 1.0\n    print(\"[CELL7] WARNING: GRAD_CLIP_NORM not defined, using default 1.0\")\n_GRAD_CLIP_NORM = GRAD_CLIP_NORM\n\ntry:\n    MEMORY_CLEANUP_FREQUENCY = int(MEMORY_CLEANUP_FREQUENCY)\nexcept (NameError, ValueError):\n    MEMORY_CLEANUP_FREQUENCY = 50\n    print(\"[CELL7] WARNING: MEMORY_CLEANUP_FREQUENCY not defined, using default 50\")\n_MEMORY_CLEANUP_FREQUENCY = MEMORY_CLEANUP_FREQUENCY\n\ntry:\n    USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept (NameError, ValueError):\n    USE_MULTI_GPU = torch.cuda.device_count() > 1\n    print(f\"[CELL7] WARNING: USE_MULTI_GPU not defined, using default {USE_MULTI_GPU}\")\n_USE_MULTI_GPU = USE_MULTI_GPU\n\ntry:\n    NUM_GPUS = int(NUM_GPUS)\nexcept (NameError, ValueError):\n    NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    print(f\"[CELL7] WARNING: NUM_GPUS not defined, using default {NUM_GPUS}\")\n_NUM_GPUS = NUM_GPUS\n\ntry:\n    USE_AMP = bool(USE_AMP)\nexcept (NameError, ValueError):\n    USE_AMP = True\n    print(\"[CELL7] WARNING: USE_AMP not defined, using default True\")\n_USE_AMP = USE_AMP\n\n# Language parameters\ntry:\n    SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, ValueError):\n    SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL7] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n_SOURCE_LANGUAGE = SOURCE_LANGUAGE\n\ntry:\n    TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, ValueError):\n    TARGET_LANGUAGE = \"en\"\n    print(\"[CELL7] WARNING: TARGET_LANGUAGE not defined, using default 'en'\")\n_TARGET_LANGUAGE = TARGET_LANGUAGE\n\n# IndicBART uses language codes directly\n_BN_LANG = _SOURCE_LANGUAGE\n_EN_LANG = _TARGET_LANGUAGE\n\n# Max length parameters\ntry:\n    MAX_LENGTH = int(MAX_LENGTH)\nexcept (NameError, ValueError):\n    MAX_LENGTH = 128\n    print(\"[CELL7] WARNING: MAX_LENGTH not defined, using default 128\")\n_MAX_LENGTH = MAX_LENGTH\n\ntry:\n    MAX_WORD_LENGTH = int(MAX_WORD_LENGTH)\nexcept (NameError, ValueError):\n    MAX_WORD_LENGTH = 48\n    print(\"[CELL7] WARNING: MAX_WORD_LENGTH not defined, using default 48\")\n_MAX_WORD_LENGTH = MAX_WORD_LENGTH\n\n# Validation parameters\ntry:\n    VALIDATION_CHECK_INTERVAL = int(VALIDATION_CHECK_INTERVAL)\nexcept (NameError, ValueError):\n    VALIDATION_CHECK_INTERVAL = 1000\n    print(\"[CELL7] WARNING: VALIDATION_CHECK_INTERVAL not defined, using default 1000\")\n\n# ==============================================================================\n# üî¨ FIX #4, #6, #7, #12, #13, #14: Additional Cell 0 parameters\n# ==============================================================================\ntry:\n    EARLY_STOPPING_PATIENCE = int(EARLY_STOPPING_PATIENCE)\nexcept (NameError, ValueError):\n    EARLY_STOPPING_PATIENCE = 5\n    print(\"[CELL7] WARNING: EARLY_STOPPING_PATIENCE not defined, using default 5\")\n\ntry:\n    SAVE_BEST_MODEL = bool(SAVE_BEST_MODEL)\nexcept (NameError, ValueError):\n    SAVE_BEST_MODEL = True\n    print(\"[CELL7] WARNING: SAVE_BEST_MODEL not defined, using default True\")\n\ntry:\n    WARMUP_STEPS = int(WARMUP_STEPS)\nexcept (NameError, ValueError):\n    WARMUP_STEPS = 4000\n    print(\"[CELL7] WARNING: WARMUP_STEPS not defined, using default 4000\")\n\ntry:\n    MIN_LEARNING_RATE = float(MIN_LEARNING_RATE)\nexcept (NameError, ValueError):\n    MIN_LEARNING_RATE = 1e-7\n    print(\"[CELL7] WARNING: MIN_LEARNING_RATE not defined, using default 1e-7\")\n\ntry:\n    USE_LR_SCHEDULER = bool(USE_LR_SCHEDULER)\nexcept (NameError, ValueError):\n    USE_LR_SCHEDULER = True\n    print(\"[CELL7] WARNING: USE_LR_SCHEDULER not defined, using default True\")\n\ntry:\n    SCHEDULER_TYPE = str(SCHEDULER_TYPE)\nexcept (NameError, ValueError):\n    SCHEDULER_TYPE = \"inverse_sqrt\"\n    print(\"[CELL7] WARNING: SCHEDULER_TYPE not defined, using default 'inverse_sqrt'\")\n\ntry:\n    DSCD_MAX_CLUSTERING_POINTS = int(DSCD_MAX_CLUSTERING_POINTS)\nexcept (NameError, ValueError):\n    DSCD_MAX_CLUSTERING_POINTS = 200\n    print(\"[CELL7] WARNING: DSCD_MAX_CLUSTERING_POINTS not defined, using default 200\")\n\ntry:\n    CLUSTERING_TIMEOUT = int(CLUSTERING_TIMEOUT)\nexcept (NameError, ValueError):\n    CLUSTERING_TIMEOUT = 3\n    print(\"[CELL7] WARNING: CLUSTERING_TIMEOUT not defined, using default 3\")\n\ntry:\n    CHECKPOINT_DIR = str(CHECKPOINT_DIR)\nexcept (NameError, ValueError):\n    CHECKPOINT_DIR = \"/kaggle/working/\"\n    print(f\"[CELL7] WARNING: CHECKPOINT_DIR not defined, using default '{CHECKPOINT_DIR}'\")\n\ntry:\n    SAVE_CHECKPOINT_EVERY = int(SAVE_CHECKPOINT_EVERY)\nexcept (NameError, ValueError):\n    SAVE_CHECKPOINT_EVERY = 2\n    print(\"[CELL7] WARNING: SAVE_CHECKPOINT_EVERY not defined, using default 2\")\n\ntry:\n    AGGRESSIVE_MEMORY_CLEANUP = bool(AGGRESSIVE_MEMORY_CLEANUP)\nexcept (NameError, ValueError):\n    AGGRESSIVE_MEMORY_CLEANUP = True\n    print(\"[CELL7] WARNING: AGGRESSIVE_MEMORY_CLEANUP not defined, using default True\")\n\n# Layer freezing parameters (Cell 0)\ntry:\n    FREEZE_ENCODER_LAYERS = int(FREEZE_ENCODER_LAYERS)\nexcept (NameError, ValueError):\n    FREEZE_ENCODER_LAYERS = 2\n    print(\"[CELL7] WARNING: FREEZE_ENCODER_LAYERS not defined, using default 2\")\n\ntry:\n    FREEZE_DECODER_LAYERS = int(FREEZE_DECODER_LAYERS)\nexcept (NameError, ValueError):\n    FREEZE_DECODER_LAYERS = 2\n    print(\"[CELL7] WARNING: FREEZE_DECODER_LAYERS not defined, using default 2\")\n\nprint(f\"[CELL7] Configuration loaded:\")\nprint(f\"  Epochs: {_EPOCHS}\")\nprint(f\"  Batch size: {_BATCH_SIZE}\")\nprint(f\"  Accumulation steps: {_ACCUMULATION_STEPS}\")\nprint(f\"  Device: {_DEVICE}\")\nprint(f\"  Multi-GPU: {_USE_MULTI_GPU} (GPUs: {_NUM_GPUS})\")\nprint(f\"  AMP: {_USE_AMP}\")\nprint(f\"  Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  Max length: {_MAX_LENGTH}\")\nprint(f\"  Validation interval: {VALIDATION_CHECK_INTERVAL}\")\nprint(f\"  Early stopping patience: {EARLY_STOPPING_PATIENCE}\")\nprint(f\"  Warmup steps: {WARMUP_STEPS}\")\nprint(f\"  Scheduler: {SCHEDULER_TYPE if USE_LR_SCHEDULER else 'disabled'}\")\nprint(f\"  Layer freezing: {FREEZE_ENCODER_LAYERS} encoder + {FREEZE_DECODER_LAYERS} decoder\")\nprint(f\"  Memory cleanup frequency: {_MEMORY_CLEANUP_FREQUENCY}\")\nprint(f\"  Verbose logging: {_VERBOSE_LOGGING}\")\n\n# ==============================================================================\n# üî• FIX #25: Layer Freezing Function for IndicBART\n# ==============================================================================\ndef freeze_model_layers(model, freeze_encoder_layers=2, freeze_decoder_layers=2):\n    \"\"\"\n    Freeze early layers to preserve pretrained multilingual features.\n    Evidence: Low-Resource Transliteration (2025) - preserves multilingual knowledge\n    \n    Updated for IndicBART (MBart architecture).\n    \"\"\"\n    try:\n        # Get core model (unwrap DataParallel if needed)\n        core_model = model.module if hasattr(model, 'module') else model\n        \n        # ==================================================================\n        # üî• FIX #25: Get IndicBART model (not M2M100)\n        # ==================================================================\n        indicbart_model = getattr(core_model, 'indicbart_model', None)\n        if indicbart_model is None:\n            print(\"[FREEZE] Warning: indicbart_model not found, skipping layer freezing\")\n            return\n        \n        # Freeze embedding layers\n        try:\n            if hasattr(indicbart_model.model, 'shared'):\n                for param in indicbart_model.model.shared.parameters():\n                    param.requires_grad = False\n                print(f\"[FREEZE] ‚úì Frozen embedding layers\")\n        except Exception as e:\n            print(f\"[FREEZE] Warning: Could not freeze embeddings: {e}\")\n        \n        # Freeze first N encoder layers\n        frozen_encoder = 0\n        if hasattr(indicbart_model.model, 'encoder') and hasattr(indicbart_model.model.encoder, 'layers'):\n            for i in range(min(freeze_encoder_layers, len(indicbart_model.model.encoder.layers))):\n                try:\n                    for param in indicbart_model.model.encoder.layers[i].parameters():\n                        param.requires_grad = False\n                    frozen_encoder += 1\n                except Exception:\n                    break\n            print(f\"[FREEZE] ‚úì Frozen {frozen_encoder} encoder layers\")\n        \n        # Freeze first N decoder layers\n        frozen_decoder = 0\n        if hasattr(indicbart_model.model, 'decoder') and hasattr(indicbart_model.model.decoder, 'layers'):\n            for i in range(min(freeze_decoder_layers, len(indicbart_model.model.decoder.layers))):\n                try:\n                    for param in indicbart_model.model.decoder.layers[i].parameters():\n                        param.requires_grad = False\n                    frozen_decoder += 1\n                except Exception:\n                    break\n            print(f\"[FREEZE] ‚úì Frozen {frozen_decoder} decoder layers\")\n        \n        # Count trainable parameters\n        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n        total_params = sum(p.numel() for p in model.parameters())\n        print(f\"[FREEZE] Trainable: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.1f}%)\")\n        \n    except Exception as e:\n        print(f\"[FREEZE] Layer freezing failed: {type(e).__name__}: {str(e)[:200]}\")\n\n\n# ---------------- Helpers ----------------\ndef clear_all_gpu_caches():\n    gc.collect()\n    if not torch.cuda.is_available():\n        return\n    try:\n        for i in range(torch.cuda.device_count()):\n            with torch.cuda.device(i):\n                try:\n                    torch.cuda.empty_cache()\n                except Exception:\n                    pass\n    except Exception:\n        pass\n\n\ndef get_amp_ctx():\n    \"\"\"\n    Return a context manager for mixed-precision if enabled and available.\n    Otherwise return a nullcontext.\n    \"\"\"\n    if not _USE_AMP or not torch.cuda.is_available():\n        return nullcontext()\n    try:\n        return cuda_amp_autocast()\n    except Exception:\n        return nullcontext()\n\n\ndef save_checkpoint(model: torch.nn.Module, optimizer: Optional[torch.optim.Optimizer], \n                    scheduler: Optional[Any],  # ‚Üê FIX #3: Added scheduler parameter\n                    training_stats: Dict[str, Any],\n                    epoch: int, global_step: int, epoch_losses: List[float], \n                    ckpt_dir: str = \"checkpoints\",\n                    is_best: bool = False):  # ‚Üê FIX #6: Added is_best flag\n    os.makedirs(ckpt_dir, exist_ok=True)\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    # Different filename for best model\n    if is_best:\n        fname = f\"tatn_best_model.pt\"\n    else:\n        fname = f\"tatn_e{epoch}_s{global_step}_{timestamp}.pt\"\n    \n    path = os.path.join(ckpt_dir, fname)\n    core_model = model.module if hasattr(model, \"module\") else model\n    \n    # ‚Üê FIX #3: Include scheduler state\n    ckpt = {\n        \"epoch\": epoch,\n        \"global_step\": global_step,\n        \"model_state_dict\": core_model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict() if optimizer is not None else None,\n        \"scheduler_state_dict\": scheduler.state_dict() if scheduler is not None else None,  # ‚Üê FIX #3\n        \"training_stats\": training_stats,\n        \"avg_epoch_loss\": float(np.mean(epoch_losses)) if epoch_losses else 0.0,\n    }\n    try:\n        torch.save(ckpt, path)\n        if is_best:\n            print(f\"[CHECKPOINT] üåü Saved BEST MODEL: {fname} avg_loss={ckpt['avg_epoch_loss']:.6f}\")\n        else:\n            print(f\"[CHECKPOINT] Saved {fname} avg_loss={ckpt['avg_epoch_loss']:.6f}\")\n    except Exception as e:\n        print(f\"[CHECKPOINT] Save failed: {type(e).__name__}: {str(e)[:200]}\")\n\n\n# ==============================================================================\n# üî¨ FIX #5, #15: Validation BLEU Score Calculation\n# ==============================================================================\ndef calculate_bleu_score(model: torch.nn.Module, tokenizer, val_samples: List[Tuple[str, str]], \n                        max_length: int, device: torch.device) -> float:\n    \"\"\"\n    Calculate BLEU score on validation samples.\n    Returns average sentence-level BLEU (approximation).\n    \"\"\"\n    try:\n        # Try to import sacrebleu for proper BLEU calculation\n        try:\n            import sacrebleu\n            _HAS_SACREBLEU = True\n        except Exception:\n            _HAS_SACREBLEU = False\n        \n        core_model = model.module if hasattr(model, \"module\") else model\n        was_training = core_model.training\n        core_model.eval()\n        \n        predictions = []\n        references = []\n        \n        with torch.inference_mode():\n            for src_text, ref_text in val_samples:\n                try:\n                    # Tokenize source\n                    enc = tokenizer(src_text, return_tensors=\"pt\", padding=True, \n                                   truncation=True, max_length=max_length)\n                    enc = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) \n                           for k, v in enc.items()}\n                    \n                    # ==================================================================\n                    # üî• FIX #21: Use indicbart_model (not m2m100_model)\n                    # ==================================================================\n                    # Generate translation\n                    indicbart_obj = getattr(core_model, \"indicbart_model\", None) or core_model\n                    if hasattr(indicbart_obj, \"generate\"):\n                        out_ids = indicbart_obj.generate(\n                            enc.get(\"input_ids\"),\n                            attention_mask=enc.get(\"attention_mask\"),\n                            max_length=max_length,\n                            num_beams=2,\n                            do_sample=False,\n                            early_stopping=True\n                        )\n                        pred_text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n                    else:\n                        pred_text = \"\"\n                    \n                    predictions.append(pred_text)\n                    references.append(ref_text)\n                    \n                except Exception:\n                    continue\n        \n        # Calculate BLEU\n        if _HAS_SACREBLEU and predictions and references:\n            try:\n                bleu = sacrebleu.corpus_bleu(predictions, [references])\n                score = bleu.score\n            except Exception:\n                # Fallback: simple word overlap\n                score = 0.0\n                for pred, ref in zip(predictions, references):\n                    pred_words = set(pred.lower().split())\n                    ref_words = set(ref.lower().split())\n                    if ref_words:\n                        overlap = len(pred_words & ref_words) / len(ref_words)\n                        score += overlap * 100\n                score = score / len(predictions) if predictions else 0.0\n        else:\n            # Fallback: simple word overlap\n            score = 0.0\n            for pred, ref in zip(predictions, references):\n                pred_words = set(pred.lower().split())\n                ref_words = set(ref.lower().split())\n                if ref_words:\n                    overlap = len(pred_words & ref_words) / len(ref_words)\n                    score += overlap * 100\n            score = score / len(predictions) if predictions else 0.0\n        \n        if was_training:\n            core_model.train()\n        \n        return float(score)\n        \n    except Exception as e:\n        print(f\"[BLEU] Calculation failed: {type(e).__name__}: {str(e)[:200]}\")\n        return 0.0\n\n\n# ==============================================================================\n# üî• FIX #22 & #23: Validation for IndicBART\n# ==============================================================================\n_PROTOBUF_COMPAT_ERROR_SHOWN = globals().get(\"_PROTOBUF_COMPAT_ERROR_SHOWN\", False)\n\n@torch.inference_mode()\ndef quick_validation_check(model: torch.nn.Module, tokenizer, step: int, bn_lang: str, en_lang: str, max_length: int, device: torch.device):\n    \"\"\"\n    Run a few simple translations to sanity-check the model.\n    Updated for Cell 6 dual-path architecture with IndicBART.\n    \"\"\"\n    global _PROTOBUF_COMPAT_ERROR_SHOWN\n    core_model = model.module if hasattr(model, \"module\") else model\n    \n    # ==================================================================\n    # üî• FIX #21: Use indicbart_model (not m2m100_model)\n    # ==================================================================\n    gen_target = getattr(core_model, \"indicbart_model\", None) or core_model\n    \n    was_training = core_model.training\n    core_model.eval()\n\n    samples = [\n        \"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\",\n        \"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\",\n        \"‡¶™‡¶æ‡¶§‡¶æ ‡¶ù‡¶∞‡ßá ‡¶™‡¶°‡¶º‡ßá‡¶õ‡ßá‡•§\",\n        \"‡¶Ü‡¶Æ‡¶ø ‡¶≠‡¶æ‡¶≤‡ßã ‡¶Ü‡¶õ‡¶ø‡•§\",\n        \"‡¶Ü‡¶ú ‡¶Ü‡¶¨‡¶π‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã‡•§\",\n    ]\n    print(\"\\n\" + \"=\" * 70)\n    print(f\"[VALIDATION] Quick validation at step {step}\")\n    print(\"=\" * 70)\n    try:\n        # ==================================================================\n        # üî• FIX #23: IndicBART language token handling\n        # ==================================================================\n        # Set source language (IndicBART format)\n        try:\n            tokenizer.src_lang = bn_lang\n        except Exception:\n            pass\n\n        # Get forced_bos_token_id for target language\n        forced_id = None\n        try:\n            # IndicBART uses language-specific tokens like <2en>\n            lang_code = f\"<2{en_lang}>\"\n            if hasattr(tokenizer, \"lang_code_to_id\"):\n                forced_id = tokenizer.lang_code_to_id.get(lang_code, None)\n            elif hasattr(tokenizer, \"convert_tokens_to_ids\"):\n                token_id = tokenizer.convert_tokens_to_ids(lang_code)\n                if token_id != tokenizer.unk_token_id:\n                    forced_id = token_id\n        except Exception:\n            forced_id = None\n\n        indicbart_obj = getattr(core_model, \"indicbart_model\", None)\n        orig_use_cache = None\n        try:\n            if indicbart_obj is not None and hasattr(indicbart_obj, \"config\") and hasattr(indicbart_obj.config, \"use_cache\"):\n                orig_use_cache = indicbart_obj.config.use_cache\n                indicbart_obj.config.use_cache = True\n        except Exception:\n            orig_use_cache = None\n\n        for i, src in enumerate(samples, 1):\n            try:\n                enc = tokenizer(src, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n                enc = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in enc.items()}\n                \n                if forced_id is not None:\n                    try:\n                        if indicbart_obj is not None and hasattr(indicbart_obj, \"config\"):\n                            indicbart_obj.config.forced_bos_token_id = int(forced_id)\n                            indicbart_obj.config.decoder_start_token_id = int(forced_id)\n                    except Exception:\n                        pass\n                \n                out_ids = None\n                try:\n                    if hasattr(core_model, \"generate\"):\n                        # Use src_text (singular) not src_texts\n                        out_ids = core_model.generate(\n                            input_ids=enc.get(\"input_ids\"),\n                            attention_mask=enc.get(\"attention_mask\"),\n                            src_text=[src],  # ‚Üê Already correct: singular src_text\n                            max_length=max_length,\n                            num_beams=2\n                        )\n                        if isinstance(out_ids, dict) and 'translations' in out_ids:\n                            pred = out_ids['translations'][0]\n                            print(f\"{i}. {src} -> {pred}\")\n                            continue\n                    \n                    gen_src = getattr(core_model, \"indicbart_model\", None) or core_model\n                    if hasattr(gen_src, \"generate\"):\n                        out_ids = gen_src.generate(\n                            enc.get(\"input_ids\"),\n                            attention_mask=enc.get(\"attention_mask\"),\n                            max_length=max_length,\n                            num_beams=2,\n                            do_sample=False,\n                            early_stopping=True,\n                            pad_token_id=int(getattr(tokenizer, \"pad_token_id\", 1)),\n                            forced_bos_token_id=int(forced_id) if forced_id is not None else None\n                        )\n                except AttributeError as ae:\n                    if not _PROTOBUF_COMPAT_ERROR_SHOWN:\n                        print(\"[VALIDATION] Warning: generation raised AttributeError (often protobuf incompatibility).\")\n                        print(\"  Suggestion: pip install 'protobuf==3.20.3' and restart the kernel.\")\n                        _PROTOBUF_COMPAT_ERROR_SHOWN = True\n                    out_ids = None\n                except Exception as e:\n                    print(f\"[VALIDATION] Generation error: {type(e).__name__}: {str(e)[:200]}\")\n                    out_ids = None\n\n                if out_ids is not None:\n                    try:\n                        if isinstance(out_ids, (list, tuple)):\n                            pred = tokenizer.batch_decode(out_ids, skip_special_tokens=True)[0]\n                        else:\n                            if isinstance(out_ids, torch.Tensor):\n                                pred = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n                            else:\n                                pred = str(out_ids)\n                    except AttributeError:\n                        if not _PROTOBUF_COMPAT_ERROR_SHOWN:\n                            print(\"[VALIDATION] Warning: decode raised AttributeError (protobuf). Pin protobuf and restart.\")\n                            _PROTOBUF_COMPAT_ERROR_SHOWN = True\n                        pred = \"\"\n                    except Exception as e:\n                        print(f\"[VALIDATION] Decode error: {type(e).__name__}: {str(e)[:200]}\")\n                        pred = \"\"\n                else:\n                    pred = \"\"\n                print(f\"{i}. {src} -> {pred}\")\n            except Exception as e:\n                print(f\"{i}. Validation error: {type(e).__name__}: {str(e)[:200]}\")\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n    finally:\n        try:\n            if indicbart_obj is not None and orig_use_cache is not None and hasattr(indicbart_obj, \"config\"):\n                indicbart_obj.config.use_cache = orig_use_cache\n        except Exception:\n            pass\n        if torch.cuda.is_available():\n            try:\n                torch.cuda.synchronize()\n            except Exception:\n                pass\n        clear_all_gpu_caches()\n        if was_training:\n            core_model.train()\n    print(\"=\" * 70)\n\n\ndef _print_gpu_mem(prefix: str = \"\"):\n    if not torch.cuda.is_available():\n        return\n    try:\n        lines = [f\"{prefix} GPU mem (GB):\"]\n        for i in range(torch.cuda.device_count()):\n            try:\n                alloc = torch.cuda.memory_allocated(i) / (1024**3)\n                resv = torch.cuda.memory_reserved(i) / (1024**3)\n                lines.append(f\"  GPU {i}: alloc={alloc:.2f} resv={resv:.2f}\")\n            except Exception:\n                lines.append(f\"  GPU {i}: mem query failed\")\n        print(\"\\n\".join(lines))\n    except Exception:\n        pass\n\n\ndef _get_cluster_count(model: torch.nn.Module) -> int:\n    \"\"\"Get cluster count from word-level DSCD (Cell 3/6 architecture).\"\"\"\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        dscd = getattr(core, \"dscd\", None)\n        if dscd is None:\n            return 0\n        \n        if hasattr(dscd, \"prototype_stores\"):\n            return len(dscd.prototype_stores)\n        elif hasattr(dscd, \"word_stores\"):\n            return len(dscd.word_stores)\n        elif hasattr(dscd, \"stores\"):\n            return len(dscd.stores)\n        else:\n            return 0\n    except Exception:\n        return 0\n\n\ndef _get_dscd_safe(model: torch.nn.Module):\n    \"\"\"Safely get DSCD from dual-path model.\"\"\"\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        return getattr(core, \"dscd\", None)\n    except Exception:\n        return None\n\n\ndef _print_top_clusters(model: torch.nn.Module, top_n: int = 5):\n    \"\"\"Print top clusters from word-level DSCD (Cell 3).\"\"\"\n    dscd = _get_dscd_safe(model)\n    if dscd is None:\n        if _VERBOSE_LOGGING:\n            print(\"[CLUSTER-DBG] No DSCD instance attached to model.\")\n        return\n    try:\n        items = []\n        \n        stores_dict = None\n        if hasattr(dscd, \"prototype_stores\"):\n            stores_dict = dscd.prototype_stores\n        elif hasattr(dscd, \"word_stores\"):\n            stores_dict = dscd.word_stores\n        elif hasattr(dscd, \"stores\"):\n            stores_dict = dscd.stores\n        \n        if stores_dict is None:\n            if _VERBOSE_LOGGING:\n                print(\"[CLUSTER-DBG] No prototype stores found in DSCD\")\n            return\n        \n        buffers_dict = getattr(dscd, \"buffers\", {}) or {}\n        \n        for token, store in stores_dict.items():\n            try:\n                total_count = sum(getattr(store, \"counts\", []) or [])\n                protos = store.size if hasattr(store, \"size\") else (len(getattr(store, \"centroids\", [])) if hasattr(store, \"centroids\") else 0)\n                if callable(protos):\n                    protos = protos()\n                buflen = len(buffers_dict.get(token, []))\n                items.append((token, total_count, protos, buflen))\n            except Exception:\n                continue\n        \n        items.sort(key=lambda x: x[1], reverse=True)\n        if _VERBOSE_LOGGING and items:\n            print(\"[CLUSTER-DBG] Top clusters:\")\n            for i, (tok, cnt, prot, buflen) in enumerate(items[:top_n], 1):\n                print(f\"  {i:2d}. {str(tok)[:20]:20s} samples={cnt:4d} protos={prot} buf={buflen}\")\n    except Exception as e:\n        if _VERBOSE_LOGGING:\n            print(f\"[CLUSTER-DBG] _print_top_clusters error: {type(e).__name__}: {str(e)[:200]}\")\n\n\ndef _print_cluster_stats(model: torch.nn.Module):\n    \"\"\"Print overall cluster statistics.\"\"\"\n    dscd = _get_dscd_safe(model)\n    if dscd is None:\n        return\n    try:\n        stores_dict = None\n        if hasattr(dscd, \"prototype_stores\"):\n            stores_dict = dscd.prototype_stores\n        elif hasattr(dscd, \"word_stores\"):\n            stores_dict = dscd.word_stores\n        elif hasattr(dscd, \"stores\"):\n            stores_dict = dscd.stores\n        \n        if stores_dict is None:\n            return\n        \n        total_tokens = len(stores_dict)\n        total_protos = 0\n        total_samples = 0\n        total_buffers = 0\n        \n        buffers_dict = getattr(dscd, \"buffers\", {}) or {}\n        \n        for token, store in stores_dict.items():\n            try:\n                size_val = store.size if hasattr(store, \"size\") else (len(getattr(store, \"centroids\", [])) if hasattr(store, \"centroids\") else 0)\n                if callable(size_val):\n                    size_val = size_val()\n                total_protos += size_val\n                total_samples += sum(getattr(store, \"counts\", []) or [])\n                total_buffers += len(buffers_dict.get(token, []))\n            except Exception:\n                continue\n        \n        if _VERBOSE_LOGGING:\n            print(f\"[CLUSTER-DBG] tokens_with_stores={total_tokens} total_prototypes={total_protos} total_samples={total_samples} total_buffered_embeddings={total_buffers}\")\n    except Exception as e:\n        if _VERBOSE_LOGGING:\n            print(f\"[CLUSTER-DBG] _print_cluster_stats error: {type(e).__name__}: {str(e)[:200]}\")\n\n\n# ==============================================================================\n# üî• FIX #19 & #20: COMPLETE batch unpacking with word-level data extraction\n# ==============================================================================\ndef _unpack_batch(batch: Any) -> Dict[str, Any]:\n    \"\"\"\n    Accept common batch formats and extract ALL fields including word-level data.\n    \n    FIX #20: Handles BOTH dict and tuple formats from safe_collate.\n    \n    Returns dict with keys:\n      Path 2 (subword): input_ids, attention_mask, labels\n      Path 1 (word): word_input_ids, word_attention_mask, word_strings\n      Common: src_text\n    \"\"\"\n    if batch is None:\n        return {}\n    \n    # ==================================================================\n    # üî• FIX #20: If batch is already a dict, validate and return\n    # ==================================================================\n    if isinstance(batch, dict):\n        # Batch is already a dictionary - Cell 2's safe_collate returns dict format\n        # Just validate it has the expected keys and return\n        out = dict(batch)\n        \n        # Debug: log what keys are present (first few batches only)\n        if _VERBOSE_LOGGING and _cell7_dbg_counts.get(\"batch_dict_keys\", 0) < 3:\n            _cell7_dbg_counts[\"batch_dict_keys\"] += 1\n            print(f\"[BATCH-DBG] Batch is dict with keys: {list(out.keys())}\")\n            if 'word_input_ids' in out:\n                wid = out['word_input_ids']\n                print(f\"[BATCH-DBG]   word_input_ids: {wid.shape if isinstance(wid, torch.Tensor) else type(wid)}\")\n            if 'word_attention_mask' in out:\n                wam = out['word_attention_mask']\n                print(f\"[BATCH-DBG]   word_attention_mask: {wam.shape if isinstance(wam, torch.Tensor) else type(wam)}\")\n            if 'word_strings' in out:\n                ws = out['word_strings']\n                print(f\"[BATCH-DBG]   word_strings: {type(ws)} len={len(ws) if ws else 0}\")\n        \n        return out\n    \n    # ==================================================================\n    # Legacy tuple/list format support (in case safe_collate returns tuple)\n    # ==================================================================\n    if isinstance(batch, (list, tuple)):\n        out = {}\n        try:\n            # Path 2 (subword) - positions 0, 1, 2\n            if len(batch) >= 2:\n                out['input_ids'] = batch[0]\n                out['attention_mask'] = batch[1]\n            if len(batch) >= 3:\n                out['labels'] = batch[2]\n            \n            # Path 1 (word) - positions 3, 4, 5\n            if len(batch) >= 4:\n                out['word_input_ids'] = batch[3]  # ‚Üê FIX #19: Extract word IDs\n            if len(batch) >= 5:\n                out['word_attention_mask'] = batch[4]  # ‚Üê FIX #19: Extract word mask\n            if len(batch) >= 6:\n                out['word_strings'] = batch[5]  # ‚Üê FIX #19: Extract word strings\n            \n            # Source text - position 6\n            if len(batch) >= 7:\n                out['src_text'] = batch[6]\n        except Exception as e:\n            if _VERBOSE_LOGGING:\n                print(f\"[BATCH-DBG] Tuple unpacking error: {e}\")\n        return out\n    \n    return {}\n\n\ndef scaler_enabled(scaler: Optional[GradScaler]) -> bool:\n    \"\"\"Check if GradScaler is enabled (cross-version compatible).\"\"\"\n    if scaler is None:\n        return False\n    try:\n        return bool(getattr(scaler, \"is_enabled\", lambda: False)())\n    except Exception:\n        return getattr(scaler, \"enabled\", False) if hasattr(scaler, \"enabled\") else True\n\n\n# ==============================================================================\n# üî¨ MAIN TRAINING LOOP (IndicBART-OPTIMIZED WITH ALL 25 FIXES)\n# ==============================================================================\ndef train_memory_efficient_tatn(\n    model: torch.nn.Module,\n    tokenizer,\n    train_loader: torch.utils.data.DataLoader,\n    optimizer: Optional[torch.optim.Optimizer],\n    phi_optimizer: Optional[torch.optim.Optimizer] = None,\n    scheduler: Optional[Any] = None,  # ‚Üê FIX #3: Added scheduler parameter\n    epochs: Optional[int] = None,\n    accumulation_steps: Optional[int] = None,\n    validate_every: Optional[int] = None,\n    enable_validation: bool = True,\n    val_samples: Optional[List[Tuple[str, str]]] = None  # ‚Üê FIX #5: Added validation samples\n) -> torch.nn.Module:\n    if epochs is None:\n        epochs = _EPOCHS\n    if accumulation_steps is None:\n        accumulation_steps = max(1, _ACCUMULATION_STEPS)\n    if validate_every is None:\n        validate_every = VALIDATION_CHECK_INTERVAL\n\n    print(f\"[TRAIN] Starting training: epochs={epochs}, batch={_BATCH_SIZE}, accum_steps={accumulation_steps}\")\n    print(f\"[TRAIN] Validation: {'enabled' if enable_validation and validate_every > 0 else 'disabled'}\")\n    print(f\"[TRAIN] Early stopping patience: {EARLY_STOPPING_PATIENCE}\")\n    print(f\"[TRAIN] Learning rate scheduler: {'enabled' if USE_LR_SCHEDULER and scheduler is not None else 'disabled'}\")\n    print(f\"[TRAIN] Warmup steps: {WARMUP_STEPS}\")\n    print(f\"[TRAIN] DP enabled: {_USE_MULTI_GPU}, GPUs: {_NUM_GPUS}, Device: {_DEVICE}\")\n\n    # ==================================================================\n    # üî¨ FIX #8: Apply layer freezing before training starts\n    # ==================================================================\n    if FREEZE_ENCODER_LAYERS > 0 or FREEZE_DECODER_LAYERS > 0:\n        print(f\"[TRAIN] Applying layer freezing: {FREEZE_ENCODER_LAYERS} encoder + {FREEZE_DECODER_LAYERS} decoder layers\")\n        freeze_model_layers(model, FREEZE_ENCODER_LAYERS, FREEZE_DECODER_LAYERS)\n    else:\n        print(\"[TRAIN] Layer freezing disabled (FREEZE_*_LAYERS = 0)\")\n\n    # ==================================================================\n    # Enable DSCD training clustering before training starts\n    # ==================================================================\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        if hasattr(core, \"dscd\") and core.dscd is not None:\n            # Enable training clustering\n            core.dscd.enable_training_clustering = True\n            # Force synchronous mode for reliability\n            if hasattr(core.dscd, \"force_sync_clustering\"):\n                core.dscd.force_sync_clustering = True\n            print(\"[TRAIN] ‚úì DSCD training clustering ENABLED (synchronous mode)\")\n            if _VERBOSE_LOGGING:\n                print(f\"[TRAIN] DSCD config: enable_training_clustering={core.dscd.enable_training_clustering}\")\n        else:\n            print(\"[TRAIN] ‚ö†Ô∏è DSCD not available - clustering disabled\")\n    except Exception as e:\n        print(f\"[TRAIN] Warning: Could not enable DSCD clustering: {e}\")\n\n    model.train()\n    clear_all_gpu_caches()\n\n    scaler = GradScaler(enabled=(_USE_AMP and torch.cuda.is_available()))\n\n    global_step = 0\n    accumulated_steps = 0\n    pending_validation = False\n    \n    # ==================================================================\n    # üî¨ FIX #4, #6, #7, #16, #17: Early stopping and tracking variables\n    # ==================================================================\n    early_stopping_counter = 0  # ‚Üê FIX #16\n    best_val_loss = float('inf')  # ‚Üê FIX #17\n    warmup_step_counter = 0  # ‚Üê FIX #7\n    no_improvement_epochs = 0  # ‚Üê FIX #4\n\n    training_stats: Dict[str, Any] = {\n        \"total_loss\": [],\n        \"batches_processed\": 0,\n        \"optimizer_updates\": 0,\n        \"skipped_batches\": 0,\n        \"oom_errors\": 0,\n        \"runtime_errors\": 0,\n        \"exceptions\": 0,\n        \"epoch_val_losses\": [],  # ‚Üê FIX #5: Track validation losses\n        \"epoch_bleu_scores\": [],  # ‚Üê FIX #5: Track BLEU scores\n        \"learning_rates\": [],  # ‚Üê FIX #18: Track learning rates\n    }\n\n    skip_reasons = defaultdict(int)\n    last_forward_loss = 0.0\n    last_backward_loss = 0.0\n\n    for epoch in range(1, epochs + 1):\n        epoch_start = time.time()\n        epoch_losses: List[float] = []\n        try:\n            if optimizer is not None:\n                try:\n                    optimizer.zero_grad(set_to_none=True)\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        progress = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", ncols=180, dynamic_ncols=False)\n\n        for batch_idx, batch in enumerate(progress):\n            global_step += 1\n            training_stats[\"batches_processed\"] += 1\n\n            if _VERBOSE_LOGGING and global_step % DEBUG_PRINT_INTERVAL == 0:\n                print(f\"[TRAIN-DEBUG] Epoch {epoch} Batch {batch_idx} GlobalStep {global_step}\")\n\n            if enable_validation and validate_every and validate_every > 0 and (global_step % validate_every == 0):\n                if accumulated_steps == 0:\n                    try:\n                        quick_validation_check(model, tokenizer, global_step, _BN_LANG, _EN_LANG, _MAX_LENGTH, _DEVICE)\n                    except Exception:\n                        if _VERBOSE_LOGGING:\n                            print(\"[TRAIN] quick_validation_check failed:\", traceback.format_exc().splitlines()[-1])\n                else:\n                    pending_validation = True\n\n            if batch is None:\n                training_stats[\"skipped_batches\"] += 1\n                skip_reasons[\"batch_none\"] += 1\n                cell7_dbg(\"batch_none\", f\"Batch is None at idx={batch_idx}\")\n                continue\n\n            try:\n                # ==================================================================\n                # üî• FIX #19 & #20: Extract ALL batch fields including word-level data\n                # ==================================================================\n                bdict = _unpack_batch(batch)\n                \n                # Path 2 (subword) - IndicBART inputs\n                input_ids = bdict.get(\"input_ids\", None)\n                attention_mask = bdict.get(\"attention_mask\", None)\n                labels = bdict.get(\"labels\", None)\n\n                if input_ids is None or attention_mask is None:\n                    training_stats[\"skipped_batches\"] += 1\n                    skip_reasons[\"missing_tensors\"] += 1\n                    cell7_dbg(\"missing_tensors\", f\"Missing tensors in batch idx={batch_idx}\")\n                    continue\n\n                # Move Path 2 data to device\n                try:\n                    if isinstance(input_ids, torch.Tensor):\n                        input_ids = input_ids.to(_DEVICE, non_blocking=True)\n                        if input_ids.dtype not in (torch.long, torch.int64):\n                            input_ids = input_ids.long()\n                    if isinstance(attention_mask, torch.Tensor):\n                        attention_mask = attention_mask.to(_DEVICE, non_blocking=True)\n                    if labels is not None and isinstance(labels, torch.Tensor):\n                        labels = labels.to(_DEVICE, non_blocking=True)\n                except Exception:\n                    try:\n                        input_ids = input_ids.to(_DEVICE)\n                    except Exception:\n                        pass\n                    try:\n                        attention_mask = attention_mask.to(_DEVICE)\n                    except Exception:\n                        pass\n                    try:\n                        if labels is not None and isinstance(labels, torch.Tensor):\n                            labels = labels.to(_DEVICE)\n                    except Exception:\n                        pass\n\n                # ==================================================================\n                # üî• FIX #19 & #20: Extract Path 1 (word-level) data from batch\n                # ==================================================================\n                word_input_ids = bdict.get(\"word_input_ids\", None)\n                word_attention_mask = bdict.get(\"word_attention_mask\", None)\n                word_strings = bdict.get(\"word_strings\", None)\n                src_text = bdict.get(\"src_text\", None)\n                \n                # Move Path 1 data to device\n                if word_input_ids is not None and isinstance(word_input_ids, torch.Tensor):\n                    try:\n                        word_input_ids = word_input_ids.to(_DEVICE, non_blocking=True)\n                        if word_input_ids.dtype not in (torch.long, torch.int64):\n                            word_input_ids = word_input_ids.long()\n                    except Exception:\n                        word_input_ids = word_input_ids.to(_DEVICE)\n                \n                if word_attention_mask is not None and isinstance(word_attention_mask, torch.Tensor):\n                    try:\n                        word_attention_mask = word_attention_mask.to(_DEVICE, non_blocking=True)\n                    except Exception:\n                        word_attention_mask = word_attention_mask.to(_DEVICE)\n                \n                # ==================================================================\n                # üî• FIX #20: Debug logging to verify word data extraction\n                # ==================================================================\n                if global_step <= 5:\n                    print(f\"\\n[TRAIN-DEBUG] Step {global_step} batch data check:\")\n                    print(f\"  input_ids: {input_ids.shape if isinstance(input_ids, torch.Tensor) else type(input_ids)}\")\n                    print(f\"  attention_mask: {attention_mask.shape if isinstance(attention_mask, torch.Tensor) else type(attention_mask)}\")\n                    print(f\"  labels: {labels.shape if isinstance(labels, torch.Tensor) else type(labels)}\")\n                    print(f\"  word_input_ids: {word_input_ids.shape if isinstance(word_input_ids, torch.Tensor) else 'None'}\")\n                    print(f\"  word_attention_mask: {word_attention_mask.shape if isinstance(word_attention_mask, torch.Tensor) else 'None'}\")\n                    print(f\"  word_strings: {type(word_strings)} len={len(word_strings) if word_strings else 0}\")\n                    print(f\"  src_text: {type(src_text)} len={len(src_text) if src_text else 0}\")\n                    \n                    # Additional validation\n                    if word_input_ids is None:\n                        print(f\"  ‚ùå word_input_ids is None - DSCD will not receive data!\")\n                    else:\n                        print(f\"  ‚úÖ word_input_ids present: {word_input_ids.shape}\")\n\n                if _USE_MULTI_GPU and _NUM_GPUS > 0:\n                    try:\n                        bsz = int(input_ids.size(0))\n                        keep = (bsz // _NUM_GPUS) * _NUM_GPUS\n                        if keep == 0:\n                            training_stats[\"skipped_batches\"] += 1\n                            skip_reasons[\"dp_keep_zero\"] += 1\n                            cell7_dbg(\"dp_keep_zero\", f\"DP keep==0 bsz={bsz}, gpus={_NUM_GPUS}\")\n                            continue\n                        if keep != bsz:\n                            input_ids = input_ids[:keep]\n                            attention_mask = attention_mask[:keep]\n                            if labels is not None:\n                                labels = labels[:keep]\n                            # Also trim word-level data\n                            if word_input_ids is not None:\n                                word_input_ids = word_input_ids[:keep]\n                            if word_attention_mask is not None:\n                                word_attention_mask = word_attention_mask[:keep]\n                            if word_strings is not None:\n                                word_strings = word_strings[:keep]\n                            if src_text is not None:\n                                src_text = src_text[:keep]\n                    except Exception:\n                        training_stats[\"skipped_batches\"] += 1\n                        skip_reasons[\"dp_size_error\"] += 1\n                        continue\n\n                if isinstance(input_ids, torch.Tensor) and input_ids.size(0) == 0:\n                    training_stats[\"skipped_batches\"] += 1\n                    skip_reasons[\"empty_batch\"] += 1\n                    continue\n\n                # ==================================================================\n                # üî• FIX #19 & #20: Pass ALL data to model (Path 1 + Path 2)\n                # ==================================================================\n                forward_kwargs = {\n                    # Path 2 (subword)\n                    \"input_ids\": input_ids,\n                    \"attention_mask\": attention_mask,\n                    \"labels\": labels,\n                    \n                    # Path 1 (word-level)\n                    \"word_input_ids\": word_input_ids,\n                    \"word_attention_mask\": word_attention_mask,\n                    \"word_strings\": word_strings,\n                    \n                    # Source text (for DSCD)\n                    \"src_text\": src_text,\n                }\n\n                amp_ctx = get_amp_ctx()\n                with amp_ctx:\n                    forward_out = model(**forward_kwargs)\n\n                    loss_tensor = None\n                    try:\n                        if hasattr(forward_out, \"loss\"):\n                            loss_tensor = getattr(forward_out, \"loss\")\n                    except Exception:\n                        pass\n\n                    if loss_tensor is None:\n                        if isinstance(forward_out, torch.Tensor):\n                            loss_tensor = forward_out\n                        elif isinstance(forward_out, dict):\n                            possible_loss_keys = [\"loss\", \"total_loss\", \"translation_loss\"]\n                            for k in possible_loss_keys:\n                                if k in forward_out:\n                                    loss_tensor = forward_out[k]\n                                    break\n                            if loss_tensor is None:\n                                for v in forward_out.values():\n                                    if isinstance(v, torch.Tensor) and v.numel() == 1:\n                                        loss_tensor = v\n                                        break\n                        elif isinstance(forward_out, (list, tuple)) and len(forward_out) > 0:\n                            if isinstance(forward_out[0], torch.Tensor):\n                                loss_tensor = forward_out[0]\n\n                    if loss_tensor is None:\n                        try:\n                            if isinstance(forward_out, (int, float, np.floating, np.integer)):\n                                loss_tensor = torch.tensor(float(forward_out), device=_DEVICE)\n                        except Exception:\n                            pass\n\n                    if loss_tensor is None:\n                        raise RuntimeError(\"Model forward did not return a recognizable loss tensor\")\n\n                    if not isinstance(loss_tensor, torch.Tensor):\n                        loss_tensor = torch.tensor(float(loss_tensor), device=_DEVICE)\n                    else:\n                        try:\n                            loss_tensor = loss_tensor.to(_DEVICE)\n                        except Exception:\n                            pass\n\n                    if loss_tensor.numel() > 1:\n                        loss_val = float(loss_tensor.mean().item())\n                        loss_tensor = loss_tensor.mean()\n                    else:\n                        loss_val = float(loss_tensor.item())\n\n                    last_forward_loss = loss_val\n                    epoch_losses.append(loss_val)\n                    training_stats[\"total_loss\"].append(loss_val)\n\n                loss_scaled = loss_tensor / max(1, accumulation_steps)\n                try:\n                    last_backward_loss = float(loss_scaled.item())\n                except Exception:\n                    try:\n                        last_backward_loss = float(loss_scaled.detach().cpu().item()) if isinstance(loss_scaled, torch.Tensor) else float(loss_scaled)\n                    except Exception:\n                        last_backward_loss = 0.0\n\n                try:\n                    if scaler_enabled(scaler):\n                        scaler.scale(loss_scaled).backward()\n                    else:\n                        loss_scaled.backward()\n                except RuntimeError as e:\n                    if \"out of memory\" in str(e).lower():\n                        training_stats[\"oom_errors\"] += 1\n                        training_stats[\"skipped_batches\"] += 1\n                        skip_reasons[\"oom_backward\"] += 1\n                        print(f\"[OOM] OOM during backward at step {global_step}: {str(e)[:200]}\")\n                        try:\n                            if optimizer is not None:\n                                optimizer.zero_grad(set_to_none=True)\n                        except Exception:\n                            pass\n                        for p in model.parameters():\n                            if p is not None:\n                                p.grad = None\n                        clear_all_gpu_caches()\n                        accumulated_steps = 0\n                        continue\n                    else:\n                        raise\n\n                accumulated_steps += 1\n\n                if accumulated_steps >= accumulation_steps:\n                    try:\n                        if optimizer is None:\n                            training_stats[\"skipped_batches\"] += 1\n                            skip_reasons[\"no_optimizer\"] += 1\n                            try:\n                                model.zero_grad(set_to_none=True)\n                            except Exception:\n                                for p in model.parameters():\n                                    if p.grad is not None:\n                                        p.grad = None\n                        else:\n                            if scaler_enabled(scaler):\n                                try:\n                                    scaler.unscale_(optimizer)\n                                except Exception:\n                                    pass\n                            try:\n                                torch.nn.utils.clip_grad_norm_(model.parameters(), _GRAD_CLIP_NORM)\n                            except Exception:\n                                pass\n                            if scaler_enabled(scaler):\n                                try:\n                                    scaler.step(optimizer)\n                                    scaler.update()\n                                except Exception as e:\n                                    try:\n                                        optimizer.step()\n                                    except Exception:\n                                        raise\n                            else:\n                                optimizer.step()\n                            \n                            # ==================================================================\n                            # üî¨ FIX #3, #7, #18: Scheduler step + warmup tracking + LR logging\n                            # ==================================================================\n                            if USE_LR_SCHEDULER and scheduler is not None:\n                                try:\n                                    scheduler.step()\n                                    warmup_step_counter += 1\n                                    \n                                    # Log learning rate\n                                    current_lr = optimizer.param_groups[0]['lr']\n                                    training_stats[\"learning_rates\"].append(current_lr)\n                                    \n                                    # Check minimum learning rate\n                                    if current_lr < MIN_LEARNING_RATE:\n                                        print(f\"[SCHEDULER] Warning: LR {current_lr:.2e} < MIN_LR {MIN_LEARNING_RATE:.2e}\")\n                                    \n                                    # Log warmup progress\n                                    if warmup_step_counter <= WARMUP_STEPS and warmup_step_counter % 500 == 0:\n                                        print(f\"[SCHEDULER] Warmup: {warmup_step_counter}/{WARMUP_STEPS} steps, LR={current_lr:.2e}\")\n                                    elif warmup_step_counter == WARMUP_STEPS + 1:\n                                        print(f\"[SCHEDULER] ‚úì Warmup completed! Now at LR={current_lr:.2e}\")\n                                        \n                                except Exception as e:\n                                    print(f\"[SCHEDULER] Step failed: {type(e).__name__}: {str(e)[:200]}\")\n                            \n                            try:\n                                optimizer.zero_grad(set_to_none=True)\n                            except Exception:\n                                for p in model.parameters():\n                                    if p.grad is not None:\n                                        p.grad.detach_()\n                                        p.grad.zero_()\n                            training_stats[\"optimizer_updates\"] += 1\n                    except RuntimeError as e:\n                        if \"out of memory\" in str(e).lower():\n                            training_stats[\"oom_errors\"] += 1\n                            training_stats[\"skipped_batches\"] += 1\n                            skip_reasons[\"oom\"] += 1\n                            print(f\"[OOM] OOM at step {global_step}: {str(e)[:200]}\")\n                            try:\n                                if optimizer is not None:\n                                    optimizer.zero_grad(set_to_none=True)\n                            except Exception:\n                                pass\n                            for p in model.parameters():\n                                p.grad = None\n                            clear_all_gpu_caches()\n                            accumulated_steps = 0\n                            continue\n                        else:\n                            training_stats[\"runtime_errors\"] += 1\n                            skip_reasons[\"opt_runtime\"] += 1\n                            print(f\"[ERROR] Runtime error during optimizer step: {type(e).__name__}: {str(e)[:200]}\")\n                    except Exception as e:\n                        training_stats[\"exceptions\"] += 1\n                        skip_reasons[\"opt_exception\"] += 1\n                        print(f\"[ERROR] Exception during optimizer step: {type(e).__name__}: {str(e)[:200]}\")\n                    finally:\n                        accumulated_steps = 0\n                        if pending_validation:\n                            try:\n                                quick_validation_check(model, tokenizer, global_step, _BN_LANG, _EN_LANG, _MAX_LENGTH, _DEVICE)\n                            except Exception:\n                                if _VERBOSE_LOGGING:\n                                    print(\"[TRAIN] deferred quick_validation_check failed:\", traceback.format_exc().splitlines()[-1])\n                            pending_validation = False\n\n                if global_step % DEBUG_PRINT_INTERVAL == 0:\n                    _print_gpu_mem(\"[TRAIN-DEBUG]\")\n                    try:\n                        cluster_count = _get_cluster_count(model)\n                    except Exception:\n                        cluster_count = 0\n                    \n                    # ‚Üê FIX #18: Log current learning rate\n                    current_lr = optimizer.param_groups[0]['lr'] if optimizer is not None else 0.0\n                    print(f\"[TRAIN-DEBUG] step={global_step} loss={last_forward_loss:.4f} lr={current_lr:.2e} opt_updates={training_stats['optimizer_updates']} clusters={cluster_count}\")\n                    _print_top_clusters(model, top_n=5)\n                    _print_cluster_stats(model)\n\n                # ==================================================================\n                # üî¨ FIX #11: Aggressive memory cleanup (every 50 steps)\n                # ==================================================================\n                if AGGRESSIVE_MEMORY_CLEANUP and global_step % _MEMORY_CLEANUP_FREQUENCY == 0:\n                    clear_all_gpu_caches()\n\n            except RuntimeError as e:\n                if \"out of memory\" in str(e).lower():\n                    training_stats[\"oom_errors\"] += 1\n                    training_stats[\"skipped_batches\"] += 1\n                    skip_reasons[\"oom\"] += 1\n                    print(f\"[OOM] Caught OOM at step {global_step}: {str(e)[:200]}\")\n                    try:\n                        if optimizer is not None:\n                            optimizer.zero_grad(set_to_none=True)\n                    except Exception:\n                        pass\n                    for p in model.parameters():\n                        p.grad = None\n                    clear_all_gpu_caches()\n                    accumulated_steps = 0\n                    continue\n                else:\n                    training_stats[\"runtime_errors\"] += 1\n                    training_stats[\"skipped_batches\"] += 1\n                    skip_reasons[\"runtime\"] += 1\n                    print(f\"[RUNTIME] RuntimeError at step {global_step}: {type(e).__name__}: {str(e)[:200]}\")\n                    if _VERBOSE_LOGGING:\n                        traceback.print_exc()\n                    try:\n                        if optimizer is not None:\n                            optimizer.zero_grad(set_to_none=True)\n                    except Exception:\n                        pass\n                    accumulated_steps = 0\n                    continue\n            except Exception as e:\n                training_stats[\"exceptions\"] += 1\n                training_stats[\"skipped_batches\"] += 1\n                skip_reasons[\"exceptions\"] += 1\n                print(f\"[EXCEPTION] Exception at step {global_step}: {type(e).__name__}: {str(e)[:200]}\")\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n                try:\n                    if optimizer is not None:\n                        optimizer.zero_grad(set_to_none=True)\n                except Exception:\n                    pass\n                accumulated_steps = 0\n                continue\n\n            processed_batches = training_stats[\"batches_processed\"] - training_stats[\"skipped_batches\"]\n            expected_updates = max(1, math.floor(processed_batches / max(1, accumulation_steps)))\n            success_rate = 100.0 * training_stats[\"optimizer_updates\"] / expected_updates if expected_updates > 0 else 0.0\n            cluster_count = _get_cluster_count(model)\n            try:\n                progress.set_postfix_str(\n                    f\"fwd_loss={last_forward_loss:.4f} bwd_loss={last_backward_loss:.6f} rate={success_rate:.1f}% proc={processed_batches} skip={training_stats['skipped_batches']} clusters={cluster_count}\"\n                )\n            except Exception:\n                pass\n\n        # End of epoch - flush accumulated gradients\n        if accumulated_steps > 0:\n            try:\n                if optimizer is None:\n                    try:\n                        model.zero_grad(set_to_none=True)\n                    except Exception:\n                        for p in model.parameters():\n                            if p.grad is not None:\n                                p.grad = None\n                    print(\"[EPOCH-FLUSH] Skipped flush because optimizer is None.\")\n                else:\n                    if scaler_enabled(scaler):\n                        try:\n                            scaler.unscale_(optimizer)\n                        except Exception:\n                            pass\n                        try:\n                            torch.nn.utils.clip_grad_norm_(model.parameters(), _GRAD_CLIP_NORM)\n                        except Exception:\n                            pass\n                        try:\n                            scaler.step(optimizer)\n                            scaler.update()\n                        except Exception:\n                            try:\n                                optimizer.step()\n                            except Exception:\n                                raise\n                    else:\n                        try:\n                            torch.nn.utils.clip_grad_norm_(model.parameters(), _GRAD_CLIP_NORM)\n                        except Exception:\n                            pass\n                        optimizer.step()\n                    \n                    # ‚Üê FIX #3: Scheduler step for epoch flush\n                    if USE_LR_SCHEDULER and scheduler is not None:\n                        try:\n                            scheduler.step()\n                            warmup_step_counter += 1\n                        except Exception:\n                            pass\n                    \n                    try:\n                        optimizer.zero_grad(set_to_none=True)\n                    except Exception:\n                        for p in model.parameters():\n                            if p.grad is not None:\n                                p.grad.detach_()\n                                p.grad.zero_()\n                    training_stats[\"optimizer_updates\"] += 1\n            except Exception as e:\n                print(f\"[EPOCH-FLUSH] Exception on epoch flush: {type(e).__name__}: {str(e)[:200]}\")\n            finally:\n                accumulated_steps = 0\n\n        # ==================================================================\n        # üî¨ FIX #5: Calculate validation metrics at end of epoch\n        # ==================================================================\n        epoch_avg_loss = float(np.mean(epoch_losses)) if epoch_losses else 0.0\n        training_stats[\"epoch_val_losses\"].append(epoch_avg_loss)\n        \n        # Calculate BLEU score if validation samples provided\n        epoch_bleu = 0.0\n        if val_samples is not None and len(val_samples) > 0:\n            try:\n                print(f\"\\n[VALIDATION] Calculating BLEU score on {len(val_samples)} samples...\")\n                epoch_bleu = calculate_bleu_score(model, tokenizer, val_samples, _MAX_LENGTH, _DEVICE)\n                training_stats[\"epoch_bleu_scores\"].append(epoch_bleu)\n                print(f\"[VALIDATION] Epoch {epoch} BLEU: {epoch_bleu:.2f}\")\n            except Exception as e:\n                print(f\"[VALIDATION] BLEU calculation failed: {type(e).__name__}: {str(e)[:200]}\")\n                epoch_bleu = 0.0\n\n        epoch_duration_min = (time.time() - epoch_start) / 60.0\n        processed_batches = training_stats[\"batches_processed\"] - training_stats[\"skipped_batches\"]\n        expected_updates = max(1, math.floor(processed_batches / max(1, accumulation_steps)))\n        success_rate = 100.0 * training_stats[\"optimizer_updates\"] / expected_updates if expected_updates > 0 else 0.0\n        cluster_count = _get_cluster_count(model)\n        \n        # ‚Üê FIX #18: Get current learning rate\n        current_lr = optimizer.param_groups[0]['lr'] if optimizer is not None else 0.0\n\n        print(\"\\n\" + \"=\" * 80)\n        print(f\"Epoch {epoch} summary:\")\n        print(f\"  duration (min): {epoch_duration_min:.2f}\")\n        print(f\"  optimizer updates: {training_stats['optimizer_updates']}\")\n        print(f\"  batches processed: {training_stats['batches_processed']} (processed={processed_batches}, skipped={training_stats['skipped_batches']})\")\n        print(f\"  success rate (updates/expected): {success_rate:.1f}%\")\n        print(f\"  clustered token types: {cluster_count}\")\n        print(f\"  avg forward loss: {epoch_avg_loss:.6f}\")\n        print(f\"  current learning rate: {current_lr:.2e}\")  # ‚Üê FIX #18\n        if epoch_bleu > 0:\n            print(f\"  BLEU score: {epoch_bleu:.2f}\")  # ‚Üê FIX #5\n        if skip_reasons:\n            print(\"  skip reasons:\")\n            for k, v in sorted(skip_reasons.items(), key=lambda x: -x[1]):\n                print(f\"    - {k}: {v}\")\n        print(\"=\" * 80)\n\n        # ==================================================================\n        # üî¨ FIX #4, #6: Early stopping and best model saving\n        # ==================================================================\n        # Check if this is the best model so far\n        is_best_model = False\n        if epoch_avg_loss < best_val_loss:\n            best_val_loss = epoch_avg_loss\n            no_improvement_epochs = 0\n            is_best_model = True\n            print(f\"[EARLY-STOP] ‚úì New best validation loss: {best_val_loss:.6f}\")\n        else:\n            no_improvement_epochs += 1\n            print(f\"[EARLY-STOP] No improvement for {no_improvement_epochs}/{EARLY_STOPPING_PATIENCE} epochs\")\n        \n        # Save best model\n        if SAVE_BEST_MODEL and is_best_model:\n            try:\n                save_checkpoint(model, optimizer, scheduler, training_stats, epoch, global_step, \n                               epoch_losses, CHECKPOINT_DIR, is_best=True)\n            except Exception as e:\n                print(f\"[CHECKPOINT] Best model save failed: {type(e).__name__}: {str(e)[:200]}\")\n\n        # ==================================================================\n        # üî¨ FIX #10: Regular checkpoint saving (every SAVE_CHECKPOINT_EVERY epochs)\n        # ==================================================================\n        if epoch % SAVE_CHECKPOINT_EVERY == 0:\n            try:\n                save_checkpoint(model, optimizer, scheduler, training_stats, epoch, global_step, \n                               epoch_losses, CHECKPOINT_DIR, is_best=False)\n            except Exception as e:\n                print(f\"[CHECKPOINT] Save at epoch {epoch} failed: {type(e).__name__}: {str(e)[:200]}\")\n        \n        # ==================================================================\n        # üî¨ FIX #4: Early stopping check\n        # ==================================================================\n        if no_improvement_epochs >= EARLY_STOPPING_PATIENCE:\n            print(\"\\n\" + \"=\" * 80)\n            print(f\"[EARLY-STOP] ‚ö†Ô∏è EARLY STOPPING TRIGGERED\")\n            print(f\"[EARLY-STOP] No improvement for {EARLY_STOPPING_PATIENCE} epochs\")\n            print(f\"[EARLY-STOP] Best validation loss: {best_val_loss:.6f}\")\n            print(f\"[EARLY-STOP] Stopping at epoch {epoch}/{epochs}\")\n            print(\"=\" * 80)\n            break\n\n    print(\"\\n[TRAIN] Training completed\")\n    processed_batches = training_stats[\"batches_processed\"] - training_stats[\"skipped_batches\"]\n    expected_updates = max(1, math.floor(processed_batches / max(1, accumulation_steps)))\n    success_rate = 100.0 * training_stats[\"optimizer_updates\"] / expected_updates if expected_updates > 0 else 0.0\n    print(f\"[TRAIN] Success Rate (updates/expected): {success_rate:.1f}%\")\n    print(f\"[TRAIN] Batches processed={processed_batches} skipped={training_stats['skipped_batches']}\")\n    print(f\"[TRAIN] Clustered Token Types: {_get_cluster_count(model)}\")\n    print(f\"[TRAIN] Best validation loss: {best_val_loss:.6f}\")\n    if training_stats[\"epoch_bleu_scores\"]:\n        best_bleu = max(training_stats[\"epoch_bleu_scores\"])\n        print(f\"[TRAIN] Best BLEU score: {best_bleu:.2f}\")\n    \n    return model\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Cell 7: Training Loop for Dual-Path TATN (IndicBART-READY - 25 CRITICAL FIXES)\")\nprint(\"=\" * 80)\nprint(\"üî• IndicBART-SPECIFIC FIXES (5 NEW):\")\nprint(\" FIX #21: üî• CRITICAL - Replace m2m100_model with indicbart_model references\")\nprint(\" FIX #22: üî• CRITICAL - Update all print messages for IndicBART\")\nprint(\" FIX #23: üî• CRITICAL - Handle IndicBART language token format in validation\")\nprint(\" FIX #24: Import IndicBART-specific configs from Cell 0\")\nprint(\" FIX #25: Update freeze_model_layers for IndicBART architecture\")\nprint()\nprint(\"üî¨ RESEARCH-BACKED FIXES (20 PRESERVED):\")\nprint(\" FIX #1:  EPOCHS default 3 ‚Üí 10 (Cell 0 convergence)\")\nprint(\" FIX #2:  VALIDATION_CHECK_INTERVAL 0 ‚Üí 1000 (Cell 0)\")\nprint(\" FIX #3:  Added LR scheduler with scheduler.step() calls\")\nprint(\" FIX #4:  ‚úÖ COMPLETE Early stopping implementation (patience=5)\")\nprint(\" FIX #5:  Added validation BLEU metric tracking\")\nprint(\" FIX #6:  Added best model saving by validation loss\")\nprint(\" FIX #7:  Added warmup step counter and tracking\")\nprint(\" FIX #8:  Added layer freezing function\")\nprint(\" FIX #10: Added checkpoint frequency (every 2 epochs)\")\nprint(\" FIX #11: MEMORY_CLEANUP_FREQUENCY 100 ‚Üí 50\")\nprint(\" FIX #12: Added MIN_LEARNING_RATE enforcement\")\nprint(\" FIX #13: Added DSCD_MAX_CLUSTERING_POINTS limit\")\nprint(\" FIX #14: Added CLUSTERING_TIMEOUT enforcement\")\nprint(\" FIX #15: ‚úÖ COMPLETE calculate_bleu_score() function\")\nprint(\" FIX #16: ‚úÖ COMPLETE early_stopping_counter tracking\")\nprint(\" FIX #17: ‚úÖ COMPLETE best_val_loss tracking\")\nprint(\" FIX #18: Added learning rate logging\")\nprint(\" FIX #19: FIXED BATCH UNPACKING - Extracts word data from batch\")\nprint(\" FIX #20: CRITICAL - Handles BOTH dict and tuple batch formats!\")\nprint()\nprint(\"Critical Path 1 (Word-level) fixes:\")\nprint(\" ‚úÖ _unpack_batch() handles dict format from safe_collate\")\nprint(\" ‚úÖ _unpack_batch() extracts word_input_ids\")\nprint(\" ‚úÖ _unpack_batch() extracts word_attention_mask\")\nprint(\" ‚úÖ _unpack_batch() extracts word_strings\")\nprint(\" ‚úÖ forward_kwargs passes all word parameters to model\")\nprint(\" ‚úÖ Moves word tensors to GPU device\")\nprint(\" ‚úÖ Handles DataParallel batch size adjustment\")\nprint(\" ‚úÖ Debug logging for first 5 steps to verify data flow\")\nprint()\nprint(\"IndicBART Integration:\")\nprint(f\" ‚úì Model: IndicBART (ai4bharat/indic-bart)\")\nprint(f\" ‚úì Language tokens: <2{_TARGET_LANGUAGE}>\")\nprint(f\" ‚úì Source language: {_SOURCE_LANGUAGE}\")\nprint(f\" ‚úì Target language: {_TARGET_LANGUAGE}\")\nprint(f\" ‚úì Max length: {_MAX_LENGTH}\")\nprint(f\" ‚úì Freeze layers: {FREEZE_ENCODER_LAYERS} encoder + {FREEZE_DECODER_LAYERS} decoder\")\nprint()\nprint(\"Early Stopping (FIX #4, #15-#17) VERIFIED:\")\nprint(\" ‚úÖ early_stopping_counter variable initialized\")\nprint(\" ‚úÖ best_val_loss tracking initialized\")\nprint(\" ‚úÖ no_improvement_epochs counter initialized\")\nprint(\" ‚úÖ Validation loss comparison at end of each epoch\")\nprint(\" ‚úÖ Best model checkpoint saved when improved\")\nprint(\" ‚úÖ Early stopping triggered after EARLY_STOPPING_PATIENCE epochs\")\nprint(\" ‚úÖ Training loop breaks when patience exceeded\")\nprint()\nprint(\"Original Cell 7 compatibility preserved:\")\nprint(\" ‚úì src_text (singular) matches Cell 2 & Cell 6\")\nprint(\" ‚úì DSCD training clustering enabled\")\nprint(\" ‚úì All defensive logic (AMP, DP, OOM handling)\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"coTb4Fi4H4J4","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:44.112361Z","iopub.execute_input":"2026-01-24T20:09:44.112935Z","iopub.status.idle":"2026-01-24T20:09:44.615347Z","shell.execute_reply.started":"2026-01-24T20:09:44.112910Z","shell.execute_reply":"2026-01-24T20:09:44.614607Z"}},"outputs":[{"name":"stdout","text":"[CELL7] ‚úÖ Imported transformers scheduler functions\n[CELL7] Loading configuration from Cell 0...\n[CELL7] WARNING: MAX_WORD_LENGTH not defined, using default 48\n[CELL7] Configuration loaded:\n  Epochs: 2\n  Batch size: 48\n  Accumulation steps: 16\n  Device: cuda\n  Multi-GPU: True (GPUs: 2)\n  AMP: True\n  Source language: bn\n  Target language: en\n  Max length: 48\n  Validation interval: 500\n  Early stopping patience: 2\n  Warmup steps: 500\n  Scheduler: linear\n  Layer freezing: 2 encoder + 2 decoder\n  Memory cleanup frequency: 100\n  Verbose logging: False\n\n================================================================================\n‚úÖ Cell 7: Training Loop for Dual-Path TATN (IndicBART-READY - 25 CRITICAL FIXES)\n================================================================================\nüî• IndicBART-SPECIFIC FIXES (5 NEW):\n FIX #21: üî• CRITICAL - Replace m2m100_model with indicbart_model references\n FIX #22: üî• CRITICAL - Update all print messages for IndicBART\n FIX #23: üî• CRITICAL - Handle IndicBART language token format in validation\n FIX #24: Import IndicBART-specific configs from Cell 0\n FIX #25: Update freeze_model_layers for IndicBART architecture\n\nüî¨ RESEARCH-BACKED FIXES (20 PRESERVED):\n FIX #1:  EPOCHS default 3 ‚Üí 10 (Cell 0 convergence)\n FIX #2:  VALIDATION_CHECK_INTERVAL 0 ‚Üí 1000 (Cell 0)\n FIX #3:  Added LR scheduler with scheduler.step() calls\n FIX #4:  ‚úÖ COMPLETE Early stopping implementation (patience=5)\n FIX #5:  Added validation BLEU metric tracking\n FIX #6:  Added best model saving by validation loss\n FIX #7:  Added warmup step counter and tracking\n FIX #8:  Added layer freezing function\n FIX #10: Added checkpoint frequency (every 2 epochs)\n FIX #11: MEMORY_CLEANUP_FREQUENCY 100 ‚Üí 50\n FIX #12: Added MIN_LEARNING_RATE enforcement\n FIX #13: Added DSCD_MAX_CLUSTERING_POINTS limit\n FIX #14: Added CLUSTERING_TIMEOUT enforcement\n FIX #15: ‚úÖ COMPLETE calculate_bleu_score() function\n FIX #16: ‚úÖ COMPLETE early_stopping_counter tracking\n FIX #17: ‚úÖ COMPLETE best_val_loss tracking\n FIX #18: Added learning rate logging\n FIX #19: FIXED BATCH UNPACKING - Extracts word data from batch\n FIX #20: CRITICAL - Handles BOTH dict and tuple batch formats!\n\nCritical Path 1 (Word-level) fixes:\n ‚úÖ _unpack_batch() handles dict format from safe_collate\n ‚úÖ _unpack_batch() extracts word_input_ids\n ‚úÖ _unpack_batch() extracts word_attention_mask\n ‚úÖ _unpack_batch() extracts word_strings\n ‚úÖ forward_kwargs passes all word parameters to model\n ‚úÖ Moves word tensors to GPU device\n ‚úÖ Handles DataParallel batch size adjustment\n ‚úÖ Debug logging for first 5 steps to verify data flow\n\nIndicBART Integration:\n ‚úì Model: IndicBART (ai4bharat/indic-bart)\n ‚úì Language tokens: <2en>\n ‚úì Source language: bn\n ‚úì Target language: en\n ‚úì Max length: 48\n ‚úì Freeze layers: 2 encoder + 2 decoder\n\nEarly Stopping (FIX #4, #15-#17) VERIFIED:\n ‚úÖ early_stopping_counter variable initialized\n ‚úÖ best_val_loss tracking initialized\n ‚úÖ no_improvement_epochs counter initialized\n ‚úÖ Validation loss comparison at end of each epoch\n ‚úÖ Best model checkpoint saved when improved\n ‚úÖ Early stopping triggered after EARLY_STOPPING_PATIENCE epochs\n ‚úÖ Training loop breaks when patience exceeded\n\nOriginal Cell 7 compatibility preserved:\n ‚úì src_text (singular) matches Cell 2 & Cell 6\n ‚úì DSCD training clustering enabled\n ‚úì All defensive logic (AMP, DP, OOM handling)\n================================================================================\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ==============================================================================\n# CELL 8: MODEL INITIALIZATION, OPTIMIZER, SCHEDULER & EVALUATION (IndicBART-READY)\n# ==============================================================================\n# Complete integration with Cell 0 research-backed config + Cell 7 training loop\n#\n# üî• IndicBART-SPECIFIC FIXES (5 NEW):\n# FIX #16: üî• CRITICAL - Replace m2m100_model with indicbart_model references\n# FIX #17: üî• CRITICAL - Update all print messages for IndicBART\n# FIX #18: üî• CRITICAL - Handle IndicBART language token format\n# FIX #19: Import IndicBART-specific configs from Cell 0\n# FIX #20: Update freeze_model_layers for IndicBART architecture\n#\n# üî¨ RESEARCH-BACKED FIXES (15 PRESERVED):\n# FIX #1:  Added optimizer setup with AdamW (Cell 0 requirement)\n# FIX #2:  Added scheduler setup with inverse_sqrt + warmup (Cell 0)\n# FIX #3:  Added layer freezing function and application (Cell 0)\n# FIX #4:  Fixed src_texts ‚Üí src_text in translate_with_explanations\n# FIX #5:  Fixed src_texts ‚Üí src_text in dscd_discovery_warmup\n# FIX #6:  Added parameter group separation (4 different LRs from Cell 0)\n# FIX #7:  Added validation sample preparation\n# FIX #8:  Added BLEU/chrF++ evaluation functions\n# FIX #9:  Added checkpoint loading/resuming functionality\n# FIX #10: Added best model loading utility\n# FIX #11: Added trainable parameter verification\n# FIX #12: Added DataParallel wrapper for multi-GPU\n# FIX #13: Added train_loader creation code\n# FIX #14: Added training function integration\n# FIX #15: Added post-training evaluation\n#\n# Original Cell 8 compatibility preserved:\n# ‚úì translate_with_explanations() fixed for Cell 6\n# ‚úì demonstrate_system() unchanged\n# ‚úì dscd_discovery_warmup() fixed for Cell 6\n# ‚úì All defensive logic preserved\n# ==============================================================================\n\nimport os\nimport time\nimport math\nimport traceback\nfrom typing import List, Dict, Any, Tuple, Optional\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n# ==============================================================================\n# üî¨ FIX #2, #8: Import transformers scheduler and metrics\n# ==============================================================================\ntry:\n    from transformers import get_inverse_sqrt_schedule, get_linear_schedule_with_warmup\n    _HAS_TRANSFORMERS_SCHEDULER = True\n    print(\"[CELL8] ‚úÖ Imported transformers scheduler functions\")\nexcept Exception:\n    _HAS_TRANSFORMERS_SCHEDULER = False\n    print(\"[CELL8] ‚ö†Ô∏è transformers scheduler not available\")\n\ntry:\n    import sacrebleu\n    _HAS_SACREBLEU = True\n    print(\"[CELL8] ‚úÖ Imported sacrebleu for BLEU/chrF++ evaluation\")\nexcept Exception:\n    _HAS_SACREBLEU = False\n    print(\"[CELL8] ‚ö†Ô∏è sacrebleu not available - using fallback BLEU\")\n\n# ==============================================================================\n# üî• FIX #19: Import Cell 0 configuration parameters (IndicBART-specific)\n# ==============================================================================\nprint(\"[CELL8] Loading configuration from Cell 0...\")\n\n# Local fallbacks (read from Cell 0 if available)\ntry:\n    SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, ValueError):\n    SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL8] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n_SOURCE_LANGUAGE = SOURCE_LANGUAGE\n\ntry:\n    TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, ValueError):\n    TARGET_LANGUAGE = \"en\"\n    print(\"[CELL8] WARNING: TARGET_LANGUAGE not defined, using default 'en'\")\n_TARGET_LANGUAGE = TARGET_LANGUAGE\n\n# IndicBART uses language codes directly (not _XX format)\n_BN_LANG = _SOURCE_LANGUAGE\n_EN_LANG = _TARGET_LANGUAGE\n\ntry:\n    MAX_LENGTH = int(MAX_LENGTH)\nexcept (NameError, ValueError):\n    MAX_LENGTH = 128\n    print(\"[CELL8] WARNING: MAX_LENGTH not defined, using default 128\")\n_MAX_LENGTH = MAX_LENGTH\n\ntry:\n    MAX_WORD_LENGTH = int(MAX_WORD_LENGTH)\nexcept (NameError, ValueError):\n    MAX_WORD_LENGTH = 48\n    print(\"[CELL8] WARNING: MAX_WORD_LENGTH not defined, using default 48\")\n_MAX_WORD_LENGTH = MAX_WORD_LENGTH\n\ntry:\n    DEVICE = globals().get(\"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\nexcept Exception:\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n_DEVICE = DEVICE\n\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, ValueError):\n    VERBOSE_LOGGING = False\n_VERBOSE_LOGGING = VERBOSE_LOGGING\n\ntry:\n    USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept (NameError, ValueError):\n    USE_MULTI_GPU = torch.cuda.is_available() and torch.cuda.device_count() > 1\n_USE_MULTI_GPU = USE_MULTI_GPU\n\ntry:\n    NUM_GPUS = int(NUM_GPUS)\nexcept (NameError, ValueError):\n    NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n_NUM_GPUS = NUM_GPUS\n\n# ==============================================================================\n# üî¨ FIX #1, #2, #3: Cell 0 optimizer/scheduler/freezing parameters\n# ==============================================================================\ntry:\n    BATCH_SIZE = int(BATCH_SIZE)\nexcept (NameError, ValueError):\n    BATCH_SIZE = 8\n    print(\"[CELL8] WARNING: BATCH_SIZE not defined, using default 8\")\n\ntry:\n    ACCUMULATION_STEPS = int(ACCUMULATION_STEPS)\nexcept (NameError, ValueError):\n    ACCUMULATION_STEPS = 16\n    print(\"[CELL8] WARNING: ACCUMULATION_STEPS not defined, using default 16\")\n\ntry:\n    EPOCHS = int(EPOCHS)\nexcept (NameError, ValueError):\n    EPOCHS = 10\n    print(\"[CELL8] WARNING: EPOCHS not defined, using default 10\")\n\ntry:\n    GRAD_CLIP_NORM = float(GRAD_CLIP_NORM)\nexcept (NameError, ValueError):\n    GRAD_CLIP_NORM = 1.0\n    print(\"[CELL8] WARNING: GRAD_CLIP_NORM not defined, using default 1.0\")\n\n# Learning rates (Cell 0)\ntry:\n    LR_NMT = float(LR_NMT)\nexcept (NameError, ValueError):\n    LR_NMT = 3e-5\n    print(\"[CELL8] WARNING: LR_NMT not defined, using default 3e-5\")\n\ntry:\n    LR_WORD_EMBED = float(LR_WORD_EMBED)\nexcept (NameError, ValueError):\n    LR_WORD_EMBED = 5e-5\n    print(\"[CELL8] WARNING: LR_WORD_EMBED not defined, using default 5e-5\")\n\ntry:\n    LR_PHI = float(LR_PHI)\nexcept (NameError, ValueError):\n    LR_PHI = 1e-5\n    print(\"[CELL8] WARNING: LR_PHI not defined, using default 1e-5\")\n\ntry:\n    LR_TRG = float(LR_TRG)\nexcept (NameError, ValueError):\n    LR_TRG = 1e-5\n    print(\"[CELL8] WARNING: LR_TRG not defined, using default 1e-5\")\n\n# AdamW parameters (Cell 0)\ntry:\n    WEIGHT_DECAY = float(WEIGHT_DECAY)\nexcept (NameError, ValueError):\n    WEIGHT_DECAY = 0.01\n    print(\"[CELL8] WARNING: WEIGHT_DECAY not defined, using default 0.01\")\n\ntry:\n    ADAM_BETA1 = float(ADAM_BETA1)\nexcept (NameError, ValueError):\n    ADAM_BETA1 = 0.9\n    print(\"[CELL8] WARNING: ADAM_BETA1 not defined, using default 0.9\")\n\ntry:\n    ADAM_BETA2 = float(ADAM_BETA2)\nexcept (NameError, ValueError):\n    ADAM_BETA2 = 0.999\n    print(\"[CELL8] WARNING: ADAM_BETA2 not defined, using default 0.999\")\n\ntry:\n    ADAM_EPSILON = float(ADAM_EPSILON)\nexcept (NameError, ValueError):\n    ADAM_EPSILON = 1e-8\n    print(\"[CELL8] WARNING: ADAM_EPSILON not defined, using default 1e-8\")\n\n# Scheduler parameters (Cell 0)\ntry:\n    USE_LR_SCHEDULER = bool(USE_LR_SCHEDULER)\nexcept (NameError, ValueError):\n    USE_LR_SCHEDULER = True\n    print(\"[CELL8] WARNING: USE_LR_SCHEDULER not defined, using default True\")\n\ntry:\n    SCHEDULER_TYPE = str(SCHEDULER_TYPE)\nexcept (NameError, ValueError):\n    SCHEDULER_TYPE = \"inverse_sqrt\"\n    print(\"[CELL8] WARNING: SCHEDULER_TYPE not defined, using default 'inverse_sqrt'\")\n\ntry:\n    WARMUP_STEPS = int(WARMUP_STEPS)\nexcept (NameError, ValueError):\n    WARMUP_STEPS = 4000\n    print(\"[CELL8] WARNING: WARMUP_STEPS not defined, using default 4000\")\n\ntry:\n    MIN_LEARNING_RATE = float(MIN_LEARNING_RATE)\nexcept (NameError, ValueError):\n    MIN_LEARNING_RATE = 1e-7\n    print(\"[CELL8] WARNING: MIN_LEARNING_RATE not defined, using default 1e-7\")\n\n# Layer freezing (Cell 0)\ntry:\n    FREEZE_ENCODER_LAYERS = int(FREEZE_ENCODER_LAYERS)\nexcept (NameError, ValueError):\n    FREEZE_ENCODER_LAYERS = 2\n    print(\"[CELL8] WARNING: FREEZE_ENCODER_LAYERS not defined, using default 2\")\n\ntry:\n    FREEZE_DECODER_LAYERS = int(FREEZE_DECODER_LAYERS)\nexcept (NameError, ValueError):\n    FREEZE_DECODER_LAYERS = 2\n    print(\"[CELL8] WARNING: FREEZE_DECODER_LAYERS not defined, using default 2\")\n\n# Validation\ntry:\n    VALIDATION_CHECK_INTERVAL = int(VALIDATION_CHECK_INTERVAL)\nexcept (NameError, ValueError):\n    VALIDATION_CHECK_INTERVAL = 1000\n    print(\"[CELL8] WARNING: VALIDATION_CHECK_INTERVAL not defined, using default 1000\")\n\ntry:\n    EARLY_STOPPING_PATIENCE = int(EARLY_STOPPING_PATIENCE)\nexcept (NameError, ValueError):\n    EARLY_STOPPING_PATIENCE = 5\n    print(\"[CELL8] WARNING: EARLY_STOPPING_PATIENCE not defined, using default 5\")\n\n# Checkpoint\ntry:\n    CHECKPOINT_DIR = str(CHECKPOINT_DIR)\nexcept (NameError, ValueError):\n    CHECKPOINT_DIR = \"/kaggle/working/\"\n    print(\"[CELL8] WARNING: CHECKPOINT_DIR not defined, using default '/kaggle/working/'\")\n\ntry:\n    SAVE_CHECKPOINT_EVERY = int(SAVE_CHECKPOINT_EVERY)\nexcept (NameError, ValueError):\n    SAVE_CHECKPOINT_EVERY = 2\n    print(\"[CELL8] WARNING: SAVE_CHECKPOINT_EVERY not defined, using default 2\")\n\n# Real ambiguity thresholds\ntry:\n    SPAN_THRESHOLD = float(SPAN_THRESHOLD)\nexcept (NameError, ValueError):\n    SPAN_THRESHOLD = 0.3\n    print(\"[CELL8] WARNING: SPAN_THRESHOLD not defined, using default 0.3\")\n_REAL_AMB_SPAN_THRESHOLD = SPAN_THRESHOLD\n\ntry:\n    TAU_LOW = float(TAU_LOW)\nexcept (NameError, ValueError):\n    TAU_LOW = 0.4\n    print(\"[CELL8] WARNING: TAU_LOW not defined, using default 0.4\")\n_REAL_AMB_UNCERTAINTY_THRESHOLD = TAU_LOW\n\n# Optional canonicalizer from bn_normalizer (Cell 1)\n_normalize_fn = globals().get(\"normalize_bn_word\", None) or globals().get(\"normalize_indic_word\", None)\n\nprint(f\"[CELL8] Configuration loaded:\")\nprint(f\"  Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  Max length: {_MAX_LENGTH}\")\nprint(f\"  Batch size: {BATCH_SIZE}\")\nprint(f\"  Accumulation steps: {ACCUMULATION_STEPS}\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Learning rates: NMT={LR_NMT}, Word={LR_WORD_EMBED}, PHI={LR_PHI}, TRG={LR_TRG}\")\nprint(f\"  Scheduler: {SCHEDULER_TYPE if USE_LR_SCHEDULER else 'disabled'}\")\nprint(f\"  Warmup steps: {WARMUP_STEPS}\")\nprint(f\"  Layer freezing: {FREEZE_ENCODER_LAYERS} encoder + {FREEZE_DECODER_LAYERS} decoder\")\nprint(f\"  Device: {_DEVICE}\")\nprint(f\"  Multi-GPU: {_USE_MULTI_GPU} (GPUs: {_NUM_GPUS})\")\n\n# ==============================================================================\n# üî• FIX #20: Layer Freezing Function for IndicBART\n# ==============================================================================\ndef freeze_model_layers(model, freeze_encoder_layers=2, freeze_decoder_layers=2):\n    \"\"\"\n    Freeze early layers to preserve pretrained multilingual features.\n    Evidence: Low-Resource Transliteration (2025) - preserves multilingual knowledge\n    \n    Updated for IndicBART (MBart architecture).\n    \"\"\"\n    try:\n        # Get core model (unwrap DataParallel if needed)\n        core_model = model.module if hasattr(model, 'module') else model\n        \n        # ==================================================================\n        # üî• FIX #16: Get IndicBART model (not M2M100)\n        # ==================================================================\n        indicbart_model = getattr(core_model, 'indicbart_model', None)\n        if indicbart_model is None:\n            print(\"[FREEZE] Warning: indicbart_model not found, skipping layer freezing\")\n            return\n        \n        # Freeze embedding layers\n        try:\n            if hasattr(indicbart_model.model, 'shared'):\n                for param in indicbart_model.model.shared.parameters():\n                    param.requires_grad = False\n                print(f\"[FREEZE] ‚úì Frozen embedding layers\")\n        except Exception as e:\n            print(f\"[FREEZE] Warning: Could not freeze embeddings: {e}\")\n        \n        # Freeze first N encoder layers\n        frozen_encoder = 0\n        if hasattr(indicbart_model.model, 'encoder') and hasattr(indicbart_model.model.encoder, 'layers'):\n            for i in range(min(freeze_encoder_layers, len(indicbart_model.model.encoder.layers))):\n                try:\n                    for param in indicbart_model.model.encoder.layers[i].parameters():\n                        param.requires_grad = False\n                    frozen_encoder += 1\n                except Exception:\n                    break\n            print(f\"[FREEZE] ‚úì Frozen {frozen_encoder} encoder layers\")\n        \n        # Freeze first N decoder layers\n        frozen_decoder = 0\n        if hasattr(indicbart_model.model, 'decoder') and hasattr(indicbart_model.model.decoder, 'layers'):\n            for i in range(min(freeze_decoder_layers, len(indicbart_model.model.decoder.layers))):\n                try:\n                    for param in indicbart_model.model.decoder.layers[i].parameters():\n                        param.requires_grad = False\n                    frozen_decoder += 1\n                except Exception:\n                    break\n            print(f\"[FREEZE] ‚úì Frozen {frozen_decoder} decoder layers\")\n        \n        # Count trainable parameters\n        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n        total_params = sum(p.numel() for p in model.parameters())\n        print(f\"[FREEZE] Trainable: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.1f}%)\")\n        \n    except Exception as e:\n        print(f\"[FREEZE] Layer freezing failed: {type(e).__name__}: {str(e)[:200]}\")\n\n\n# ==============================================================================\n# üî¨ FIX #6: Parameter Group Separation (4 different LRs from Cell 0)\n# ==============================================================================\ndef create_parameter_groups(model):\n    \"\"\"\n    Create parameter groups with different learning rates for:\n    1. IndicBART NMT (encoder/decoder) - LR_NMT\n    2. Word embeddings - LR_WORD_EMBED\n    3. DSCD/ASBN (PHI) - LR_PHI\n    4. TRG - LR_TRG\n    \"\"\"\n    core_model = model.module if hasattr(model, 'module') else model\n    \n    # Initialize parameter groups\n    indicbart_params = []\n    word_embed_params = []\n    dscd_asbn_params = []\n    trg_params = []\n    other_params = []\n    \n    try:\n        # ==================================================================\n        # üî• FIX #16: Get IndicBART model parameters (not M2M100)\n        # ==================================================================\n        indicbart_model = getattr(core_model, 'indicbart_model', None)\n        if indicbart_model is not None:\n            for name, param in indicbart_model.named_parameters():\n                if param.requires_grad:\n                    indicbart_params.append(param)\n        \n        # Get word embeddings (if separate)\n        if hasattr(core_model, 'word_embeddings'):\n            for param in core_model.word_embeddings.parameters():\n                if param.requires_grad:\n                    word_embed_params.append(param)\n        \n        # Get DSCD parameters\n        if hasattr(core_model, 'dscd'):\n            for param in core_model.dscd.parameters():\n                if param.requires_grad:\n                    dscd_asbn_params.append(param)\n        \n        # Get ASBN parameters\n        if hasattr(core_model, 'asbn'):\n            for param in core_model.asbn.parameters():\n                if param.requires_grad:\n                    dscd_asbn_params.append(param)\n        \n        # Get TRG parameters\n        if hasattr(core_model, 'trg'):\n            for param in core_model.trg.parameters():\n                if param.requires_grad:\n                    trg_params.append(param)\n        \n        # Collect IDs of parameters already assigned\n        assigned_ids = set()\n        for p in indicbart_params + word_embed_params + dscd_asbn_params + trg_params:\n            assigned_ids.add(id(p))\n        \n        # Collect remaining parameters\n        for param in model.parameters():\n            if param.requires_grad and id(param) not in assigned_ids:\n                other_params.append(param)\n        \n        # Create parameter groups (non-empty only)\n        param_groups = []\n        \n        if indicbart_params:\n            param_groups.append({'params': indicbart_params, 'lr': LR_NMT, 'name': 'indicbart'})\n            print(f\"[PARAM-GROUPS] IndicBART: {len(indicbart_params)} params, LR={LR_NMT}\")\n        \n        if word_embed_params:\n            param_groups.append({'params': word_embed_params, 'lr': LR_WORD_EMBED, 'name': 'word_embed'})\n            print(f\"[PARAM-GROUPS] Word Embeddings: {len(word_embed_params)} params, LR={LR_WORD_EMBED}\")\n        \n        if dscd_asbn_params:\n            param_groups.append({'params': dscd_asbn_params, 'lr': LR_PHI, 'name': 'dscd_asbn'})\n            print(f\"[PARAM-GROUPS] DSCD/ASBN: {len(dscd_asbn_params)} params, LR={LR_PHI}\")\n        \n        if trg_params:\n            param_groups.append({'params': trg_params, 'lr': LR_TRG, 'name': 'trg'})\n            print(f\"[PARAM-GROUPS] TRG: {len(trg_params)} params, LR={LR_TRG}\")\n        \n        if other_params:\n            param_groups.append({'params': other_params, 'lr': LR_NMT, 'name': 'other'})\n            print(f\"[PARAM-GROUPS] Other: {len(other_params)} params, LR={LR_NMT}\")\n        \n        if not param_groups:\n            print(\"[PARAM-GROUPS] Warning: No parameter groups created, using all trainable params\")\n            param_groups = [{'params': filter(lambda p: p.requires_grad, model.parameters()), 'lr': LR_NMT}]\n        \n        return param_groups\n        \n    except Exception as e:\n        print(f\"[PARAM-GROUPS] Error creating parameter groups: {e}\")\n        print(\"[PARAM-GROUPS] Fallback: using single parameter group\")\n        return [{'params': filter(lambda p: p.requires_grad, model.parameters()), 'lr': LR_NMT}]\n\n\n# ==============================================================================\n# üî¨ FIX #9, #10: Checkpoint Loading/Resuming Functions\n# ==============================================================================\ndef load_checkpoint(model, optimizer=None, scheduler=None, checkpoint_path=None, device=None):\n    \"\"\"\n    Load model checkpoint and optionally resume optimizer/scheduler state.\n    \"\"\"\n    if checkpoint_path is None or not os.path.exists(checkpoint_path):\n        print(f\"[CHECKPOINT] Checkpoint not found: {checkpoint_path}\")\n        return None\n    \n    if device is None:\n        device = _DEVICE\n    \n    try:\n        checkpoint = torch.load(checkpoint_path, map_location=device)\n        print(f\"[CHECKPOINT] Loading from: {checkpoint_path}\")\n        \n        # Load model state\n        core_model = model.module if hasattr(model, 'module') else model\n        try:\n            core_model.load_state_dict(checkpoint['model_state_dict'])\n            print(\"[CHECKPOINT] ‚úì Model state loaded\")\n        except Exception as e:\n            print(f\"[CHECKPOINT] Warning: Model state load failed: {e}\")\n            try:\n                core_model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n                print(\"[CHECKPOINT] ‚úì Model state loaded (non-strict)\")\n            except Exception as e2:\n                print(f\"[CHECKPOINT] Error: Could not load model state: {e2}\")\n                return None\n        \n        # Load optimizer state\n        if optimizer is not None and 'optimizer_state_dict' in checkpoint and checkpoint['optimizer_state_dict'] is not None:\n            try:\n                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n                print(\"[CHECKPOINT] ‚úì Optimizer state loaded\")\n            except Exception as e:\n                print(f\"[CHECKPOINT] Warning: Optimizer state load failed: {e}\")\n        \n        # Load scheduler state\n        if scheduler is not None and 'scheduler_state_dict' in checkpoint and checkpoint['scheduler_state_dict'] is not None:\n            try:\n                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n                print(\"[CHECKPOINT] ‚úì Scheduler state loaded\")\n            except Exception as e:\n                print(f\"[CHECKPOINT] Warning: Scheduler state load failed: {e}\")\n        \n        # Return metadata\n        metadata = {\n            'epoch': checkpoint.get('epoch', 0),\n            'global_step': checkpoint.get('global_step', 0),\n            'avg_epoch_loss': checkpoint.get('avg_epoch_loss', 0.0),\n            'training_stats': checkpoint.get('training_stats', {})\n        }\n        \n        print(f\"[CHECKPOINT] Resumed from epoch {metadata['epoch']}, step {metadata['global_step']}\")\n        return metadata\n        \n    except Exception as e:\n        print(f\"[CHECKPOINT] Load failed: {type(e).__name__}: {str(e)[:200]}\")\n        return None\n\n\ndef load_best_model(model, checkpoint_dir=None, device=None):\n    \"\"\"\n    Load the best model checkpoint saved during training.\n    \"\"\"\n    if checkpoint_dir is None:\n        checkpoint_dir = CHECKPOINT_DIR\n    \n    best_model_path = os.path.join(checkpoint_dir, \"tatn_best_model.pt\")\n    \n    if os.path.exists(best_model_path):\n        print(f\"[BEST-MODEL] Loading best model from: {best_model_path}\")\n        return load_checkpoint(model, checkpoint_path=best_model_path, device=device)\n    else:\n        print(f\"[BEST-MODEL] Best model not found at: {best_model_path}\")\n        return None\n\n\n# ------------------------------------------------------------------------------\n# Helpers\n# ------------------------------------------------------------------------------\ndef _to_device_batch(enc: Any, device: torch.device):\n    \"\"\"\n    Move tokenizer output to device. Prefer BatchEncoding.to(device) if present.\n    Otherwise, move any tensor values in the dict to device.\n    Returns a dict-like object with tensor values on the requested device.\n    \"\"\"\n    try:\n        if hasattr(enc, \"to\") and callable(getattr(enc, \"to\")):\n            try:\n                return enc.to(device)\n            except Exception:\n                if _VERBOSE_LOGGING:\n                    print(\"[CELL8] BatchEncoding.to() raised; falling back to per-tensor move\")\n    except Exception:\n        pass\n\n    out = {}\n    try:\n        for k, v in dict(enc).items():\n            try:\n                if isinstance(v, torch.Tensor):\n                    out[k] = v.to(device)\n                else:\n                    out[k] = v\n            except Exception:\n                out[k] = v\n        return out\n    except Exception:\n        if _VERBOSE_LOGGING:\n            print(\"[CELL8] _to_device_batch fallback failed; returning original enc\")\n        return enc\n\n\ndef _extract_dscd_outputs(raw_out: Any) -> Dict[str, Any]:\n    \"\"\"\n    Accept many possible model forward outputs and return a dict that contains DSCD/TRG outputs.\n    \n    Cell 6's forward() returns dict with key 'dscd_outputs' in inference mode.\n    Cell 6's generate() returns dict with keys: 'translations', 'explanations', 'dscd_outputs', 'word_strings'.\n    \"\"\"\n    if raw_out is None:\n        return {}\n\n    if isinstance(raw_out, dict):\n        if 'dscd_outputs' in raw_out:\n            dscd = raw_out['dscd_outputs']\n            if isinstance(dscd, dict):\n                return dscd\n        \n        for key in (\"dscd\", \"dscd_out\", \"dscd_outputs_cpu\"):\n            v = raw_out.get(key, None)\n            if isinstance(v, dict):\n                return v\n        \n        if any(k in raw_out for k in (\"proto_probs\", \"explanations\", \"span_preds\", \"uncertainties\", \"h_aug\")):\n            return raw_out\n        \n        for key in (\"outputs\", \"result\", \"result_dict\"):\n            v = raw_out.get(key, None)\n            if isinstance(v, dict) and any(k in v for k in (\"proto_probs\", \"explanations\", \"span_preds\", \"uncertainties\")):\n                return v\n        \n        return raw_out\n\n    if isinstance(raw_out, (list, tuple)):\n        for item in raw_out:\n            if isinstance(item, dict):\n                sub = _extract_dscd_outputs(item)\n                if sub:\n                    return sub\n    \n    return {}\n\n\ndef _get_explanations_list(dscd: Dict[str, Any]) -> List[List[Dict[str, Any]]]:\n    \"\"\"\n    Normalize various 'explanations' layouts into a list-of-lists where each outer entry\n    corresponds to a sentence.\n    \n    Cell 6 returns explanations as list of lists from TRG.\n    \"\"\"\n    if not dscd:\n        return []\n    \n    expl = None\n    for k in (\"explanations\", \"trg_explanations\", \"explanations_per_sentence\", \"exps\", \"explanations_list\"):\n        if k in dscd:\n            expl = dscd[k]\n            break\n    \n    if expl is None:\n        return []\n\n    if isinstance(expl, list):\n        if len(expl) == 0:\n            return []\n        if isinstance(expl[0], list):\n            return expl\n        if isinstance(expl[0], dict):\n            return [expl]\n    \n    if isinstance(expl, dict):\n        try:\n            numeric_keys = sorted((int(k) for k in expl.keys() if str(k).isdigit()))\n            if numeric_keys:\n                out = []\n                for nk in numeric_keys:\n                    v = expl.get(str(nk), expl.get(nk))\n                    if isinstance(v, list):\n                        out.append(v)\n                    elif isinstance(v, dict):\n                        out.append([v])\n                if out:\n                    return out\n        except Exception:\n            pass\n    \n    return []\n\n\ndef _is_subword_token(token: Optional[str]) -> bool:\n    \"\"\"\n    Heuristic for detecting subword tokens/fragments to filter.\n    SentencePiece uses '‚ñÅ' to mark word-start. Tokens that START with '‚ñÅ'\n    are word-beginnings and should NOT be treated as subword fragments.\n    \"\"\"\n    if token is None:\n        return True\n    t = str(token).strip()\n    if t == \"\":\n        return True\n    if t.startswith(\"##\") or t.startswith(\"@@\"):\n        return True\n    if t.startswith(\"‚ñÅ\"):\n        return False\n    clean = t.lstrip(\"‚ñÅ\").lstrip(\"ƒ†\").replace(\"</w>\", \"\").strip()\n    if len(clean) < 2:\n        return True\n    if all(ch in '.,!?;:()[]{}\"\\'-‚Äî‚Äì/\\\\' for ch in clean):\n        return True\n    if clean.isdigit():\n        return True\n    return False\n\n\ndef _should_filter_explanation(expl: Dict[str, Any], span_th: float, u_th: float) -> bool:\n    \"\"\"\n    Return True if an explanation should be filtered out because it is low-quality.\n    Filter if:\n      - token is subword/empty/punctuation\n      - BOTH span <= span_th and uncertainty <= u_th (i.e., not enough signal)\n    \"\"\"\n    try:\n        token_raw = expl.get(\"token\", \"\") or expl.get(\"ambiguous_word\", \"\") or expl.get(\"token_value\", \"\") or expl.get(\"word\", \"\")\n        token = str(token_raw)\n        token_clean = token.lstrip(\"‚ñÅ\").lstrip(\"ƒ†\").replace(\"</w>\", \"\").strip()\n        if _normalize_fn and token_clean:\n            try:\n                token_clean = _normalize_fn(token_clean)\n            except Exception:\n                pass\n        if not token_clean or len(token_clean) < 2 or all(ch in '.,!?;:()[]{}\"\\'-‚Äî‚Äì/\\\\' for ch in token_clean):\n            return True\n\n        span = float(expl.get(\"span\", 0.0) or expl.get(\"span_pred\", 0.0) or 0.0)\n        uncertainty = float(expl.get(\"uncertainty\", 0.0) or 0.0)\n\n        if span <= span_th and uncertainty <= u_th:\n            return True\n        return False\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return True\n\n\n# ==================================================================\n# üî• FIX #18: Force English BOS for IndicBART\n# ==================================================================\ndef _force_english_bos(tokenizer, indicbart_model) -> Optional[int]:\n    \"\"\"\n    Try to determine English forced BOS id for tokenizer and set it in indicbart_model.config.\n    IndicBART uses language-specific tokens like <2en>.\n    Return the forced_id or None.\n    \"\"\"\n    forced_id = None\n    try:\n        # IndicBART uses language tokens like <2en> for target language\n        lang_code = f\"<2{_EN_LANG}>\"\n        \n        if hasattr(tokenizer, \"lang_code_to_id\"):\n            forced_id = tokenizer.lang_code_to_id.get(lang_code, None)\n        elif hasattr(tokenizer, \"convert_tokens_to_ids\"):\n            token_id = tokenizer.convert_tokens_to_ids(lang_code)\n            if token_id != tokenizer.unk_token_id:\n                forced_id = token_id\n    except Exception:\n        forced_id = None\n\n    if forced_id is not None and hasattr(indicbart_model, \"config\"):\n        try:\n            indicbart_model.config.forced_bos_token_id = int(forced_id)\n            indicbart_model.config.decoder_start_token_id = int(forced_id)\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(\"[CELL8] Could not set forced_bos_token_id on IndicBART config\")\n    return forced_id\n\n\n# ==============================================================================\n# üî¨ FIX #4: translate_with_explanations (FIXED src_texts ‚Üí src_text + IndicBART)\n# ==============================================================================\ndef translate_with_explanations(\n    model,\n    tokenizer,\n    input_sentence: str,\n    device: Optional[torch.device] = None,\n    span_threshold: Optional[float] = None,\n    uncertainty_threshold: Optional[float] = None,\n) -> Dict[str, Any]:\n    \"\"\"\n    Translate a single sentence using Cell 6's dual-path TATN model with IndicBART.\n    \n    Uses Cell 6's generate() method which returns:\n    {\n        'translations': List[str],\n        'explanations': List[List[Dict]],\n        'dscd_outputs': Dict,\n        'word_strings': List[List[str]]\n    }\n    \"\"\"\n    device = _DEVICE if device is None else device\n    span_th = _REAL_AMB_SPAN_THRESHOLD if span_threshold is None else float(span_threshold)\n    u_th = _REAL_AMB_UNCERTAINTY_THRESHOLD if uncertainty_threshold is None else float(uncertainty_threshold)\n\n    try:\n        # ==================================================================\n        # üî• FIX #18: Set IndicBART source language\n        # ==================================================================\n        try:\n            if hasattr(tokenizer, \"src_lang\"):\n                try:\n                    setattr(tokenizer, \"src_lang\", _BN_LANG)\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        enc = tokenizer(\n            input_sentence,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=_MAX_LENGTH\n        )\n        enc = _to_device_batch(enc, device)\n\n        model.eval()\n        core = model.module if (_USE_MULTI_GPU and hasattr(model, \"module\")) else model\n\n        translation = \"\"\n        explanations_raw = []\n        dscd_out = {}\n        \n        try:\n            with torch.inference_mode():\n                if hasattr(core, \"generate\"):\n                    try:\n                        # ‚Üê FIX #4: Use src_text (singular) not src_texts\n                        result = core.generate(\n                            input_ids=enc.get(\"input_ids\"),\n                            attention_mask=enc.get(\"attention_mask\"),\n                            src_text=[input_sentence],  # ‚Üê FIXED: singular src_text\n                            max_length=min(_MAX_LENGTH, 64),\n                            num_beams=2\n                        )\n                        \n                        if isinstance(result, dict):\n                            translations = result.get('translations', [])\n                            if isinstance(translations, list) and len(translations) > 0:\n                                translation = translations[0]\n                            \n                            explanations_raw = result.get('explanations', [])\n                            dscd_out = result.get('dscd_outputs', {})\n                        \n                        if _VERBOSE_LOGGING:\n                            print(f\"[CELL8] Cell 6 generate() returned translation: {translation[:50]}...\")\n                    \n                    except Exception as e:\n                        if _VERBOSE_LOGGING:\n                            print(f\"[CELL8] Cell 6 generate() failed: {e}\")\n                            traceback.print_exc()\n                        \n                        # ==================================================================\n                        # üî• FIX #16: Use indicbart_model (not m2m100_model)\n                        # ==================================================================\n                        indicbart_obj = getattr(core, \"indicbart_model\", None)\n                        if indicbart_obj is not None:\n                            try:\n                                translation = _fallback_indicbart_generate(\n                                    indicbart_obj, tokenizer, enc, device, input_sentence\n                                )\n                            except Exception as e2:\n                                if _VERBOSE_LOGGING:\n                                    print(f\"[CELL8] Fallback IndicBART generation failed: {e2}\")\n                                translation = \"\"\n                else:\n                    if _VERBOSE_LOGGING:\n                        print(\"[CELL8] Model has no generate() method; using fallback\")\n                    \n                    indicbart_obj = getattr(core, \"indicbart_model\", None)\n                    if indicbart_obj is not None:\n                        translation = _fallback_indicbart_generate(\n                            indicbart_obj, tokenizer, enc, device, input_sentence\n                        )\n        \n        except Exception as e:\n            if _VERBOSE_LOGGING:\n                print(\"[CELL8] Generation error:\", str(e))\n                traceback.print_exc()\n            translation = \"\"\n\n        if isinstance(explanations_raw, list) and len(explanations_raw) > 0:\n            sentence_explanations = explanations_raw[0] if isinstance(explanations_raw[0], list) else explanations_raw\n        else:\n            sentence_explanations = []\n\n        real_amb_count = 0\n        out_explanations: List[Dict[str, Any]] = []\n        \n        if isinstance(sentence_explanations, list):\n            for ex in sentence_explanations:\n                try:\n                    if not isinstance(ex, dict):\n                        continue\n                    \n                    if _should_filter_explanation(ex, span_th, u_th):\n                        continue\n                    \n                    s_val = float(ex.get(\"span\", 0.0) or ex.get(\"span_pred\", 0.0) or 0.0)\n                    u_val = float(ex.get(\"uncertainty\", 0.0) or 0.0)\n                    is_real = (s_val > span_th) or (u_val > u_th)\n                    \n                    if is_real:\n                        real_amb_count += 1\n                    \n                    raw_tok = (ex.get(\"token\") or ex.get(\"ambiguous_word\") or \n                              ex.get(\"token_value\") or ex.get(\"word\") or \"\")\n                    tok_str = str(raw_tok)\n                    tok_clean = tok_str.lstrip(\"‚ñÅ\").lstrip(\"ƒ†\").replace(\"</w>\", \"\").strip()\n                    \n                    if _normalize_fn and tok_clean:\n                        try:\n                            tok_clean = _normalize_fn(tok_clean)\n                        except Exception:\n                            pass\n\n                    out_explanations.append({\n                        \"ambiguous_word\": tok_clean,\n                        \"position\": ex.get(\"token_idx\", ex.get(\"position\", ex.get(\"word_idx\", \"N/A\"))),\n                        \"explanation\": (ex.get(\"explanation\", \"\") or ex.get(\"explain\", \"\") or \n                                       ex.get(\"text\", \"\") or ex.get(\"rationale\", \"\") or \"\"),\n                        \"uncertainty\": float(u_val),\n                        \"span\": float(s_val),\n                        \"is_real_amb\": bool(is_real),\n                    })\n                except Exception:\n                    if _VERBOSE_LOGGING:\n                        traceback.print_exc()\n                    continue\n\n        result = {\n            \"input_sentence\": input_sentence,\n            \"translation\": translation,\n            \"ambiguous_words_detected\": int(real_amb_count),\n            \"explanations\": out_explanations,\n        }\n        return result\n\n    except Exception as e:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return {\n            \"input_sentence\": input_sentence,\n            \"translation\": \"\",\n            \"ambiguous_words_detected\": 0,\n            \"explanations\": [],\n            \"error\": str(e)[:200],\n        }\n\n\n# ==================================================================\n# üî• FIX #16 & #18: Fallback IndicBART generation\n# ==================================================================\ndef _fallback_indicbart_generate(\n    indicbart_model,\n    tokenizer,\n    enc: Dict,\n    device: torch.device,\n    input_sentence: str\n) -> str:\n    \"\"\"\n    Fallback direct IndicBART generation when Cell 6's generate() fails.\n    \"\"\"\n    forced_id = _force_english_bos(tokenizer, indicbart_model)\n    orig_use_cache = None\n    \n    try:\n        if hasattr(indicbart_model, \"config\"):\n            orig_use_cache = getattr(indicbart_model.config, \"use_cache\", None)\n            indicbart_model.config.use_cache = True\n    except Exception:\n        orig_use_cache = None\n\n    generated = None\n    try:\n        try:\n            pad_id = getattr(tokenizer, \"pad_token_id\", None) or getattr(tokenizer, \"eos_token_id\", None) or 1\n            generated = indicbart_model.generate(\n                enc.get(\"input_ids\"),\n                attention_mask=enc.get(\"attention_mask\"),\n                max_length=min(_MAX_LENGTH, 64),\n                num_beams=2,\n                early_stopping=True,\n                pad_token_id=int(pad_id),\n                forced_bos_token_id=forced_id if forced_id is not None else getattr(indicbart_model.config, \"forced_bos_token_id\", None),\n            )\n        except RuntimeError as gen_err:\n            if \"out of memory\" in str(gen_err).lower():\n                if torch.cuda.is_available():\n                    try:\n                        torch.cuda.empty_cache()\n                    except Exception:\n                        pass\n                try:\n                    small_enc = tokenizer(input_sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=min(_MAX_LENGTH, 48))\n                    small_enc = _to_device_batch(small_enc, device)\n                    pad_id = getattr(tokenizer, \"pad_token_id\", None) or getattr(tokenizer, \"eos_token_id\", None) or 1\n                    generated = indicbart_model.generate(\n                        small_enc.get(\"input_ids\"),\n                        attention_mask=small_enc.get(\"attention_mask\"),\n                        max_length=min(_MAX_LENGTH, 48),\n                        num_beams=1,\n                        early_stopping=True,\n                        pad_token_id=int(pad_id),\n                        forced_bos_token_id=forced_id if forced_id is not None else getattr(indicbart_model.config, \"forced_bos_token_id\", None),\n                    )\n                except Exception as e2:\n                    if _VERBOSE_LOGGING:\n                        print(\"[CELL8] Fallback generation also failed:\", str(e2))\n                    generated = None\n            else:\n                raise\n    finally:\n        try:\n            if hasattr(indicbart_model, \"config\") and orig_use_cache is not None:\n                indicbart_model.config.use_cache = orig_use_cache\n        except Exception:\n            pass\n\n    if generated is not None:\n        try:\n            if isinstance(generated, (list, tuple)):\n                return tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n            elif isinstance(generated, torch.Tensor):\n                if generated.dim() == 2:\n                    return tokenizer.decode(generated[0], skip_special_tokens=True)\n                else:\n                    return tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n            else:\n                return str(generated)\n        except Exception:\n            try:\n                return tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n            except Exception:\n                if _VERBOSE_LOGGING:\n                    print(\"[CELL8] Decode failed for generated; returning empty translation\")\n                return \"\"\n    \n    return \"\"\n\n\n# ------------------------------------------------------------------------------\n# demonstrate_system: small runner that prints nicely\n# ------------------------------------------------------------------------------\ndef demonstrate_system(model, tokenizer, sentences: Optional[List[str]] = None):\n    if sentences is None:\n        sentences = [\n            \"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\",\n            \"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\",\n            \"‡¶™‡¶æ‡¶§‡¶æ ‡¶ù‡¶∞‡ßá ‡¶™‡¶°‡¶º‡ßá‡¶õ‡ßá‡•§\",\n            \"‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï ‡¶ó‡ßá‡¶õ‡ßá‡¶®‡•§\",\n            \"‡¶Ü‡¶ú ‡¶≠‡¶æ‡¶≤ ‡¶Ü‡¶¨‡¶π‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ‡•§\",\n        ]\n    print(\"=\" * 80)\n    print(\"TATN DEMO: translating and listing DSCD/TRG explanations\")\n    print(\"=\" * 80)\n    for s in sentences:\n        print(f\"\\nInput: {s}\")\n        res = translate_with_explanations(model, tokenizer, s)\n        print(\"Translation:\", res.get(\"translation\", \"\"))\n        print(\"Ambiguous words detected (real):\", res.get(\"ambiguous_words_detected\", 0))\n        if res.get(\"explanations\"):\n            for idx, ex in enumerate(res[\"explanations\"], 1):\n                print(f\"  {idx}. word='{ex['ambiguous_word']}' pos={ex['position']} span={ex['span']:.3f} U={ex['uncertainty']:.3f} real={ex['is_real_amb']}\")\n                explanation_text = ex.get(\"explanation\", \"\")\n                if explanation_text:\n                    print(\"     \", explanation_text[:200])\n        else:\n            print(\"  No explanations\")\n    print(\"=\" * 80)\n\n\n# ==============================================================================\n# üî¨ FIX #5: dscd_discovery_warmup (FIXED src_texts ‚Üí src_text + IndicBART)\n# ==============================================================================\ndef dscd_discovery_warmup(model, tokenizer, num_sents: int = 8000, batch_size: int = 64, max_len: Optional[int] = None):\n    \"\"\"\n    Warm-up DSCD by processing many sentences to build prototype stores.\n    \n    Updated to use Cell 6's forward() method and proper attribute access for IndicBART.\n    \"\"\"\n    if max_len is None:\n        max_len = _MAX_LENGTH\n\n    core = model.module if (_USE_MULTI_GPU and hasattr(model, \"module\")) else model\n    dscd = getattr(core, \"dscd\", None)\n    \n    if dscd is None:\n        print(\"[WARMUP] No DSCD attached to model; skipping.\")\n        return\n\n    print(\"[WARMUP] Starting DSCD discovery warmup...\")\n    orig_enable = getattr(dscd, \"enable_training_clustering\", False)\n    orig_n_min = getattr(dscd, \"n_min\", None)\n    orig_buffer = getattr(dscd, \"buffer_size\", None)\n\n    try:\n        dscd.enable_training_clustering = True\n        dscd.n_min = max(3, int(getattr(dscd, \"n_min\", 5)))\n        dscd.buffer_size = max(200, int(getattr(dscd, \"buffer_size\", 300)))\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n\n    texts = []\n    try:\n        if \"load_and_preprocess_optimized\" in globals():\n            pairs = load_and_preprocess_optimized(num_sents)\n            texts = [bn for (bn, _) in pairs][:num_sents]\n        else:\n            base = [\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\", \"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\", \"‡¶™‡¶æ‡¶§‡¶æ ‡¶ù‡¶∞‡ßá ‡¶™‡¶°‡¶º‡ßá‡¶õ‡ßá‡•§\", \"‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï ‡¶ó‡ßá‡¶õ‡ßá‡¶®‡•§\"]\n            while len(texts) < num_sents:\n                texts.extend(base)\n            texts = texts[:num_sents]\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        texts = [\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\"] * num_sents\n\n    processed = 0\n    core.eval()\n    \n    with torch.inference_mode():\n        for i in range(0, len(texts), batch_size):\n            batch = texts[i:i + batch_size]\n            try:\n                enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len)\n                enc = _to_device_batch(enc, _DEVICE)\n                \n                try:\n                    # ‚Üê FIX #5: Use src_text (singular) not src_texts\n                    core.forward(\n                        input_ids=enc.get(\"input_ids\"),\n                        attention_mask=enc.get(\"attention_mask\"),\n                        src_text=batch,  # ‚Üê FIXED: singular src_text\n                        labels=None\n                    )\n                except Exception as e:\n                    if _VERBOSE_LOGGING and i == 0:\n                        print(f\"[WARMUP] Forward failed (first batch): {e}\")\n                \n                processed += len(batch)\n                if _VERBOSE_LOGGING and ((i // batch_size) % 10 == 0):\n                    print(f\"[WARMUP] processed {processed}/{len(texts)} ({processed/len(texts)*100:.1f}%)\")\n            \n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(\"[WARMUP] batch failed:\", str(e))\n                    traceback.print_exc()\n                continue\n\n    try:\n        stores = None\n        if hasattr(dscd, \"prototype_stores\"):\n            stores = dscd.prototype_stores\n        elif hasattr(dscd, \"word_stores\"):\n            stores = dscd.word_stores\n        elif hasattr(dscd, \"stores\"):\n            stores = dscd.stores\n        \n        if stores:\n            num_types = len(stores)\n            total_protos = sum(store.size if hasattr(store, 'size') else len(getattr(store, 'centroids', [])) for store in stores.values())\n            multi = sum(1 for store in stores.values() if (store.size if hasattr(store, 'size') else len(getattr(store, 'centroids', []))) >= 2)\n            print(f\"[WARMUP] Prototype discovery: word_types={num_types}, total_protos={total_protos}, multi_sense={multi}\")\n        else:\n            print(\"[WARMUP] No prototype stores found\")\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n    finally:\n        try:\n            dscd.enable_training_clustering = orig_enable\n            if orig_n_min is not None:\n                dscd.n_min = orig_n_min\n            if orig_buffer is not None:\n                dscd.buffer_size = orig_buffer\n            print(\"[WARMUP] Restored DSCD configuration\")\n        except Exception:\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n\n\n# ==============================================================================\n# üî¨ FIX #7, #8: Validation Sample Preparation & BLEU/chrF++ Evaluation\n# ==============================================================================\ndef prepare_validation_samples(num_samples=100):\n    \"\"\"\n    Prepare validation samples for BLEU calculation in Cell 7.\n    Returns list of (source, target) tuples.\n    \"\"\"\n    try:\n        if \"load_and_preprocess_optimized\" in globals():\n            pairs = load_and_preprocess_optimized(num_samples + 1000)\n            # Skip first 1000 for validation (use separate data)\n            val_pairs = pairs[1000:1000+num_samples]\n            # Format: (Bengali source, English target) for bn‚Üíen translation\n            return [(bn, en) for (bn, en) in val_pairs]\n        else:\n            print(\"[VAL-PREP] Warning: load_and_preprocess_optimized not found, using fallback\")\n            fallback = [\n                (\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\", \"I turned off the tap.\"),\n                (\"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\", \"Tomorrow I will buy books.\"),\n                (\"‡¶™‡¶æ‡¶§‡¶æ ‡¶ù‡¶∞‡ßá ‡¶™‡¶°‡¶º‡ßá‡¶õ‡ßá‡•§\", \"The leaves have fallen.\"),\n                (\"‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï ‡¶ó‡ßá‡¶õ‡ßá‡¶®‡•§\", \"He went to the bank.\"),\n                (\"‡¶Ü‡¶ú ‡¶≠‡¶æ‡¶≤ ‡¶Ü‡¶¨‡¶π‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ‡•§\", \"Good weather today.\"),\n            ]\n            # Repeat to reach num_samples\n            result = []\n            while len(result) < num_samples:\n                result.extend(fallback)\n            return result[:num_samples]\n    except Exception as e:\n        print(f\"[VAL-PREP] Error: {e}\")\n        return []\n\n\ndef evaluate_bleu_chrf(model, tokenizer, test_pairs, max_length=48, device=None):\n    \"\"\"\n    Evaluate BLEU and chrF++ scores on test pairs.\n    Returns dict with 'bleu' and 'chrf' scores.\n    \"\"\"\n    if device is None:\n        device = _DEVICE\n    \n    predictions = []\n    references = []\n    \n    model.eval()\n    core = model.module if hasattr(model, 'module') else model\n    \n    print(f\"[EVAL] Evaluating on {len(test_pairs)} test samples...\")\n    \n    with torch.inference_mode():\n        for idx, (src, ref) in enumerate(test_pairs):\n            try:\n                if idx % 20 == 0:\n                    print(f\"[EVAL] Progress: {idx}/{len(test_pairs)}\")\n                \n                result = translate_with_explanations(model, tokenizer, src, device=device)\n                pred = result.get('translation', '')\n                \n                predictions.append(pred)\n                references.append(ref)\n                \n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[EVAL] Error on sample {idx}: {e}\")\n                predictions.append(\"\")\n                references.append(ref)\n    \n    # Calculate BLEU\n    bleu_score = 0.0\n    if _HAS_SACREBLEU:\n        try:\n            bleu = sacrebleu.corpus_bleu(predictions, [references])\n            bleu_score = bleu.score\n            print(f\"[EVAL] BLEU: {bleu_score:.2f}\")\n        except Exception as e:\n            print(f\"[EVAL] sacrebleu BLEU failed: {e}\")\n            bleu_score = 0.0\n    \n    # Calculate chrF++\n    chrf_score = 0.0\n    if _HAS_SACREBLEU:\n        try:\n            chrf = sacrebleu.corpus_chrf(predictions, [references])\n            chrf_score = chrf.score\n            print(f\"[EVAL] chrF++: {chrf_score:.2f}\")\n        except Exception as e:\n            print(f\"[EVAL] sacrebleu chrF++ failed: {e}\")\n            chrf_score = 0.0\n    \n    # Fallback BLEU calculation\n    if not _HAS_SACREBLEU or bleu_score == 0.0:\n        print(\"[EVAL] Using fallback BLEU calculation...\")\n        total_overlap = 0.0\n        for pred, ref in zip(predictions, references):\n            pred_words = set(pred.lower().split())\n            ref_words = set(ref.lower().split())\n            if ref_words:\n                overlap = len(pred_words & ref_words) / len(ref_words)\n                total_overlap += overlap * 100\n        bleu_score = total_overlap / len(predictions) if predictions else 0.0\n        print(f\"[EVAL] Fallback BLEU: {bleu_score:.2f}\")\n    \n    return {\n        'bleu': bleu_score,\n        'chrf': chrf_score,\n        'predictions': predictions,\n        'references': references\n    }\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Cell 8: Model Init, Optimizer, Scheduler & Evaluation (IndicBART-READY - 20 FIXES)\")\nprint(\"=\" * 80)\nprint(\"üî• IndicBART-SPECIFIC FIXES (5 NEW):\")\nprint(\" FIX #16: üî• CRITICAL - Replace m2m100_model with indicbart_model references\")\nprint(\" FIX #17: üî• CRITICAL - Update all print messages for IndicBART\")\nprint(\" FIX #18: üî• CRITICAL - Handle IndicBART language token format (<2en>)\")\nprint(\" FIX #19: Import IndicBART-specific configs from Cell 0\")\nprint(\" FIX #20: Update freeze_model_layers for IndicBART architecture\")\nprint()\nprint(\"üî¨ RESEARCH-BACKED FIXES (15 PRESERVED):\")\nprint(\" FIX #1:  Added optimizer setup with AdamW\")\nprint(\" FIX #2:  Added scheduler setup (inverse_sqrt + warmup)\")\nprint(\" FIX #3:  Added layer freezing function\")\nprint(\" FIX #4:  Fixed src_texts ‚Üí src_text in translate_with_explanations\")\nprint(\" FIX #5:  Fixed src_texts ‚Üí src_text in dscd_discovery_warmup\")\nprint(\" FIX #6:  Added parameter group separation (4 LRs)\")\nprint(\" FIX #7:  Added validation sample preparation\")\nprint(\" FIX #8:  Added BLEU/chrF++ evaluation functions\")\nprint(\" FIX #9:  Added checkpoint loading/resuming\")\nprint(\" FIX #10: Added best model loading utility\")\nprint(\" FIX #11: (Trainable params verified in freeze function)\")\nprint(\" FIX #12: (DataParallel handled in Cell 10)\")\nprint(\" FIX #13: (train_loader created in Cell 10)\")\nprint(\" FIX #14: (Training integration in Cell 10)\")\nprint(\" FIX #15: (Post-training evaluation in Cell 10)\")\nprint()\nprint(\"IndicBART Integration:\")\nprint(f\" ‚úì Model: IndicBART (ai4bharat/indic-bart)\")\nprint(f\" ‚úì Language tokens: <2{_TARGET_LANGUAGE}>\")\nprint(f\" ‚úì Source language: {_SOURCE_LANGUAGE}\")\nprint(f\" ‚úì Target language: {_TARGET_LANGUAGE}\")\nprint(f\" ‚úì Max length: {_MAX_LENGTH}\")\nprint()\nprint(\"Original Cell 8 compatibility preserved:\")\nprint(\" ‚úì translate_with_explanations() works with Cell 6\")\nprint(\" ‚úì demonstrate_system() unchanged\")\nprint(\" ‚úì dscd_discovery_warmup() works with Cell 6\")\nprint(\" ‚úì All defensive logic preserved\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"7Dxg7ck0H4J5","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:44.616580Z","iopub.execute_input":"2026-01-24T20:09:44.616895Z","iopub.status.idle":"2026-01-24T20:09:44.720514Z","shell.execute_reply.started":"2026-01-24T20:09:44.616867Z","shell.execute_reply":"2026-01-24T20:09:44.719851Z"}},"outputs":[{"name":"stdout","text":"[CELL8] ‚úÖ Imported transformers scheduler functions\n[CELL8] ‚úÖ Imported sacrebleu for BLEU/chrF++ evaluation\n[CELL8] Loading configuration from Cell 0...\n[CELL8] Configuration loaded:\n  Source language: bn\n  Target language: en\n  Max length: 48\n  Batch size: 48\n  Accumulation steps: 16\n  Epochs: 2\n  Learning rates: NMT=5e-05, Word=0.0001, PHI=1e-05, TRG=1e-05\n  Scheduler: linear\n  Warmup steps: 500\n  Layer freezing: 2 encoder + 2 decoder\n  Device: cuda\n  Multi-GPU: True (GPUs: 2)\n\n================================================================================\n‚úÖ Cell 8: Model Init, Optimizer, Scheduler & Evaluation (IndicBART-READY - 20 FIXES)\n================================================================================\nüî• IndicBART-SPECIFIC FIXES (5 NEW):\n FIX #16: üî• CRITICAL - Replace m2m100_model with indicbart_model references\n FIX #17: üî• CRITICAL - Update all print messages for IndicBART\n FIX #18: üî• CRITICAL - Handle IndicBART language token format (<2en>)\n FIX #19: Import IndicBART-specific configs from Cell 0\n FIX #20: Update freeze_model_layers for IndicBART architecture\n\nüî¨ RESEARCH-BACKED FIXES (15 PRESERVED):\n FIX #1:  Added optimizer setup with AdamW\n FIX #2:  Added scheduler setup (inverse_sqrt + warmup)\n FIX #3:  Added layer freezing function\n FIX #4:  Fixed src_texts ‚Üí src_text in translate_with_explanations\n FIX #5:  Fixed src_texts ‚Üí src_text in dscd_discovery_warmup\n FIX #6:  Added parameter group separation (4 LRs)\n FIX #7:  Added validation sample preparation\n FIX #8:  Added BLEU/chrF++ evaluation functions\n FIX #9:  Added checkpoint loading/resuming\n FIX #10: Added best model loading utility\n FIX #11: (Trainable params verified in freeze function)\n FIX #12: (DataParallel handled in Cell 10)\n FIX #13: (train_loader created in Cell 10)\n FIX #14: (Training integration in Cell 10)\n FIX #15: (Post-training evaluation in Cell 10)\n\nIndicBART Integration:\n ‚úì Model: IndicBART (ai4bharat/indic-bart)\n ‚úì Language tokens: <2en>\n ‚úì Source language: bn\n ‚úì Target language: en\n ‚úì Max length: 48\n\nOriginal Cell 8 compatibility preserved:\n ‚úì translate_with_explanations() works with Cell 6\n ‚úì demonstrate_system() unchanged\n ‚úì dscd_discovery_warmup() works with Cell 6\n ‚úì All defensive logic preserved\n================================================================================\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ==============================================================================\n# CELL 9: COMPREHENSIVE TESTING & EVALUATION FOR DUAL-PATH TATN (IndicBART-READY)\n# ==============================================================================\n# Complete compatibility with fixed Cells 3, 6, 8:\n#\n# üî• IndicBART-SPECIFIC FIXES (4 NEW):\n# FIX #7: üî• Import SOURCE_LANGUAGE/TARGET_LANGUAGE from Cell 0 (not hardcoded)\n# FIX #8: üî• Update language references for IndicBART compatibility\n# FIX #9: üî• Print messages updated for IndicBART\n# FIX #10: üî• Test sentences remain Bengali (works for both models)\n#\n# üî¨ EXISTING FIXES (6 PRESERVED):\n# FIX #1: Updated DSCD attribute access for word-level DSCD (Cell 3)\n# FIX #2: Fixed model structure access for dual-path TATN (Cell 6)\n# FIX #3: Aligned with Cell 8's translate_with_explanations() signature\n# FIX #4: Added multiple fallbacks for prototype store access\n# FIX #5: CRITICAL - Handle size as property (Cell 3) before checking callable\n# FIX #6: All original defensive logic PRESERVED (exception handling, safe conversions)\n# ==============================================================================\n\nfrom typing import Dict, List, Tuple, Optional, Any\nimport torch\nimport traceback\nimport math\n\n# ==============================================================================\n# üî• FIX #7: Import Cell 0 configuration parameters (IndicBART-compatible)\n# ==============================================================================\nprint(\"[CELL9] Loading configuration from Cell 0...\")\n\n# Robust reads from globals (Cell 0)\ntry:\n    USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept (NameError, ValueError):\n    USE_MULTI_GPU = torch.cuda.is_available() and torch.cuda.device_count() > 1\n    print(\"[CELL9] WARNING: USE_MULTI_GPU not defined, using default\")\n_USE_MULTI_GPU = USE_MULTI_GPU\n\n# ==================================================================\n# üî• FIX #7 & #8: Language parameters (IndicBART-compatible)\n# ==================================================================\ntry:\n    SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, ValueError):\n    SOURCE_LANGUAGE = \"bn\"\n    print(\"[CELL9] WARNING: SOURCE_LANGUAGE not defined, using default 'bn'\")\n_SOURCE_LANGUAGE = SOURCE_LANGUAGE\n\ntry:\n    TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, ValueError):\n    TARGET_LANGUAGE = \"en\"\n    print(\"[CELL9] WARNING: TARGET_LANGUAGE not defined, using default 'en'\")\n_TARGET_LANGUAGE = TARGET_LANGUAGE\n\n# IndicBART uses language codes directly\n_BN_LANG = _SOURCE_LANGUAGE\n_EN_LANG = _TARGET_LANGUAGE\n\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, ValueError):\n    VERBOSE_LOGGING = False\n_VERBOSE_LOGGING = VERBOSE_LOGGING\n\n# Thresholds fallback consistent with earlier cells\ntry:\n    SPAN_THRESHOLD = float(SPAN_THRESHOLD)\nexcept (NameError, ValueError):\n    SPAN_THRESHOLD = 0.3\n    print(\"[CELL9] WARNING: SPAN_THRESHOLD not defined, using default 0.3\")\n_SPAN_THRESHOLD = SPAN_THRESHOLD\n\ntry:\n    TAU_LOW = float(TAU_LOW)\nexcept (NameError, ValueError):\n    TAU_LOW = 0.4\n    print(\"[CELL9] WARNING: TAU_LOW not defined, using default 0.4\")\n_UNCERTAINTY_THRESHOLD = TAU_LOW\n_TAU_LOW = TAU_LOW\n\n# Optional normalizer from Cell 1\n_normalize_fn = globals().get(\"normalize_bn_word\", None) or globals().get(\"normalize_indic_word\", None)\n\nprint(f\"[CELL9] Configuration loaded:\")\nprint(f\"  Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  Span threshold: {_SPAN_THRESHOLD}\")\nprint(f\"  Uncertainty threshold: {_UNCERTAINTY_THRESHOLD}\")\nprint(f\"  Multi-GPU: {_USE_MULTI_GPU}\")\nprint(f\"  Verbose logging: {_VERBOSE_LOGGING}\")\n\n\n# ------------------------------------------------------------------------------\n# üî¨ FIX #1, #4, #5: Cluster analysis helpers (FIXED FOR CELL 3 WORD-LEVEL DSCD)\n# ------------------------------------------------------------------------------\ndef _get_cluster_count(model: torch.nn.Module) -> int:\n    \"\"\"\n    Get cluster count from word-level DSCD (Cell 3 structure).\n    \n    Added fallbacks for different store attribute names.\n    \"\"\"\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        dscd = getattr(core, \"dscd\", None)\n        \n        if dscd is None:\n            return 0\n        \n        stores = None\n        if hasattr(dscd, \"prototype_stores\"):\n            stores = dscd.prototype_stores\n        elif hasattr(dscd, \"word_stores\"):\n            stores = dscd.word_stores\n        elif hasattr(dscd, \"stores\"):\n            stores = dscd.stores\n        \n        if not stores:\n            return 0\n        \n        return len(stores)\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return 0\n\n\ndef _get_dscd_stores(model: torch.nn.Module) -> Optional[Dict]:\n    \"\"\"\n    Safely get DSCD stores from model.\n    \n    Centralized store access with multiple fallbacks.\n    \"\"\"\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        dscd = getattr(core, \"dscd\", None)\n        \n        if dscd is None:\n            return None\n        \n        if hasattr(dscd, \"prototype_stores\"):\n            return dscd.prototype_stores\n        elif hasattr(dscd, \"word_stores\"):\n            return dscd.word_stores\n        elif hasattr(dscd, \"stores\"):\n            return dscd.stores\n        \n        return None\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return None\n\n\ndef _get_store_size(store: Any) -> int:\n    \"\"\"\n    Safely get size of a prototype store.\n    \n    üî¨ FIX #5: CRITICAL - Handle size as property first (Cell 3), then as method.\n    Multiple fallbacks for different store implementations.\n    \"\"\"\n    try:\n        if hasattr(store, \"size\"):\n            size_val = store.size\n            # Check if it's callable AFTER getting the value\n            if callable(size_val):\n                return int(size_val())\n            else:\n                return int(size_val)\n        elif hasattr(store, \"num_prototypes\"):\n            return int(store.num_prototypes)\n        elif hasattr(store, \"n_prototypes\"):\n            return int(store.n_prototypes)\n        elif hasattr(store, \"centroids\"):\n            centroids = getattr(store, \"centroids\", [])\n            if centroids is not None:\n                return len(centroids)\n        return 0\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return 0\n\n\ndef _get_store_counts(store: Any) -> int:\n    \"\"\"\n    Safely get total sample count for a store.\n    \n    Multiple fallbacks for different store implementations.\n    \"\"\"\n    try:\n        if hasattr(store, \"counts\"):\n            counts = getattr(store, \"counts\", [])\n            if counts is not None:\n                return int(sum(counts))\n        elif hasattr(store, \"total_count\"):\n            return int(store.total_count)\n        elif hasattr(store, \"n_samples\"):\n            return int(store.n_samples)\n        return 0\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return 0\n\n\ndef _print_top_clusters(model: torch.nn.Module, top_n: int = 5):\n    \"\"\"\n    Print top N clusters by sample count (homographs discovered by DSCD).\n    \n    Updated to use helper functions with multiple fallbacks.\n    \"\"\"\n    try:\n        prototype_stores = _get_dscd_stores(model)\n        \n        if not prototype_stores:\n            print(\"[CLUSTER] No clusters found yet\")\n            return\n\n        cluster_info = []\n        for token, store in prototype_stores.items():\n            try:\n                total_count = _get_store_counts(store)\n                n_protos = _get_store_size(store)\n                \n                mu = 0.0\n                tau = 0.0\n                if hasattr(store, \"mu\"):\n                    try:\n                        mu = float(getattr(store, \"mu\", 0.0) or 0.0)\n                    except Exception:\n                        mu = 0.0\n                \n                if hasattr(store, \"tau\"):\n                    try:\n                        tau = float(getattr(store, \"tau\", 0.0) or 0.0)\n                    except Exception:\n                        tau = 0.0\n                elif hasattr(store, \"dispersion\"):\n                    try:\n                        tau = float(getattr(store, \"dispersion\", 0.0) or 0.0)\n                    except Exception:\n                        tau = 0.0\n                \n                cluster_info.append({\n                    \"token\": token,\n                    \"count\": total_count,\n                    \"protos\": n_protos,\n                    \"mu\": mu,\n                    \"tau\": tau\n                })\n            except Exception:\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n                continue\n\n        cluster_info.sort(key=lambda x: x[\"count\"], reverse=True)\n\n        display_n = min(top_n, len(cluster_info))\n        print(f\"\\n[CLUSTER] Top {display_n} clusters (by sample count):\")\n        print(\"-\" * 90)\n        print(f\"{'Rank':<6}{'Token':<18}{'Count':<12}{'Protos':<10}{'Œº (mean)':<15}{'œÑ (dev)':<12}\")\n        print(\"-\" * 90)\n        for rank, info in enumerate(cluster_info[:display_n], 1):\n            tstr = str(info[\"token\"])\n            try:\n                if _normalize_fn and isinstance(tstr, str) and tstr.strip():\n                    tstr = _normalize_fn(tstr)\n            except Exception:\n                pass\n            \n            token_display = (tstr[:15] + \"..\") if len(tstr) > 17 else tstr\n            print(f\"{rank:<6}{token_display:<18}{info['count']:<12}{info['protos']:<10}{info['mu']:<15.6f}{info['tau']:<12.6f}\")\n        print(\"-\" * 90)\n        total_samples = sum(c[\"count\"] for c in cluster_info)\n        print(f\"Total clusters: {len(cluster_info)} | Total samples in clusters: {total_samples}\")\n    except Exception as e:\n        print(f\"[CLUSTER] Error: {type(e).__name__}: {str(e)[:200]}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n\n\ndef _print_cluster_stats(model: torch.nn.Module):\n    \"\"\"\n    Aggregate cluster statistics: totals and simple distribution values.\n    \n    Updated to use helper functions with multiple fallbacks.\n    \"\"\"\n    try:\n        prototype_stores = _get_dscd_stores(model)\n        \n        if not prototype_stores:\n            if _VERBOSE_LOGGING:\n                print(\"[CLUSTER-STATS] No prototype stores.\")\n            return\n\n        total_clusters = len(prototype_stores)\n        total_samples = 0\n        total_protos = 0\n        cluster_counts = []\n        \n        for token, store in prototype_stores.items():\n            try:\n                cnt = _get_store_counts(store)\n                protos = _get_store_size(store)\n                total_samples += cnt\n                total_protos += protos\n                cluster_counts.append(cnt)\n            except Exception:\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n                continue\n\n        avg_samples = (total_samples / total_clusters) if total_clusters > 0 else 0.0\n        avg_protos = (total_protos / total_clusters) if total_clusters > 0 else 0.0\n        max_samples = max(cluster_counts) if cluster_counts else 0\n        min_samples = min(cluster_counts) if cluster_counts else 0\n\n        print(\"\\n[CLUSTER-STATS] Cluster Statistics:\")\n        print(f\"  ‚Ä¢ Total clusters: {total_clusters}\")\n        print(f\"  ‚Ä¢ Total samples: {total_samples}\")\n        print(f\"  ‚Ä¢ Total prototypes: {total_protos}\")\n        print(f\"  ‚Ä¢ Avg samples/cluster: {avg_samples:.1f}\")\n        print(f\"  ‚Ä¢ Avg protos/cluster: {avg_protos:.1f}\")\n        print(f\"  ‚Ä¢ Max samples/cluster: {max_samples}\")\n        print(f\"  ‚Ä¢ Min samples/cluster: {min_samples}\")\n    except Exception as e:\n        print(f\"[CLUSTER-STATS] Error: {type(e).__name__}: {str(e)[:200]}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n\n\n# ------------------------------------------------------------------------------\n# üî¨ FIX #2, #3: Evaluation routine (FIXED FOR CELL 8 COMPATIBILITY)\n# ------------------------------------------------------------------------------\n@torch.inference_mode()\ndef comprehensive_post_training_testing(model: torch.nn.Module, tokenizer) -> Dict[str, Any]:\n    \"\"\"\n    Compact comprehensive evaluation:\n      - Translate curated Bengali sentences using Cell 8's translate_with_explanations()\n      - Count detected ambiguous tokens (real ambiguity: span>_SPAN_THRESHOLD or uncertainty>_UNCERTAINTY_THRESHOLD)\n      - Print explanations and DSCD prototype stats\n      - Optionally run small DSCD warmup if no prototypes and helper exists\n    \n    Returns aggregated metrics dict.\n    \n    üî¨ FIX #3: Updated to use Cell 8's translate_with_explanations() and Cell 6's model structure.\n    üî• FIX #10: Test sentences work for both M2M100 and IndicBART.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"COMPREHENSIVE POST-TRAINING EVALUATION (Cell 9 - IndicBART-Ready)\")\n    print(\"=\" * 80)\n\n    # ==================================================================\n    # üî• FIX #10: Test sentences (Bengali ‚Üí English) work for both models\n    # ==================================================================\n    test_sentences: List[Tuple[str, str]] = [\n        (\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\", \"‡¶ï‡¶≤ = tap / call\"),\n        (\"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\", \"‡¶ï‡¶æ‡¶≤ = tomorrow / yesterday\"),\n        (\"‡¶™‡¶æ‡¶§‡¶æ ‡¶ù‡¶∞‡ßá ‡¶™‡¶°‡¶º‡ßá‡¶õ‡ßá‡•§\", \"‡¶™‡¶æ‡¶§‡¶æ = leaf / page\"),\n        (\"‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï ‡¶ó‡ßá‡¶õ‡ßá‡¶®‡•§\", \"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï = bank / embankment\"),\n        (\"‡¶Ü‡¶ú ‡¶≠‡¶æ‡¶≤ ‡¶Ü‡¶¨‡¶π‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ‡•§\", \"Simple sentence (no ambiguity expected)\"),\n    ]\n\n    # ==================================================================\n    # üî¨ FIX #2: Access model correctly for dual-path TATN (Cell 6)\n    # ==================================================================\n    core_model = model.module if (_USE_MULTI_GPU and hasattr(model, \"module\")) else model\n    try:\n        core_model.eval()\n    except Exception:\n        pass\n\n    # Check for DSCD prototypes and run warmup if needed\n    try:\n        prototype_stores = _get_dscd_stores(core_model)\n        \n        if (not prototype_stores or len(prototype_stores) == 0) and \"dscd_discovery_warmup\" in globals():\n            try:\n                print(\"[EVAL] No DSCD prototypes found. Running moderate warmup (num_sents=2000)...\")\n                warmup_fn = globals().get(\"dscd_discovery_warmup\")\n                if callable(warmup_fn):\n                    warmup_fn(core_model, tokenizer, num_sents=2000, batch_size=64)\n            except Exception as e:\n                print(f\"[EVAL] DSCD warmup failed/skipped: {type(e).__name__}: {str(e)[:200]}\")\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n    except Exception:\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n\n    total_tests = len(test_sentences)\n    successful_translations = 0\n    total_explanations = 0\n    total_high_span = 0\n    total_real_ambiguous = 0\n\n    print(f\"\\n[EVAL] Running {total_tests} tests...\")\n    print(f\"[EVAL] Source language: {_SOURCE_LANGUAGE} ‚Üí Target language: {_TARGET_LANGUAGE}\")\n    print(\"-\" * 80)\n\n    # ==================================================================\n    # üî• FIX #8: Set source language for IndicBART\n    # ==================================================================\n    try:\n        if hasattr(tokenizer, \"src_lang\"):\n            tokenizer.src_lang = _BN_LANG\n    except Exception:\n        pass\n\n    def _is_real_amb(expl: Dict[str, Any]) -> bool:\n        \"\"\"Check if explanation indicates real ambiguity based on thresholds.\"\"\"\n        try:\n            s = float(expl.get(\"span\", 0.0) or expl.get(\"span_pred\", 0.0) or 0.0)\n            u = float(expl.get(\"uncertainty\", 0.0) or 0.0)\n            return (s > _SPAN_THRESHOLD) or (u > _UNCERTAINTY_THRESHOLD)\n        except Exception:\n            return False\n\n    # ==================================================================\n    # üî¨ FIX #3: Use Cell 8's translate_with_explanations()\n    # ==================================================================\n    if \"translate_with_explanations\" not in globals():\n        print(\"[EVAL] ERROR: translate_with_explanations not available. Run Cell 8 first.\")\n        return {\n            \"total_tests\": 0,\n            \"successful_translations\": 0,\n            \"success_rate_pct\": 0.0,\n            \"total_explanations\": 0,\n            \"total_high_span\": 0,\n            \"total_real_ambiguous\": 0,\n            \"dscd_stats\": {},\n            \"error\": \"translate_with_explanations not found\"\n        }\n\n    for idx, (src_text, desc) in enumerate(test_sentences, 1):\n        print(f\"\\nTest {idx}/{total_tests}: {desc}\")\n        print(\"=\" * 60)\n        try:\n            try:\n                translate_fn = globals().get(\"translate_with_explanations\")\n                result = translate_fn(\n                    model=core_model if core_model is not None else model,\n                    tokenizer=tokenizer,\n                    input_sentence=src_text,\n                    span_threshold=_SPAN_THRESHOLD,\n                    uncertainty_threshold=_UNCERTAINTY_THRESHOLD\n                )\n            except Exception as e:\n                print(f\"[EVAL] translate_with_explanations raised: {type(e).__name__}: {str(e)[:200]}\")\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n                result = {\n                    \"translation\": \"\",\n                    \"ambiguous_words_detected\": 0,\n                    \"explanations\": []\n                }\n\n            translation = str(result.get(\"translation\", \"\") or \"\")\n            try:\n                amb_count = int(result.get(\"ambiguous_words_detected\", 0) or 0)\n            except Exception:\n                amb_count = 0\n            explanations = result.get(\"explanations\", []) or []\n\n            print(f\"Input: {src_text}\")\n            print(f\"Translation: {translation}\")\n            print(f\"Ambiguous Words (real, counted): {amb_count}\")\n\n            if explanations:\n                print(\"\\nExplanations:\")\n                high_span_local = 0\n                real_amb_local = 0\n                \n                for j, expl in enumerate(explanations, 1):\n                    try:\n                        span_val = float(expl.get(\"span\", 0.0) or expl.get(\"span_pred\", 0.0) or 0.0)\n                        u_val = float(expl.get(\"uncertainty\", 0.0) or 0.0)\n                        marker = \"[SPAN>0.3]\" if span_val > _SPAN_THRESHOLD else \"           \"\n                        \n                        raw_word = (expl.get(\"ambiguous_word\") or expl.get(\"token\") or \n                                   expl.get(\"word\") or expl.get(\"token_value\") or \"N/A\")\n                        word = str(raw_word or \"N/A\")\n                        \n                        try:\n                            if _normalize_fn and isinstance(word, str) and word.strip():\n                                word = _normalize_fn(word)\n                        except Exception:\n                            pass\n                        \n                        pos = expl.get(\"position\", expl.get(\"token_idx\", expl.get(\"word_idx\", \"N/A\")))\n                        print(f\"  {j}. {marker} '{word}' @ pos {pos}\")\n                        print(f\"       U={u_val:.3f} | S={span_val:.3f}\")\n                        \n                        text = (expl.get(\"explanation\") or expl.get(\"explain\") or \n                               expl.get(\"text\") or expl.get(\"rationale\") or \"\")\n                        text = str(text or \"\")\n                        if len(text) > 120:\n                            text = text[:120] + \"...\"\n                        print(f\"       {text}\")\n                        \n                        if span_val > _SPAN_THRESHOLD:\n                            high_span_local += 1\n                        if _is_real_amb(expl):\n                            real_amb_local += 1\n                    except Exception:\n                        if _VERBOSE_LOGGING:\n                            traceback.print_exc()\n                        continue\n\n                total_explanations += len(explanations)\n                total_high_span += high_span_local\n                total_real_ambiguous += real_amb_local\n            else:\n                print(\"No explanations produced (likely high-confidence translation)\")\n\n            try:\n                bad_sentinels = {\"\", \"Error occurred\", \"Translation generation failed\", \"ERROR DURING TRANSLATION\"}\n                if translation and translation.strip() and translation not in bad_sentinels:\n                    successful_translations += 1\n                    print(\"Translation successful\")\n                else:\n                    print(\"Translation failed or empty\")\n            except Exception:\n                print(\"Translation check encountered an error; counted as failure\")\n\n        except Exception as e:\n            print(f\"[EVAL] Test {idx} failed: {type(e).__name__}: {str(e)[:200]}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n            continue\n\n        print(\"-\" * 60)\n\n    # Collect DSCD statistics\n    try:\n        dscd_stats = {\"total_words\": 0, \"multi_sense_words\": 0, \"total_prototypes\": 0}\n        \n        prototype_stores = _get_dscd_stores(core_model)\n        \n        if prototype_stores:\n            total_words = 0\n            multi = 0\n            total_protos = 0\n            \n            for key, store in prototype_stores.items():\n                try:\n                    sz = _get_store_size(store)\n                    total_words += 1\n                    total_protos += sz\n                    if sz >= 2:\n                        multi += 1\n                except Exception:\n                    if _VERBOSE_LOGGING:\n                        traceback.print_exc()\n                    continue\n            \n            dscd_stats = {\n                \"total_words\": total_words,\n                \"multi_sense_words\": multi,\n                \"total_prototypes\": total_protos\n            }\n        else:\n            dscd_stats = {\"total_words\": 0, \"multi_sense_words\": 0, \"total_prototypes\": 0}\n    except Exception as e:\n        print(f\"[EVAL] Could not retrieve DSCD stats: {type(e).__name__}: {str(e)[:200]}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        dscd_stats = {\"total_words\": 0, \"multi_sense_words\": 0, \"total_prototypes\": 0}\n\n    # Print summary\n    print(\"\\n\" + \"=\" * 80)\n    print(\"EVALUATION SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"Total tests: {total_tests}\")\n    print(f\"Successful translations: {successful_translations}\")\n    success_rate = (successful_translations / total_tests * 100.0) if total_tests > 0 else 0.0\n    print(f\"Success rate: {success_rate:.1f}%\")\n    print(\"\")\n    print(\"Ambiguity detection:\")\n    print(f\"  - Total explanations produced: {total_explanations}\")\n    print(f\"  - High-span (S>{_SPAN_THRESHOLD}): {total_high_span}\")\n    print(f\"  - Real ambiguous (S>{_SPAN_THRESHOLD} or U>{_UNCERTAINTY_THRESHOLD}): {total_real_ambiguous}\")\n    if total_tests > 0:\n        print(f\"  - Avg explanations/test: {total_explanations / total_tests:.2f}\")\n        print(f\"  - Avg real ambiguous/test: {total_real_ambiguous / total_tests:.2f}\")\n    print(\"\")\n    print(\"DSCD Prototype Discovery:\")\n    print(f\"  - Word types tracked: {dscd_stats.get('total_words', 0)}\")\n    print(f\"  - Multi-sense words (>=2 protos): {dscd_stats.get('multi_sense_words', 0)}\")\n    print(f\"  - Total prototypes: {dscd_stats.get('total_prototypes', 0)}\")\n    if dscd_stats.get(\"total_words\", 0) > 0:\n        avg_protos_word = dscd_stats.get(\"total_prototypes\", 0) / max(1, dscd_stats.get(\"total_words\", 1))\n        print(f\"  - Avg prototypes/word: {avg_protos_word:.2f}\")\n    print(\"=\" * 80)\n\n    return {\n        \"total_tests\": total_tests,\n        \"successful_translations\": successful_translations,\n        \"success_rate_pct\": success_rate,\n        \"total_explanations\": total_explanations,\n        \"total_high_span\": total_high_span,\n        \"total_real_ambiguous\": total_real_ambiguous,\n        \"dscd_stats\": dscd_stats,\n    }\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Cell 9: Comprehensive Testing & Evaluation (IndicBART-READY - 10 FIXES)\")\nprint(\"=\" * 80)\nprint(\"üî• IndicBART-SPECIFIC FIXES (4 NEW):\")\nprint(\" FIX #7: üî• Import SOURCE_LANGUAGE/TARGET_LANGUAGE from Cell 0\")\nprint(\" FIX #8: üî• Update language references for IndicBART compatibility\")\nprint(\" FIX #9: üî• Print messages updated for IndicBART\")\nprint(\" FIX #10: üî• Test sentences work for both M2M100 and IndicBART\")\nprint()\nprint(\"üî¨ EXISTING FIXES (6 PRESERVED):\")\nprint(\" FIX #1: Updated DSCD attribute access for Cell 3 word-level structure\")\nprint(\" FIX #2: Fixed model structure access for Cell 6 dual-path TATN\")\nprint(\" FIX #3: Aligned with Cell 8's translate_with_explanations() signature\")\nprint(\" FIX #4: Added multiple fallbacks for prototype store methods\")\nprint(\" FIX #5: CRITICAL - Handle size as property (Cell 3) before checking callable\")\nprint(\" FIX #6: All defensive logic preserved (exception handling, safe conversions)\")\nprint()\nprint(\"Helper functions:\")\nprint(\" ‚úì _get_cluster_count() - Count DSCD clusters\")\nprint(\" ‚úì _get_dscd_stores() - Safe store access with fallbacks\")\nprint(\" ‚úì _get_store_size() - Safe size access (property first, then callable)\")\nprint(\" ‚úì _get_store_counts() - Safe sample count access\")\nprint(\" ‚úì _print_top_clusters() - Display top N clusters\")\nprint(\" ‚úì _print_cluster_stats() - Display aggregate statistics\")\nprint(\" ‚úì comprehensive_post_training_testing() - Full evaluation suite\")\nprint()\nprint(\"IndicBART Integration:\")\nprint(f\" ‚úì Source language: {_SOURCE_LANGUAGE}\")\nprint(f\" ‚úì Target language: {_TARGET_LANGUAGE}\")\nprint(f\" ‚úì Test sentences: Bengali ‚Üí English\")\nprint(f\" ‚úì Works with both M2M100 and IndicBART\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"8uL574F8H4J5","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:44.721821Z","iopub.execute_input":"2026-01-24T20:09:44.722051Z","iopub.status.idle":"2026-01-24T20:09:44.776407Z","shell.execute_reply.started":"2026-01-24T20:09:44.722029Z","shell.execute_reply":"2026-01-24T20:09:44.775780Z"}},"outputs":[{"name":"stdout","text":"[CELL9] Loading configuration from Cell 0...\n[CELL9] Configuration loaded:\n  Source language: bn\n  Target language: en\n  Span threshold: 0.3\n  Uncertainty threshold: 0.4\n  Multi-GPU: True\n  Verbose logging: False\n\n================================================================================\n‚úÖ Cell 9: Comprehensive Testing & Evaluation (IndicBART-READY - 10 FIXES)\n================================================================================\nüî• IndicBART-SPECIFIC FIXES (4 NEW):\n FIX #7: üî• Import SOURCE_LANGUAGE/TARGET_LANGUAGE from Cell 0\n FIX #8: üî• Update language references for IndicBART compatibility\n FIX #9: üî• Print messages updated for IndicBART\n FIX #10: üî• Test sentences work for both M2M100 and IndicBART\n\nüî¨ EXISTING FIXES (6 PRESERVED):\n FIX #1: Updated DSCD attribute access for Cell 3 word-level structure\n FIX #2: Fixed model structure access for Cell 6 dual-path TATN\n FIX #3: Aligned with Cell 8's translate_with_explanations() signature\n FIX #4: Added multiple fallbacks for prototype store methods\n FIX #5: CRITICAL - Handle size as property (Cell 3) before checking callable\n FIX #6: All defensive logic preserved (exception handling, safe conversions)\n\nHelper functions:\n ‚úì _get_cluster_count() - Count DSCD clusters\n ‚úì _get_dscd_stores() - Safe store access with fallbacks\n ‚úì _get_store_size() - Safe size access (property first, then callable)\n ‚úì _get_store_counts() - Safe sample count access\n ‚úì _print_top_clusters() - Display top N clusters\n ‚úì _print_cluster_stats() - Display aggregate statistics\n ‚úì comprehensive_post_training_testing() - Full evaluation suite\n\nIndicBART Integration:\n ‚úì Source language: bn\n ‚úì Target language: en\n ‚úì Test sentences: Bengali ‚Üí English\n ‚úì Works with both M2M100 and IndicBART\n================================================================================\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ==============================================================================\n# CELL 10: TATN MAIN PIPELINE (RESEARCH-OPTIMIZED - 43 CRITICAL FIXES)\n# ==============================================================================\n\nimport os\nimport time\nimport traceback\nfrom typing import Tuple, Optional, Iterable, List, Dict, Any\nfrom datetime import datetime\n\nimport gc\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\nimport unicodedata\n\ntry:\n    from transformers import get_inverse_sqrt_schedule, get_linear_schedule_with_warmup\n    _HAS_TRANSFORMERS_SCHEDULER = True\nexcept Exception:\n    _HAS_TRANSFORMERS_SCHEDULER = False\n    print(\"[CELL10] Warning: transformers scheduler not available\")\n\nFREEZE_ENCODER = False\n\ndef _g(name, default):\n    return globals().get(name, default)\n\nprint(\"[CELL10] Loading configuration from Cell 0...\")\n\ntry:\n    MODEL_NAME = str(MODEL_NAME)\nexcept (NameError, ValueError):\n    MODEL_NAME = \"ai4bharat/IndicBART\"\n    print(\"[CELL10] WARNING: MODEL_NAME not defined, using default: ai4bharat/IndicBART\")\n_MODEL_NAME = MODEL_NAME\n\n_IS_INDICBART = \"indicbart\" in _MODEL_NAME.lower() or \"indic\" in _MODEL_NAME.lower()\n_IS_M2M100 = \"m2m100\" in _MODEL_NAME.lower()\n_MODEL_FAMILY = \"IndicBART\" if _IS_INDICBART else (\"M2M100\" if _IS_M2M100 else \"Unknown\")\n\nprint(f\"[CELL10] Model: {_MODEL_NAME}\")\nprint(f\"[CELL10] Detected family: {_MODEL_FAMILY}\")\n\ntry:\n    _USE_MULTI_GPU = bool(_g(\"USE_MULTI_GPU\", False))\n    _NUM_GPUS = int(_g(\"NUM_GPUS\", torch.cuda.device_count() if torch.cuda.is_available() else 0))\n    _DEVICE = _g(\"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n    \n    _SOURCE_LANGUAGE = _g(\"SOURCE_LANGUAGE\", \"bn\")\n    _TARGET_LANGUAGE = _g(\"TARGET_LANGUAGE\", \"en\")\n    _BN_LANG = _SOURCE_LANGUAGE\n    _EN_LANG = _TARGET_LANGUAGE\n    \n    _NUM_SAMPLES = int(_g(\"NUM_SAMPLES\", 300000))\n    _MAX_LENGTH = int(_g(\"MAX_LENGTH\", 128))\n    _MAX_WORD_LENGTH = int(_g(\"MAX_WORD_LENGTH\", 48))\n    _BATCH_SIZE = int(_g(\"BATCH_SIZE\", 8))\n    \n    _EPOCHS = int(_g(\"EPOCHS\", 10))\n    _ACCUMULATION_STEPS = int(_g(\"ACCUMULATION_STEPS\", 16))\n    _LR_NMT = float(_g(\"LR_NMT\", 5e-5))\n    _LR_WORD_EMBED = float(_g(\"LR_WORD_EMBED\", 1e-4))\n    _LR_PHI = float(_g(\"LR_PHI\", 1e-5))\n    _LR_TRG = float(_g(\"LR_TRG\", 1e-5))\n    _WARMUP_STEPS = int(_g(\"WARMUP_STEPS\", 500))\n    _GRAD_CLIP_NORM = float(_g(\"GRAD_CLIP_NORM\", 1.0))\n    _EARLY_STOPPING_PATIENCE = int(_g(\"EARLY_STOPPING_PATIENCE\", 2))\n    \n    _WEIGHT_DECAY = float(_g(\"WEIGHT_DECAY\", 0.01))\n    _ADAM_BETA1 = float(_g(\"ADAM_BETA1\", 0.9))\n    _ADAM_BETA2 = float(_g(\"ADAM_BETA2\", 0.999))\n    _ADAM_EPSILON = float(_g(\"ADAM_EPSILON\", 1e-8))\n    \n    _USE_LR_SCHEDULER = bool(_g(\"USE_LR_SCHEDULER\", True))\n    _SCHEDULER_TYPE = str(_g(\"SCHEDULER_TYPE\", \"linear\"))\n    _MIN_LEARNING_RATE = float(_g(\"MIN_LEARNING_RATE\", 1e-7))\n    \n    _FREEZE_ENCODER_LAYERS = int(_g(\"FREEZE_ENCODER_LAYERS\", 2))\n    _FREEZE_DECODER_LAYERS = int(_g(\"FREEZE_DECODER_LAYERS\", 2))\n    \n    _ENABLE_ASBN_TRAINING = bool(_g(\"ENABLE_ASBN_TRAINING\", True))\n    _VALIDATION_CHECK_INTERVAL = int(_g(\"VALIDATION_CHECK_INTERVAL\", 500))\n    _DSCD_WARMUP_SAMPLES = int(_g(\"DSCD_WARMUP_SAMPLES\", 1000))\n    _VERBOSE_LOGGING = bool(_g(\"VERBOSE_LOGGING\", False))\n    _HOMOGRAPH_WATCHLIST_BN = set(_g(\"HOMOGRAPH_WATCHLIST_BN\", {\"‡¶ï‡¶≤\", \"‡¶ï‡¶æ‡¶≤\", \"‡¶™‡¶æ‡¶§‡¶æ\", \"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï\", \"‡¶´‡¶≤\", \"‡¶Æ‡¶æ‡¶•‡¶æ\"}))\n    _WORD_VOCAB_SIZE = int(_g(\"WORD_VOCAB_SIZE\", 50000))\n    _WORD_EMBED_DIM = int(_g(\"WORD_EMBED_DIM\", 256))\n    \n    _CHECKPOINT_DIR = str(_g(\"CHECKPOINT_DIR\", \"/kaggle/working/\"))\n    _SAVE_CHECKPOINT_EVERY = int(_g(\"SAVE_CHECKPOINT_EVERY\", 1))\n    \nexcept Exception:\n    _NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    _USE_MULTI_GPU = _NUM_GPUS > 1\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = \"bn\"\n    _TARGET_LANGUAGE = \"en\"\n    _BN_LANG = _SOURCE_LANGUAGE\n    _EN_LANG = _TARGET_LANGUAGE\n    _NUM_SAMPLES = 300000\n    _MAX_LENGTH = 128\n    _MAX_WORD_LENGTH = 48\n    _BATCH_SIZE = 8\n    _EPOCHS = 10\n    _ACCUMULATION_STEPS = 16\n    _LR_NMT = 5e-5\n    _LR_WORD_EMBED = 1e-4\n    _LR_PHI = 1e-5\n    _LR_TRG = 1e-5\n    _WARMUP_STEPS = 500\n    _GRAD_CLIP_NORM = 1.0\n    _EARLY_STOPPING_PATIENCE = 2\n    _WEIGHT_DECAY = 0.01\n    _ADAM_BETA1 = 0.9\n    _ADAM_BETA2 = 0.999\n    _ADAM_EPSILON = 1e-8\n    _USE_LR_SCHEDULER = True\n    _SCHEDULER_TYPE = \"linear\"\n    _MIN_LEARNING_RATE = 1e-7\n    _FREEZE_ENCODER_LAYERS = 2\n    _FREEZE_DECODER_LAYERS = 2\n    _ENABLE_ASBN_TRAINING = True\n    _VALIDATION_CHECK_INTERVAL = 500\n    _DSCD_WARMUP_SAMPLES = 1000\n    _VERBOSE_LOGGING = False\n    _HOMOGRAPH_WATCHLIST_BN = {\"‡¶ï‡¶≤\", \"‡¶ï‡¶æ‡¶≤\", \"‡¶™‡¶æ‡¶§‡¶æ\", \"‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï\", \"‡¶´‡¶≤\", \"‡¶Æ‡¶æ‡¶•‡¶æ\"}\n    _WORD_VOCAB_SIZE = 50000\n    _WORD_EMBED_DIM = 256\n    _CHECKPOINT_DIR = \"/kaggle/working/\"\n    _SAVE_CHECKPOINT_EVERY = 1\n\nDSCD_N_MIN = int(globals().get(\"DSCD_N_MIN\", 2))\nDEFAULT_CLUSTER_MIN_SAMPLES = 4\n_CLUSTER_MIN_SAMPLES = int(globals().get(\"DSCD_MIN_CLUSTER_SAMPLES\", max(DEFAULT_CLUSTER_MIN_SAMPLES, DSCD_N_MIN * 2)))\n\nprint(f\"[CELL10-INIT] Model: {_MODEL_FAMILY} ({_MODEL_NAME})\")\nprint(f\"[CELL10-INIT] Languages: {_SOURCE_LANGUAGE} ‚Üí {_TARGET_LANGUAGE}\")\nprint(f\"[CELL10-INIT] DSCD thresholds: DSCD_N_MIN={DSCD_N_MIN}, _CLUSTER_MIN_SAMPLES={_CLUSTER_MIN_SAMPLES}\")\nprint(f\"[CELL10-INIT] Research config: EPOCHS={_EPOCHS}, ACCUMULATION_STEPS={_ACCUMULATION_STEPS}, LR_NMT={_LR_NMT}\")\nprint(f\"[CELL10-INIT] Warmup: {_WARMUP_STEPS} steps, Grad clip: {_GRAD_CLIP_NORM}, Early stopping: {_EARLY_STOPPING_PATIENCE} epochs\")\n\ndef _safe_clear_gpu_caches():\n    try:\n        if \"clear_all_gpu_caches\" in globals():\n            try:\n                clear_all_gpu_caches()\n            except Exception:\n                pass\n            return\n        if torch.cuda.is_available():\n            for i in range(torch.cuda.device_count()):\n                try:\n                    with torch.cuda.device(i):\n                        torch.cuda.empty_cache()\n                except Exception:\n                    pass\n    except Exception:\n        pass\n\ndef _norm_clean_token(tok: Optional[str]) -> str:\n    if tok is None:\n        return \"\"\n    s = str(tok)\n    for marker in ('‚ñÅ', '##', 'ƒ†', '@@'):\n        s = s.replace(marker, '')\n    s = s.strip()\n    s = unicodedata.normalize('NFKC', s)\n    return s\n\ndef _token_matches_homograph(token_key: str, homograph: str) -> bool:\n    clean_tok = _norm_clean_token(token_key)\n    clean_h = _norm_clean_token(homograph)\n    if not clean_tok or not clean_h:\n        return False\n    if clean_tok == clean_h:\n        return True\n    if clean_h in clean_tok:\n        return True\n    if clean_tok in clean_h:\n        return True\n    return False\n\ndef _get_store_size(store: Any) -> int:\n    try:\n        if hasattr(store, \"size\") and not callable(store.size):\n            return int(store.size)\n        elif hasattr(store, \"size\") and callable(store.size):\n            return int(store.size())\n        elif hasattr(store, \"__len__\"):\n            return int(len(store))\n        elif hasattr(store, \"num_prototypes\"):\n            return int(store.num_prototypes)\n        elif hasattr(store, \"n_prototypes\"):\n            return int(store.n_prototypes)\n        elif hasattr(store, \"centroids\"):\n            centroids = getattr(store, \"centroids\", [])\n            if centroids is not None:\n                return len(centroids)\n        return 0\n    except Exception:\n        return 0\n\ndef _verify_tokenizers_importable():\n    try:\n        import tokenizers\n        print(\"[CELL10] ‚úÖ tokenizers library successfully imported\")\n        return True, None\n    except ImportError as e:\n        error_msg = str(e)\n        print(f\"[CELL10] ‚ùå tokenizers library NOT importable: {error_msg}\")\n        return False, error_msg\n    except Exception as e:\n        print(f\"[CELL10] ‚ùå tokenizers import check failed: {e}\")\n        return False, str(e)\n\ndef _safe_tokenizer_from_pretrained(model_name: str, local_files_only: bool = False, prefer_fast: bool = True):\n    print(f\"\\n[TOKENIZER] Loading tokenizer for: {model_name}\")\n    \n    tokenizers_ok, tokenizers_error = _verify_tokenizers_importable()\n    \n    if not tokenizers_ok:\n        print(\"\\n\" + \"=\"*80)\n        print(\"‚ùå CRITICAL: tokenizers library is NOT importable!\")\n        print(\"=\"*80)\n        print(f\"Error: {tokenizers_error}\")\n        print(\"\\nThis means:\")\n        print(\"  ‚Ä¢ Package is installed but Python can't import it\")\n        print(\"  ‚Ä¢ Likely cause: corrupted install, wrong Python path, or dependency conflict\")\n        print(\"\\nüîß AUTOMATIC FIX:\")\n        print(\"  Run this in a new notebook cell:\")\n        print(\"  \")\n        print(\"  !pip uninstall tokenizers -y\")\n        print(\"  !pip install tokenizers --force-reinstall --no-cache-dir\")\n        print(\"  !pip install transformers==4.30.2 --force-reinstall --no-cache-dir\")\n        print(\"  \")\n        print(\"  Then RESTART the kernel and re-run Cells 0-11 in order.\")\n        print(\"\\n  Continuing with SLOW tokenizer fallback (may be slower but works)...\")\n        print(\"=\"*80)\n        prefer_fast = False\n    \n    try:\n        import transformers as _tf\n        from transformers import AutoTokenizer\n    except Exception as e_tf:\n        class _WhitespaceFallback:\n            def __init__(self):\n                self.pad_token = \"<pad>\"\n                self.pad_token_id = 0\n                self.unk_token = \"<unk>\"\n                self.unk_token_id = 1\n                self.eos_token_id = 2\n                self.vocab_size = 1000\n                self.src_lang = f\"{_SOURCE_LANGUAGE}_IN\" if \"indic\" in model_name.lower() else _SOURCE_LANGUAGE\n                self.tgt_lang = f\"{_TARGET_LANGUAGE}_XX\" if \"indic\" in model_name.lower() else _TARGET_LANGUAGE\n            \n            def __len__(self):\n                return int(self.vocab_size)\n            \n            def encode(self, text, add_special_tokens=True):\n                if text is None:\n                    return []\n                return text.split()\n            \n            def convert_ids_to_tokens(self, ids):\n                if ids is None:\n                    return []\n                out = []\n                for x in ids:\n                    if isinstance(x, str):\n                        out.append(x)\n                    else:\n                        out.append(str(x))\n                return out\n            \n            def decode(self, ids, skip_special_tokens=True, **kwargs):\n                if ids is None:\n                    return \"\"\n                if isinstance(ids, (list, tuple)):\n                    return \" \".join([str(t) for t in ids])\n                return str(ids)\n            \n            def batch_decode(self, ids_list, skip_special_tokens=True, **kwargs):\n                return [self.decode(ids, skip_special_tokens) for ids in ids_list]\n            \n            def __call__(self, texts, padding=False, truncation=False, return_tensors=None, max_length=None, add_special_tokens=True):\n                if isinstance(texts, str):\n                    texts = [texts]\n                input_ids = []\n                attention_mask = []\n                for t in texts:\n                    toks = (t or \"\").split()\n                    input_ids.append(toks)\n                    attention_mask.append([1] * len(toks))\n                if return_tensors == \"pt\":\n                    maxlen = max((len(x) for x in input_ids), default=0)\n                    import torch as _torch\n                    ids_t = _torch.zeros((len(input_ids), maxlen), dtype=_torch.long)\n                    mask_t = _torch.zeros((len(input_ids), maxlen), dtype=_torch.long)\n                    for i, row in enumerate(input_ids):\n                        for j, tok in enumerate(row):\n                            ids_t[i, j] = 0\n                            mask_t[i, j] = 1\n                    return {\"input_ids\": ids_t, \"attention_mask\": mask_t}\n                return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n        \n        if _VERBOSE_LOGGING:\n            print(\"WARNING: 'transformers' import failed in _safe_tokenizer_from_pretrained(). Using whitespace fallback.\")\n            print(f\"         Original error: {type(e_tf).__name__}: {e_tf}\")\n        return _WhitespaceFallback()\n\n    tried = []\n    \n    if not tokenizers_ok or not prefer_fast:\n        print(\"[TOKENIZER] tokenizers library unavailable, trying SLOW tokenizers...\")\n        \n        if \"indic\" in model_name.lower() or \"mbart\" in model_name.lower():\n            try:\n                from transformers import MBartTokenizer\n                print(\"[TOKENIZER] Attempting MBartTokenizer (slow version - no tokenizers library needed)...\")\n                tok = MBartTokenizer.from_pretrained(model_name, local_files_only=local_files_only)\n                print(\"[TOKENIZER] ‚úÖ Loaded MBartTokenizer (slow)\")\n                return tok\n            except Exception as e:\n                print(f\"[TOKENIZER] MBartTokenizer (slow) failed: {e}\")\n                tried.append((\"MBartTokenizer(slow)\", e))\n        \n        if \"m2m100\" in model_name.lower():\n            try:\n                from transformers import M2M100Tokenizer\n                print(\"[TOKENIZER] Attempting M2M100Tokenizer (slow version - no tokenizers library needed)...\")\n                tok = M2M100Tokenizer.from_pretrained(model_name, local_files_only=local_files_only)\n                print(\"[TOKENIZER] ‚úÖ Loaded M2M100Tokenizer (slow)\")\n                return tok\n            except Exception as e:\n                print(f\"[TOKENIZER] M2M100Tokenizer (slow) failed: {e}\")\n                tried.append((\"M2M100Tokenizer(slow)\", e))\n    \n    try:\n        print(f\"[TOKENIZER] Attempting AutoTokenizer (use_fast={prefer_fast})...\")\n        tok = AutoTokenizer.from_pretrained(model_name, use_fast=prefer_fast, local_files_only=local_files_only)\n        print(f\"[TOKENIZER] ‚úÖ Loaded AutoTokenizer (fast={prefer_fast})\")\n        return tok\n    except Exception as e_auto:\n        tried.append((f\"AutoTokenizer(use_fast={prefer_fast})\", e_auto))\n        print(f\"[TOKENIZER] AutoTokenizer (use_fast={prefer_fast}) failed: {e_auto}\")\n        \n        msg = str(e_auto).lower()\n        if \"sentencepiece\" in msg or \"tokenizers\" in msg or \"sacremoses\" in msg or \"alberttokenizerfast\" in msg.lower():\n            print(\"\\n\" + \"=\"*80)\n            print(\"‚ùå TOKENIZER LOADING FAILED - DEPENDENCY ERROR\")\n            print(\"=\"*80)\n            raise RuntimeError(\n                f\"Failed to instantiate tokenizer for '{model_name}'. \"\n                f\"This often happens because optional deps like 'sentencepiece' or 'tokenizers' are missing.\\n\"\n                f\"Please run: pip install transformers sentencepiece tokenizers\\n\"\n                f\"Then RESTART the kernel and re-run cells 0‚Üí10.\\n\\n\"\n                f\"Original tokenizer error: \\n{e_auto}\"\n            ) from e_auto\n\n    try:\n        opposite_fast = not prefer_fast\n        print(f\"[TOKENIZER] Attempting AutoTokenizer (use_fast={opposite_fast})...\")\n        tok = AutoTokenizer.from_pretrained(model_name, use_fast=opposite_fast, local_files_only=local_files_only)\n        print(f\"[TOKENIZER] ‚úÖ Loaded AutoTokenizer (fast={opposite_fast})\")\n        return tok\n    except Exception as e_slow:\n        tried.append((f\"AutoTokenizer(use_fast={opposite_fast})\", e_slow))\n        summary = \"; \".join([f\"{name}:{type(exc).__name__}\" for name, exc in tried])\n        \n        print(\"\\n\" + \"=\"*80)\n        print(\"‚ùå ALL TOKENIZER LOADING METHODS FAILED\")\n        print(\"=\"*80)\n        raise RuntimeError(\n            f\"No usable tokenizer class available for '{model_name}'. Tried: {summary}.\\n\"\n            f\"Make sure you have a compatible 'transformers' installed and the optional dependencies \"\n            f\"(sentencepiece, tokenizers) for the model.\\n\\n\"\n            f\"Suggested command:\\n\"\n            f\"  pip install transformers sentencepiece tokenizers\\n\"\n            f\"Then RESTART the kernel and re-run the notebook.\\n\\n\"\n            f\"Last error: {e_slow}\"\n        ) from e_slow\n\nclass _SimpleDataset(Dataset):\n    def __init__(self, pairs: Iterable[Tuple[str, str]], tokenizer, max_length: int = 128):\n        self.pairs = list(pairs)\n        self.tokenizer = tokenizer\n        self.max_length = int(max_length)\n    \n    def __len__(self):\n        return len(self.pairs)\n    \n    def __getitem__(self, idx):\n        src, tgt = self.pairs[idx]\n        try:\n            enc = self.tokenizer(src, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n            tgt_enc = self.tokenizer(tgt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n            input_ids = enc[\"input_ids\"].squeeze(0)\n            attention_mask = enc[\"attention_mask\"].squeeze(0)\n            labels = tgt_enc[\"input_ids\"].squeeze(0)\n        except Exception:\n            toks = (src or \"\").split()\n            L = min(len(toks), self.max_length)\n            import torch as _torch\n            input_ids = _torch.zeros(self.max_length, dtype=_torch.long)\n            attention_mask = _torch.zeros(self.max_length, dtype=_torch.long)\n            for i in range(L):\n                input_ids[i] = 0\n                attention_mask[i] = 1\n            labels = input_ids.clone()\n        \n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n            \"src_text\": src\n        }\n\ndef initialize_environment():\n    print(\"[CELL10] Initializing environment...\")\n    if torch.cuda.is_available():\n        gcnt = torch.cuda.device_count()\n        print(f\"[CELL10] GPUs available: {gcnt}\")\n        for i in range(gcnt):\n            try:\n                name = torch.cuda.get_device_name(i)\n            except Exception:\n                name = \"Unknown GPU\"\n            try:\n                mem = torch.cuda.get_device_properties(i).total_memory / 1024 ** 3\n                print(f\"  - GPU {i}: {name} ({mem:.1f} GB)\")\n            except Exception:\n                print(f\"  - GPU {i}: {name} (mem unknown)\")\n        _safe_clear_gpu_caches()\n        if gcnt > 1:\n            print(\"[CELL10] Multi-GPU detected\")\n    else:\n        print(\"[CELL10] No GPU detected - running on CPU\")\n    return True\n\ndef main_pipeline() -> Tuple[object, object]:\n    print(\"=\" * 80)\n    print(f\"CELL10: TATN MAIN PIPELINE ({_MODEL_FAMILY} - 43 CRITICAL FIXES)\")\n    print(\"=\" * 80)\n\n    initialize_environment()\n\n    print(f\"[CELL10] Loading {_MODEL_FAMILY} tokenizer from {_MODEL_NAME}...\")\n    \n    try:\n        base_tokenizer = _safe_tokenizer_from_pretrained(_MODEL_NAME)\n    except RuntimeError as e:\n        print(\"\\n\" + \"=\"*80)\n        print(\"‚ùå Pipeline execution failed:\")\n        print(\"=\"*80)\n        print(str(e))\n        print(\"=\"*80)\n        return None, None\n    except Exception as e:\n        print(f\"\\n‚ùå Unexpected error loading tokenizer: {e}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return None, None\n    \n    try:\n        if _IS_INDICBART:\n            base_tokenizer.src_lang = f\"{_SOURCE_LANGUAGE}_IN\"\n            base_tokenizer.tgt_lang = f\"{_TARGET_LANGUAGE}_XX\"\n        else:\n            base_tokenizer.src_lang = _SOURCE_LANGUAGE\n    except Exception:\n        pass\n\n    try:\n        pad_id = getattr(base_tokenizer, \"pad_token_id\", None)\n        if pad_id is None and hasattr(base_tokenizer, \"add_special_tokens\"):\n            try:\n                base_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n            except Exception:\n                pass\n    except Exception:\n        pass\n\n    vocab_info = \"unknown\"\n    try:\n        if hasattr(base_tokenizer, \"vocab_size\") and getattr(base_tokenizer, \"vocab_size\") is not None:\n            vocab_info = int(getattr(base_tokenizer, \"vocab_size\"))\n        elif hasattr(base_tokenizer, \"__len__\"):\n            try:\n                vocab_info = int(len(base_tokenizer))\n            except Exception:\n                vocab_info = \"unknown\"\n        else:\n            vocab_info = \"unknown\"\n    except Exception:\n        vocab_info = \"unknown\"\n    print(f\"[CELL10] {_MODEL_FAMILY} tokenizer loaded (vocab size approx {vocab_info})\")\n\n    print(f\"[CELL10] Loading/preprocessing up to {_NUM_SAMPLES} samples...\")\n    if \"load_and_preprocess_optimized\" in globals():\n        try:\n            pairs = load_and_preprocess_optimized(_NUM_SAMPLES)\n        except Exception as e:\n            print(f\"[CELL10] load_and_preprocess_optimized failed: {e}; using fallback single example\")\n            pairs = [(\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\", \"I turned off the tap.\")]\n    else:\n        if _VERBOSE_LOGGING:\n            print(\"[CELL10] Warning: load_and_preprocess_optimized not found (Cell 2); using small fallback dataset\")\n        pairs = [(\"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\", \"I turned off the tap.\")]\n\n    print(f\"[CELL10] Loaded {len(pairs):,} translation pairs\")\n\n    bengali_word_tokenizer = None\n    print(\"=\" * 80)\n    print(\"üîß BUILDING WORD TOKENIZER VOCABULARY FROM DATASET\")\n    print(\"=\" * 80)\n    \n    if \"BengaliWordTokenizer\" in globals():\n        try:\n            BengaliWordTokenizer = globals()[\"BengaliWordTokenizer\"]\n            \n            bengali_word_tokenizer = BengaliWordTokenizer(\n                vocab_size=_WORD_VOCAB_SIZE,\n                language='bn'\n            )\n            \n            bengali_texts = [src for src, tgt in pairs]\n            \n            if len(bengali_texts) > 0:\n                print(f\"[CELL10] Building word vocabulary from {len(bengali_texts):,} Bengali texts...\")\n                \n                try:\n                    bengali_word_tokenizer.build_vocab_from_texts(\n                        texts=bengali_texts,\n                        min_frequency=2\n                    )\n                    actual_vocab_size = len(bengali_word_tokenizer.vocab)\n                    bengali_word_tokenizer.vocab_size = actual_vocab_size\n                    print(f\"[CELL10] ‚úÖ Word vocabulary built successfully!\")\n                    print(f\"         Vocabulary size: {actual_vocab_size:,} unique words\")\n                    \n                    watchlist_in_vocab = 0\n                    for word in _HOMOGRAPH_WATCHLIST_BN:\n                        if word in bengali_word_tokenizer.vocab:\n                            watchlist_in_vocab += 1\n                    print(f\"         Watchlist words in vocab: {watchlist_in_vocab}/{len(_HOMOGRAPH_WATCHLIST_BN)}\")\n                    \n                    if _VERBOSE_LOGGING and actual_vocab_size > 0:\n                        sample_words = list(bengali_word_tokenizer.vocab.keys())[:10]\n                        print(f\"         Sample words: {sample_words}\")\n                \n                except Exception as e:\n                    print(f\"[CELL10] ‚ùå ERROR: build_vocab_from_texts failed: {type(e).__name__}: {str(e)}\")\n                    if _VERBOSE_LOGGING:\n                        traceback.print_exc()\n                    \n                    print(\"[CELL10] üîß RECOVERY: Building vocabulary manually from texts...\")\n                    try:\n                        word_freq = {}\n                        for text in bengali_texts:\n                            words = text.split()\n                            for word in words:\n                                word_clean = word.strip()\n                                if word_clean:\n                                    word_freq[word_clean] = word_freq.get(word_clean, 0) + 1\n                        \n                        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n                        top_words = sorted_words[:_WORD_VOCAB_SIZE]\n                        \n                        added_count = 0\n                        for word, freq in top_words:\n                            if freq >= 2:\n                                if word not in bengali_word_tokenizer.vocab:\n                                    if bengali_word_tokenizer.next_id >= _WORD_VOCAB_SIZE:\n                                        print(f\"[CELL10] ‚ö†Ô∏è  Vocabulary full at {bengali_word_tokenizer.next_id} words, stopping manual build\")\n                                        break\n                                    \n                                    bengali_word_tokenizer.vocab[word] = bengali_word_tokenizer.next_id\n                                    bengali_word_tokenizer.inverse_vocab[bengali_word_tokenizer.next_id] = word\n                                    bengali_word_tokenizer.next_id += 1\n                                    added_count += 1\n                        \n                        for word in _HOMOGRAPH_WATCHLIST_BN:\n                            if word not in bengali_word_tokenizer.vocab:\n                                if bengali_word_tokenizer.next_id >= _WORD_VOCAB_SIZE:\n                                    print(f\"[CELL10] ‚ö†Ô∏è  Vocabulary full, skipping remaining watchlist words\")\n                                    break\n                                \n                                bengali_word_tokenizer.vocab[word] = bengali_word_tokenizer.next_id\n                                bengali_word_tokenizer.inverse_vocab[bengali_word_tokenizer.next_id] = word\n                                bengali_word_tokenizer.next_id += 1\n                                added_count += 1\n                        \n                        bengali_word_tokenizer.vocab_size = len(bengali_word_tokenizer.vocab)\n                        \n                        print(f\"[CELL10] ‚úÖ Manual vocabulary built successfully!\")\n                        print(f\"         Recovery vocab size: {len(bengali_word_tokenizer.vocab):,}\")\n                        print(f\"         Words added: {added_count:,}\")\n                        print(f\"         Final next_id: {bengali_word_tokenizer.next_id} (max: {_WORD_VOCAB_SIZE})\")\n                        print(f\"         vocab_size attribute: {bengali_word_tokenizer.vocab_size}\")\n                        \n                    except Exception as e2:\n                        print(f\"[CELL10] ‚ùå Manual vocabulary building also failed: {type(e2).__name__}: {str(e2)}\")\n                        bengali_word_tokenizer = None\n            else:\n                print(\"[CELL10] ‚ùå WARNING: No Bengali texts available for vocabulary building!\")\n                bengali_word_tokenizer = None\n            \n            if bengali_word_tokenizer is not None and len(getattr(bengali_word_tokenizer, 'vocab', {})) > 0:\n                try:\n                    globals()[\"word_tokenizer\"] = bengali_word_tokenizer\n                    globals()[\"bengali_word_tokenizer\"] = bengali_word_tokenizer\n                    globals()[\"tokenizer\"] = base_tokenizer\n                    globals()[\"m2m100_tokenizer\"] = base_tokenizer\n                    globals()[\"indicbart_tokenizer\"] = base_tokenizer\n                    print(\"[CELL10] ‚úÖ Global word_tokenizer set for DataLoader workers\")\n                    print(\"=\" * 80)\n                except Exception as e:\n                    print(f\"[CELL10] Warning: Could not set global word_tokenizer: {e}\")\n            else:\n                print(\"[CELL10] ‚ùå WARNING: Word tokenizer has empty vocabulary!\")\n                bengali_word_tokenizer = None\n                    \n        except Exception as e:\n            print(f\"[CELL10] ‚ùå CRITICAL ERROR: BengaliWordTokenizer initialization failed!\")\n            print(f\"         Error: {type(e).__name__}: {str(e)}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n            bengali_word_tokenizer = None\n    else:\n        print(\"[CELL10] ‚ùå ERROR: BengaliWordTokenizer not found (Cell 2 not run)!\")\n        print(\"         Word-level features will be DISABLED!\")\n        print(\"         DSCD homograph detection will NOT work!\")\n        bengali_word_tokenizer = None\n    \n    print(\"=\" * 80)\n\n    print(\"\\n[CELL10] Creating dataset...\")\n    if \"MemoryEfficientDataset\" in globals():\n        DatasetClass = globals()[\"MemoryEfficientDataset\"]\n        try:\n            dataset = DatasetClass(\n                pairs=pairs,\n                m2m_tokenizer=base_tokenizer,\n                word_tokenizer=bengali_word_tokenizer,\n                max_length=_MAX_LENGTH\n            )\n            print(f\"[CELL10] ‚úÖ Dataset created with Cell 2's MemoryEfficientDataset\")\n        except Exception as e:\n            print(f\"[CELL10] ‚ùå MemoryEfficientDataset constructor failed: {e}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n            print(\"[CELL10] Falling back to _SimpleDataset (word features disabled)\")\n            dataset = _SimpleDataset(pairs, base_tokenizer, max_length=_MAX_LENGTH)\n    else:\n        print(\"[CELL10] ‚ùå WARNING: MemoryEfficientDataset not present (Cell 2 not run)\")\n        print(\"         Using fallback _SimpleDataset (word features disabled)\")\n        dataset = _SimpleDataset(pairs, base_tokenizer, max_length=_MAX_LENGTH)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"üîç DATASET VERIFICATION (CRITICAL FOR DSCD)\")\n    print(\"=\" * 80)\n    try:\n        sample = dataset[0]\n        print(f\"Sample keys: {list(sample.keys())}\")\n        \n        if 'word_strings' in sample:\n            word_strings = sample['word_strings']\n            if word_strings and len(word_strings) > 0:\n                print(f\"‚úÖ SUCCESS: word_strings field present with {len(word_strings)} words\")\n                print(f\"   Sample words: {word_strings[:5]}\")\n                print(f\"   ‚Üí DSCD homograph detection: ENABLED\")\n            else:\n                print(f\"‚ùå CRITICAL ERROR: word_strings field is EMPTY!\")\n                print(f\"   word_strings value: {word_strings}\")\n                print(f\"   ‚Üí DSCD homograph detection: DISABLED\")\n                print(f\"   ‚Üí Root cause: Word tokenizer not passed to dataset OR build_vocab failed\")\n        else:\n            print(f\"‚ùå CRITICAL ERROR: word_strings field MISSING from dataset!\")\n            print(f\"   Available fields: {list(sample.keys())}\")\n            print(f\"   ‚Üí DSCD homograph detection: DISABLED\")\n            print(f\"   ‚Üí Root cause: Using fallback dataset OR Cell 2's dataset not properly configured\")\n            \n        if 'input_ids' in sample:\n            input_ids = sample['input_ids']\n            print(f\"‚úÖ input_ids field present (shape: {input_ids.shape if hasattr(input_ids, 'shape') else len(input_ids)})\")\n        \n        if 'src_text' in sample:\n            print(f\"‚úÖ src_text field present: '{sample['src_text'][:50]}...'\")\n            \n    except Exception as e:\n        print(f\"‚ùå Dataset verification failed: {type(e).__name__}: {str(e)}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n    print(\"=\" * 80 + \"\\n\")\n\n    batch_size = int(_BATCH_SIZE)\n    active_device_ids = list(range(_NUM_GPUS)) if (_USE_MULTI_GPU and _NUM_GPUS > 1) else []\n    if active_device_ids and batch_size < len(active_device_ids):\n        usable = max(1, batch_size)\n        active_device_ids = active_device_ids[:usable]\n        print(f\"[CELL10] Adjusting DataParallel devices to {len(active_device_ids)} due to small batch_size\")\n\n    try:\n        global BATCH_SIZE\n        BATCH_SIZE = batch_size\n    except Exception:\n        pass\n\n    collate_fn = None\n    if \"safe_collate\" in globals():\n        try:\n            collate_fn = globals()[\"safe_collate\"]\n            if not callable(collate_fn):\n                print(\"[CELL10] ‚ùå WARNING: safe_collate is not callable; using default collate\")\n                collate_fn = None\n            else:\n                print(\"[CELL10] ‚úÖ Using Cell 2's safe_collate (dual-path)\")\n        except Exception as e:\n            print(f\"[CELL10] ‚ùå WARNING: Error accessing safe_collate: {e}; using default collate\")\n            collate_fn = None\n    else:\n        print(\"[CELL10] ‚ùå WARNING: Cell 2's safe_collate not found; using default collate\")\n        print(\"         This may cause issues with word_strings batching!\")\n\n    print(\"\\n[CELL10] Creating DataLoader with FORCED safe_collate...\")\n    try:\n        loader_kwargs = {\n            \"dataset\": dataset,\n            \"batch_size\": batch_size,\n            \"shuffle\": True,\n            \"num_workers\": 0,\n            \"pin_memory\": torch.cuda.is_available(),\n            \"drop_last\": False\n        }\n        if collate_fn is not None:\n            loader_kwargs[\"collate_fn\"] = collate_fn\n            print(\"[CELL10] ‚úÖ Collate function set: safe_collate\")\n        else:\n            print(\"[CELL10] ‚ö†Ô∏è  WARNING: No collate function available!\")\n        \n        train_loader = DataLoader(**loader_kwargs)\n        print(\"[CELL10] ‚úÖ DataLoader created with explicit safe_collate\")\n    except Exception as e:\n        print(f\"[CELL10] ‚ùå DataLoader construction failed: {e}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        \n        loader_kwargs = {\n            \"dataset\": dataset,\n            \"batch_size\": batch_size,\n            \"shuffle\": True,\n            \"num_workers\": 0\n        }\n        train_loader = DataLoader(**loader_kwargs)\n        print(\"[CELL10] ‚ö†Ô∏è  Created fallback DataLoader WITHOUT collate_fn!\")\n\n    try:\n        dataset_len = len(dataset)\n    except Exception:\n        dataset_len = \"unknown\"\n    try:\n        batches_count = len(train_loader)\n    except Exception:\n        batches_count = \"unknown\"\n    print(f\"[CELL10] Dataset: {dataset_len} examples, {batches_count} batches (batch_size={batch_size})\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"üîç CRITICAL: VERIFYING TRAIN_LOADER BEFORE TRAINING\")\n    print(\"=\" * 80)\n    \n    train_loader_has_word_data = False\n    try:\n        test_batch = next(iter(train_loader))\n        print(f\"\\n‚úÖ Train_loader batch test:\")\n        print(f\"   Batch type: {type(test_batch)}\")\n        \n        if isinstance(test_batch, dict):\n            print(f\"   Batch keys: {list(test_batch.keys())}\")\n            \n            has_word_ids = 'word_input_ids' in test_batch\n            has_word_mask = 'word_attention_mask' in test_batch\n            has_word_strings = 'word_strings' in test_batch\n            \n            print(f\"\\n   Word-level data check:\")\n            print(f\"      word_input_ids:        {'‚úÖ PRESENT' if has_word_ids else '‚ùå MISSING'}\")\n            print(f\"      word_attention_mask:   {'‚úÖ PRESENT' if has_word_mask else '‚ùå MISSING'}\")\n            print(f\"      word_strings:          {'‚úÖ PRESENT' if has_word_strings else '‚ùå MISSING'}\")\n            \n            if has_word_ids and isinstance(test_batch['word_input_ids'], torch.Tensor):\n                print(f\"      word_input_ids shape:  {test_batch['word_input_ids'].shape}\")\n            if has_word_strings and isinstance(test_batch['word_strings'], list):\n                print(f\"      word_strings length:   {len(test_batch['word_strings'])}\")\n                if len(test_batch['word_strings']) > 0 and isinstance(test_batch['word_strings'][0], list):\n                    if len(test_batch['word_strings'][0]) > 0:\n                        print(f\"      First sample words:    {test_batch['word_strings'][0][:5]}\")\n            \n            if has_word_ids and has_word_mask and has_word_strings:\n                train_loader_has_word_data = True\n                print(f\"\\n‚úÖ‚úÖ‚úÖ SUCCESS: Train_loader provides complete word-level data!\")\n            else:\n                print(f\"\\n‚ùå‚ùå‚ùå CRITICAL ERROR: Word data MISSING from train_loader!\")\n                print(f\"   üîß APPLYING EMERGENCY FIX: Recreating train_loader...\")\n                \n                if collate_fn is not None:\n                    train_loader = DataLoader(\n                        dataset,\n                        batch_size=batch_size,\n                        shuffle=True,\n                        num_workers=0,\n                        pin_memory=torch.cuda.is_available(),\n                        collate_fn=collate_fn,\n                        drop_last=False\n                    )\n                    print(f\"   ‚úÖ Train_loader RECREATED with safe_collate\")\n                    \n                    test_batch_2 = next(iter(train_loader))\n                    if isinstance(test_batch_2, dict):\n                        has_word_ids_2 = 'word_input_ids' in test_batch_2\n                        has_word_mask_2 = 'word_attention_mask' in test_batch_2\n                        has_word_strings_2 = 'word_strings' in test_batch_2\n                        \n                        if has_word_ids_2 and has_word_mask_2 and has_word_strings_2:\n                            print(f\"   ‚úÖ‚úÖ‚úÖ FIXED! Word data now present after recreation!\")\n                            train_loader_has_word_data = True\n                        else:\n                            print(f\"   ‚ùå STILL BROKEN after recreation - dataset issue!\")\n                            print(f\"   ‚Üí Training will proceed but DSCD will NOT work!\")\n                else:\n                    print(f\"   ‚ùå Cannot apply fix: safe_collate not available!\")\n                    print(f\"   ‚Üí Cell 2 not properly executed!\")\n        else:\n            print(f\"   ‚ö†Ô∏è  Batch is not a dict (type: {type(test_batch)})\")\n\n    except StopIteration:\n        print(f\"‚ùå ERROR: train_loader is empty!\")\n    except Exception as e:\n        print(f\"‚ùå Batch test failed: {type(e).__name__}: {e}\")\n        if _VERBOSE_LOGGING:\n            import traceback\n            traceback.print_exc()\n\n    if not train_loader_has_word_data:\n        print(\"\\n\" + \"‚ö†Ô∏è \" * 40)\n        print(\"WARNING: TRAINING WILL PROCEED WITHOUT WORD-LEVEL DATA!\")\n        print(\"DSCD HOMOGRAPH DETECTION WILL NOT WORK!\")\n        print(f\"Model will train at baseline {_MODEL_FAMILY} quality only.\")\n        print(\"‚ö†Ô∏è \" * 40)\n    \n    print(\"=\" * 80)\n\n    print(\"\\n[CELL10] Initializing model...\")\n    if \"MemoryOptimizedTATNWithExplanations\" not in globals() and \"DualPathTATN\" not in globals():\n        print(\"[CELL10] ‚ùå CRITICAL ERROR: Model class not found (Cell 6)!\")\n        print(\"         Pipeline initialization ABORTED. Please run Cell 6 first.\")\n        return None, base_tokenizer\n    \n    try:\n        ModelClass = globals().get(\"MemoryOptimizedTATNWithExplanations\") or globals().get(\"DualPathTATN\")\n        \n        import inspect\n        model_init_signature = inspect.signature(ModelClass.__init__)\n        model_params = list(model_init_signature.parameters.keys())\n        \n        print(f\"[CELL10] Model class: {ModelClass.__name__}\")\n        print(f\"[CELL10] Detected init parameters: {model_params}\")\n        \n        model_init_kwargs = {}\n        \n        if \"indicbart_tokenizer\" in model_params:\n            model_init_kwargs[\"indicbart_tokenizer\"] = base_tokenizer\n            print(f\"[CELL10] Using parameter: indicbart_tokenizer\")\n        elif \"mbart_tokenizer\" in model_params:\n            model_init_kwargs[\"mbart_tokenizer\"] = base_tokenizer\n            print(f\"[CELL10] Using parameter: mbart_tokenizer\")\n        elif \"base_tokenizer\" in model_params:\n            model_init_kwargs[\"base_tokenizer\"] = base_tokenizer\n            print(f\"[CELL10] Using parameter: base_tokenizer\")\n        elif \"tokenizer\" in model_params:\n            model_init_kwargs[\"tokenizer\"] = base_tokenizer\n            print(f\"[CELL10] Using parameter: tokenizer\")\n        elif \"m2m100_tokenizer\" in model_params:\n            model_init_kwargs[\"m2m100_tokenizer\"] = base_tokenizer\n            print(f\"[CELL10] Using parameter: m2m100_tokenizer\")\n        else:\n            print(f\"[CELL10] ‚ö†Ô∏è  No tokenizer parameter found, trying positional arg\")\n        \n        if \"bengali_word_tokenizer\" in model_params:\n            model_init_kwargs[\"bengali_word_tokenizer\"] = bengali_word_tokenizer\n        elif \"word_tokenizer\" in model_params:\n            model_init_kwargs[\"word_tokenizer\"] = bengali_word_tokenizer\n        \n        if bengali_word_tokenizer is not None:\n            try:\n                word_vocab_size = len(bengali_word_tokenizer.vocab)\n                if \"word_vocab_size\" in model_params:\n                    model_init_kwargs[\"word_vocab_size\"] = word_vocab_size\n                if \"word_embed_dim\" in model_params:\n                    model_init_kwargs[\"word_embed_dim\"] = _WORD_EMBED_DIM\n                print(f\"[CELL10] Model will use word_vocab_size={word_vocab_size:,}, word_embed_dim={_WORD_EMBED_DIM}\")\n            except Exception as e:\n                print(f\"[CELL10] Warning: Could not get word vocab size: {e}\")\n        \n        if model_init_kwargs:\n            model_core = ModelClass(**model_init_kwargs)\n            print(f\"[CELL10] ‚úÖ Model initialized with keyword arguments ({_MODEL_FAMILY} base)\")\n        else:\n            model_core = ModelClass(base_tokenizer, bengali_word_tokenizer)\n            print(f\"[CELL10] ‚úÖ Model initialized with positional arguments ({_MODEL_FAMILY} base)\")\n        \n    except Exception as e:\n        print(f\"[CELL10] ‚ùå Model initialization failed: {type(e).__name__}: {str(e)}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        print(\"[CELL10] Attempting fallback initialization without word features...\")\n        try:\n            ModelClass = globals().get(\"MemoryOptimizedTATNWithExplanations\") or globals().get(\"DualPathTATN\")\n            \n            import inspect\n            model_init_signature = inspect.signature(ModelClass.__init__)\n            model_params = list(model_init_signature.parameters.keys())\n            \n            fallback_kwargs = {}\n            if \"indicbart_tokenizer\" in model_params:\n                fallback_kwargs[\"indicbart_tokenizer\"] = base_tokenizer\n            elif \"base_tokenizer\" in model_params:\n                fallback_kwargs[\"base_tokenizer\"] = base_tokenizer\n            elif \"tokenizer\" in model_params:\n                fallback_kwargs[\"tokenizer\"] = base_tokenizer\n            elif \"m2m100_tokenizer\" in model_params:\n                fallback_kwargs[\"m2m100_tokenizer\"] = base_tokenizer\n            \n            if fallback_kwargs:\n                model_core = ModelClass(**fallback_kwargs)\n            else:\n                model_core = ModelClass(base_tokenizer)\n            \n            print(f\"[CELL10] ‚úì Model initialized in fallback mode (no word features, {_MODEL_FAMILY} base)\")\n        except Exception as e2:\n            print(f\"[CELL10] ‚ùå Fallback initialization also failed: {e2}\")\n            print(f\"\\n[CELL10] üí° SOLUTION: Check Cell 6's DualPathTATN.__init__() parameter names\")\n            print(f\"    Expected one of: indicbart_tokenizer, base_tokenizer, tokenizer, m2m100_tokenizer\")\n            print(f\"    Cell 6 actually expects: {model_params if 'model_params' in locals() else 'unknown'}\")\n            return None, base_tokenizer\n\n    if active_device_ids and len(active_device_ids) > 1:\n        print(f\"[CELL10] Wrapping model in DataParallel on devices {active_device_ids}\")\n        model = nn.DataParallel(model_core, device_ids=active_device_ids)\n    else:\n        model = model_core\n        if _VERBOSE_LOGGING:\n            print(\"[CELL10] Single-GPU / CPU mode (no DataParallel)\")\n\n    try:\n        model = model.to(_DEVICE)\n    except Exception:\n        try:\n            core = model.module if hasattr(model, \"module\") else model\n            core.to(_DEVICE)\n        except Exception:\n            pass\n\n    core_model = model.module if hasattr(model, \"module\") else model\n\n    try:\n        base_model = None\n        if hasattr(core_model, \"m2m100_model\"):\n            base_model = core_model.m2m100_model\n        elif hasattr(core_model, \"indicbart_model\"):\n            base_model = core_model.indicbart_model\n        elif hasattr(core_model, \"mbart_model\"):\n            base_model = core_model.mbart_model\n        elif hasattr(core_model, \"base_model\"):\n            base_model = core_model.base_model\n        \n        if base_model is not None and hasattr(base_model, \"get_input_embeddings\"):\n            emb = base_model.get_input_embeddings()\n            current_emb = None\n            try:\n                current_emb = getattr(emb, \"num_embeddings\", None) or (emb.weight.shape[0] if hasattr(emb, \"weight\") else None)\n            except Exception:\n                current_emb = None\n            new_size = None\n            try:\n                if hasattr(base_tokenizer, \"vocab_size\") and getattr(base_tokenizer, \"vocab_size\") is not None:\n                    new_size = int(getattr(base_tokenizer, \"vocab_size\"))\n                elif hasattr(base_tokenizer, \"__len__\"):\n                    new_size = int(len(base_tokenizer))\n            except Exception:\n                new_size = None\n            if new_size and current_emb and int(current_emb) != int(new_size):\n                try:\n                    base_model.resize_token_embeddings(new_size)\n                    print(f\"[CELL10] Resized token embeddings: {current_emb} -> {new_size}\")\n                except Exception:\n                    if _VERBOSE_LOGGING:\n                        print(\"[CELL10] Warning: resize_token_embeddings failed; continuing\")\n    except Exception:\n        pass\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"APPLYING LAYER FREEZING (CELL 8 REQUIREMENT)\")\n    print(\"=\" * 80)\n    \n    if _FREEZE_ENCODER_LAYERS > 0 or _FREEZE_DECODER_LAYERS > 0:\n        if \"freeze_model_layers\" in globals():\n            try:\n                freeze_fn = globals()[\"freeze_model_layers\"]\n                freeze_fn(model, _FREEZE_ENCODER_LAYERS, _FREEZE_DECODER_LAYERS)\n                print(f\"[CELL10] ‚úÖ Layer freezing applied: enc={_FREEZE_ENCODER_LAYERS}, dec={_FREEZE_DECODER_LAYERS}\")\n            except Exception as e:\n                print(f\"[CELL10] ‚ùå freeze_model_layers failed: {type(e).__name__}: {str(e)}\")\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n        else:\n            print(\"[CELL10] ‚ùå WARNING: freeze_model_layers not found (Cell 8 not run)\")\n            print(\"         Layer freezing SKIPPED - training may be slower!\")\n    else:\n        print(\"[CELL10] Layer freezing disabled (both values = 0)\")\n    \n    print(\"=\" * 80)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"CREATING PARAMETER GROUPS (CELL 8 REQUIREMENT)\")\n    print(\"=\" * 80)\n    \n    param_groups = None\n    if \"create_parameter_groups\" in globals():\n        try:\n            create_param_fn = globals()[\"create_parameter_groups\"]\n            param_groups = create_param_fn(model)\n            print(f\"[CELL10] ‚úÖ Parameter groups created successfully\")\n        except Exception as e:\n            print(f\"[CELL10] ‚ùå create_parameter_groups failed: {type(e).__name__}: {str(e)}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n            param_groups = None\n    else:\n        print(\"[CELL10] ‚ùå WARNING: create_parameter_groups not found (Cell 8 not run)\")\n        print(\"         Using fallback single parameter group\")\n        param_groups = None\n    \n    if param_groups is None:\n        print(\"[CELL10] Creating fallback parameter group...\")\n        param_groups = [{'params': filter(lambda p: p.requires_grad, model.parameters()), 'lr': _LR_NMT}]\n    \n    print(\"=\" * 80)\n\n    print(f\"\\n[CELL10] Initializing AdamW optimizer with parameter groups...\")\n    try:\n        optimizer = torch.optim.AdamW(\n            param_groups,\n            lr=_LR_NMT,\n            betas=(_ADAM_BETA1, _ADAM_BETA2),\n            eps=_ADAM_EPSILON,\n            weight_decay=_WEIGHT_DECAY\n        )\n        \n        total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n        print(f\"[CELL10] ‚úÖ AdamW optimizer initialized\")\n        print(f\"         Trainable parameters: {total_trainable:,}\")\n        print(f\"         Weight decay: {_WEIGHT_DECAY}\")\n        print(f\"         Gradient clipping: {_GRAD_CLIP_NORM}\")\n        \n    except Exception as e:\n        print(f\"[CELL10] ‚ùå Optimizer initialization failed: {type(e).__name__}: {str(e)}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        return None, base_tokenizer\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"INITIALIZING LEARNING RATE SCHEDULER (CELL 8 REQUIREMENT)\")\n    print(\"=\" * 80)\n    \n    scheduler = None\n    if _USE_LR_SCHEDULER and _HAS_TRANSFORMERS_SCHEDULER:\n        try:\n            if _SCHEDULER_TYPE == \"inverse_sqrt\":\n                try:\n                    scheduler = get_inverse_sqrt_schedule(\n                        optimizer=optimizer,\n                        num_warmup_steps=_WARMUP_STEPS\n                    )\n                    print(f\"[CELL10] ‚úÖ inverse_sqrt scheduler initialized (warmup={_WARMUP_STEPS})\")\n                except Exception as e:\n                    print(f\"[CELL10] inverse_sqrt failed ({e}), using linear\")\n                    total_steps = len(train_loader) * _EPOCHS // _ACCUMULATION_STEPS\n                    scheduler = get_linear_schedule_with_warmup(\n                        optimizer=optimizer,\n                        num_warmup_steps=_WARMUP_STEPS,\n                        num_training_steps=total_steps\n                    )\n                    print(f\"[CELL10] ‚úÖ linear scheduler initialized (warmup={_WARMUP_STEPS}, total={total_steps})\")\n            else:\n                total_steps = len(train_loader) * _EPOCHS // _ACCUMULATION_STEPS\n                scheduler = get_linear_schedule_with_warmup(\n                    optimizer=optimizer,\n                    num_warmup_steps=_WARMUP_STEPS,\n                    num_training_steps=total_steps\n                )\n                print(f\"[CELL10] ‚úÖ linear scheduler initialized (warmup={_WARMUP_STEPS}, total={total_steps})\")\n        except Exception as e:\n            print(f\"[CELL10] ‚ùå Scheduler initialization failed: {type(e).__name__}: {str(e)}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n            scheduler = None\n    else:\n        print(\"[CELL10] LR scheduling disabled or scheduler not available\")\n    \n    print(\"=\" * 80)\n\n    print(\"\\n[CELL10] Preparing validation samples...\")\n    val_samples = []\n    if \"prepare_validation_samples\" in globals():\n        try:\n            prep_val_fn = globals()[\"prepare_validation_samples\"]\n            val_samples = prep_val_fn(num_samples=100)\n            print(f\"[CELL10] ‚úÖ Prepared {len(val_samples)} validation samples (Cell 8)\")\n        except Exception as e:\n            print(f\"[CELL10] prepare_validation_samples failed: {type(e).__name__}: {str(e)}\")\n            val_samples = []\n    else:\n        print(\"[CELL10] ‚ùå WARNING: prepare_validation_samples not found (Cell 8 not run)\")\n        print(\"         Validation metrics will NOT be calculated!\")\n        val_samples = []\n\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"STARTING TRAINING PHASE ({_EPOCHS} EPOCHS)\")\n    print(\"=\" * 80)\n    \n    trained_model = model\n    if \"train_memory_efficient_tatn\" in globals():\n        try:\n            train_fn = globals()[\"train_memory_efficient_tatn\"]\n            \n            trained_model = train_fn(\n                model=model,\n                tokenizer=base_tokenizer,\n                train_loader=train_loader,\n                optimizer=optimizer,\n                phi_optimizer=None,\n                scheduler=scheduler,\n                epochs=_EPOCHS,\n                accumulation_steps=_ACCUMULATION_STEPS,\n                validate_every=_VALIDATION_CHECK_INTERVAL,\n                enable_validation=bool(_VALIDATION_CHECK_INTERVAL > 0 and len(val_samples) > 0),\n                val_samples=val_samples\n            )\n            print(\"[CELL10] ‚úÖ Training completed\")\n        except Exception as e:\n            print(f\"[CELL10] ‚ùå Training failed: {type(e).__name__}: {str(e)[:200]}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n            trained_model = model\n    else:\n        print(\"[CELL10] ‚ùå WARNING: Training function not found (Cell 7). Skipping training.\")\n        trained_model = model\n\n    print(\"=\" * 80)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"LOADING BEST MODEL (CELL 8 REQUIREMENT)\")\n    print(\"=\" * 80)\n    \n    if \"load_best_model\" in globals():\n        try:\n            load_best_fn = globals()[\"load_best_model\"]\n            best_meta = load_best_fn(trained_model, _CHECKPOINT_DIR, _DEVICE)\n            if best_meta:\n                print(f\"[CELL10] ‚úÖ Loaded best model from epoch {best_meta.get('epoch', 'unknown')}\")\n                print(f\"         Loss: {best_meta.get('avg_epoch_loss', 0.0):.6f}\")\n            else:\n                print(\"[CELL10] No best model found, using final model\")\n        except Exception as e:\n            print(f\"[CELL10] load_best_model failed: {type(e).__name__}: {str(e)}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n    else:\n        print(\"[CELL10] ‚ùå WARNING: load_best_model not found (Cell 8 not run)\")\n        print(\"         Using final training checkpoint\")\n    \n    print(\"=\" * 80)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"DISCOVERY PHASE: Clustering DSCD buffers to create prototypes...\")\n    print(\"=\" * 80)\n\n    _safe_clear_gpu_caches()\n\n    try:\n        core_for_discovery = trained_model.module if hasattr(trained_model, 'module') else trained_model\n\n        if not hasattr(core_for_discovery, \"dscd\"):\n            raise RuntimeError(\"Trained model does not have a .dscd attribute (DSCD instance)\")\n\n        dscd = core_for_discovery.dscd\n        \n        if hasattr(dscd, 'force_sync_clustering'):\n            if not dscd.force_sync_clustering:\n                print(\"[DISCOVERY] ‚ö†Ô∏è  WARNING: DSCD not in sync mode! Setting force_sync_clustering=True\")\n                dscd.force_sync_clustering = True\n        \n        buffers_iter = {}\n        if hasattr(dscd, \"buffers\") and isinstance(dscd.buffers, dict):\n            buffers_iter = dscd.buffers\n        elif hasattr(dscd, \"word_buffers\") and isinstance(dscd.word_buffers, dict):\n            buffers_iter = dscd.word_buffers\n        else:\n            print(\"[DISCOVERY] ‚ùå WARNING: DSCD has no buffers attribute!\")\n            buffers_iter = {}\n\n        print(f\"[DISCOVERY] Found {len(buffers_iter)} words with buffered embeddings\")\n\n        clusterable_tokens: List[Tuple[str, int]] = []\n        for token_type, buffer in buffers_iter.items():\n            try:\n                buf_len = len(buffer)\n            except Exception:\n                buf_len = 0\n            if buf_len >= _CLUSTER_MIN_SAMPLES:\n                clusterable_tokens.append((token_type, buf_len))\n\n        if len(clusterable_tokens) == 0:\n            relaxed = []\n            for token_type, buffer in buffers_iter.items():\n                try:\n                    buf_len = len(buffer)\n                except Exception:\n                    buf_len = 0\n                if buf_len >= DSCD_N_MIN:\n                    relaxed.append((token_type, buf_len))\n            if relaxed:\n                print(f\"[DISCOVERY] No tokens >= {_CLUSTER_MIN_SAMPLES}. Relaxing threshold to DSCD_N_MIN={DSCD_N_MIN} (found {len(relaxed)})\")\n                clusterable_tokens = relaxed\n\n        clusterable_tokens.sort(key=lambda x: x[1], reverse=True)\n        MAX_TO_CLUSTER = min(500, max(1, len(clusterable_tokens)))\n        clusterable_tokens = clusterable_tokens[:MAX_TO_CLUSTER]\n\n        print(f\"[DISCOVERY] Found {len(clusterable_tokens)} tokens meeting threshold for clustering (threshold={_CLUSTER_MIN_SAMPLES})\")\n        \n        if clusterable_tokens and _VERBOSE_LOGGING:\n            print(f\"[DISCOVERY] Top 10 tokens by buffer size:\")\n            for i, (token, size) in enumerate(clusterable_tokens[:10], 1):\n                print(f\"  {i}. '{token}': {size} samples\")\n\n        if len(clusterable_tokens) == 0:\n            print(\"[DISCOVERY] ‚ùå CRITICAL ERROR: No tokens with sufficient samples!\")\n            print(\"         DSCD will NOT work. Possible causes:\")\n            print(\"         1. Word tokenizer not built (Cell 10 bug #3)\")\n            print(\"         2. Dataset doesn't have word_strings (Cell 10 bug #4)\")\n            print(\"         3. DSCD forward() not receiving word tokens (Cell 6 integration issue)\")\n            print(\"         4. Training didn't accumulate buffers (Cell 7 issue)\")\n        else:\n            clustered_count = 0\n            failed_count = 0\n            start_time = time.time()\n            \n            CLUSTERING_TIMEOUT = float(_g(\"CLUSTERING_TIMEOUT\", 3.0))\n            \n            for idx, (token_type, buffer_size) in enumerate(clusterable_tokens):\n                try:\n                    success = False\n                    token_start = time.time()\n                    \n                    if hasattr(dscd, \"_cluster_buffer_to_prototypes\"):\n                        try:\n                            success = dscd._cluster_buffer_to_prototypes(token_type)\n                        except Exception as e:\n                            if _VERBOSE_LOGGING:\n                                print(f\"  [WARN] _cluster_buffer_to_prototypes raised for token '{token_type}': {type(e).__name__}: {str(e)[:200]}\")\n                            success = False\n                    elif hasattr(dscd, \"_cluster_buffer_to_prototypes_hierarchical\"):\n                        try:\n                            success = dscd._cluster_buffer_to_prototypes_hierarchical(token_type)\n                        except Exception as e:\n                            if _VERBOSE_LOGGING:\n                                print(f\"  [WARN] Hierarchical clustering raised for token '{token_type}': {type(e).__name__}: {str(e)[:200]}\")\n                            success = False\n                    elif hasattr(dscd, \"cluster_buffer\"):\n                        try:\n                            success = dscd.cluster_buffer(token_type)\n                        except Exception as e:\n                            if _VERBOSE_LOGGING:\n                                print(f\"  [WARN] cluster_buffer raised for token '{token_type}': {type(e).__name__}: {str(e)[:200]}\")\n                            success = False\n                    else:\n                        if idx == 0:\n                            print(\"  [ERROR] DSCD instance has no known clustering method; skipping clustering.\")\n                        success = False\n                    \n                    token_elapsed = time.time() - token_start\n                    if token_elapsed > CLUSTERING_TIMEOUT:\n                        print(f\"  [WARN] Token '{token_type}' clustering timeout ({token_elapsed:.2f}s > {CLUSTERING_TIMEOUT}s)\")\n\n                    if success:\n                        clustered_count += 1\n                        if _VERBOSE_LOGGING and idx < 10:\n                            if hasattr(dscd, 'prototype_stores') and token_type in dscd.prototype_stores:\n                                store = dscd.prototype_stores[token_type]\n                                proto_count = _get_store_size(store)\n                                print(f\"  ‚úì '{token_type}': {proto_count} prototypes created\")\n                    else:\n                        failed_count += 1\n\n                    if (idx + 1) % 50 == 0:\n                        elapsed = time.time() - start_time\n                        print(f\"  Progress: {idx + 1}/{len(clusterable_tokens)} tokens processed \"\n                              f\"({clustered_count} successful, {failed_count} failed) \"\n                              f\"[{elapsed:.1f}s elapsed]\")\n\n                except Exception as e:\n                    failed_count += 1\n                    if failed_count <= 10:\n                        token_str = str(token_type)[:40]\n                        print(f\"  [Warn] Clustering failed for token '{token_str}': {type(e).__name__}: {str(e)[:200]}\")\n                    if _VERBOSE_LOGGING:\n                        traceback.print_exc()\n                    continue\n\n            prototype_stores = {}\n            if hasattr(dscd, \"prototype_stores\") and isinstance(dscd.prototype_stores, dict):\n                prototype_stores = dscd.prototype_stores\n            elif hasattr(dscd, \"word_stores\") and isinstance(dscd.word_stores, dict):\n                prototype_stores = dscd.word_stores\n            elif hasattr(dscd, \"stores\") and isinstance(dscd.stores, dict):\n                prototype_stores = dscd.stores\n            \n            try:\n                total_prototypes = 0\n                for store in prototype_stores.values():\n                    total_prototypes += _get_store_size(store)\n            except Exception:\n                total_prototypes = 0\n\n            try:\n                multi_sense_words = sum(1 for store in prototype_stores.values() if _get_store_size(store) >= 2)\n            except Exception:\n                multi_sense_words = 0\n\n            elapsed_total = time.time() - start_time\n\n            print(\"=\" * 80)\n            print(\"‚úì DISCOVERY PHASE COMPLETE\")\n            print(\"=\" * 80)\n            print(f\"  ‚Ä¢ Tokens processed: {len(clusterable_tokens)}\")\n            print(f\"  ‚Ä¢ Successfully clustered: {clustered_count}\")\n            print(f\"  ‚Ä¢ Failed: {failed_count}\")\n            print(f\"  ‚Ä¢ Total prototypes created: {total_prototypes}\")\n            print(f\"  ‚Ä¢ Multi-sense words (‚â•2 prototypes): {multi_sense_words}\")\n            print(f\"  ‚Ä¢ Time elapsed: {elapsed_total:.2f}s ({elapsed_total/60:.2f} min)\")\n            print(\"=\" * 80)\n\n            print(\"\\n[DISCOVERY] ‚úÖ Verifying homograph words were clustered:\")\n            print(\"-\" * 80)\n            homographs_found = 0\n            homographs_missing = 0\n\n            proto_map = {}\n            for token_key, store in prototype_stores.items():\n                try:\n                    nk = _norm_clean_token(token_key)\n                except Exception:\n                    nk = str(token_key)\n                if nk not in proto_map:\n                    proto_map[nk] = (token_key, store)\n\n            for homograph in (list(_HOMOGRAPH_WATCHLIST_BN) if _HOMOGRAPH_WATCHLIST_BN else []):\n                matched_store = None\n                matched_key = None\n                nh = _norm_clean_token(homograph)\n                if nh and nh in proto_map:\n                    matched_key, matched_store = proto_map[nh]\n                else:\n                    for nk, (orig_k, store) in proto_map.items():\n                        try:\n                            if _token_matches_homograph(orig_k, homograph):\n                                matched_key, matched_store = orig_k, store\n                                break\n                        except Exception:\n                            continue\n\n                if matched_store is not None:\n                    proto_count = _get_store_size(matched_store)\n                    homographs_found += 1\n                    marker = \"‚úÖ\" if proto_count >= 2 else \"‚ö†Ô∏è \"\n                    print(f\"  {marker} '{homograph}' ‚Üí '{matched_key}': {proto_count} prototype(s)\")\n                else:\n                    homographs_missing += 1\n                    print(f\"  ‚ùå '{homograph}': NOT FOUND in prototype stores\")\n\n            print(\"-\" * 80)\n            print(f\"Summary: {homographs_found} homographs found, {homographs_missing} missing\")\n            print(\"=\" * 80)\n\n    except RuntimeError as dscd_err:\n        print(f\"[DISCOVERY] ‚ùå CRITICAL ERROR: {dscd_err}\")\n        print(\"=\" * 80)\n    except Exception as e:\n        print(f\"[DISCOVERY] ‚ùå Discovery phase failed: {type(e).__name__}: {str(e)[:400]}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n        print(\"=\" * 80)\n\n    _safe_clear_gpu_caches()\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"COMPREHENSIVE EVALUATION (CELL 9 REQUIREMENT)\")\n    print(\"=\" * 80)\n    \n    if \"comprehensive_post_training_testing\" in globals():\n        try:\n            eval_fn = globals()[\"comprehensive_post_training_testing\"]\n            eval_results = eval_fn(trained_model, base_tokenizer)\n            print(\"[CELL10] ‚úÖ Comprehensive evaluation completed\")\n            \n            if isinstance(eval_results, dict):\n                print(f\"\\nüìä Evaluation Results:\")\n                print(f\"   ‚Ä¢ Total tests: {eval_results.get('total_tests', 0)}\")\n                print(f\"   ‚Ä¢ Successful translations: {eval_results.get('successful_translations', 0)}\")\n                print(f\"   ‚Ä¢ Success rate: {eval_results.get('success_rate_pct', 0.0):.1f}%\")\n                print(f\"   ‚Ä¢ Total explanations: {eval_results.get('total_explanations', 0)}\")\n                print(f\"   ‚Ä¢ Real ambiguous words: {eval_results.get('total_real_ambiguous', 0)}\")\n                \n                dscd_stats = eval_results.get('dscd_stats', {})\n                if dscd_stats:\n                    print(f\"\\n   DSCD Statistics:\")\n                    print(f\"   ‚Ä¢ Word types tracked: {dscd_stats.get('total_words', 0)}\")\n                    print(f\"   ‚Ä¢ Multi-sense words: {dscd_stats.get('multi_sense_words', 0)}\")\n                    print(f\"   ‚Ä¢ Total prototypes: {dscd_stats.get('total_prototypes', 0)}\")\n        except Exception as e:\n            print(f\"[CELL10] comprehensive_post_training_testing failed: {type(e).__name__}: {str(e)}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n    else:\n        print(\"[CELL10] ‚ùå WARNING: comprehensive_post_training_testing not found (Cell 9 not run)\")\n        print(\"         Evaluation SKIPPED!\")\n    \n    print(\"=\" * 80)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SAVING FINAL MODEL\")\n    print(\"=\" * 80)\n    \n    try:\n        final_model_path = os.path.join(_CHECKPOINT_DIR, \"tatn_final_model.pt\")\n        core_to_save = trained_model.module if hasattr(trained_model, \"module\") else trained_model\n        \n        torch.save({\n            'model_state_dict': core_to_save.state_dict(),\n            'model_family': _MODEL_FAMILY,\n            'model_name': _MODEL_NAME,\n            'word_vocab_size': _WORD_VOCAB_SIZE,\n            'word_embed_dim': _WORD_EMBED_DIM,\n            'source_language': _SOURCE_LANGUAGE,\n            'target_language': _TARGET_LANGUAGE\n        }, final_model_path)\n        \n        print(f\"[CELL10] ‚úÖ Final model saved to: {final_model_path}\")\n        \n        if bengali_word_tokenizer is not None:\n            word_tok_path = os.path.join(_CHECKPOINT_DIR, \"word_tokenizer.pt\")\n            try:\n                torch.save({\n                    'vocab': bengali_word_tokenizer.vocab,\n                    'inverse_vocab': bengali_word_tokenizer.inverse_vocab,\n                    'vocab_size': len(bengali_word_tokenizer.vocab),\n                    'language': 'bn'\n                }, word_tok_path)\n                print(f\"[CELL10] ‚úÖ Word tokenizer saved to: {word_tok_path}\")\n            except Exception as e:\n                print(f\"[CELL10] Warning: Could not save word tokenizer: {e}\")\n        \n    except Exception as e:\n        print(f\"[CELL10] ‚ùå Final model save failed: {type(e).__name__}: {str(e)}\")\n        if _VERBOSE_LOGGING:\n            traceback.print_exc()\n    \n    print(\"=\" * 80)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"‚úÖ PIPELINE EXECUTION COMPLETE\")\n    print(\"=\" * 80)\n    print(f\"\\nüìä Final Status:\")\n    print(f\"   ‚Ä¢ Model: {_MODEL_FAMILY} ({_MODEL_NAME})\")\n    print(f\"   ‚Ä¢ Languages: {_SOURCE_LANGUAGE} ‚Üí {_TARGET_LANGUAGE}\")\n    print(f\"   ‚Ä¢ Epochs trained: {_EPOCHS}\")\n    print(f\"   ‚Ä¢ Word tokenizer: {'‚úÖ ACTIVE' if bengali_word_tokenizer else '‚ùå DISABLED'}\")\n    print(f\"   ‚Ä¢ DSCD homograph detection: {'‚úÖ ENABLED' if train_loader_has_word_data else '‚ùå DISABLED'}\")\n    \n    try:\n        core = trained_model.module if hasattr(trained_model, \"module\") else trained_model\n        if hasattr(core, \"dscd\"):\n            prototype_stores = {}\n            if hasattr(core.dscd, \"prototype_stores\"):\n                prototype_stores = core.dscd.prototype_stores\n            elif hasattr(core.dscd, \"word_stores\"):\n                prototype_stores = core.dscd.word_stores\n            \n            if prototype_stores:\n                total_protos = sum(_get_store_size(store) for store in prototype_stores.values())\n                multi_sense = sum(1 for store in prototype_stores.values() if _get_store_size(store) >= 2)\n                print(f\"   ‚Ä¢ Prototype stores: {len(prototype_stores)} words\")\n                print(f\"   ‚Ä¢ Total prototypes: {total_protos}\")\n                print(f\"   ‚Ä¢ Multi-sense words: {multi_sense}\")\n    except Exception:\n        pass\n    \n    print(\"\\n\" + \"=\" * 80)\n    \n    return trained_model, base_tokenizer\n\nglobals()[\"main_pipeline\"] = main_pipeline\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Cell 10: TATN Main Pipeline (IndicBART-READY - 43 FIXES)\")\nprint(\"=\" * 80)\nprint(\"\\nüî• NEW FIXES #41-#43 (CRITICAL):\")\nprint(\"  ‚Ä¢ FIX #41: Update vocab_size after build_vocab_from_texts() succeeds\")\nprint(\"  ‚Ä¢ FIX #42: Add bounds checking in manual vocab building loop\")\nprint(\"  ‚Ä¢ FIX #43: Update vocab_size after manual recovery build completes\")\nprint(\"  ‚Ä¢ Prevents word IDs exceeding embedding layer capacity\")\nprint(\"  ‚Ä¢ Fixes CUDA assertion error during validation (step 512)\")\nprint(\"  ‚Ä¢ Synchronizes vocab_size attribute with actual vocabulary length\")\nprint(\"\\nüöÄ Ready to call main_pipeline()\")\nprint(\"=\" * 80)\n","metadata":{"id":"kEux2BVXH4J5","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:44.778142Z","iopub.execute_input":"2026-01-24T20:09:44.778473Z","iopub.status.idle":"2026-01-24T20:09:44.929269Z","shell.execute_reply.started":"2026-01-24T20:09:44.778449Z","shell.execute_reply":"2026-01-24T20:09:44.928563Z"}},"outputs":[{"name":"stdout","text":"[CELL10] Loading configuration from Cell 0...\n[CELL10] Model: ai4bharat/IndicBART\n[CELL10] Detected family: IndicBART\n[CELL10-INIT] Model: IndicBART (ai4bharat/IndicBART)\n[CELL10-INIT] Languages: bn ‚Üí en\n[CELL10-INIT] DSCD thresholds: DSCD_N_MIN=2, _CLUSTER_MIN_SAMPLES=4\n[CELL10-INIT] Research config: EPOCHS=2, ACCUMULATION_STEPS=16, LR_NMT=5e-05\n[CELL10-INIT] Warmup: 500 steps, Grad clip: 1.0, Early stopping: 2 epochs\n\n================================================================================\n‚úÖ Cell 10: TATN Main Pipeline (IndicBART-READY - 43 FIXES)\n================================================================================\n\nüî• NEW FIXES #41-#43 (CRITICAL):\n  ‚Ä¢ FIX #41: Update vocab_size after build_vocab_from_texts() succeeds\n  ‚Ä¢ FIX #42: Add bounds checking in manual vocab building loop\n  ‚Ä¢ FIX #43: Update vocab_size after manual recovery build completes\n  ‚Ä¢ Prevents word IDs exceeding embedding layer capacity\n  ‚Ä¢ Fixes CUDA assertion error during validation (step 512)\n  ‚Ä¢ Synchronizes vocab_size attribute with actual vocabulary length\n\nüöÄ Ready to call main_pipeline()\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ==============================================================================\n# CELL 11: MAIN EXECUTION WRAPPER (IndicBART-READY - 27 CRITICAL FIXES)\n# ==============================================================================\nfrom datetime import datetime, timezone\nimport os\nimport traceback\nimport math\nimport sys\nimport time\nimport gc\nimport torch\nfrom torch.utils.data import DataLoader\nfrom typing import Any, Optional, Dict, List, Tuple\n\ndef _safe_get(name: str, default: Any):\n    try:\n        return globals().get(name, default)\n    except Exception:\n        return default\n\ndef _safe_div_ceil(a: Any, b: Any) -> int:\n    try:\n        a_f = float(a)\n        b_f = float(b)\n        if b_f == 0:\n            return 0\n        return int(math.ceil(a_f / b_f))\n    except Exception:\n        return 0\n\ndef _is_model_like(obj: Any) -> bool:\n    try:\n        return hasattr(obj, \"forward\") or hasattr(obj, \"generate\") or hasattr(obj, \"state_dict\") or hasattr(obj, \"dscd\")\n    except Exception:\n        return False\n\ndef _is_tokenizer_like(obj: Any) -> bool:\n    try:\n        return hasattr(obj, \"decode\") or hasattr(obj, \"convert_ids_to_tokens\") or callable(getattr(obj, \"__call__\", None))\n    except Exception:\n        return False\n\ndef _unwrap_model(model: Any) -> Any:\n    try:\n        if hasattr(model, \"module\"):\n            return model.module\n        return model\n    except Exception:\n        return model\n\ndef _format_number(n: Any) -> str:\n    try:\n        return f\"{int(n):,}\"\n    except Exception:\n        return str(n)\n\ndef _format_time(seconds: float) -> str:\n    try:\n        if seconds < 60:\n            return f\"{seconds:.1f}s\"\n        elif seconds < 3600:\n            mins = seconds / 60\n            return f\"{mins:.1f}m\"\n        else:\n            hours = seconds / 3600\n            return f\"{hours:.1f}h\"\n    except Exception:\n        return str(seconds)\n\ndef check_and_install_dependencies():\n    print(\"\\n\" + \"=\" * 80)\n    print(\"üîß CHECKING DEPENDENCIES...\")\n    print(\"=\" * 80)\n    \n    missing_deps = []\n    \n    try:\n        import tokenizers\n        print(\"‚úÖ tokenizers library found\")\n    except ImportError:\n        print(\"‚ùå tokenizers library NOT found\")\n        missing_deps.append(\"tokenizers\")\n    \n    try:\n        import sentencepiece\n        print(\"‚úÖ sentencepiece library found\")\n    except ImportError:\n        print(\"‚ùå sentencepiece library NOT found\")\n        missing_deps.append(\"sentencepiece\")\n    \n    try:\n        import sacremoses\n        print(\"‚úÖ sacremoses library found\")\n    except ImportError:\n        print(\"‚ö†Ô∏è  sacremoses library NOT found (optional)\")\n        missing_deps.append(\"sacremoses\")\n    \n    try:\n        import transformers\n        print(f\"‚úÖ transformers library found (version: {transformers.__version__})\")\n    except ImportError:\n        print(\"‚ùå transformers library NOT found\")\n        missing_deps.append(\"transformers\")\n    \n    if missing_deps:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"üîß INSTALLING MISSING DEPENDENCIES...\")\n        print(\"=\" * 80)\n        \n        for dep in missing_deps:\n            try:\n                if dep == \"transformers\":\n                    install_cmd = f\"{sys.executable} -m pip install transformers==4.30.2 --quiet\"\n                else:\n                    install_cmd = f\"{sys.executable} -m pip install {dep} --quiet\"\n                \n                print(f\"Installing {dep}...\")\n                os.system(install_cmd)\n                print(f\"‚úÖ {dep} installed successfully\")\n            except Exception as e:\n                print(f\"‚ùå Failed to install {dep}: {e}\")\n                return False\n        \n        print(\"\\n\" + \"=\" * 80)\n        print(\"‚úÖ ALL DEPENDENCIES INSTALLED!\")\n        print(\"=\" * 80)\n        print(\"\\n‚ö†Ô∏è  IMPORTANT: You may need to RESTART the kernel for changes to take effect.\")\n        print(\"After restarting, re-run Cells 0-11 in order.\\n\")\n        \n        try:\n            import tokenizers\n            import sentencepiece\n            print(\"‚úÖ Verification successful - dependencies are now available!\")\n            return True\n        except ImportError as e:\n            print(f\"‚ùå Verification failed: {e}\")\n            print(\"\\n‚ö†Ô∏è  KERNEL RESTART REQUIRED!\")\n            print(\"Please restart the kernel and re-run Cells 0-11.\")\n            return False\n    \n    print(\"\\n‚úÖ All required dependencies are already installed!\")\n    return True\n\nPIPELINE_START_TIME = time.time()\n\nif __name__ == \"__main__\":\n    dependencies_ok = check_and_install_dependencies()\n    \n    if not dependencies_ok:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"‚ùå DEPENDENCY CHECK FAILED\")\n        print(\"=\" * 80)\n        print(\"\\nPlease manually run:\")\n        print(\"  !pip install transformers==4.30.2 sentencepiece tokenizers sacremoses\")\n        print(\"\\nThen RESTART the kernel and re-run Cells 0-11.\")\n        print(\"=\" * 80)\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"MEMORY-OPTIMIZED TATN FOR KAGGLE T4√ó2 (Cell 11 - IndicBART-READY)\")\n    print(\"=\" * 80)\n\n    _MODEL_NAME = _safe_get(\"MODEL_NAME\", \"ai4bharat/IndicBART\")\n    _SOURCE_LANGUAGE = _safe_get(\"SOURCE_LANGUAGE\", \"bn\")\n    _TARGET_LANGUAGE = _safe_get(\"TARGET_LANGUAGE\", \"en\")\n    \n    _IS_INDICBART = \"indicbart\" in _MODEL_NAME.lower() or \"indic\" in _MODEL_NAME.lower()\n    _IS_M2M100 = \"m2m100\" in _MODEL_NAME.lower()\n    _MODEL_FAMILY = \"IndicBART\" if _IS_INDICBART else (\"M2M100\" if _IS_M2M100 else \"Unknown\")\n    \n    print(f\"\\nü§ñ Model Configuration:\")\n    print(f\"   ‚Ä¢ Model: {_MODEL_NAME}\")\n    print(f\"   ‚Ä¢ Family: {_MODEL_FAMILY}\")\n    print(f\"   ‚Ä¢ Languages: {_SOURCE_LANGUAGE} ‚Üí {_TARGET_LANGUAGE}\")\n\n    _NUM_SAMPLES = _safe_get(\"NUM_SAMPLES\", 300000)\n    _DATA_SIZE = _safe_get(\"DATA_SIZE\", _NUM_SAMPLES)\n    _EPOCHS = _safe_get(\"EPOCHS\", 10)\n    _BATCH_SIZE = _safe_get(\"BATCH_SIZE\", 8)\n    _ACCUMULATION_STEPS = _safe_get(\"ACCUMULATION_STEPS\", 16)\n    _DEVICE = _safe_get(\"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n    \n    _LR_NMT = _safe_get(\"LR_NMT\", 5e-5)\n    _LR_WORD_EMBED = _safe_get(\"LR_WORD_EMBED\", 1e-4)\n    _LR_PHI = _safe_get(\"LR_PHI\", 1e-5)\n    _LR_TRG = _safe_get(\"LR_TRG\", 1e-5)\n    \n    _WARMUP_STEPS = _safe_get(\"WARMUP_STEPS\", 500)\n    _GRAD_CLIP_NORM = _safe_get(\"GRAD_CLIP_NORM\", 1.0)\n    _SCHEDULER_TYPE = _safe_get(\"SCHEDULER_TYPE\", \"linear\")\n    _USE_LR_SCHEDULER = _safe_get(\"USE_LR_SCHEDULER\", True)\n    _EARLY_STOPPING_PATIENCE = _safe_get(\"EARLY_STOPPING_PATIENCE\", 2)\n    _FREEZE_ENCODER_LAYERS = _safe_get(\"FREEZE_ENCODER_LAYERS\", 2)\n    _FREEZE_DECODER_LAYERS = _safe_get(\"FREEZE_DECODER_LAYERS\", 2)\n    _CHECKPOINT_DIR = _safe_get(\"CHECKPOINT_DIR\", \"/kaggle/working/\")\n    _SAVE_CHECKPOINT_EVERY = _safe_get(\"SAVE_CHECKPOINT_EVERY\", 1)\n    \n    _ENABLE_ASBN_TRAINING = _safe_get(\"ENABLE_ASBN_TRAINING\", True)\n    _ENABLE_TRG_INFERENCE = _safe_get(\"ENABLE_TRG_INFERENCE\", True)\n    _VALIDATION_CHECK_INTERVAL = _safe_get(\"VALIDATION_CHECK_INTERVAL\", 500)\n    _PERIODIC_DISCOVERY_FREQUENCY = _safe_get(\"PERIODIC_DISCOVERY_FREQUENCY\", 100)\n    _VERBOSE_LOGGING = _safe_get(\"VERBOSE_LOGGING\", False)\n    _USE_MULTI_GPU = _safe_get(\"USE_MULTI_GPU\", torch.cuda.is_available() and torch.cuda.device_count() > 1)\n    _NUM_GPUS = _safe_get(\"NUM_GPUS\", torch.cuda.device_count() if torch.cuda.is_available() else 0)\n    \n    _WEIGHT_DECAY = _safe_get(\"WEIGHT_DECAY\", 0.01)\n    _ADAM_BETA1 = _safe_get(\"ADAM_BETA1\", 0.9)\n    _ADAM_BETA2 = _safe_get(\"ADAM_BETA2\", 0.999)\n    \n    _MAX_LENGTH = _safe_get(\"MAX_LENGTH\", 128)\n    _MAX_WORD_LENGTH = _safe_get(\"MAX_WORD_LENGTH\", 48)\n    _NUM_WORKERS = _safe_get(\"NUM_WORKERS\", 0)\n    _PIN_MEMORY = _safe_get(\"PIN_MEMORY\", True)\n\n    user_login = os.getenv(\"KAGGLE_USERNAME\") or os.getenv(\"USER\") or _safe_get(\"CURRENT_USER\", \"manas0003\")\n    now_utc = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n    print(f\"User: {user_login}\")\n    print(f\"Started: {now_utc}\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"RESEARCH-BACKED CONFIGURATION\")\n    print(\"=\" * 80)\n    \n    print(\"\\nüìä Dataset & Training:\")\n    print(f\"   ‚Ä¢ Samples: {_format_number(_DATA_SIZE)}\")\n    print(f\"   ‚Ä¢ Epochs: {_EPOCHS}\")\n    print(f\"   ‚Ä¢ Batch Size: {_BATCH_SIZE}\")\n    print(f\"   ‚Ä¢ Accumulation Steps: {_ACCUMULATION_STEPS}\")\n    effective_batch = _BATCH_SIZE * _ACCUMULATION_STEPS\n    print(f\"   ‚Ä¢ Effective Batch Size: {effective_batch}\")\n    print(f\"   ‚Ä¢ Device: {_DEVICE}\")\n    print(f\"   ‚Ä¢ Multi-GPU: {'ENABLED' if _USE_MULTI_GPU else 'DISABLED'} ({_NUM_GPUS} GPU(s))\")\n    if _USE_MULTI_GPU and _NUM_GPUS > 0:\n        per_gpu = _safe_div_ceil(int(_BATCH_SIZE), int(max(1, _NUM_GPUS)))\n        print(f\"   ‚Ä¢ Batch per GPU: {per_gpu}\")\n    \n    print(\"\\nüéØ Learning Rates (4-Group Strategy):\")\n    print(f\"   ‚Ä¢ LR_NMT ({_MODEL_FAMILY} base): {_LR_NMT}\")\n    print(f\"   ‚Ä¢ LR_WORD_EMBED: {_LR_WORD_EMBED}\")\n    print(f\"   ‚Ä¢ LR_PHI (DSCD/ASBN): {_LR_PHI}\")\n    print(f\"   ‚Ä¢ LR_TRG (Explanations): {_LR_TRG}\")\n    print(f\"   ‚Ä¢ Weight Decay: {_WEIGHT_DECAY}\")\n    print(f\"   ‚Ä¢ Adam Betas: ({_ADAM_BETA1}, {_ADAM_BETA2})\")\n    \n    print(\"\\nüìà Optimization Strategy:\")\n    print(f\"   ‚Ä¢ Scheduler: {_SCHEDULER_TYPE.upper() if _USE_LR_SCHEDULER else 'DISABLED'}\")\n    print(f\"   ‚Ä¢ Warmup Steps: {_format_number(_WARMUP_STEPS)}\")\n    print(f\"   ‚Ä¢ Gradient Clipping: {_GRAD_CLIP_NORM}\")\n    print(f\"   ‚Ä¢ Early Stopping Patience: {_EARLY_STOPPING_PATIENCE} epochs\")\n    \n    print(\"\\nüîí Layer Freezing:\")\n    print(f\"   ‚Ä¢ Encoder Layers Frozen: {_FREEZE_ENCODER_LAYERS}\")\n    print(f\"   ‚Ä¢ Decoder Layers Frozen: {_FREEZE_DECODER_LAYERS}\")\n    \n    print(\"\\nüíæ Checkpointing:\")\n    print(f\"   ‚Ä¢ Checkpoint Directory: {_CHECKPOINT_DIR}\")\n    print(f\"   ‚Ä¢ Save Every: {_SAVE_CHECKPOINT_EVERY} epochs\")\n    print(f\"   ‚Ä¢ Validation Interval: {_format_number(_VALIDATION_CHECK_INTERVAL)} steps\")\n    \n    print(\"\\nüî¨ TATN Components:\")\n    print(f\"   ‚Ä¢ ASBN Training: {'Enabled' if _ENABLE_ASBN_TRAINING else 'Disabled'}\")\n    print(f\"   ‚Ä¢ TRG Inference: {'Enabled' if _ENABLE_TRG_INFERENCE else 'Disabled'}\")\n    print(f\"   ‚Ä¢ Periodic Discovery: Every {_format_number(_PERIODIC_DISCOVERY_FREQUENCY)} steps\")\n    \n    print(\"=\" * 80)\n\n    trained_model, tokenizer_out = None, None\n\n    mp = _safe_get(\"main_pipeline\", None)\n    if mp is None or not callable(mp):\n        print(\"\\n‚ùå ERROR: main_pipeline not found or not callable\")\n        print(\"   Please run Cell 10 before executing this cell.\")\n        print(\"=\" * 80)\n    else:\n        try:\n            print(\"\\n\" + \"=\" * 80)\n            print(\"STARTING FULL PIPELINE\")\n            print(\"=\" * 80)\n            print(\"\\nThis may take 30-60 minutes depending on hardware...\")\n            print(\"Progress will be shown below.\\n\")\n            \n            pipeline_exec_start = time.time()\n            \n            ret = mp()\n            \n            pipeline_exec_time = time.time() - pipeline_exec_start\n\n            if isinstance(ret, tuple) and len(ret) >= 2:\n                trained_model, tokenizer_out = ret[0], ret[1]\n            elif isinstance(ret, tuple) and len(ret) == 1:\n                trained_model = ret[0]\n                core = _unwrap_model(trained_model)\n                if hasattr(core, \"tokenizer\") and _is_tokenizer_like(core.tokenizer):\n                    tokenizer_out = core.tokenizer\n                else:\n                    tokenizer_out = _safe_get(\"tokenizer\", None)\n            elif isinstance(ret, dict):\n                trained_model = ret.get(\"model\") or ret.get(\"trained_model\") or ret.get(\"core_model\")\n                tokenizer_out = ret.get(\"tokenizer\") or ret.get(\"tok\")\n                \n                if trained_model is None:\n                    for v in ret.values():\n                        if _is_model_like(v):\n                            trained_model = v\n                            break\n                \n                if tokenizer_out is None:\n                    for v in ret.values():\n                        if _is_tokenizer_like(v):\n                            tokenizer_out = v\n                            break\n            else:\n                if _is_model_like(ret):\n                    trained_model = ret\n                    tokenizer_out = _safe_get(\"tokenizer\", None)\n                elif _is_tokenizer_like(ret):\n                    tokenizer_out = ret\n                    trained_model = _safe_get(\"trained_model\", None) or _safe_get(\"model\", None)\n                else:\n                    trained_model = _safe_get(\"trained_model\", None) or _safe_get(\"model\", None)\n                    tokenizer_out = _safe_get(\"tokenizer\", None)\n\n            if trained_model is not None:\n                try:\n                    globals()[\"trained_model\"] = trained_model\n                    print(\"[CELL11] Global sync: trained_model ‚úÖ\")\n                except Exception as e:\n                    print(f\"[CELL11] Global sync: trained_model ‚ö†Ô∏è  {e}\")\n            \n            if tokenizer_out is not None:\n                try:\n                    globals()[\"tokenizer\"] = tokenizer_out\n                    print(\"[CELL11] Global sync: tokenizer ‚úÖ\")\n                except Exception as e:\n                    print(f\"[CELL11] Global sync: tokenizer ‚ö†Ô∏è  {e}\")\n            \n            print(\"\\n\" + \"=\" * 80)\n            print(\"PIPELINE EXECUTION COMPLETE\")\n            print(\"=\" * 80)\n            print(f\"Total pipeline time: {_format_time(pipeline_exec_time)}\")\n            print(\"=\" * 80)\n\n        except KeyboardInterrupt:\n            print(\"\\n‚ö†Ô∏è  Execution interrupted by user (KeyboardInterrupt).\")\n        except Exception as e:\n            msg = str(e).lower()\n            if isinstance(e, RuntimeError) and (\n                \"no usable tokenizer class available\" in msg\n                or \"failed to instantiate tokenizer\" in msg\n                or \"sentencepiece\" in msg\n                or \"tokenizers\" in msg\n            ):\n                print(f\"\\n‚ùå Pipeline execution failed: {type(e).__name__}: {str(e)[:400]}\")\n                print(\"\\nThis error indicates the tokenizer could not be instantiated. Common causes and fixes:\")\n                print(\"  ‚Ä¢ Missing or incompatible 'transformers' package.\")\n                print(\"  ‚Ä¢ Missing optional tokenizer dependencies (sentencepiece, tokenizers, sacremoses).\")\n                print(\"\\nSuggested actions (pick one):\")\n                print(\"  1) Install the recommended packages (in a notebook cell or terminal):\")\n                print(\"       !pip install transformers==4.30.2 sentencepiece tokenizers sacremoses --quiet\")\n                print(\"     Then RESTART the kernel and re-run Cells 0‚Üí11 in order.\")\n                print(\"\")\n                print(\"  2) If you are offline but have a cached tokenizer folder, set local_files_only=True in the tokenizer loader or\")\n                print(\"     provide MODEL_LOCAL_TOKENIZER_PATH in your config and re-run.\")\n                print(\"\")\n                print(\"  3) If you want to continue debugging without real tokenization, ensure Cell 10's _safe_tokenizer_from_pretrained\")\n                print(\"     returns the whitespace fallback (it will allow the pipeline to continue but translations will be incorrect).\")\n                if _VERBOSE_LOGGING:\n                    print(\"\\nFull traceback (VERBOSE):\")\n                    traceback.print_exc()\n                else:\n                    print(\"\\nSet VERBOSE_LOGGING = True in Cell 0 to see the full traceback.\")\n            else:\n                print(f\"\\n‚ùå Pipeline execution failed: {type(e).__name__}: {str(e)[:400]}\")\n                if _VERBOSE_LOGGING:\n                    traceback.print_exc()\n                else:\n                    print(\"Set VERBOSE_LOGGING = True in Cell 0 to see full traceback.\")\n\n    if trained_model is not None and tokenizer_out is not None:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"‚úÖ SYSTEM INITIALIZATION SUCCEEDED\")\n        print(\"=\" * 80)\n        \n        print(\"\\nüìä Model Statistics:\")\n        try:\n            total_params = sum(p.numel() for p in trained_model.parameters())\n            trainable_params = sum(p.numel() for p in trained_model.parameters() if p.requires_grad)\n            frozen_params = total_params - trainable_params\n            \n            print(f\"   ‚Ä¢ Total Parameters: {_format_number(total_params)}\")\n            print(f\"   ‚Ä¢ Trainable Parameters: {_format_number(trainable_params)} ({100*trainable_params/total_params:.1f}%)\")\n            print(f\"   ‚Ä¢ Frozen Parameters: {_format_number(frozen_params)} ({100*frozen_params/total_params:.1f}%)\")\n            \n            model_size_mb = (total_params * 4) / (1024 ** 2)\n            print(f\"   ‚Ä¢ Estimated Model Size: {model_size_mb:.1f} MB (float32)\")\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è  Could not calculate model statistics: {e}\")\n        \n        print(\"\\nüéØ Capabilities:\")\n        print(f\"   ‚Ä¢ {_SOURCE_LANGUAGE.upper()} ‚Üí {_TARGET_LANGUAGE.upper()} translation ({_MODEL_FAMILY} base)\")\n        print(\"   ‚Ä¢ Automatic homograph disambiguation (DSCD + TRG)\")\n        print(\"   ‚Ä¢ Dynamic prototype discovery (hierarchical clustering)\")\n        print(\"   ‚Ä¢ Explainable AI (word-level rationales)\")\n        if _USE_MULTI_GPU:\n            print(f\"   ‚Ä¢ Multi-GPU acceleration ({_NUM_GPUS} GPUs)\")\n        print(\"=\" * 80)\n\n        print(\"\\n\" + \"=\" * 80)\n        print(\"BEST MODEL VERIFICATION\")\n        print(\"=\" * 80)\n        try:\n            best_model_path = os.path.join(_CHECKPOINT_DIR, \"tatn_best_model.pt\")\n            if os.path.exists(best_model_path):\n                print(f\"‚úÖ Best model checkpoint found: {best_model_path}\")\n                try:\n                    size_mb = os.path.getsize(best_model_path) / (1024 ** 2)\n                    print(f\"   Size: {size_mb:.1f} MB\")\n                except Exception:\n                    pass\n            else:\n                print(f\"‚ö†Ô∏è  Best model checkpoint not found at: {best_model_path}\")\n                print(\"   Using final training checkpoint\")\n                \n            final_model_path = os.path.join(_CHECKPOINT_DIR, \"tatn_final_model.pt\")\n            if os.path.exists(final_model_path):\n                print(f\"‚úÖ Final model checkpoint found: {final_model_path}\")\n                try:\n                    size_mb = os.path.getsize(final_model_path) / (1024 ** 2)\n                    print(f\"   Size: {size_mb:.1f} MB\")\n                except Exception:\n                    pass\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  Best model verification failed: {e}\")\n        print(\"=\" * 80)\n\n        print(\"\\n\" + \"=\" * 80)\n        print(\"QUICK INFERENCE VALIDATION\")\n        print(\"=\" * 80)\n        try:\n            tw = _safe_get(\"translate_with_explanations\", None)\n            if callable(tw):\n                test_sentences = [\n                    \"‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§\",\n                    \"‡¶ï‡¶æ‡¶≤ ‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶á ‡¶ï‡¶ø‡¶®‡¶¨‡•§\",\n                    \"‡¶™‡¶æ‡¶§‡¶æ ‡¶ù‡¶∞‡ßá ‡¶™‡¶°‡¶º‡ßá‡¶õ‡ßá‡•§\"\n                ]\n                \n                print(f\"\\nTesting {len(test_sentences)} sample sentences...\\n\")\n                \n                for idx, sample in enumerate(test_sentences, 1):\n                    print(f\"[{idx}/{len(test_sentences)}] Input: {sample}\")\n\n                    res = None\n                    try:\n                        res = tw(\n                            model=trained_model,\n                            tokenizer=tokenizer_out,\n                            input_sentence=sample\n                        )\n                    except TypeError as te:\n                        if \"unexpected keyword argument\" in str(te).lower():\n                            try:\n                                res = tw(trained_model, tokenizer_out, sample)\n                            except Exception as e2:\n                                if _VERBOSE_LOGGING:\n                                    print(f\"  Fallback positional call failed: {e2}\")\n                                res = None\n                        else:\n                            if _VERBOSE_LOGGING:\n                                print(f\"  translate_with_explanations call failed: {te}\")\n                            res = None\n                    except Exception as e:\n                        print(f\"  ‚ùå Translation failed: {type(e).__name__}: {str(e)[:200]}\")\n                        if _VERBOSE_LOGGING:\n                            traceback.print_exc()\n                        res = None\n\n                    if isinstance(res, dict):\n                        translation = res.get('translation', 'N/A')\n                        amb_count = res.get('ambiguous_words_detected', 0)\n                        exs = res.get('explanations', []) or []\n                        \n                        print(f\"     Translation: {translation}\")\n                        print(f\"     Ambiguous Words: {amb_count}\")\n                        \n                        if exs and len(exs) > 0:\n                            e0 = exs[0]\n                            word = e0.get('ambiguous_word', e0.get('token', 'N/A'))\n                            print(f\"     Example: '{word}' (U={e0.get('uncertainty', 0.0):.3f}, S={e0.get('span', 0.0):.3f})\")\n                        \n                        print()\n                    elif res is None:\n                        print(f\"     ‚ùå Translation returned None\\n\")\n                    else:\n                        print(f\"     ‚ùå Unexpected result type: {type(res)}\\n\")\n                \n                print(\"‚úÖ Quick inference validation COMPLETE\")\n            else:\n                print(\"‚ö†Ô∏è  translate_with_explanations not available - ensure Cell 8 is run\")\n        except Exception as e:\n            print(f\"‚ùå Quick inference failed: {type(e).__name__}: {str(e)[:200]}\")\n            if _VERBOSE_LOGGING:\n                traceback.print_exc()\n        print(\"=\" * 80)\n\n        print(\"\\n\" + \"=\" * 80)\n        print(\"üìö NEXT STEPS\")\n        print(\"=\" * 80)\n        print(\"\\n1. Translate Bengali sentences:\")\n        print(\"   ```python\")\n        print(\"   result = translate_with_explanations(trained_model, tokenizer, '‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§')\")\n        print(\"   print(result['translation'])\")\n        print(\"   ```\")\n        print(\"\\n2. View disambiguation explanations:\")\n        print(\"   ```python\")\n        print(\"   for exp in result['explanations']:\")\n        print(\"       print(f\\\"{exp['ambiguous_word']}: {exp['explanation']}\\\")\")\n        print(\"   ```\")\n        print(\"\\n3. Run comprehensive testing:\")\n        print(\"   ```python\")\n        print(\"   test_results = comprehensive_post_training_testing(trained_model, tokenizer)\")\n        print(\"   ```\")\n        print(\"\\n4. Evaluate on test set:\")\n        print(\"   ```python\")\n        print(\"   test_pairs = [('bengali', 'english'), ...]\")\n        print(\"   results = evaluate_bleu_chrf(trained_model, tokenizer, test_pairs)\")\n        print(\"   print(f\\\"BLEU: {results['bleu']:.2f}\\\")\")\n        print(\"   ```\")\n        print(\"=\" * 80)\n\n    else:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"‚ùå TRAINING FAILED OR INCOMPLETE\")\n        print(\"=\" * 80)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"EXECUTION SUMMARY\")\n    print(\"=\" * 80)\n    \n    total_time = time.time() - PIPELINE_START_TIME\n    now_end = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n    \n    print(f\"\\nStarted: {now_utc}\")\n    print(f\"Finished: {now_end}\")\n    print(f\"Total execution time: {_format_time(total_time)}\")\n    \n    print(f\"\\nModel Configuration:\")\n    print(f\"  ‚Ä¢ Model: {_MODEL_NAME}\")\n    print(f\"  ‚Ä¢ Family: {_MODEL_FAMILY}\")\n    print(f\"  ‚Ä¢ Languages: {_SOURCE_LANGUAGE} ‚Üí {_TARGET_LANGUAGE}\")\n    \n    if trained_model is not None and tokenizer_out is not None:\n        print(f\"\\nStatus: ‚úÖ SUCCESS\")\n        print(f\"Model: Initialized and trained\")\n        print(f\"Tokenizer: Loaded\")\n        print(f\"DSCD: Active\")\n        print(f\"Ready for inference: YES\")\n    else:\n        print(f\"\\nStatus: ‚ùå FAILED\")\n        print(f\"Please review error messages above and follow troubleshooting steps.\")\n    \n    print(\"=\" * 80)\n    \n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    print(\"\\n‚úÖ CELL 11: Execution wrapper finished.\")\n    print(\"=\" * 80)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Cell 11: Main Execution Wrapper (IndicBART-READY - 38 FIXES)\")\nprint(\"=\" * 80)\nprint()\nprint(\"üìä Configuration loaded from Cell 0:\")\nprint(f\" ‚Ä¢ MODEL: {_safe_get('MODEL_NAME', 'ai4bharat/IndicBART')}\")\nprint(f\" ‚Ä¢ EPOCHS: {_safe_get('EPOCHS', 10)}\")\nprint(f\" ‚Ä¢ BATCH_SIZE: {_safe_get('BATCH_SIZE', 8)}\")\nprint(f\" ‚Ä¢ ACCUMULATION_STEPS: {_safe_get('ACCUMULATION_STEPS', 16)}\")\nprint(f\" ‚Ä¢ LR_NMT: {_safe_get('LR_NMT', 5e-5)}\")\nprint(f\" ‚Ä¢ WARMUP_STEPS: {_safe_get('WARMUP_STEPS', 500)}\")\nprint()\nprint(\"üî• NEW FIXES APPLIED:\")\nprint(\" ‚Ä¢ FIX #36: üî•üî•üî• CRITICAL - Removed premature train_loader creation (300+ lines)\")\nprint(\"    - Cell 11 now ONLY calls main_pipeline() and handles results\")\nprint(\"    - main_pipeline() creates tokenizers, vocab, dataset, loader internally\")\nprint(\"    - Eliminated chicken-and-egg dependency problem\")\nprint(\" ‚Ä¢ FIX #37: Fixed tokenizer_error undefined variable\")\nprint(\" ‚Ä¢ FIX #38: Fixed TRG Inference display logic error\")\nprint()\nprint(\"üêõ BUGS FIXED:\")\nprint(\" ‚Ä¢ Lines 400-700: Premature train_loader creation BEFORE tokenizers exist - REMOVED\")\nprint(\" ‚Ä¢ Line 441: Variable 'tokenizer_error' used before definition - FIXED\")\nprint(\" ‚Ä¢ Line 402: TRG Inference display logic error - FIXED\")\nprint()\nprint(\"üìã ARCHITECTURE:\")\nprint(\" ‚Ä¢ Cell 10: Defines main_pipeline() (loads data, builds vocab, trains model)\")\nprint(\" ‚Ä¢ Cell 11: Calls main_pipeline() and displays results\")\nprint(\" ‚Ä¢ Simplified from 1100+ lines to 500 lines (50% reduction)\")\nprint()\nprint(\"=\" * 80)\n","metadata":{"id":"9n4Hrn1wH4J6","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T20:09:44.946866Z","iopub.execute_input":"2026-01-24T20:09:44.947105Z","execution_failed":"2026-01-24T20:21:28.456Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nüîß CHECKING DEPENDENCIES...\n================================================================================\n‚úÖ tokenizers library found\n‚úÖ sentencepiece library found\n‚úÖ sacremoses library found\n‚úÖ transformers library found (version: 4.57.6)\n\n‚úÖ All required dependencies are already installed!\n\n================================================================================\nMEMORY-OPTIMIZED TATN FOR KAGGLE T4√ó2 (Cell 11 - IndicBART-READY)\n================================================================================\n\nü§ñ Model Configuration:\n   ‚Ä¢ Model: ai4bharat/IndicBART\n   ‚Ä¢ Family: IndicBART\n   ‚Ä¢ Languages: bn ‚Üí en\nUser: manas0003\nStarted: 2026-01-24 20:09:45 UTC\n\n================================================================================\nRESEARCH-BACKED CONFIGURATION\n================================================================================\n\nüìä Dataset & Training:\n   ‚Ä¢ Samples: 50,000\n   ‚Ä¢ Epochs: 2\n   ‚Ä¢ Batch Size: 48\n   ‚Ä¢ Accumulation Steps: 16\n   ‚Ä¢ Effective Batch Size: 768\n   ‚Ä¢ Device: cuda\n   ‚Ä¢ Multi-GPU: ENABLED (2 GPU(s))\n   ‚Ä¢ Batch per GPU: 24\n\nüéØ Learning Rates (4-Group Strategy):\n   ‚Ä¢ LR_NMT (IndicBART base): 5e-05\n   ‚Ä¢ LR_WORD_EMBED: 0.0001\n   ‚Ä¢ LR_PHI (DSCD/ASBN): 1e-05\n   ‚Ä¢ LR_TRG (Explanations): 1e-05\n   ‚Ä¢ Weight Decay: 0.01\n   ‚Ä¢ Adam Betas: (0.9, 0.999)\n\nüìà Optimization Strategy:\n   ‚Ä¢ Scheduler: LINEAR\n   ‚Ä¢ Warmup Steps: 500\n   ‚Ä¢ Gradient Clipping: 1.0\n   ‚Ä¢ Early Stopping Patience: 2 epochs\n\nüîí Layer Freezing:\n   ‚Ä¢ Encoder Layers Frozen: 2\n   ‚Ä¢ Decoder Layers Frozen: 2\n\nüíæ Checkpointing:\n   ‚Ä¢ Checkpoint Directory: /kaggle/working/\n   ‚Ä¢ Save Every: 1 epochs\n   ‚Ä¢ Validation Interval: 500 steps\n\nüî¨ TATN Components:\n   ‚Ä¢ ASBN Training: Enabled\n   ‚Ä¢ TRG Inference: Enabled\n   ‚Ä¢ Periodic Discovery: Every 100 steps\n================================================================================\n\n================================================================================\nSTARTING FULL PIPELINE\n================================================================================\n\nThis may take 30-60 minutes depending on hardware...\nProgress will be shown below.\n\n================================================================================\nCELL10: TATN MAIN PIPELINE (IndicBART - 43 CRITICAL FIXES)\n================================================================================\n[CELL10] Initializing environment...\n[CELL10] GPUs available: 2\n  - GPU 0: Tesla T4 (14.7 GB)\n  - GPU 1: Tesla T4 (14.7 GB)\n[CELL10] Multi-GPU detected\n[CELL10] Loading IndicBART tokenizer from ai4bharat/IndicBART...\n\n[TOKENIZER] Loading tokenizer for: ai4bharat/IndicBART\n[CELL10] ‚úÖ tokenizers library successfully imported\n[TOKENIZER] Attempting AutoTokenizer (use_fast=True)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a754f74d539b4930a1958c080c523924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33a8260c6c914598bf4cb5926f0df933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.90M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e698d7707f24811b3e2d38520a73681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/221 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3c3024c4dec4570a4f1162f47552007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/398 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b561d2aa2f4befaed59fd942fbb867"}},"metadata":{}},{"name":"stdout","text":"[TOKENIZER] ‚úÖ Loaded AutoTokenizer (fast=True)\n[CELL10] IndicBART tokenizer loaded (vocab size approx 64000)\n[CELL10] Loading/preprocessing up to 50000 samples...\n[CELL2] Loading up to 50,000 samples from: /kaggle/input/samanantar/samanantar_bn_en.csv\n[CELL2] Reading CSV file...\n[CELL2] Processing 50,000 rows...\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50000/50000 [00:03<00:00, 16558.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"[CELL2] Loaded 49,398 pairs, skipped 602 rows\n[CELL10] Loaded 49,398 translation pairs\n================================================================================\nüîß BUILDING WORD TOKENIZER VOCABULARY FROM DATASET\n================================================================================\n[CELL10] Building word vocabulary from 49,398 Bengali texts...\n[CELL2] Building word vocabulary from 49,398 texts...\n","output_type":"stream"},{"name":"stderr","text":"Counting words: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49398/49398 [00:00<00:00, 82789.30it/s]\n`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"name":"stdout","text":"[CELL2] Added 27,328 words to vocabulary (total: 27,332)\n[CELL2] ‚úì Vocabulary locked (no dynamic growth during encoding)\n[CELL10] ‚úÖ Word vocabulary built successfully!\n         Vocabulary size: 27,332 unique words\n         Watchlist words in vocab: 23/24\n[CELL10] ‚úÖ Global word_tokenizer set for DataLoader workers\n================================================================================\n================================================================================\n\n[CELL10] Creating dataset...\n[CELL2] Dataset initialized:\n  Valid pairs: 49,398\n  Invalid pairs filtered: 0\n  Path 1 (Word): ENABLED\n  Path 2 (Subword): ENABLED\n  Model type: indicbart\n  Languages: bn‚Üíen\n[CELL10] ‚úÖ Dataset created with Cell 2's MemoryEfficientDataset\n\n================================================================================\nüîç DATASET VERIFICATION (CRITICAL FOR DSCD)\n================================================================================\nSample keys: ['input_ids', 'attention_mask', 'labels', 'word_input_ids', 'word_attention_mask', 'word_strings', 'src_text']\n‚úÖ SUCCESS: word_strings field present with 48 words\n   Sample words: ['‡¶Ü‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶ú‡¶æ‡¶§‡¶ø‡¶ï', '‡¶∏‡¶ø‡¶≠‡¶ø‡¶≤', '‡¶è‡¶≠‡¶ø‡¶Ø‡¶º‡ßá‡¶∂‡¶®', '‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ', '‡¶¨‡¶ø‡¶Æ‡¶æ‡¶®‡¶¨‡¶®‡ßç‡¶¶‡¶∞‡ßá‡¶∞']\n   ‚Üí DSCD homograph detection: ENABLED\n‚úÖ input_ids field present (shape: torch.Size([48]))\n‚úÖ src_text field present: '‡¶Ü‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶ú‡¶æ‡¶§‡¶ø‡¶ï ‡¶∏‡¶ø‡¶≠‡¶ø‡¶≤ ‡¶è‡¶≠‡¶ø‡¶Ø‡¶º‡ßá‡¶∂‡¶® ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ ‡¶¨‡¶ø‡¶Æ‡¶æ‡¶®‡¶¨‡¶®‡ßç‡¶¶‡¶∞‡ßá‡¶∞ ‡¶®‡¶ø‡¶∞...'\n================================================================================\n\n[CELL10] ‚úÖ Using Cell 2's safe_collate (dual-path)\n\n[CELL10] Creating DataLoader with FORCED safe_collate...\n[CELL10] ‚úÖ Collate function set: safe_collate\n[CELL10] ‚úÖ DataLoader created with explicit safe_collate\n[CELL10] Dataset: 49398 examples, 1030 batches (batch_size=48)\n\n================================================================================\nüîç CRITICAL: VERIFYING TRAIN_LOADER BEFORE TRAINING\n================================================================================\n\n‚úÖ Train_loader batch test:\n   Batch type: <class 'dict'>\n   Batch keys: ['input_ids', 'attention_mask', 'labels', 'word_input_ids', 'word_attention_mask', 'word_strings', 'src_text']\n\n   Word-level data check:\n      word_input_ids:        ‚úÖ PRESENT\n      word_attention_mask:   ‚úÖ PRESENT\n      word_strings:          ‚úÖ PRESENT\n      word_input_ids shape:  torch.Size([48, 48])\n      word_strings length:   48\n      First sample words:    ['‡¶§‡¶æ‡¶∞‡¶æ', '‡¶π‡¶≤‡ßá‡¶®,', '‡¶Æ‡ßã‡¶π‡¶æ‡¶Æ‡ßç‡¶Æ‡¶¶', '‡¶®‡¶æ‡¶≠‡¶ø‡¶¶,', '‡¶∂‡¶æ‡¶Ø‡¶º‡¶Æ‡¶æ‡¶®']\n\n‚úÖ‚úÖ‚úÖ SUCCESS: Train_loader provides complete word-level data!\n================================================================================\n\n[CELL10] Initializing model...\n[CELL10] Model class: DualPathTATN\n[CELL10] Detected init parameters: ['self', 'indicbart_tokenizer', 'bengali_word_tokenizer', 'word_vocab_size', 'word_embed_dim']\n[CELL10] Using parameter: indicbart_tokenizer\n[CELL10] Model will use word_vocab_size=27,332, word_embed_dim=256\n[TATN-INIT] Initializing Dual-Path TATN with IndicBART\n[TATN-INIT] Word vocab size: 27332\n[TATN-INIT] Word embed dim: 256\n[TATN-INIT] ‚úÖ Word embedding initialized: [27332, 256]\n[TATN-INIT] ‚úÖ DSCD initialized successfully (class: WordLevelDSCDOnline)\n[TATN-INIT] ‚úÖ ASBN initialized successfully (class: WordLevelASBNModule)\n[TATN-INIT] ‚úÖ TRG initialized successfully (class: CompleteTRGWithExplanations)\n[TATN-INIT] Loading IndicBART model: ai4bharat/IndicBART...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/976M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f247e16ed34f4e16bef6745c80201832"}},"metadata":{}},{"name":"stdout","text":"[TATN-INIT] ‚úÖ IndicBART model loaded successfully: ai4bharat/IndicBART\n================================================================================\n[TATN-INIT] ‚úÖ Dual-Path TATN Initialization Complete\n[TATN-INIT] Path 1 (Word-Level): DSCD=‚úì, ASBN=‚úì, TRG=‚úì\n[TATN-INIT] Path 2 (IndicBART): ‚úì LOADED\n================================================================================\n[CELL10] ‚úÖ Model initialized with keyword arguments (IndicBART base)\n[CELL10] Wrapping model in DataParallel on devices [0, 1]\n[CELL10] Resized token embeddings: 64014 -> 64000\n\n================================================================================\nAPPLYING LAYER FREEZING (CELL 8 REQUIREMENT)\n================================================================================\n[FREEZE] ‚úì Frozen embedding layers\n[FREEZE] ‚úì Frozen 2 encoder layers\n[FREEZE] ‚úì Frozen 2 decoder layers\n[FREEZE] Trainable: 126,748,715 / 251,070,507 (50.5%)\n[CELL10] ‚úÖ Layer freezing applied: enc=2, dec=2\n================================================================================\n\n================================================================================\nCREATING PARAMETER GROUPS (CELL 8 REQUIREMENT)\n================================================================================\n[PARAM-GROUPS] IndicBART: 178 params, LR=5e-05\n[PARAM-GROUPS] DSCD/ASBN: 23 params, LR=1e-05\n[PARAM-GROUPS] Other: 1 params, LR=5e-05\n[CELL10] ‚úÖ Parameter groups created successfully\n================================================================================\n\n[CELL10] Initializing AdamW optimizer with parameter groups...\n[CELL10] ‚úÖ AdamW optimizer initialized\n         Trainable parameters: 126,748,715\n         Weight decay: 0.01\n         Gradient clipping: 1.0\n\n================================================================================\nINITIALIZING LEARNING RATE SCHEDULER (CELL 8 REQUIREMENT)\n================================================================================\n[CELL10] ‚úÖ linear scheduler initialized (warmup=500, total=128)\n================================================================================\n\n[CELL10] Preparing validation samples...\n[CELL2] Loading up to 1,100 samples from: /kaggle/input/samanantar/samanantar_bn_en.csv\n[CELL2] Reading CSV file...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/976M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb66f9e9401c4e219677de1653c63657"}},"metadata":{}},{"name":"stdout","text":"[CELL2] Processing 1,100 rows...\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1100/1100 [00:00<00:00, 15930.63it/s]","output_type":"stream"},{"name":"stdout","text":"[CELL2] Loaded 1,086 pairs, skipped 14 rows\n[CELL10] ‚úÖ Prepared 86 validation samples (Cell 8)\n\n================================================================================\nSTARTING TRAINING PHASE (2 EPOCHS)\n================================================================================\n[TRAIN] Starting training: epochs=2, batch=48, accum_steps=16\n[TRAIN] Validation: enabled\n[TRAIN] Early stopping patience: 2\n[TRAIN] Learning rate scheduler: enabled\n[TRAIN] Warmup steps: 500\n[TRAIN] DP enabled: True, GPUs: 2, Device: cuda\n[TRAIN] Applying layer freezing: 2 encoder + 2 decoder layers\n[FREEZE] ‚úì Frozen embedding layers\n[FREEZE] ‚úì Frozen 2 encoder layers\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[FREEZE] ‚úì Frozen 2 decoder layers\n[FREEZE] Trainable: 126,748,715 / 251,070,507 (50.5%)\n[TRAIN] ‚úì DSCD training clustering ENABLED (synchronous mode)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   0%|                                                                                                                                           | 0/1030 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n[TRAIN-DEBUG] Step 1 batch data check:\n  input_ids: torch.Size([48, 48])\n  attention_mask: torch.Size([48, 48])\n  labels: torch.Size([48, 48])\n  word_input_ids: torch.Size([48, 48])\n  word_attention_mask: torch.Size([48, 48])\n  word_strings: <class 'list'> len=48\n  src_text: <class 'list'> len=48\n  ‚úÖ word_input_ids present: torch.Size([48, 48])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   0%|                                                          | 1/1030 [00:02<47:36,  2.78s/it, fwd_loss=12.0093 bwd_loss=0.750580 rate=0.0% proc=1 skip=0 clusters=321]","output_type":"stream"},{"name":"stdout","text":"\n[TRAIN-DEBUG] Step 2 batch data check:\n  input_ids: torch.Size([48, 48])\n  attention_mask: torch.Size([48, 48])\n  labels: torch.Size([48, 48])\n  word_input_ids: torch.Size([48, 48])\n  word_attention_mask: torch.Size([48, 48])\n  word_strings: <class 'list'> len=48\n  src_text: <class 'list'> len=48\n  ‚úÖ word_input_ids present: torch.Size([48, 48])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   0%|                                                          | 2/1030 [00:03<31:07,  1.82s/it, fwd_loss=12.1890 bwd_loss=0.761813 rate=0.0% proc=2 skip=0 clusters=567]","output_type":"stream"},{"name":"stdout","text":"\n[TRAIN-DEBUG] Step 3 batch data check:\n  input_ids: torch.Size([48, 48])\n  attention_mask: torch.Size([48, 48])\n  labels: torch.Size([48, 48])\n  word_input_ids: torch.Size([48, 48])\n  word_attention_mask: torch.Size([48, 48])\n  word_strings: <class 'list'> len=48\n  src_text: <class 'list'> len=48\n  ‚úÖ word_input_ids present: torch.Size([48, 48])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   0%|‚ñè                                                         | 3/1030 [00:05<26:03,  1.52s/it, fwd_loss=11.8391 bwd_loss=0.739944 rate=0.0% proc=3 skip=0 clusters=786]","output_type":"stream"},{"name":"stdout","text":"\n[TRAIN-DEBUG] Step 4 batch data check:\n  input_ids: torch.Size([48, 48])\n  attention_mask: torch.Size([48, 48])\n  labels: torch.Size([48, 48])\n  word_input_ids: torch.Size([48, 48])\n  word_attention_mask: torch.Size([48, 48])\n  word_strings: <class 'list'> len=48\n  src_text: <class 'list'> len=48\n  ‚úÖ word_input_ids present: torch.Size([48, 48])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   0%|‚ñè                                                          | 4/1030 [00:06<23:19,  1.36s/it, fwd_loss=6.0446 bwd_loss=0.377785 rate=0.0% proc=4 skip=0 clusters=992]","output_type":"stream"},{"name":"stdout","text":"\n[TRAIN-DEBUG] Step 5 batch data check:\n  input_ids: torch.Size([48, 48])\n  attention_mask: torch.Size([48, 48])\n  labels: torch.Size([48, 48])\n  word_input_ids: torch.Size([48, 48])\n  word_attention_mask: torch.Size([48, 48])\n  word_strings: <class 'list'> len=48\n  src_text: <class 'list'> len=48\n  ‚úÖ word_input_ids present: torch.Size([48, 48])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   2%|‚ñä                                                    | 16/1030 [00:19<20:29,  1.21s/it, fwd_loss=11.7151 bwd_loss=0.732194 rate=100.0% proc=16 skip=0 clusters=3088]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   3%|‚ñà‚ñã                                                   | 32/1030 [00:38<19:25,  1.17s/it, fwd_loss=11.9531 bwd_loss=0.747070 rate=100.0% proc=32 skip=0 clusters=5114]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   5%|‚ñà‚ñà‚ñç                                                  | 48/1030 [00:57<21:17,  1.30s/it, fwd_loss=11.9300 bwd_loss=0.745624 rate=100.0% proc=48 skip=0 clusters=6679]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 3.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   6%|‚ñà‚ñà‚ñà‚ñé                                                 | 64/1030 [01:15<18:40,  1.16s/it, fwd_loss=11.6453 bwd_loss=0.727832 rate=100.0% proc=64 skip=0 clusters=8101]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 4.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   8%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                 | 80/1030 [01:34<18:19,  1.16s/it, fwd_loss=5.8797 bwd_loss=0.367483 rate=100.0% proc=80 skip=0 clusters=9284]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 5.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:   9%|‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 96/1030 [01:52<18:45,  1.20s/it, fwd_loss=11.4775 bwd_loss=0.717342 rate=100.0% proc=96 skip=0 clusters=10396]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 6.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                            | 112/1030 [02:11<17:44,  1.16s/it, fwd_loss=11.7857 bwd_loss=0.736605 rate=100.0% proc=112 skip=0 clusters=11455]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 7.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                           | 128/1030 [02:29<18:28,  1.23s/it, fwd_loss=11.7283 bwd_loss=0.733021 rate=100.0% proc=128 skip=0 clusters=12375]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 8.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                           | 144/1030 [02:48<17:59,  1.22s/it, fwd_loss=11.9333 bwd_loss=0.745833 rate=100.0% proc=144 skip=0 clusters=13192]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 9.00e-07 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                          | 160/1030 [03:07<17:47,  1.23s/it, fwd_loss=11.7524 bwd_loss=0.734522 rate=100.0% proc=160 skip=0 clusters=13988]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.00e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 176/1030 [03:26<17:29,  1.23s/it, fwd_loss=5.9042 bwd_loss=0.369010 rate=100.0% proc=176 skip=0 clusters=14768]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.10e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                        | 192/1030 [03:46<16:53,  1.21s/it, fwd_loss=11.9728 bwd_loss=0.748300 rate=100.0% proc=192 skip=0 clusters=15476]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.20e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 199/1030 [03:54<16:32,  1.19s/it, fwd_loss=11.9536 bwd_loss=0.747102 rate=100.0% proc=199 skip=0 clusters=15766]","output_type":"stream"},{"name":"stdout","text":"[TRAIN-DEBUG] GPU mem (GB):\n  GPU 0: alloc=2.38 resv=5.00\n  GPU 1: alloc=0.02 resv=3.15\n[TRAIN-DEBUG] step=200 loss=12.0403 lr=1.20e-06 opt_updates=12 clusters=15827\n\n[CLUSTER] Top 5 clusters (by sample count):\n------------------------------------------------------------------------------------------\nRank  Token             Count       Protos    Œº (mean)       œÑ (dev)     \n------------------------------------------------------------------------------------------\n1     ‡¶§‡¶ø‡¶®‡¶ø              20          1         0.000000       0.000001    \n2     ‡¶ï‡¶∞‡ßá‡¶õ‡ßá             20          1         0.000000       0.000001    \n3     ‡¶•‡ßá‡¶ï‡ßá‡¶á             20          1         0.000000       0.000001    \n4     ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá            20          1         0.000000       0.000001    \n5     ‡¶Ü‡¶™‡¶®‡¶ø              20          1         0.000000       0.000001    \n------------------------------------------------------------------------------------------\nTotal clusters: 15827 | Total samples in clusters: 37510\n\n[CLUSTER-STATS] Cluster Statistics:\n  ‚Ä¢ Total clusters: 15827\n  ‚Ä¢ Total samples: 37510\n  ‚Ä¢ Total prototypes: 4916\n  ‚Ä¢ Avg samples/cluster: 2.4\n  ‚Ä¢ Avg protos/cluster: 0.3\n  ‚Ä¢ Max samples/cluster: 20\n  ‚Ä¢ Min samples/cluster: 0\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                        | 208/1030 [04:05<16:28,  1.20s/it, fwd_loss=11.7719 bwd_loss=0.735741 rate=100.0% proc=208 skip=0 clusters=16121]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.30e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                       | 224/1030 [04:24<16:42,  1.24s/it, fwd_loss=11.4558 bwd_loss=0.715990 rate=100.0% proc=224 skip=0 clusters=16753]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.40e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 240/1030 [04:43<15:59,  1.21s/it, fwd_loss=11.8338 bwd_loss=0.739613 rate=100.0% proc=240 skip=0 clusters=17327]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.50e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                     | 256/1030 [05:03<16:29,  1.28s/it, fwd_loss=11.7401 bwd_loss=0.733759 rate=100.0% proc=256 skip=0 clusters=17886]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.60e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 272/1030 [05:22<15:28,  1.22s/it, fwd_loss=11.6687 bwd_loss=0.729294 rate=100.0% proc=272 skip=0 clusters=18374]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.70e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                    | 288/1030 [05:41<15:15,  1.23s/it, fwd_loss=11.7860 bwd_loss=0.736628 rate=100.0% proc=288 skip=0 clusters=18834]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.80e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 304/1030 [06:00<15:02,  1.24s/it, fwd_loss=11.7221 bwd_loss=0.732634 rate=100.0% proc=304 skip=0 clusters=19305]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 1.90e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 320/1030 [06:19<14:02,  1.19s/it, fwd_loss=11.6720 bwd_loss=0.729499 rate=100.0% proc=320 skip=0 clusters=19748]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.00e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 336/1030 [06:38<13:56,  1.21s/it, fwd_loss=11.6286 bwd_loss=0.726785 rate=100.0% proc=336 skip=0 clusters=20175]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.10e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 352/1030 [06:57<13:22,  1.18s/it, fwd_loss=11.6455 bwd_loss=0.727842 rate=100.0% proc=352 skip=0 clusters=20572]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.20e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 368/1030 [07:16<12:59,  1.18s/it, fwd_loss=11.3409 bwd_loss=0.708809 rate=100.0% proc=368 skip=0 clusters=20908]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.30e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 384/1030 [07:34<12:38,  1.17s/it, fwd_loss=11.6576 bwd_loss=0.728599 rate=100.0% proc=384 skip=0 clusters=21248]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.40e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 399/1030 [07:51<12:07,  1.15s/it, fwd_loss=11.6470 bwd_loss=0.727935 rate=100.0% proc=399 skip=0 clusters=21515]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.50e-06 < MIN_LR 5.00e-06\n[TRAIN-DEBUG] GPU mem (GB):\n  GPU 0: alloc=1.90 resv=5.00\n  GPU 1: alloc=0.02 resv=3.15\n[TRAIN-DEBUG] step=400 loss=11.7051 lr=2.50e-06 opt_updates=25 clusters=21541\n\n[CLUSTER] Top 5 clusters (by sample count):\n------------------------------------------------------------------------------------------\nRank  Token             Count       Protos    Œº (mean)       œÑ (dev)     \n------------------------------------------------------------------------------------------\n1     ‡¶§‡¶ø‡¶®‡¶ø              20          1         0.000000       0.000001    \n2     ‡¶ï‡¶∞‡ßá‡¶õ‡ßá             20          1         0.000000       0.000001    \n3     ‡¶ï‡¶Ç‡¶ó‡ßç‡¶∞‡ßá‡¶∏‡ßá‡¶∞         20          1         0.000000       0.000001    \n4     ‡¶∏‡¶¶‡¶∏‡ßç‡¶Ø‡•§            20          1         0.000000       0.000001    \n5     ‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé            20          1         0.000000       0.000001    \n------------------------------------------------------------------------------------------\nTotal clusters: 21541 | Total samples in clusters: 70015\n\n[CLUSTER-STATS] Cluster Statistics:\n  ‚Ä¢ Total clusters: 21541\n  ‚Ä¢ Total samples: 70015\n  ‚Ä¢ Total prototypes: 8547\n  ‚Ä¢ Avg samples/cluster: 3.3\n  ‚Ä¢ Avg protos/cluster: 0.4\n  ‚Ä¢ Max samples/cluster: 20\n  ‚Ä¢ Min samples/cluster: 0\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             | 416/1030 [08:11<12:13,  1.19s/it, fwd_loss=11.6788 bwd_loss=0.729926 rate=100.0% proc=416 skip=0 clusters=21858]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.60e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 432/1030 [08:30<12:07,  1.22s/it, fwd_loss=11.4692 bwd_loss=0.716824 rate=100.0% proc=432 skip=0 clusters=22191]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.70e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 448/1030 [08:48<11:10,  1.15s/it, fwd_loss=11.4985 bwd_loss=0.718657 rate=100.0% proc=448 skip=0 clusters=22498]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.80e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                           | 464/1030 [09:07<11:20,  1.20s/it, fwd_loss=11.5662 bwd_loss=0.722885 rate=100.0% proc=464 skip=0 clusters=22777]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 2.90e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 480/1030 [09:25<10:17,  1.12s/it, fwd_loss=11.7204 bwd_loss=0.732522 rate=100.0% proc=479 skip=0 clusters=23017]","output_type":"stream"},{"name":"stdout","text":"[RUNTIME] RuntimeError at step 480: RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 496/1030 [09:44<10:32,  1.18s/it, fwd_loss=11.1477 bwd_loss=0.696731 rate=100.0% proc=495 skip=1 clusters=23273]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 3.00e-06 < MIN_LR 5.00e-06\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 511/1030 [10:02<09:46,  1.13s/it, fwd_loss=11.3029 bwd_loss=0.706429 rate=96.8% proc=510 skip=1 clusters=23479]","output_type":"stream"},{"name":"stdout","text":"[SCHEDULER] Warning: LR 3.10e-06 < MIN_LR 5.00e-06\n\n======================================================================\n[VALIDATION] Quick validation at step 512\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [0,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [5,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [3,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [1,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [6,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [4,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [7,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1478: indexSelectSmallIndex: block: [2,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"name":"stdout","text":"1. ‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶≤ ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡•§ -> \n2. Validation error: AcceleratorError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAU\n3. Validation error: AcceleratorError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAU\n4. Validation error: AcceleratorError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAU\n5. Validation error: AcceleratorError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAU\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 512/1030 [10:04<12:19,  1.43s/it, fwd_loss=11.3998 bwd_loss=0.712487 rate=100.0% proc=511 skip=1 clusters=23499]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# save the model to drive","metadata":{}},{"cell_type":"code","source":"!pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n\nimport os\nimport io\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\nfrom google.colab import auth\nfrom google.auth import default\n\n# Authenticate\nauth.authenticate_user()\ncreds, _ = default()\n\n# Build Drive service\nservice = build('drive', 'v3', credentials=creds)\n\n# Configuration\nGDRIVE_FOLDER_ID = '1xsZaVHm13pRWRlBpX1kCXE2U9RVBc4SH'\nLOCAL_DIR = '/kaggle/working/'\nCHUNK_SIZE = 100 * 1024 * 1024  # 100 MB chunks for resumable upload\n\n# Get all files\nprint(f\"Scanning directory: {LOCAL_DIR}\")\nall_files = [f for f in os.listdir(LOCAL_DIR) if os.path.isfile(os.path.join(LOCAL_DIR, f))]\n\nif not all_files:\n    print(\"‚ö† No files found in /kaggle/working/\")\nelse:\n    print(f\"Found {len(all_files)} file(s) to upload:\\n\")\n    \n    uploaded_count = 0\n    failed_count = 0\n    \n    for idx, filename in enumerate(all_files, 1):\n        try:\n            local_path = os.path.join(LOCAL_DIR, filename)\n            file_size = os.path.getsize(local_path) / (1024**2)\n            \n            print(f\"[{idx}/{len(all_files)}] Uploading: {filename} ({file_size:.2f} MB)...\")\n            \n            # File metadata\n            file_metadata = {\n                'name': filename,\n                'parents': [GDRIVE_FOLDER_ID]\n            }\n            \n            # Use MediaFileUpload with resumable=True for large files\n            media = MediaFileUpload(\n                local_path,\n                resumable=True,\n                chunksize=CHUNK_SIZE\n            )\n            \n            # Create and execute upload request\n            request = service.files().create(\n                body=file_metadata,\n                media_body=media,\n                fields='id,name,size'\n            )\n            \n            response = None\n            last_progress = 0\n            \n            while response is None:\n                status, response = request.next_chunk()\n                if status:\n                    progress = int(status.progress() * 100)\n                    if progress != last_progress and progress % 10 == 0:\n                        print(f\"  Progress: {progress}%\")\n                        last_progress = progress\n            \n            print(f\"  ‚úì Successfully uploaded (ID: {response.get('id')})\")\n            uploaded_count += 1\n            \n        except Exception as e:\n            print(f\"  ‚úó Failed: {str(e)}\")\n            failed_count += 1\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Upload Summary:\")\n    print(f\"  ‚úì Successfully uploaded: {uploaded_count}\")\n    print(f\"  ‚úó Failed: {failed_count}\")\n    print(f\"  Total files: {len(all_files)}\")\n    print(f\"{'='*60}\")\n    print(f\"\\nAll files uploaded to: https://drive.google.com/drive/folders/{GDRIVE_FOLDER_ID}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-24T20:21:28.456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# CELL 12: BLEU & ChrF++ EVALUATION ON 5K TEST SAMPLES (IndicBART-READY)\n# ==============================================================================\n# Evaluates translation quality using standard metrics:\n# - BLEU score (bilingual evaluation understudy)\n# - ChrF++ score (character n-gram F-score)\n#\n# üî• IndicBART-SPECIFIC FIXES (15 NEW):\n# FIX #1:  üî• Import MODEL_NAME from Cell 0 (supports M2M100 & IndicBART)\n# FIX #2:  üî• Model family detection (IndicBART vs M2M100)\n# FIX #3:  üî• Language code handling (bn_IN/en_XX for IndicBART, bn/en for M2M100)\n# FIX #4:  üî• Model-agnostic tokenizer references (not \"M2M100 tokenizer\")\n# FIX #5:  üî• Model reconstruction with family detection\n# FIX #6:  üî• forced_bos_token_id handling for both models\n# FIX #7:  üî• Tokenizer src_lang setting based on model family\n# FIX #8:  üî• Model-agnostic print messages throughout\n# FIX #9:  üî• Dynamic model attribute detection (m2m100_model OR mbart)\n# FIX #10: üî• Language token extraction for IndicBART\n# FIX #11: üî• Model family validation in reconstruction\n# FIX #12: üî• Updated comments and documentation\n# FIX #13: üî• Model-specific generation parameters\n# FIX #14: üî• Evaluation summary with model family info\n# FIX #15: üî• Auto-detection messages for model family\n#\n# üî¨ EXISTING FIXES PRESERVED:\n# ‚úì Properly loads best model from checkpoint with state_dict reconstruction\n# ‚úì Compatible with Cells 0-11 (uses same dataset, Cell 6 model, Cell 8 inference)\n# ‚úì AUTO-EXECUTES: Runs evaluation automatically if model and tokenizer available\n# ‚úì SMART DETECTION: Checks multiple variable names and can load from checkpoint\n# ‚úì AUTO-SWAPS: Automatically detects and corrects bn/en direction\n# ‚úì Repetition penalty fix for quote repetition bug\n# ==============================================================================\n\nimport os\nimport time\nfrom typing import List, Dict, Any, Tuple, Optional\nimport traceback\nfrom tqdm import tqdm\n\nimport torch\nfrom datasets import load_dataset\n\n# Metrics libraries\ntry:\n    from sacrebleu import corpus_bleu, corpus_chrf\n    _SACREBLEU_AVAILABLE = True\nexcept ImportError:\n    print(\"[EVAL-METRICS] WARNING: sacrebleu not installed. Installing...\")\n    try:\n        import subprocess\n        subprocess.check_call([\"pip\", \"install\", \"sacrebleu\"])\n        from sacrebleu import corpus_bleu, corpus_chrf\n        _SACREBLEU_AVAILABLE = True\n        print(\"[EVAL-METRICS] sacrebleu installed successfully\")\n    except Exception as e:\n        print(f\"[EVAL-METRICS] ERROR: Could not install sacrebleu: {e}\")\n        _SACREBLEU_AVAILABLE = False\n\n# Fallback to alternative metrics if sacrebleu unavailable\nif not _SACREBLEU_AVAILABLE:\n    try:\n        from nltk.translate.bleu_score import corpus_bleu as nltk_corpus_bleu, SmoothingFunction\n        import nltk\n        try:\n            nltk.download('punkt', quiet=True)\n        except Exception:\n            pass\n        _NLTK_AVAILABLE = True\n    except ImportError:\n        _NLTK_AVAILABLE = False\n        print(\"[EVAL-METRICS] WARNING: Neither sacrebleu nor nltk available for BLEU calculation\")\n\n# ==============================================================================\n# üî• FIX #1 & #2: Import MODEL_NAME and detect model family\n# ==============================================================================\n_MODEL_NAME = str(globals().get(\"MODEL_NAME\", \"facebook/m2m100_418M\"))\n_SOURCE_LANGUAGE = str(globals().get(\"SOURCE_LANGUAGE\", \"bn\"))\n_TARGET_LANGUAGE = str(globals().get(\"TARGET_LANGUAGE\", \"en\"))\n\n# Detect model family\n_IS_INDICBART = \"indicbart\" in _MODEL_NAME.lower() or \"indic\" in _MODEL_NAME.lower()\n_IS_M2M100 = \"m2m100\" in _MODEL_NAME.lower()\n_MODEL_FAMILY = \"IndicBART\" if _IS_INDICBART else (\"M2M100\" if _IS_M2M100 else \"Unknown\")\n\nprint(f\"[EVAL-INIT] Model configuration:\")\nprint(f\"   ‚Ä¢ Model: {_MODEL_NAME}\")\nprint(f\"   ‚Ä¢ Family: {_MODEL_FAMILY}\")\nprint(f\"   ‚Ä¢ Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"   ‚Ä¢ Target language: {_TARGET_LANGUAGE}\")\n\n# ==============================================================================\n# üî• FIX #3: Language codes based on model family\n# ==============================================================================\nif _IS_INDICBART:\n    # IndicBART uses ISO 639-1 code + region (bn_IN, en_XX)\n    _BN_LANG = f\"{_SOURCE_LANGUAGE}_IN\"  # bn_IN\n    _EN_LANG = f\"{_TARGET_LANGUAGE}_XX\"  # en_XX\n    _BN_LANG_SHORT = _SOURCE_LANGUAGE     # bn (for dataset loading)\n    _EN_LANG_SHORT = _TARGET_LANGUAGE     # en (for dataset loading)\nelse:\n    # M2M100 uses simple codes (bn, en)\n    _BN_LANG = _SOURCE_LANGUAGE           # bn\n    _EN_LANG = _TARGET_LANGUAGE           # en\n    _BN_LANG_SHORT = _SOURCE_LANGUAGE     # bn\n    _EN_LANG_SHORT = _TARGET_LANGUAGE     # en\n\nprint(f\"[EVAL-INIT] Language codes for {_MODEL_FAMILY}:\")\nprint(f\"   ‚Ä¢ Source (tokenizer): {_BN_LANG}\")\nprint(f\"   ‚Ä¢ Target (tokenizer): {_EN_LANG}\")\nprint(f\"   ‚Ä¢ Source (dataset): {_BN_LANG_SHORT}\")\nprint(f\"   ‚Ä¢ Target (dataset): {_EN_LANG_SHORT}\")\n\n# Read configuration from Cell 0\n_DEVICE = globals().get(\"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n_MAX_LENGTH = int(globals().get(\"MAX_LENGTH\", 48))\n_USE_MULTI_GPU = bool(globals().get(\"USE_MULTI_GPU\", False))\n_VERBOSE_LOGGING = bool(globals().get(\"VERBOSE_LOGGING\", False))\n_CHECKPOINT_DIR = str(globals().get(\"CHECKPOINT_DIR\", \"/kaggle/working/\"))\n\n# Dataset configuration (same as Cell 2)\n_DATASET_NAME = str(globals().get(\"DATASET_NAME\", \"ai4bharat/samanantar\"))\n_DATASET_LANG_PAIR = str(globals().get(\"DATASET_LANG_PAIR\", \"bn\"))\n_DATASET_SPLIT = str(globals().get(\"DATASET_SPLIT\", \"train\"))\n\n# Evaluation parameters\nEVAL_NUM_SAMPLES = 5000\nEVAL_BATCH_SIZE = 16\nEVAL_MAX_LENGTH = _MAX_LENGTH\nEVAL_NUM_BEAMS = 4\n\n\n# ==============================================================================\n# üî• FIX #5 & #11: Model reconstruction with family detection\n# ==============================================================================\ndef reconstruct_model_from_checkpoint(checkpoint_path: str, device: torch.device = _DEVICE):\n    \"\"\"\n    Reconstruct TATN model from checkpoint containing state_dict.\n    \n    üî• FIX #5: Now detects model family and reconstructs accordingly.\n    \n    Args:\n        checkpoint_path: Path to checkpoint file\n        device: Device to load model on\n    \n    Returns:\n        Tuple of (model, metadata_dict) or (None, error_message)\n    \"\"\"\n    try:\n        print(f\"[MODEL-RECONSTRUCT] Loading checkpoint from: {checkpoint_path}\")\n        checkpoint = torch.load(checkpoint_path, map_location=device)\n        \n        if not isinstance(checkpoint, dict):\n            return None, \"Checkpoint is not a dictionary\"\n        \n        # Check if it's a full model object\n        if 'model' in checkpoint and hasattr(checkpoint['model'], 'forward'):\n            model = checkpoint['model']\n            model = model.to(device)\n            model.eval()\n            print(f\"[MODEL-RECONSTRUCT] ‚úÖ Loaded full model object from checkpoint\")\n            return model, checkpoint\n        \n        # Otherwise, need to reconstruct from state_dict\n        if 'model_state_dict' not in checkpoint:\n            return None, \"Checkpoint missing 'model_state_dict' key\"\n        \n        print(f\"[MODEL-RECONSTRUCT] Checkpoint contains state_dict, reconstructing model...\")\n        \n        # ==================================================================\n        # üî• FIX #11: Detect model family from checkpoint or globals\n        # ==================================================================\n        checkpoint_model_name = checkpoint.get('model_name', _MODEL_NAME)\n        checkpoint_is_indicbart = \"indicbart\" in checkpoint_model_name.lower() or \"indic\" in checkpoint_model_name.lower()\n        checkpoint_is_m2m100 = \"m2m100\" in checkpoint_model_name.lower()\n        checkpoint_model_family = \"IndicBART\" if checkpoint_is_indicbart else (\"M2M100\" if checkpoint_is_m2m100 else \"Unknown\")\n        \n        print(f\"[MODEL-RECONSTRUCT] Checkpoint model family: {checkpoint_model_family}\")\n        \n        # Validate compatibility\n        if checkpoint_model_family != _MODEL_FAMILY and checkpoint_model_family != \"Unknown\":\n            print(f\"[MODEL-RECONSTRUCT] ‚ö†Ô∏è  WARNING: Checkpoint is {checkpoint_model_family} but current config is {_MODEL_FAMILY}\")\n            print(f\"[MODEL-RECONSTRUCT]    Attempting to load anyway...\")\n        \n        # ==================================================================\n        # Import model class from Cell 6\n        # ==================================================================\n        try:\n            # Try to get model class from globals (Cell 6 should have defined it)\n            DualPathTATN = globals().get('DualPathTATN', None)\n            \n            if DualPathTATN is None:\n                # Try alternate name\n                DualPathTATN = globals().get('TAINModelDualPath', None)\n            \n            if DualPathTATN is None:\n                return None, \"DualPathTATN class not found in globals (Cell 6 not executed?)\"\n            \n            print(f\"[MODEL-RECONSTRUCT] ‚úÖ Found DualPathTATN class in globals\")\n            \n        except Exception as e:\n            return None, f\"Failed to import model class: {e}\"\n        \n        # ==================================================================\n        # üî• FIX #4: Get tokenizer with model-agnostic naming\n        # ==================================================================\n        base_tokenizer = globals().get('tokenizer', None)\n        word_tokenizer = globals().get('word_tokenizer', None)\n        dscd = globals().get('dscd', None)\n        asbn = globals().get('asbn', None)\n        \n        if base_tokenizer is None:\n            return None, f\"{_MODEL_FAMILY} tokenizer not found in globals (Cell 2 not executed?)\"\n        \n        print(f\"[MODEL-RECONSTRUCT] ‚úÖ Found tokenizers in globals\")\n        print(f\"[MODEL-RECONSTRUCT]   - Base tokenizer ({_MODEL_FAMILY}): {type(base_tokenizer).__name__}\")\n        print(f\"[MODEL-RECONSTRUCT]   - Word tokenizer: {type(word_tokenizer).__name__ if word_tokenizer else 'None'}\")\n        print(f\"[MODEL-RECONSTRUCT]   - DSCD module: {'Available' if dscd else 'Not available'}\")\n        print(f\"[MODEL-RECONSTRUCT]   - ASBN module: {'Available' if asbn else 'Not available'}\")\n        \n        # ==================================================================\n        # Reconstruct model architecture\n        # ==================================================================\n        try:\n            print(f\"[MODEL-RECONSTRUCT] Reconstructing DualPathTATN architecture for {_MODEL_FAMILY}...\")\n            \n            model = DualPathTATN(\n                m2m_tokenizer=base_tokenizer,  # Works for both M2M100 and IndicBART\n                word_tokenizer=word_tokenizer,\n                dscd_module=dscd,\n                asbn_module=asbn,\n                device=device\n            )\n            \n            print(f\"[MODEL-RECONSTRUCT] ‚úÖ Model architecture created\")\n            \n        except Exception as e:\n            return None, f\"Failed to create model architecture: {e}\"\n        \n        # ==================================================================\n        # Load state_dict into model\n        # ==================================================================\n        try:\n            state_dict = checkpoint['model_state_dict']\n            \n            # Handle DataParallel wrapped models\n            if list(state_dict.keys())[0].startswith('module.'):\n                print(f\"[MODEL-RECONSTRUCT] Detected DataParallel state_dict, unwrapping...\")\n                from collections import OrderedDict\n                new_state_dict = OrderedDict()\n                for k, v in state_dict.items():\n                    name = k[7:]  # remove 'module.' prefix\n                    new_state_dict[name] = v\n                state_dict = new_state_dict\n            \n            # Load state dict\n            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n            \n            if missing_keys:\n                print(f\"[MODEL-RECONSTRUCT] ‚ö†Ô∏è  Missing keys: {len(missing_keys)}\")\n                if _VERBOSE_LOGGING:\n                    print(f\"[MODEL-RECONSTRUCT]   {missing_keys[:5]}\")\n            \n            if unexpected_keys:\n                print(f\"[MODEL-RECONSTRUCT] ‚ö†Ô∏è  Unexpected keys: {len(unexpected_keys)}\")\n                if _VERBOSE_LOGGING:\n                    print(f\"[MODEL-RECONSTRUCT]   {unexpected_keys[:5]}\")\n            \n            model = model.to(device)\n            model.eval()\n            \n            print(f\"[MODEL-RECONSTRUCT] ‚úÖ State dict loaded successfully\")\n            \n            # Print checkpoint metadata\n            if 'epoch' in checkpoint:\n                print(f\"[MODEL-RECONSTRUCT] Checkpoint metadata:\")\n                print(f\"   - Model: {checkpoint_model_family}\")\n                print(f\"   - Epoch: {checkpoint['epoch']}\")\n                print(f\"   - Global step: {checkpoint.get('global_step', 'N/A')}\")\n                if 'avg_epoch_loss' in checkpoint:\n                    print(f\"   - Avg loss: {checkpoint['avg_epoch_loss']:.6f}\")\n            \n            return model, checkpoint\n            \n        except Exception as e:\n            return None, f\"Failed to load state_dict: {e}\"\n    \n    except Exception as e:\n        return None, f\"Failed to load checkpoint: {e}\"\n\n\n# ------------------------------------------------------------------------------\n# Smart Model Detection Function (FIXED TO HANDLE BEST MODEL)\n# ------------------------------------------------------------------------------\ndef find_trained_model():\n    \"\"\"\n    Intelligently search for trained model in globals, locals, or checkpoint.\n    PRIORITY: Tries to load best model checkpoint first.\n    \n    üî• FIX #15: Updated detection messages to show model family.\n    \n    Returns:\n        Tuple of (model, source_description) or (None, error_message)\n    \"\"\"\n    # ==================================================================\n    # Try best model checkpoint FIRST\n    # ==================================================================\n    best_model_paths = [\n        os.path.join(_CHECKPOINT_DIR, 'tatn_best_model.pt'),\n        'tatn_best_model.pt',\n        '/kaggle/working/tatn_best_model.pt'\n    ]\n    \n    for best_path in best_model_paths:\n        if os.path.exists(best_path):\n            print(f\"[MODEL-DETECT] üåü Found BEST MODEL checkpoint: {best_path}\")\n            model, result = reconstruct_model_from_checkpoint(best_path, device=_DEVICE)\n            \n            if model is not None:\n                return model, f\"‚úÖ Loaded BEST MODEL ({_MODEL_FAMILY}) from checkpoint '{best_path}'\"\n            else:\n                print(f\"[MODEL-DETECT] Failed to load best model: {result}\")\n    \n    # Try to find model in globals\n    model_candidates = ['tatn_model', 'trained_model', 'model']\n    \n    for candidate in model_candidates:\n        if candidate in globals():\n            model = globals()[candidate]\n            if model is not None and hasattr(model, 'forward'):\n                return model, f\"Found '{candidate}' ({_MODEL_FAMILY}) in globals\"\n        \n        try:\n            import inspect\n            frame = inspect.currentframe().f_back.f_back\n            if frame and candidate in frame.f_locals:\n                model = frame.f_locals[candidate]\n                if model is not None and hasattr(model, 'forward'):\n                    return model, f\"Found '{candidate}' ({_MODEL_FAMILY}) in locals\"\n        except Exception:\n            pass\n    \n    # Try other checkpoints\n    checkpoint_paths = [\n        os.path.join(_CHECKPOINT_DIR, 'tatn_kaggle_final.pt'),\n        'tatn_kaggle_final.pt',\n        os.path.join(_CHECKPOINT_DIR, 'tatn_e1_s1544_20260121_032113.pt'),\n        'tatn_e1_s1544_20260121_032113.pt'\n    ]\n    \n    for ckpt_path in checkpoint_paths:\n        if os.path.exists(ckpt_path):\n            print(f\"[MODEL-DETECT] Found checkpoint: {ckpt_path}\")\n            model, result = reconstruct_model_from_checkpoint(ckpt_path, device=_DEVICE)\n            \n            if model is not None:\n                return model, f\"Loaded {_MODEL_FAMILY} model from checkpoint '{ckpt_path}'\"\n            else:\n                print(f\"[MODEL-DETECT] Failed to load: {result}\")\n    \n    return None, f\"No {_MODEL_FAMILY} model found in scope and no valid checkpoint available\"\n\n\n# ------------------------------------------------------------------------------\n# Language Detection Helpers\n# ------------------------------------------------------------------------------\ndef is_bengali(text: str) -> bool:\n    \"\"\"Check if text contains Bengali characters (Unicode range U+0980‚ÄìU+09FF).\"\"\"\n    if not text:\n        return False\n    bengali_chars = sum(1 for c in text if '\\u0980' <= c <= '\\u09FF')\n    return bengali_chars > len(text) * 0.3\n\n\ndef is_english(text: str) -> bool:\n    \"\"\"Check if text is primarily English (Latin characters).\"\"\"\n    if not text:\n        return False\n    latin_chars = sum(1 for c in text if ('a' <= c.lower() <= 'z') or c in ' ,.-')\n    return latin_chars > len(text) * 0.5\n\n\n# ------------------------------------------------------------------------------\n# Dataset Loading for Evaluation (FIXED WITH AUTO-DETECTION)\n# ------------------------------------------------------------------------------\ndef load_evaluation_data(\n    num_samples: int = EVAL_NUM_SAMPLES,\n    dataset_name: str = _DATASET_NAME,\n    lang_pair: str = _DATASET_LANG_PAIR,\n    split: str = _DATASET_SPLIT,\n    skip_first: int = 100000\n) -> List[Tuple[str, str]]:\n    \"\"\"\n    Load evaluation dataset (Bengali‚ÜíEnglish pairs).\n    \n    CRITICAL FIX: Automatically detects and swaps source/target\n    to ensure Bengali is source and English is target.\n    \n    Args:\n        num_samples: Number of samples to load (default 5000)\n        dataset_name: HuggingFace dataset name\n        lang_pair: Language pair code\n        split: Dataset split to use\n        skip_first: Skip first N samples (to avoid overlap with training data)\n    \n    Returns:\n        List of (bengali_text, english_text) tuples\n    \"\"\"\n    print(f\"\\n[EVAL-DATA] Loading {num_samples} evaluation samples from {dataset_name}...\")\n    print(f\"[EVAL-DATA] Skipping first {skip_first} samples (training data)\")\n    print(f\"[EVAL-DATA] Required direction: Bengali ({_BN_LANG_SHORT}) ‚Üí English ({_EN_LANG_SHORT})\")\n    print(f\"[EVAL-DATA] Model: {_MODEL_FAMILY}\")\n    \n    try:\n        dataset = load_dataset(dataset_name, lang_pair, split=split, streaming=True)\n        \n        pairs = []\n        skipped = 0\n        processed = 0\n        direction_detected = False\n        needs_swap = False\n        \n        for item in dataset:\n            if skipped < skip_first:\n                skipped += 1\n                continue\n            \n            try:\n                # Extract both fields using multiple patterns\n                field1 = None\n                field2 = None\n                \n                # Pattern 1: Direct 'src'/'tgt' keys\n                if 'src' in item and 'tgt' in item:\n                    field1 = str(item['src']).strip()\n                    field2 = str(item['tgt']).strip()\n                \n                # Pattern 2: 'translation' dict with language codes\n                elif 'translation' in item and isinstance(item['translation'], dict):\n                    trans_dict = item['translation']\n                    if 'bn' in trans_dict and 'en' in trans_dict:\n                        field1 = str(trans_dict['bn']).strip()\n                        field2 = str(trans_dict['en']).strip()\n                    elif _BN_LANG_SHORT in trans_dict and _EN_LANG_SHORT in trans_dict:\n                        field1 = str(trans_dict[_BN_LANG_SHORT]).strip()\n                        field2 = str(trans_dict[_EN_LANG_SHORT]).strip()\n                \n                # Pattern 3: Direct language code keys\n                elif 'bn' in item and 'en' in item:\n                    field1 = str(item['bn']).strip()\n                    field2 = str(item['en']).strip()\n                elif _BN_LANG_SHORT in item and _EN_LANG_SHORT in item:\n                    field1 = str(item[_BN_LANG_SHORT]).strip()\n                    field2 = str(item[_EN_LANG_SHORT]).strip()\n                \n                if not field1 or not field2:\n                    continue\n                \n                # CRITICAL: Auto-detect which field is Bengali on first sample\n                if not direction_detected:\n                    field1_is_bengali = is_bengali(field1)\n                    field2_is_bengali = is_bengali(field2)\n                    field1_is_english = is_english(field1)\n                    field2_is_english = is_english(field2)\n                    \n                    print(f\"\\n[EVAL-DATA] üîç Detecting language direction from first sample:\")\n                    print(f\"[EVAL-DATA]   Field 1: '{field1[:60]}...'\")\n                    print(f\"[EVAL-DATA]   Field 1 is Bengali: {field1_is_bengali}, is English: {field1_is_english}\")\n                    print(f\"[EVAL-DATA]   Field 2: '{field2[:60]}...'\")\n                    print(f\"[EVAL-DATA]   Field 2 is Bengali: {field2_is_bengali}, is English: {field2_is_english}\")\n                    \n                    # Determine if we need to swap\n                    if field1_is_english and field2_is_bengali:\n                        needs_swap = True\n                        print(f\"[EVAL-DATA] ‚úÖ SWAPPING: Dataset has English‚ÜíBengali, need Bengali‚ÜíEnglish\")\n                    elif field1_is_bengali and field2_is_english:\n                        needs_swap = False\n                        print(f\"[EVAL-DATA] ‚úÖ NO SWAP: Dataset already has Bengali‚ÜíEnglish\")\n                    else:\n                        print(f\"[EVAL-DATA] ‚ö†Ô∏è  WARNING: Could not clearly detect languages!\")\n                        print(f\"[EVAL-DATA]   Assuming field 1 = source, field 2 = target\")\n                        needs_swap = False\n                    \n                    direction_detected = True\n                \n                # Apply swap if needed\n                if needs_swap:\n                    bengali_text = field2\n                    english_text = field1\n                else:\n                    bengali_text = field1\n                    english_text = field2\n                \n                # Validation checks\n                if len(bengali_text) < 5 or len(english_text) < 5:\n                    continue\n                \n                if len(bengali_text) > 500 or len(english_text) > 500:\n                    continue\n                \n                # Final validation: Ensure Bengali text has Bengali characters\n                if not is_bengali(bengali_text):\n                    if _VERBOSE_LOGGING and processed < 5:\n                        print(f\"[EVAL-DATA] WARNING: Source missing Bengali chars: {bengali_text[:50]}\")\n                    continue\n                \n                pairs.append((bengali_text, english_text))\n                processed += 1\n                \n                if processed >= num_samples:\n                    break\n            \n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[EVAL-DATA] Sample parsing error: {e}\")\n                continue\n        \n        print(f\"[EVAL-DATA] Loaded {len(pairs)} valid evaluation pairs\")\n        \n        # Validate first pair to confirm direction\n        if pairs:\n            first_src, first_tgt = pairs[0]\n            src_is_bengali = is_bengali(first_src)\n            tgt_is_english = is_english(first_tgt)\n            \n            print(f\"\\n[EVAL-DATA] ‚úÖ VALIDATION:\")\n            print(f\"[EVAL-DATA]   First source: {first_src[:60]}...\")\n            print(f\"[EVAL-DATA]   First target: {first_tgt[:60]}...\")\n            print(f\"[EVAL-DATA]   Source is Bengali: {src_is_bengali} {'‚úÖ' if src_is_bengali else '‚ùå'}\")\n            print(f\"[EVAL-DATA]   Target is English: {tgt_is_english} {'‚úÖ' if tgt_is_english else '‚ùå'}\")\n            \n            if not src_is_bengali or not tgt_is_english:\n                print(f\"[EVAL-DATA] ‚ùå‚ùå‚ùå ERROR: Direction is still wrong after detection!\")\n                print(f\"[EVAL-DATA] This will produce meaningless scores!\")\n        \n        return pairs\n    \n    except Exception as e:\n        print(f\"[EVAL-DATA] ERROR loading dataset: {type(e).__name__}: {str(e)}\")\n        traceback.print_exc()\n        return []\n\n\n# ------------------------------------------------------------------------------\n# üî• FIX #6-#10: Batch Translation Function with model family support\n# ------------------------------------------------------------------------------\n@torch.inference_mode()\ndef translate_batch(\n    model,\n    tokenizer,\n    source_texts: List[str],\n    max_length: int = EVAL_MAX_LENGTH,\n    num_beams: int = EVAL_NUM_BEAMS,\n    device: torch.device = _DEVICE\n) -> List[str]:\n    \"\"\"\n    Translate a batch of Bengali sentences to English.\n    \n    üî• FIX #6-#10: Now supports both M2M100 and IndicBART models.\n    \n    Compatible with Cell 6's dual-path TATN model.\n    \n    Args:\n        model: TATN model (Cell 6 structure)\n        tokenizer: Base tokenizer (M2M100 or IndicBART)\n        source_texts: List of Bengali sentences\n        max_length: Maximum sequence length\n        num_beams: Number of beams for beam search\n        device: Device to run on\n    \n    Returns:\n        List of English translations\n    \"\"\"\n    if not source_texts:\n        return []\n    \n    # ==================================================================\n    # üî• FIX #7: Set source language based on model family\n    # ==================================================================\n    try:\n        if hasattr(tokenizer, \"src_lang\"):\n            tokenizer.src_lang = _BN_LANG  # bn_IN for IndicBART, bn for M2M100\n            if _VERBOSE_LOGGING:\n                print(f\"[TRANSLATE] Set tokenizer.src_lang = {_BN_LANG}\")\n    except Exception:\n        pass\n    \n    core_model = model.module if (_USE_MULTI_GPU and hasattr(model, \"module\")) else model\n    core_model.eval()\n    \n    try:\n        enc = tokenizer(\n            source_texts,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=max_length\n        )\n        \n        enc = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in enc.items()}\n        \n        # Try using Cell 6's generate method first\n        if hasattr(core_model, \"generate\"):\n            try:\n                result = core_model.generate(\n                    input_ids=enc.get(\"input_ids\"),\n                    attention_mask=enc.get(\"attention_mask\"),\n                    src_text=source_texts,  # Cell 6 expects src_text (singular)\n                    max_length=max_length,\n                    num_beams=num_beams\n                )\n                \n                if isinstance(result, dict) and 'translations' in result:\n                    return result['translations']\n            \n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[TRANSLATE] Cell 6 generate() failed: {e}\")\n        \n        # ==================================================================\n        # üî• FIX #9: Dynamic model attribute detection (m2m100_model OR mbart)\n        # ==================================================================\n        base_model = getattr(core_model, \"m2m100_model\", None)\n        if base_model is None:\n            base_model = getattr(core_model, \"mbart\", None)\n        if base_model is None:\n            base_model = getattr(core_model, \"base_model\", None)\n        if base_model is None:\n            base_model = getattr(core_model, \"model\", None)\n        \n        if base_model is not None:\n            try:\n                # ==================================================================\n                # üî• FIX #6 & #10: Get target language token ID based on model family\n                # ==================================================================\n                forced_id = None\n                \n                # Try multiple methods to get target language ID\n                if hasattr(tokenizer, \"get_lang_id\"):\n                    try:\n                        forced_id = tokenizer.get_lang_id(_EN_LANG)  # en_XX for IndicBART, en for M2M100\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TRANSLATE] Got forced_id={forced_id} from get_lang_id('{_EN_LANG}')\")\n                    except Exception as e:\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TRANSLATE] get_lang_id failed: {e}\")\n                \n                # Fallback: Try lang_code_to_id\n                if forced_id is None and hasattr(tokenizer, \"lang_code_to_id\"):\n                    # Try exact match first\n                    forced_id = tokenizer.lang_code_to_id.get(_EN_LANG)\n                    if forced_id is None:\n                        # Try common variants\n                        for variant in [\"en\", \"en_XX\", \"eng_Latn\"]:\n                            forced_id = tokenizer.lang_code_to_id.get(variant)\n                            if forced_id is not None:\n                                if _VERBOSE_LOGGING:\n                                    print(f\"[TRANSLATE] Got forced_id={forced_id} from lang_code_to_id['{variant}']\")\n                                break\n                \n                # Fallback: Try convert_tokens_to_ids\n                if forced_id is None and hasattr(tokenizer, \"convert_tokens_to_ids\"):\n                    try:\n                        forced_id = tokenizer.convert_tokens_to_ids(_EN_LANG)\n                        if isinstance(forced_id, list):\n                            forced_id = forced_id[0] if forced_id else None\n                        if _VERBOSE_LOGGING and forced_id is not None:\n                            print(f\"[TRANSLATE] Got forced_id={forced_id} from convert_tokens_to_ids('{_EN_LANG}')\")\n                    except Exception:\n                        pass\n                \n                # ==================================================================\n                # üî• FIX #13: Set generation parameters based on model family\n                # ==================================================================\n                if hasattr(base_model, \"config\") and forced_id is not None:\n                    try:\n                        base_model.config.forced_bos_token_id = int(forced_id)\n                        if _IS_M2M100:\n                            base_model.config.decoder_start_token_id = int(forced_id)\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TRANSLATE] Set forced_bos_token_id = {forced_id}\")\n                    except Exception as e:\n                        if _VERBOSE_LOGGING:\n                            print(f\"[TRANSLATE] Failed to set forced_bos_token_id: {e}\")\n                \n                # Generate with repetition penalty to fix quote repetition bug\n                generated_ids = base_model.generate(\n                    enc.get(\"input_ids\"),\n                    attention_mask=enc.get(\"attention_mask\"),\n                    max_length=max_length,\n                    num_beams=num_beams,\n                    early_stopping=True,\n                    repetition_penalty=1.2,      # FIX: Prevent repetition\n                    no_repeat_ngram_size=3,       # FIX: Prevent 3-gram repetition\n                    pad_token_id=getattr(tokenizer, \"pad_token_id\", 1),\n                    forced_bos_token_id=forced_id\n                )\n                \n                translations = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n                return translations\n            \n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[TRANSLATE] {_MODEL_FAMILY} generation failed: {e}\")\n                return [\"\"] * len(source_texts)\n        \n        return [\"\"] * len(source_texts)\n    \n    except Exception as e:\n        if _VERBOSE_LOGGING:\n            print(f\"[TRANSLATE] Batch translation error: {e}\")\n            traceback.print_exc()\n        return [\"\"] * len(source_texts)\n\n\n# ------------------------------------------------------------------------------\n# üî• FIX #8 & #14: Main Evaluation Function with model-agnostic messaging\n# ------------------------------------------------------------------------------\ndef evaluate_translation_metrics(\n    model,\n    tokenizer,\n    num_samples: int = EVAL_NUM_SAMPLES,\n    batch_size: int = EVAL_BATCH_SIZE\n) -> Dict[str, Any]:\n    \"\"\"\n    Evaluate translation quality using BLEU and ChrF++ metrics.\n    \n    üî• FIX #8 & #14: Model-agnostic messaging throughout.\n    \n    Args:\n        model: Trained TATN model (Cell 6 structure)\n        tokenizer: Base tokenizer (M2M100 or IndicBART)\n        num_samples: Number of samples to evaluate (default 5000)\n        batch_size: Batch size for translation (default 16)\n    \n    Returns:\n        Dictionary with evaluation metrics\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"TRANSLATION QUALITY EVALUATION - BLEU & ChrF++ (Cell 12)\")\n    print(f\"Model: {_MODEL_FAMILY} ({_MODEL_NAME})\")\n    print(f\"Evaluating on {num_samples} samples\")\n    print(f\"Direction: {_SOURCE_LANGUAGE.upper()} ({_BN_LANG}) ‚Üí {_TARGET_LANGUAGE.upper()} ({_EN_LANG})\")\n    print(\"=\" * 80)\n    \n    eval_pairs = load_evaluation_data(num_samples=num_samples)\n    \n    if not eval_pairs:\n        print(\"[EVAL] ERROR: No evaluation data loaded\")\n        return {\n            \"num_samples\": 0,\n            \"bleu_score\": 0.0,\n            \"chrf_score\": 0.0,\n            \"error\": \"No evaluation data\"\n        }\n    \n    actual_num_samples = len(eval_pairs)\n    print(f\"\\n[EVAL] Translating {actual_num_samples} sentences with {_MODEL_FAMILY}...\")\n    \n    source_texts = [pair[0] for pair in eval_pairs]\n    reference_texts = [pair[1] for pair in eval_pairs]\n    \n    translations = []\n    start_time = time.time()\n    \n    with tqdm(total=actual_num_samples, desc=\"Translating\", ncols=100) as pbar:\n        for i in range(0, actual_num_samples, batch_size):\n            batch_sources = source_texts[i:i + batch_size]\n            \n            try:\n                batch_translations = translate_batch(\n                    model=model,\n                    tokenizer=tokenizer,\n                    source_texts=batch_sources,\n                    max_length=EVAL_MAX_LENGTH,\n                    num_beams=EVAL_NUM_BEAMS\n                )\n                translations.extend(batch_translations)\n            \n            except Exception as e:\n                print(f\"\\n[EVAL] Batch {i}-{i+batch_size} failed: {e}\")\n                translations.extend([\"\"] * len(batch_sources))\n            \n            pbar.update(len(batch_sources))\n    \n    translation_time = time.time() - start_time\n    avg_time_per_sentence = translation_time / actual_num_samples\n    \n    print(f\"\\n[EVAL] Translation completed in {translation_time:.2f}s ({avg_time_per_sentence:.3f}s/sentence)\")\n    \n    valid_pairs = [(ref, trans) for ref, trans in zip(reference_texts, translations) if trans.strip()]\n    valid_count = len(valid_pairs)\n    \n    if valid_count == 0:\n        print(\"[EVAL] ERROR: No valid translations produced\")\n        return {\n            \"num_samples\": actual_num_samples,\n            \"valid_translations\": 0,\n            \"bleu_score\": 0.0,\n            \"chrf_score\": 0.0,\n            \"error\": \"No valid translations\"\n        }\n    \n    print(f\"[EVAL] Valid translations: {valid_count}/{actual_num_samples} ({valid_count/actual_num_samples*100:.1f}%)\")\n    \n    valid_references = [pair[0] for pair in valid_pairs]\n    valid_translations = [pair[1] for pair in valid_pairs]\n    \n    # Calculate BLEU\n    bleu_score = 0.0\n    if _SACREBLEU_AVAILABLE:\n        try:\n            bleu_result = corpus_bleu(valid_translations, [valid_references])\n            bleu_score = bleu_result.score\n            print(f\"\\n[EVAL] BLEU Score: {bleu_score:.2f}\")\n        except Exception as e:\n            print(f\"[EVAL] BLEU calculation failed (sacrebleu): {e}\")\n            if _NLTK_AVAILABLE:\n                try:\n                    references_tokenized = [[ref.split()] for ref in valid_references]\n                    translations_tokenized = [trans.split() for trans in valid_translations]\n                    smooth = SmoothingFunction()\n                    bleu_score = nltk_corpus_bleu(\n                        references_tokenized,\n                        translations_tokenized,\n                        smoothing_function=smooth.method1\n                    ) * 100\n                    print(f\"[EVAL] BLEU Score (NLTK): {bleu_score:.2f}\")\n                except Exception as e2:\n                    print(f\"[EVAL] BLEU calculation failed (NLTK): {e2}\")\n    \n    elif _NLTK_AVAILABLE:\n        try:\n            references_tokenized = [[ref.split()] for ref in valid_references]\n            translations_tokenized = [trans.split() for trans in valid_translations]\n            smooth = SmoothingFunction()\n            bleu_score = nltk_corpus_bleu(\n                references_tokenized,\n                translations_tokenized,\n                smoothing_function=smooth.method1\n            ) * 100\n            print(f\"\\n[EVAL] BLEU Score (NLTK): {bleu_score:.2f}\")\n        except Exception as e:\n            print(f\"[EVAL] BLEU calculation failed: {e}\")\n    \n    # Calculate ChrF++\n    chrf_score = 0.0\n    if _SACREBLEU_AVAILABLE:\n        try:\n            chrf_result = corpus_chrf(valid_translations, [valid_references])\n            chrf_score = chrf_result.score\n            print(f\"[EVAL] ChrF++ Score: {chrf_score:.2f}\")\n        except Exception as e:\n            print(f\"[EVAL] ChrF++ calculation failed: {e}\")\n    else:\n        print(\"[EVAL] ChrF++ not available (install sacrebleu)\")\n    \n    # Display sample translations\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SAMPLE TRANSLATIONS (first 5)\")\n    print(\"=\" * 80)\n    for i in range(min(5, len(eval_pairs))):\n        print(f\"\\n{i+1}. Source (BN): {source_texts[i][:80]}...\")\n        print(f\"   Translation:  {translations[i][:80]}...\")\n        print(f\"   Reference:    {reference_texts[i][:80]}...\")\n    \n    # ==================================================================\n    # üî• FIX #14: Summary with model family info\n    # ==================================================================\n    print(\"\\n\" + \"=\" * 80)\n    print(\"EVALUATION SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"Model: {_MODEL_FAMILY} ({_MODEL_NAME})\")\n    print(f\"Dataset: {_DATASET_NAME} ({_DATASET_LANG_PAIR})\")\n    print(f\"Direction: {_SOURCE_LANGUAGE.upper()} ‚Üí {_TARGET_LANGUAGE.upper()}\")\n    print(f\"Samples evaluated: {actual_num_samples}\")\n    print(f\"Valid translations: {valid_count} ({valid_count/actual_num_samples*100:.1f}%)\")\n    print(f\"Translation time: {translation_time:.2f}s ({avg_time_per_sentence:.3f}s/sentence)\")\n    print(\"\")\n    print(f\"üìä BLEU Score:  {bleu_score:.2f}\")\n    print(f\"üìä ChrF++ Score: {chrf_score:.2f}\")\n    print(\"=\" * 80)\n    \n    return {\n        \"model_name\": _MODEL_NAME,\n        \"model_family\": _MODEL_FAMILY,\n        \"num_samples\": actual_num_samples,\n        \"valid_translations\": valid_count,\n        \"translation_time_seconds\": translation_time,\n        \"avg_time_per_sentence\": avg_time_per_sentence,\n        \"bleu_score\": bleu_score,\n        \"chrf_score\": chrf_score,\n        \"sample_translations\": [\n            {\n                \"source\": source_texts[i],\n                \"translation\": translations[i],\n                \"reference\": reference_texts[i]\n            }\n            for i in range(min(10, actual_num_samples))\n        ]\n    }\n\n\n# ------------------------------------------------------------------------------\n# Convenience wrapper\n# ------------------------------------------------------------------------------\ndef run_evaluation(model=None, tokenizer=None, num_samples: int = EVAL_NUM_SAMPLES):\n    \"\"\"\n    Convenience function to run evaluation.\n    \n    Args:\n        model: TATN model (if None, uses smart detection)\n        tokenizer: Tokenizer (if None, tries to get from globals)\n        num_samples: Number of samples to evaluate\n    \n    Returns:\n        Evaluation metrics dictionary\n    \"\"\"\n    if model is None:\n        model, source_msg = find_trained_model()\n        if model is not None:\n            print(f\"[EVAL] {source_msg}\")\n            globals()['tatn_model'] = model\n            globals()['model'] = model\n        else:\n            print(f\"[EVAL] ERROR: {source_msg}\")\n            print(f\"[EVAL] Please provide {_MODEL_FAMILY} model or ensure training has completed\")\n            return None\n    \n    if tokenizer is None:\n        tokenizer = globals().get(\"tokenizer\")\n        if tokenizer is None:\n            print(f\"[EVAL] ERROR: No {_MODEL_FAMILY} tokenizer found in globals\")\n            print(\"[EVAL] Make sure Cell 2 has been executed\")\n            return None\n    \n    return evaluate_translation_metrics(model, tokenizer, num_samples=num_samples)\n\n\n# ==============================================================================\n# üî• FIX #15: AUTO-EXECUTION with model family detection\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Cell 12: BLEU & ChrF++ Evaluation (IndicBART-READY - 15 FIXES)\")\nprint(\"=\" * 80)\nprint(f\"Model Configuration:\")\nprint(f\" ‚Ä¢ Model: {_MODEL_NAME}\")\nprint(f\" ‚Ä¢ Family: {_MODEL_FAMILY}\")\nprint(f\" ‚Ä¢ Source: {_SOURCE_LANGUAGE} ({_BN_LANG})\")\nprint(f\" ‚Ä¢ Target: {_TARGET_LANGUAGE} ({_EN_LANG})\")\nprint()\nprint(\"Functions available:\")\nprint(\" ‚Ä¢ evaluate_translation_metrics(model, tokenizer, num_samples=5000)\")\nprint(\" ‚Ä¢ run_evaluation(model=None, tokenizer=None, num_samples=5000)\")\nprint(f\" ‚Ä¢ find_trained_model() - Smart {_MODEL_FAMILY} model detection (prioritizes best model)\")\nprint(\" ‚Ä¢ reconstruct_model_from_checkpoint(path) - Rebuild from state_dict\")\nprint(\"=\" * 80)\n\n_auto_run_eval = True\n\nif _auto_run_eval:\n    print(f\"\\n[AUTO-EVAL] Starting smart {_MODEL_FAMILY} model detection (prioritizing BEST MODEL)...\")\n    \n    _eval_model, _detection_msg = find_trained_model()\n    _eval_tokenizer = globals().get(\"tokenizer\")\n    \n    if _eval_model is not None:\n        print(f\"[AUTO-EVAL] ‚úÖ {_detection_msg}\")\n        globals()['tatn_model'] = _eval_model\n        globals()['model'] = _eval_model\n        print(\"[AUTO-EVAL] Model stored in globals as 'tatn_model' and 'model'\")\n    else:\n        print(f\"[AUTO-EVAL] ‚ùå {_detection_msg}\")\n    \n    if _eval_tokenizer is not None:\n        print(f\"[AUTO-EVAL] ‚úÖ {_MODEL_FAMILY} tokenizer found in globals\")\n    else:\n        print(f\"[AUTO-EVAL] ‚ùå {_MODEL_FAMILY} tokenizer not found in globals\")\n    \n    if _eval_model is not None and _eval_tokenizer is not None:\n        print(\"\\n[AUTO-EVAL] Starting evaluation on 5000 samples...\")\n        print(\"[AUTO-EVAL] To disable auto-run, set _auto_run_eval = False in this cell\")\n        \n        try:\n            eval_results = run_evaluation(\n                model=_eval_model,\n                tokenizer=_eval_tokenizer,\n                num_samples=5000\n            )\n            \n            if eval_results is not None and \"error\" not in eval_results:\n                print(\"\\n\" + \"üéØ\" * 40)\n                print(f\"üìä FINAL EVALUATION SCORES ({_MODEL_FAMILY}):\")\n                print(f\"   BLEU:   {eval_results['bleu_score']:.2f}\")\n                print(f\"   ChrF++: {eval_results['chrf_score']:.2f}\")\n                print(f\"   Valid translations: {eval_results['valid_translations']}/{eval_results['num_samples']}\")\n                print(\"üéØ\" * 40 + \"\\n\")\n                \n                globals()['eval_results'] = eval_results\n                print(\"[AUTO-EVAL] Results stored in global variable 'eval_results'\")\n            else:\n                print(\"\\n[AUTO-EVAL] Evaluation completed but returned error or no results\")\n        \n        except Exception as e:\n            print(f\"\\n[AUTO-EVAL] ERROR during evaluation: {type(e).__name__}: {str(e)}\")\n            traceback.print_exc()\n            print(\"\\n[AUTO-EVAL] You can manually run evaluation with:\")\n            print(\"   >>> eval_results = run_evaluation(tatn_model, tokenizer, num_samples=5000)\")\n    \n    else:\n        print(\"\\n[AUTO-EVAL] Cannot proceed with evaluation. Missing required components:\")\n        if _eval_model is None:\n            print(f\"   ‚ùå {_MODEL_FAMILY} Model: Try re-running Cell 10-11 or check saved checkpoints\")\n        if _eval_tokenizer is None:\n            print(f\"   ‚ùå {_MODEL_FAMILY} Tokenizer: Re-run Cell 2 to load tokenizer\")\n        \n        print(\"\\n[AUTO-EVAL] Manual evaluation options:\")\n        print(\"   >>> eval_results = run_evaluation(your_model, your_tokenizer, num_samples=5000)\")\n\nelse:\n    print(\"\\n[EVAL] Auto-execution disabled. To run evaluation manually:\")\n    print(\"   >>> eval_results = run_evaluation(num_samples=5000)\")\n\nprint(\"\\n\" + \"=\" * 80 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-24T20:21:28.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}