{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"A100"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14838798,"sourceType":"datasetVersion","datasetId":9475099},{"sourceId":14816532,"sourceType":"datasetVersion","datasetId":9361675}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# CELL 0: ENVIRONMENT SETUP & IMPORTS - mBART-50 Compatible (fixed)\n# ============================================================================\n# Note: run this cell in a Jupyter / Colab notebook. It reinstalls the specified\n# transformers version and required libs, then performs a quick tokenizer check.\n# ----------------------------------------------------------------------------\n\n# Step 0: (Optional) show what's being done\nprint(\"Installing exact package versions. This may take a few minutes...\")\n\n# Step 1: Clean uninstall potentially conflicting packages (quiet)\n# (Using %pip / !pip is fine in notebooks; here we use the bang form.)\n!pip uninstall -y transformers tokenizers sentence-transformers huggingface-hub datasets tokenizers -q || true\n\n# Step 2: Install required packages with the requested transformers version\n# Add huggingface-hub and datasets, and sentencepiece which is required by MBART tokenizers.\n!pip install -q --upgrade pip\n!pip install -q transformers==4.57.6 huggingface-hub datasets tokenizers sacrebleu sacremoses sentencepiece\n\n# Step 3: Import and verify core libraries\nimport importlib, sys, os, gc, time, warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\n\nprint(\"=\"*80)\nprint(\"IMPORT & VERSION CHECK\")\nprint(\"=\"*80)\n\n# Try imports and print versions with defensive guards\ntry:\n    import transformers\n    print(f\"✅ transformers: {transformers.__version__}\")\nexcept Exception as e:\n    print(f\"❌ transformers import failed: {type(e).__name__}: {e}\")\n    raise\n\ntry:\n    import tokenizers\n    print(f\"✅ tokenizers: {tokenizers.__version__}\")\nexcept Exception as e:\n    # tokenizers might be part of the transformers wheel; still try to continue\n    print(f\"⚠️  tokenizers import issue: {type(e).__name__}: {e}\")\n\ntry:\n    import sacrebleu\n    print(f\"✅ sacrebleu: {sacrebleu.__version__}\")\nexcept Exception as e:\n    print(f\"⚠️  sacrebleu import issue: {type(e).__name__}: {e}\")\n\ntry:\n    import datasets\n    print(f\"✅ datasets: {datasets.__version__}\")\nexcept Exception as e:\n    print(f\"⚠️  datasets import issue: {type(e).__name__}: {e}\")\n\nprint(\"=\"*80)\nprint(\"IMPORTS FOR TATN & mBART-50\")\nprint(\"=\"*80)\n\n# Core Python libs\nimport math, re, json, traceback\nfrom collections import defaultdict, OrderedDict\nfrom typing import List, Dict, Tuple, Optional, Any, Union\nfrom datetime import datetime\n\n# Data processing\nimport numpy as np\nimport pandas as pd\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Hugging Face - mBART-50 specific imports (names depend on transformers version)\nfrom transformers import (\n    MBartForConditionalGeneration,\n    MBart50TokenizerFast,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq,\n)\nfrom transformers.modeling_outputs import BaseModelOutput\n\n# Metrics\nfrom sacrebleu.metrics import BLEU, CHRF\n\n# Threading for TATN\nimport threading\n\nprint(\"✅ All libraries imported (attempt).\")\n\n# Step 4: Check CUDA availability\nprint(\"\\n\" + \"=\"*80)\nprint(\"HARDWARE DETECTION\")\nprint(\"=\"*80)\n\nif torch.cuda.is_available():\n    gpu_count = torch.cuda.device_count()\n    print(f\"✅ CUDA available: {gpu_count} GPU(s)\")\n    for i in range(gpu_count):\n        try:\n            gpu_name = torch.cuda.get_device_name(i)\n            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n            print(f\"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n        except Exception:\n            print(f\"   GPU {i}: (name lookup failed)\")\nelse:\n    print(\"⚠️  CUDA not available - using CPU\")\n\n# Step 5: Test mBART-50 tokenizer/model availability\nprint(\"\\n\" + \"=\"*80)\nprint(\"TESTING mBART-50 TOKENIZER ACCESS\")\nprint(\"=\"*80)\n\n# Use the many-to-many model by default; many-to-one exists but many-to-many is standard.\nHF_MODEL = \"facebook/mbart-large-50-many-to-many-mmt\"\n\ntry:\n    # Load the tokenizer (this performs network access the first time)\n    test_tokenizer = MBart50TokenizerFast.from_pretrained(HF_MODEL)\n    # Set src/tgt language codes (some tokenizer versions expect these attributes)\n    try:\n        test_tokenizer.src_lang = \"bn_IN\"\n        test_tokenizer.tgt_lang = \"en_XX\"\n    except Exception:\n        # Not all tokenizer wrappers accept direct assignment; it's OK\n        pass\n\n    # Vocab size: prefer tokenizer.vocab_size or len(tokenizer)\n    vocab_size = getattr(test_tokenizer, \"vocab_size\", None)\n    if vocab_size is None:\n        try:\n            vocab_size = len(test_tokenizer)\n        except Exception:\n            vocab_size = \"unknown\"\n\n    print(\"✅ Tokenizer loaded successfully\")\n    print(f\"   Model: {HF_MODEL}\")\n    print(f\"   Vocab size: {vocab_size}\")\n\n    # Print language token IDs if available\n    lang_map = getattr(test_tokenizer, \"lang_code_to_id\", None)\n    if isinstance(lang_map, dict):\n        bn_token = lang_map.get(\"bn_IN\", lang_map.get(\"bn\", \"N/A\"))\n        en_token = lang_map.get(\"en_XX\", lang_map.get(\"en\", \"N/A\"))\n        print(f\"   lang_code_to_id keys present. bn_IN -> {bn_token}, en_XX -> {en_token}\")\n    else:\n        # try alternative get_lang_id if available\n        if hasattr(test_tokenizer, \"get_lang_id\"):\n            try:\n                bn_token = test_tokenizer.get_lang_id(\"bn_IN\")\n                en_token = test_tokenizer.get_lang_id(\"en_XX\")\n                print(f\"   get_lang_id: bn_IN -> {bn_token}, en_XX -> {en_token}\")\n            except Exception:\n                print(\"   No lang mapping available on tokenizer instance.\")\n        else:\n            print(\"   No lang mapping available on tokenizer instance.\")\n\n    # Quick encode/decode smoke test\n    sample = \"আমি কল বন্ধ করেছি।\"\n    enc = test_tokenizer(sample, return_tensors=\"pt\", truncation=True, padding=True)\n    ids = enc[\"input_ids\"][0][:10].tolist()\n    dec = test_tokenizer.decode(ids, skip_special_tokens=True)\n    print(f\"   Sample encode/decode OK. Encoded IDs (first 10): {ids}\")\n    print(f\"   Decoded sample (trimmed): {dec[:60]}\")\n\n    # Clean up\n    del test_tokenizer\n    torch.cuda.empty_cache()\n    gc.collect()\n\nexcept Exception as e:\n    print(f\"❌ mBART-50 tokenizer test failed: {type(e).__name__}: {e}\")\n    print(\"   Check internet access or HF model availability and retry.\")\n    # Re-raise so user sees the full traceback if desired\n    raise\n\n# Step 6: Final message\nprint(\"\\n\" + \"=\"*80)\nprint(\"ENVIRONMENT SETUP COMPLETE ✅\")\nprint(\"=\"*80)\nprint(\"Ready for:\")\nprint(\"  ✅ PATH 1: TATN (DSCD + ASBN + TRG) - Homograph detection\")\nprint(\"  ✅ PATH 2: mBART-50 M2M - Translation\")\nprint(\"\\nProceed to next cells...\")\nprint(\"=\"*80)","metadata":{"id":"W8IIWAEHH4Jy","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:39:04.360012Z","iopub.execute_input":"2026-02-18T08:39:04.360277Z","iopub.status.idle":"2026-02-18T08:39:56.466373Z","shell.execute_reply.started":"2026-02-18T08:39:04.360247Z","shell.execute_reply":"2026-02-18T08:39:56.465739Z"}},"outputs":[{"name":"stdout","text":"Installing exact package versions. This may take a few minutes...\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, which is not installed.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m================================================================================\nIMPORT & VERSION CHECK\n================================================================================\n✅ transformers: 4.57.6\n✅ tokenizers: 0.22.2\n✅ sacrebleu: 2.6.0\n✅ datasets: 4.5.0\n================================================================================\nIMPORTS FOR TATN & mBART-50\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"2026-02-18 08:39:38.117807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771403978.273572      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771403978.316530      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771403978.687475      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771403978.687511      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771403978.687514      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771403978.687516      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"✅ All libraries imported (attempt).\n\n================================================================================\nHARDWARE DETECTION\n================================================================================\n✅ CUDA available: 2 GPU(s)\n   GPU 0: Tesla T4 (14.6 GB)\n   GPU 1: Tesla T4 (14.6 GB)\n\n================================================================================\nTESTING mBART-50 TOKENIZER ACCESS\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14364b4b80574c14bb03ba32debdb970"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f314349ade3747b9b5ee16f682e0e2ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f5300b69abd410eb14326c288a1802b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1636c3fe0854bc884bf3ae9ad5dd8f6"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"✅ Tokenizer loaded successfully\n   Model: facebook/mbart-large-50-many-to-many-mmt\n   Vocab size: 250054\n   lang_code_to_id keys present. bn_IN -> 250028, en_XX -> 250004\n   Sample encode/decode OK. Encoded IDs (first 10): [250028, 21145, 6, 69233, 69057, 203353, 125, 2]\n   Decoded sample (trimmed): আমি কল বন্ধ করেছি।\n\n================================================================================\nENVIRONMENT SETUP COMPLETE ✅\n================================================================================\nReady for:\n  ✅ PATH 1: TATN (DSCD + ASBN + TRG) - Homograph detection\n  ✅ PATH 2: mBART-50 M2M - Translation\n\nProceed to next cells...\n================================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==============================================================================\n# CELL 0: DUAL-PATH TATN CONFIGURATION - mBART-50 M2O COMPATIBLE\n# ==============================================================================\nimport os\nimport sys\nimport math\nimport random\nimport re\nimport unicodedata\nimport time\nimport threading\nfrom pathlib import Path\nfrom collections import deque, defaultdict\nfrom typing import List, Dict, Tuple, Optional, Union, Set, Any\nfrom types import SimpleNamespace\n\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nimport gc\n\ntry:\n    import pandas as pd\n    _HAS_PANDAS = True\nexcept ImportError:\n    _HAS_PANDAS = False\n\ntry:\n    from transformers import MBart50TokenizerFast\n    _HAS_MBART_TOKENIZER = True\nexcept Exception:\n    MBart50TokenizerFast = None\n    _HAS_MBART_TOKENIZER = False\n\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nNUM_GPUS = 1\nUSE_MULTI_GPU = False\n\nif USE_MULTI_GPU:\n    print(f\"[Cell 0] Multi-GPU Mode: {NUM_GPUS} GPUs available\")\n    DEVICE = torch.device(\"cuda:0\")\nelse:\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"[Cell 0] Single GPU Mode\")\n\nprint(f\"[Cell 0] Device: {DEVICE}\")\n\nDATASET_CSV_PATH = os.environ.get(\n    \"DATASET_PATH\",\n    \"/kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\"\n)\n\nNTREX_BN_PATH = \"/kaggle/input/datasets/manas00000003/paper-dataset/ntrex_ref_ben.txt\"\nNTREX_EN_PATH = \"/kaggle/input/datasets/manas00000003/paper-dataset/ntrex_src_eng.txt\"\nUSE_NTREX_DATASET = False\n\nVALIDATION_SPLIT = 0.1\n\ndef _safe_int(value, default: int, name: str, min_val: int = 1) -> int:\n    try:\n        result = int(value)\n        if result < min_val:\n            return default\n        return result\n    except:\n        return default\n\ndef _safe_float(value, default: float, name: str, min_val: float = 0.0) -> float:\n    try:\n        result = float(value)\n        if result < min_val:\n            return default\n        return result\n    except:\n        return default\n\nBATCH_SIZE = _safe_int(4, 4, \"BATCH_SIZE\", min_val=1)\nNUM_SAMPLES = _safe_int(100000, 100000, \"NUM_SAMPLES\", min_val=1)\nMAX_LENGTH = _safe_int(256, 256, \"MAX_LENGTH\", min_val=8)\n\nLR_NMT = _safe_float(5e-5, 5e-5, \"LR_NMT\", min_val=1e-7)\nLR_TRG = _safe_float(1e-5, 1e-5, \"LR_TRG\", min_val=1e-7)\nLR_PHI = _safe_float(1e-4, 1e-4, \"LR_PHI\", min_val=1e-7)\n\nEPOCHS = _safe_int(2, 2, \"EPOCHS\", min_val=1)\nGRAD_CLIP_NORM = _safe_float(1.0, 1.0, \"GRAD_CLIP_NORM\", min_val=0.1)\nUSE_AMP = True\nPRINT_INTERVAL = _safe_int(1000, 1000, \"PRINT_INTERVAL\", min_val=1)\nSEED = _safe_int(42, 42, \"SEED\", min_val=0)\n\nACCUMULATION_STEPS = _safe_int(4, 4, \"ACCUMULATION_STEPS\", min_val=1)\n\nMC_DROPOUT_PASSES = _safe_int(3, 3, \"MC_DROPOUT_PASSES\", min_val=1)\nTRG_EVIDENCE_K = _safe_int(3, 3, \"TRG_EVIDENCE_K\", min_val=1)\nMAX_SILVER_BUFFER = _safe_int(50, 50, \"MAX_SILVER_BUFFER\", min_val=1)\n\nNUM_WORKERS = _safe_int(0, 0, \"NUM_WORKERS\", min_val=0)\nPIN_MEMORY = True\nPREFETCH_FACTOR = _safe_int(1, 1, \"PREFETCH_FACTOR\", min_val=1)\nGRADIENT_CHECKPOINTING = True\n\nDEBUG_DISCOVERY = False\nDEBUG_TIMING = True\nDEBUG_VERBOSE = False\n\nDSCD_BUFFER_SIZE = _safe_int(40, 40, \"DSCD_BUFFER_SIZE\", min_val=1)\nDSCD_MAX_PROTOS = _safe_int(5, 5, \"DSCD_MAX_PROTOS\", min_val=1)\nDSCD_N_MIN = _safe_int(5, 5, \"DSCD_N_MIN\", min_val=1)\nDSCD_DISPERSION_THRESHOLD = _safe_float(0.40, 0.40, \"DSCD_DISPERSION_THRESHOLD\", min_val=0.0)\nDSCD_NEWSENSE_LAMBDA = _safe_float(1.5, 1.5, \"DSCD_NEWSENSE_LAMBDA\", min_val=0.1)\nDSCD_EMBED_DIM = _safe_int(1024, 1024, \"DSCD_EMBED_DIM\", min_val=64)\nDSCD_TEMPERATURE = _safe_float(0.7, 0.7, \"DSCD_TEMPERATURE\", min_val=0.01)\nDSCD_DROPOUT = _safe_float(0.1, 0.1, \"DSCD_DROPOUT\", min_val=0.0)\nDSCD_AUGMENT_SCALE = _safe_float(0.05, 0.05, \"DSCD_AUGMENT_SCALE\", min_val=0.0)\nDSCD_ENABLE_TRAINING_CLUSTERING = True\nDSCD_WARMUP_SAMPLES = _safe_int(9000, 9000, \"DSCD_WARMUP_SAMPLES\", min_val=0)\nDSCD_MIN_LETTERS = _safe_int(3, 3, \"DSCD_MIN_LETTERS\", min_val=2)\nDSCD_MIN_LETTER_FRACTION = _safe_float(0.6, 0.6, \"DSCD_MIN_LETTER_FRACTION\", min_val=0.0)\n\nPERIODIC_DISCOVERY_FREQUENCY = _safe_int(300, 300, \"PERIODIC_DISCOVERY_FREQUENCY\", min_val=1)\nMAX_TOKENS_PER_DISCOVERY = _safe_int(100, 100, \"MAX_TOKENS_PER_DISCOVERY\", min_val=1)\n\nENABLE_ASBN_TRAINING = True\nENABLE_ASBN_INFERENCE = True\nENABLE_TRG_TRAINING = True\nENABLE_TRG_INFERENCE = True\nUSE_DUAL_PATH_TRAINING = True\n\nCLUSTERING_TIMEOUT = _safe_int(3, 3, \"CLUSTERING_TIMEOUT\", min_val=1)\nMEMORY_CLEANUP_FREQUENCY = _safe_int(100, 100, \"MEMORY_CLEANUP_FREQUENCY\", min_val=1)\nVALIDATION_CHECK_INTERVAL = _safe_int(500, 500, \"VALIDATION_CHECK_INTERVAL\", min_val=1)\nVERBOSE_LOGGING = False\n\nCHECKPOINT_DIR = \"/kaggle/working/\"\nCHECKPOINT_SAVE_AFTER_TRAINING = True\nCHECKPOINT_FILENAME = \"tatn_final.pt\"\nCHECKPOINT_INTERVAL = 99999999\nSAVE_REPLAY_BUFFER = False\nLOAD_REPLAY_BUFFER = False\nREPLAY_BUFFER_SIZE = _safe_int(10000, 10000, \"REPLAY_BUFFER_SIZE\", min_val=0)\nRESUME_FROM_CHECKPOINT = False\nCHECKPOINT_PATH = \"\"\n\nTAU_LOW = _safe_float(0.15, 0.15, \"TAU_LOW\", min_val=0.0)\nTAU_HIGH = _safe_float(0.85, 0.85, \"TAU_HIGH\", min_val=0.0)\nTAU_ACCEPT = _safe_float(0.70, 0.70, \"TAU_ACCEPT\", min_val=0.0)\n\nTRG_MAX_GEN_LEN = _safe_int(12, 12, \"TRG_MAX_GEN_LEN\", min_val=1)\nTRG_GEN_EMBED = _safe_int(64, 64, \"TRG_GEN_EMBED\", min_val=8)\nTRG_GEN_HID = _safe_int(64, 64, \"TRG_GEN_HID\", min_val=8)\nTRG_SPAN_THRESHOLD = _safe_float(0.20, 0.20, \"TRG_SPAN_THRESHOLD\", min_val=0.0)\nTRG_UNCERTAINTY_THRESHOLD = _safe_float(0.15, 0.15, \"TRG_UNCERTAINTY_THRESHOLD\", min_val=0.0)\nTRG_TEMPERATURE = _safe_float(1.0, 1.0, \"TRG_TEMPERATURE\", min_val=0.01)\nMAX_EXPLANATIONS_PER_SENTENCE = _safe_int(10, 10, \"MAX_EXPLANATIONS_PER_SENTENCE\", min_val=1)\n\nSPAN_THRESHOLD = _safe_float(0.20, 0.20, \"SPAN_THRESHOLD\", min_val=0.0)\nUNCERTAINTY_THRESHOLD = _safe_float(0.15, 0.15, \"UNCERTAINTY_THRESHOLD\", min_val=0.0)\n\nASBN_HIDDEN_DIM = _safe_int(64, 64, \"ASBN_HIDDEN_DIM\", min_val=8)\nASBN_LAMBDA = _safe_float(0.05, 0.05, \"ASBN_LAMBDA\", min_val=0.0)\nASBN_DROPOUT = _safe_float(0.1, 0.1, \"ASBN_DROPOUT\", min_val=0.0)\n\nWARMUP_STEPS = _safe_int(2000, 2000, \"WARMUP_STEPS\", min_val=1)\n\nLAMBDA_ASBN = _safe_float(0.0, 0.0, \"LAMBDA_ASBN\", min_val=0.0)\nLAMBDA_DSCD = _safe_float(0.01, 0.01, \"LAMBDA_DSCD\", min_val=0.0)\nLAMBDA_TRG = _safe_float(0.001, 0.001, \"LAMBDA_TRG\", min_val=0.0)\nLAMBDA_TOKEN = _safe_float(0.0, 0.0, \"LAMBDA_TOKEN\", min_val=0.0)\nLAMBDA_CONFIDENCE = _safe_float(0.0, 0.0, \"LAMBDA_CONFIDENCE\", min_val=0.0)\nLAMBDA_LENGTH = _safe_float(0.0, 0.0, \"LAMBDA_LENGTH\", min_val=0.0)\n\nLABEL_SMOOTHING = _safe_float(0.1, 0.1, \"LABEL_SMOOTHING\", min_val=0.0)\nRDROP_ALPHA = _safe_float(0.0, 0.0, \"RDROP_ALPHA\", min_val=0.0)\nUSE_RDROP = True\nWEIGHT_DECAY = _safe_float(0.01, 0.01, \"WEIGHT_DECAY\", min_val=0.0)\n\nTRAIN_DOMAIN = 0\nTEST_DOMAIN = 1\nUSE_DOMAIN_LABELS = True\n\nGRL_ALPHA_START = _safe_float(0.1, 0.1, \"GRL_ALPHA_START\", min_val=0.0)\nGRL_ALPHA_END = _safe_float(1.0, 1.0, \"GRL_ALPHA_END\", min_val=0.0)\nGRL_ALPHA_SCHEDULE = \"linear\"\nGRL_ALPHA_STEPS = _safe_int(500, 500, \"GRL_ALPHA_STEPS\", min_val=1)\n\nSOURCE_LANGUAGE = \"bn_IN\"\nTARGET_LANGUAGE = \"en_XX\"\n\nMBART50_BN_TOKEN_ID = 250028\nMBART50_EN_TOKEN_ID = 250004\nMBART50_VOCAB_SIZE = 250054\n\nFREEZE_ENCODER = False\nFREEZE_FIRST_N_LAYERS = 0\n\nEVAL_BATCH_SIZE = _safe_int(8, 8, \"EVAL_BATCH_SIZE\", min_val=1)\nEVAL_NUM_BEAMS = _safe_int(5, 5, \"EVAL_NUM_BEAMS\", min_val=1)\nEVAL_LENGTH_PENALTY = _safe_float(1.0, 1.0, \"EVAL_LENGTH_PENALTY\", min_val=0.0)\nEVAL_MIN_LENGTH = _safe_int(5, 5, \"EVAL_MIN_LENGTH\", min_val=1)\nEVAL_NO_REPEAT_NGRAM_SIZE = _safe_int(3, 3, \"EVAL_NO_REPEAT_NGRAM_SIZE\", min_val=1)\n\nUSE_CONTEXT_GATES = True\nCONTEXT_GATE_TEMPERATURE = 0.7\n\nUSE_SENSE_CONDITIONING = True\nSENSE_BLEND_ALPHA = 0.3\n\nUSE_ATTENTION_ENTROPY_PENALTY = True\nLAMBDA_ATTENTION_ENTROPY = 0.01\n\nUSE_COVERAGE = True\nLAMBDA_COVERAGE = 0.1\n\nUSE_CONTEXT_BEAM_SEARCH = False\nCONTEXT_BEAM_ALPHA = 0.2\n\nUSE_POSITION_GUIDANCE = True\nPOSITION_GUIDANCE_ALPHA = 0.3\n\nHOMOGRAPH_REFERENCE_LIST_BN: Set[str] = {\n    \"কল\", \"কাল\", \"পাতা\", \"ফল\", \"বার\", \"হার\", \"তারা\",\n    \"পড়া\", \"দেখা\", \"চলা\", \"ধরা\", \"অর্থ\", \"শব্দ\", \"মুখ\",\n    \"তোলা\", \"বাঁচা\", \"মারা\", \"উত্তর\", \"পাত্র\", \"বেলা\", \"গান\",\n    \"নাম\", \"বল\", \"চাল\", \"কলা\", \"ধারা\", \"পত্র\", \"রাগ\", \"রস\",\n    \"তীর\", \"জমা\", \"মান\", \"দাবি\", \"আসন\", \"সাড়া\", \"বসা\", \"পদ\",\n    \"অংশ\", \"মোড়\", \"ঘর\", \"মন\", \"ব্যাংক\"\n}\n\nHOMOGRAPH_WATCHLIST_BN: Set[str] = set()\nHOMOGRAPH_WATCHLIST: Set[str] = set()\nUSE_WATCHLIST_PRIORITIZATION = False\nWATCHLIST_ONLY_FOR_TRG = False\n\ndef normalize_bengali(t: str) -> str:\n    if not t:\n        return \"\"\n    t = unicodedata.normalize(\"NFKC\", t)\n    t = t.replace(\"▁\", \"\").replace(\"##\", \"\").strip()\n    return t\n\ndef normalize_english(t: str) -> str:\n    if not t:\n        return \"\"\n    t = unicodedata.normalize(\"NFKC\", t).lower().strip()\n    return t\n\ndef empty_cuda_cache() -> None:\n    gc.collect()\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.empty_cache()\n        except Exception:\n            pass\n\ndef safe_cuda_synchronize() -> None:\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.synchronize()\n        except Exception:\n            pass\n\ndef monitor_gpu_usage() -> None:\n    if torch.cuda.is_available():\n        visible_gpus = torch.cuda.device_count()\n        print(f\"\\n[GPU MONITOR] Checking {visible_gpus} GPU(s):\")\n        for i in range(visible_gpus):\n            try:\n                mem_alloc = torch.cuda.memory_allocated(i) / (1024 ** 3)\n                mem_reserved = torch.cuda.memory_reserved(i) / (1024 ** 3)\n                print(f\"  GPU {i}: {mem_alloc:.2f}GB allocated / {mem_reserved:.2f}GB reserved\")\n            except Exception:\n                pass\n\ndef get_checkpoint_path() -> str:\n    return os.path.join(CHECKPOINT_DIR, CHECKPOINT_FILENAME)\n\ndef should_save_checkpoint(global_step: int, epoch: int, is_final: bool = False) -> bool:\n    if is_final and CHECKPOINT_SAVE_AFTER_TRAINING:\n        return True\n    return False\n\nclass FunctionTimeoutError(Exception):\n    pass\n\ndef with_timeout(seconds: int):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            result = [FunctionTimeoutError(\"Function timed out\")]\n            def target():\n                try:\n                    result[0] = func(*args, **kwargs)\n                except Exception as e:\n                    result[0] = e\n            thread = threading.Thread(target=target, daemon=True)\n            thread.start()\n            thread.join(timeout=seconds)\n            if thread.is_alive():\n                return None\n            if isinstance(result[0], Exception):\n                if isinstance(result[0], FunctionTimeoutError):\n                    return None\n                raise result[0]\n            return result[0]\n        return wrapper\n    return decorator\n\ndef get_special_tokens(tokenizer) -> Set[str]:\n    try:\n        s = set(getattr(tokenizer, \"all_special_tokens\", []))\n    except Exception:\n        s = {\"<pad>\", \"</s>\", \"<s>\", \"<unk>\"}\n    s.update({f\"__{SOURCE_LANGUAGE}__\", f\"__{TARGET_LANGUAGE}__\"})\n    return s\n\n_token_validation_cache: Dict[Tuple[str, str], bool] = {}\n_cache_lock = threading.Lock()\n_cache_max_size = 5000\n\ndef is_valid_token(\n    token,\n    special_tokens: Optional[Set[str]] = None,\n    tokenizer=None,\n    language: str = \"bn\",\n) -> bool:\n    token = \"\" if token is None else str(token)\n    cache_key = (token, language)\n    with _cache_lock:\n        if cache_key in _token_validation_cache:\n            return _token_validation_cache[cache_key]\n    clean = token.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n    if special_tokens and token in special_tokens:\n        result = False\n    else:\n        if len(clean) < 2:\n            result = False\n        else:\n            has_bengali_chars = any(\"\\u0980\" <= c <= \"\\u09FF\" for c in clean)\n            if not has_bengali_chars:\n                result = False\n            else:\n                bengali_count = sum(1 for c in clean if \"\\u0980\" <= c <= \"\\u09FF\")\n                alphanum_count = sum(1 for c in clean if c.isalnum())\n                if alphanum_count == 0:\n                    result = False\n                else:\n                    result = (bengali_count / alphanum_count) >= 0.5\n    with _cache_lock:\n        if len(_token_validation_cache) < _cache_max_size:\n            _token_validation_cache[cache_key] = result\n    return result\n\nclass DiscoveryTimer:\n    def __init__(self):\n        self.discovery_times: List[float] = []\n        self.discovery_steps: List[int] = []\n    def record(self, step: int, duration: float) -> None:\n        self.discovery_times.append(duration)\n        self.discovery_steps.append(step)\n    def get_stats(self) -> Dict[str, float]:\n        if not self.discovery_times:\n            return {\"count\": 0, \"total\": 0.0, \"avg\": 0.0, \"max\": 0.0}\n        total = sum(self.discovery_times)\n        return {\n            \"count\": len(self.discovery_times),\n            \"total\": total,\n            \"avg\": total / len(self.discovery_times),\n            \"max\": max(self.discovery_times),\n        }\n\n_discovery_timer = DiscoveryTimer()\ndiscoverytimer = _discovery_timer\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\nif hasattr(torch, \"set_float32_matmul_precision\"):\n    try:\n        torch.set_float32_matmul_precision(\"high\")\n    except Exception:\n        pass\n\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\n\ntry:\n    effective_batch = BATCH_SIZE * ACCUMULATION_STEPS\n    if USE_MULTI_GPU and NUM_GPUS > 0:\n        effective_batch *= NUM_GPUS\nexcept Exception:\n    effective_batch = BATCH_SIZE\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TATN CONFIGURATION - A100 OPTIMIZED + 6 MODIFICATIONS\")\nprint(\"=\" * 80)\nprint(f\"User: {os.getenv('KAGGLE_USERNAME', os.getenv('USER', 'manas0003'))}\")\nprint(f\"Multi-GPU: {'ENABLED' if USE_MULTI_GPU else 'DISABLED'} ({NUM_GPUS} GPUs)\")\nprint(f\"Dataset: {'NTREX (parallel text files)' if USE_NTREX_DATASET else 'CSV (Samanantar)'}\")\nif USE_NTREX_DATASET:\n    print(f\"  Bengali: {NTREX_BN_PATH}\")\n    print(f\"  English: {NTREX_EN_PATH}\")\nelse:\n    print(f\"  CSV: {DATASET_CSV_PATH}\")\nprint(f\"Samples: {NUM_SAMPLES:,} | Batch: {BATCH_SIZE} | Accum: {ACCUMULATION_STEPS}\")\nprint(f\"Effective batch: {effective_batch}\")\nprint(f\"Max length: {MAX_LENGTH} | Epochs: {EPOCHS}\")\nprint(f\"Train/Val split: {int((1-VALIDATION_SPLIT)*100)}% / {int(VALIDATION_SPLIT*100)}%\")\nprint()\nprint(\"PATH 1 (TATN):\")\nprint(f\"  - DSCD discovery freq: {PERIODIC_DISCOVERY_FREQUENCY} steps\")\nprint(f\"  - ASBN: {'DISABLED' if not ENABLE_ASBN_TRAINING else 'ENABLED'}\")\nprint(f\"  - TRG: {'ENABLED' if ENABLE_TRG_TRAINING else 'DISABLED'}\")\nprint(f\"  - LAMBDA_DSCD: {LAMBDA_DSCD}\")\nprint(f\"  - LAMBDA_TRG: {LAMBDA_TRG}\")\nprint()\nprint(\"PATH 2 (mBART-50 many-to-many):\")\nprint(f\"  - Model: facebook/mbart-large-50-many-to-many-mmt\")\nprint(f\"  - Vocab: {MBART50_VOCAB_SIZE:,}\")\nprint(f\"  - Languages: {SOURCE_LANGUAGE} -> {TARGET_LANGUAGE}\")\nprint(f\"  - LR: {LR_NMT}\")\nprint(f\"  - Label smoothing: {LABEL_SMOOTHING}\")\nprint(f\"  - Weight decay: {WEIGHT_DECAY}\")\nprint(f\"  - Warmup: {WARMUP_STEPS}\")\nprint()\nprint(\"6 MODIFICATIONS:\")\nprint(f\"  #1 Context Gates: {USE_CONTEXT_GATES}\")\nprint(f\"  #2 Sense Conditioning: {USE_SENSE_CONDITIONING}\")\nprint(f\"  #3 Attention Entropy: {USE_ATTENTION_ENTROPY_PENALTY}\")\nprint(f\"  #4 Coverage: {USE_COVERAGE}\")\nprint(f\"  #5 Context Beam: {USE_CONTEXT_BEAM_SEARCH}\")\nprint(f\"  #6 Position Guidance: {USE_POSITION_GUIDANCE}\")\nprint()\nprint(\"EXPECTED BLEU: 38-42 (from baseline 15.6)\")\nprint(\"  - Tokenizer fix: +8-12 BLEU\")\nprint(\"  - 6 Modifications: +6-9 BLEU\")\nprint()\nmonitor_gpu_usage()\nprint(\"=\" * 80)\nprint(\"Cell 0: Configuration loaded - Ready for training\")\nprint(\"=\" * 80)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"5jMPDi9xH4Jz","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:39:56.468154Z","iopub.execute_input":"2026-02-18T08:39:56.468755Z","iopub.status.idle":"2026-02-18T08:39:56.518318Z","shell.execute_reply.started":"2026-02-18T08:39:56.468727Z","shell.execute_reply":"2026-02-18T08:39:56.517631Z"}},"outputs":[{"name":"stdout","text":"[Cell 0] Single GPU Mode\n[Cell 0] Device: cuda\n\n================================================================================\nTATN CONFIGURATION - A100 OPTIMIZED + 6 MODIFICATIONS\n================================================================================\nUser: manas0003\nMulti-GPU: DISABLED (1 GPUs)\nDataset: CSV (Samanantar)\n  CSV: /kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\nSamples: 100,000 | Batch: 4 | Accum: 4\nEffective batch: 16\nMax length: 256 | Epochs: 2\nTrain/Val split: 90% / 10%\n\nPATH 1 (TATN):\n  - DSCD discovery freq: 300 steps\n  - ASBN: ENABLED\n  - TRG: ENABLED\n  - LAMBDA_DSCD: 0.01\n  - LAMBDA_TRG: 0.001\n\nPATH 2 (mBART-50 many-to-many):\n  - Model: facebook/mbart-large-50-many-to-many-mmt\n  - Vocab: 250,054\n  - Languages: bn_IN -> en_XX\n  - LR: 5e-05\n  - Label smoothing: 0.1\n  - Weight decay: 0.01\n  - Warmup: 2000\n\n6 MODIFICATIONS:\n  #1 Context Gates: True\n  #2 Sense Conditioning: True\n  #3 Attention Entropy: True\n  #4 Coverage: True\n  #5 Context Beam: False\n  #6 Position Guidance: True\n\nEXPECTED BLEU: 38-42 (from baseline 15.6)\n  - Tokenizer fix: +8-12 BLEU\n  - 6 Modifications: +6-9 BLEU\n\n\n[GPU MONITOR] Checking 2 GPU(s):\n  GPU 0: 0.00GB allocated / 0.00GB reserved\n  GPU 1: 0.00GB allocated / 0.00GB reserved\n================================================================================\nCell 0: Configuration loaded - Ready for training\n================================================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 1: DUAL-PATH TOKENIZER UTILITIES + TRAINING LOSSES\n# ===========================================================================================\n\nimport threading\nfrom typing import Tuple, List, Dict, Optional, Set, Union\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport re\n\ntry:\n    if isinstance(MAX_LENGTH, (int, float)) and MAX_LENGTH > 0:\n        SAFE_OFFSET_MAX_LEN = int(MAX_LENGTH)\n    else:\n        SAFE_OFFSET_MAX_LEN = 48\nexcept (NameError, ValueError, TypeError):\n    SAFE_OFFSET_MAX_LEN = 48\n\ntry:\n    _SOURCE_LANG = SOURCE_LANGUAGE\nexcept NameError:\n    _SOURCE_LANG = \"bn_IN\"\n\ntry:\n    _TARGET_LANG = TARGET_LANGUAGE\nexcept NameError:\n    _TARGET_LANG = \"en_XX\"\n\ntry:\n    _DEBUG_VERBOSE = DEBUG_VERBOSE\nexcept NameError:\n    _DEBUG_VERBOSE = False\n\ntry:\n    _DEBUG_DISCOVERY = DEBUG_DISCOVERY\nexcept NameError:\n    _DEBUG_DISCOVERY = False\n\ntry:\n    _MBART_BN_TOKEN_ID = MBART50_BN_TOKEN_ID\nexcept NameError:\n    _MBART_BN_TOKEN_ID = 9\n\ntry:\n    _MBART_EN_TOKEN_ID = MBART50_EN_TOKEN_ID\nexcept NameError:\n    _MBART_EN_TOKEN_ID = 2\n\ntry:\n    _MBART_VOCAB_SIZE = MBART50_VOCAB_SIZE\nexcept NameError:\n    _MBART_VOCAB_SIZE = 250054\n\ntry:\n    _DSCD_MIN_LETTERS = int(DSCD_MIN_LETTERS)\nexcept NameError:\n    _DSCD_MIN_LETTERS = 3\n\ntry:\n    _DSCD_MIN_LETTER_FRACTION = float(DSCD_MIN_LETTER_FRACTION)\nexcept NameError:\n    _DSCD_MIN_LETTER_FRACTION = 0.6\n\ntry:\n    _LABEL_SMOOTHING_EPS = float(LABEL_SMOOTHING)\nexcept NameError:\n    _LABEL_SMOOTHING_EPS = 0.1\n\ntry:\n    _RDROP_ALPHA = float(RDROP_ALPHA)\nexcept NameError:\n    _RDROP_ALPHA = 5.0\n\n_SPECIAL_TOKENS_CACHE: Dict[str, Set[str]] = {}\n_SPECIAL_TOKENS_LOCK = threading.Lock()\n_LANGUAGE_WARNING_COUNT = 0\n_MAX_LANGUAGE_WARNINGS = 3\n_VOCAB_SIZE_CACHE: Dict[str, int] = {}\n\n\nclass BengaliWordTokenizer:\n    def __init__(self, vocab_size: int = 50000):\n        self.vocab_size = vocab_size\n        self.word_to_id: Dict[str, int] = {\"<pad>\": 0, \"<unk>\": 1, \"<s>\": 2, \"</s>\": 3}\n        self.id_to_word: Dict[int, str] = {0: \"<pad>\", 1: \"<unk>\", 2: \"<s>\", 3: \"</s>\"}\n        self.next_id = 4\n        self._lock = threading.Lock()\n\n        self.pad_token = \"<pad>\"\n        self.unk_token = \"<unk>\"\n        self.bos_token = \"<s>\"\n        self.eos_token = \"</s>\"\n        self.pad_token_id = 0\n        self.unk_token_id = 1\n        self.bos_token_id = 2\n        self.eos_token_id = 3\n\n        self.bengali_pattern = re.compile(r'[\\u0980-\\u09FF]+')\n        self.punct_pattern = re.compile(r'[।॥,.;:!?\"\\'\\-\\(\\)\\[\\]{}]')\n\n    def tokenize(self, text: str) -> List[str]:\n        if not text or not isinstance(text, str):\n            return []\n\n        text = text.strip()\n        if not text:\n            return []\n\n        words = []\n        tokens = re.findall(r'[\\u0980-\\u09FF]+|[a-zA-Z]+|[0-9]+|[।॥]|[,.;:!?\"\\'\\-\\(\\)\\[\\]{}]', text)\n\n        for token in tokens:\n            token = token.strip()\n            if token:\n                words.append(token)\n\n        return words\n\n    def encode(\n        self,\n        text: Union[str, List[str]],\n        add_special_tokens: bool = True,\n        max_length: Optional[int] = None,\n        padding: bool = False,\n        truncation: bool = False,\n        return_tensors: Optional[str] = None,\n    ) -> Dict[str, Union[List[int], torch.Tensor]]:\n        if isinstance(text, str):\n            texts = [text]\n        else:\n            texts = text\n\n        all_input_ids = []\n        all_attention_masks = []\n\n        for txt in texts:\n            words = self.tokenize(txt)\n\n            with self._lock:\n                ids = []\n                for word in words:\n                    if word not in self.word_to_id:\n                        if self.next_id < self.vocab_size:\n                            self.word_to_id[word] = self.next_id\n                            self.id_to_word[self.next_id] = word\n                            self.next_id += 1\n                            ids.append(self.word_to_id[word])\n                        else:\n                            ids.append(self.unk_token_id)\n                    else:\n                        ids.append(self.word_to_id[word])\n\n            if add_special_tokens:\n                ids = [self.bos_token_id] + ids + [self.eos_token_id]\n\n            if truncation and max_length:\n                ids = ids[:max_length]\n\n            attention_mask = [1] * len(ids)\n\n            all_input_ids.append(ids)\n            all_attention_masks.append(attention_mask)\n\n        if padding and max_length:\n            for i in range(len(all_input_ids)):\n                if len(all_input_ids[i]) < max_length:\n                    pad_len = max_length - len(all_input_ids[i])\n                    all_input_ids[i] = all_input_ids[i] + [self.pad_token_id] * pad_len\n                    all_attention_masks[i] = all_attention_masks[i] + [0] * pad_len\n\n        if return_tensors == \"pt\":\n            max_len = max(len(ids) for ids in all_input_ids)\n            for i in range(len(all_input_ids)):\n                if len(all_input_ids[i]) < max_len:\n                    pad_len = max_len - len(all_input_ids[i])\n                    all_input_ids[i] = all_input_ids[i] + [self.pad_token_id] * pad_len\n                    all_attention_masks[i] = all_attention_masks[i] + [0] * pad_len\n\n            return {\n                \"input_ids\": torch.tensor(all_input_ids, dtype=torch.long),\n                \"attention_mask\": torch.tensor(all_attention_masks, dtype=torch.long),\n            }\n\n        if len(all_input_ids) == 1:\n            return {\n                \"input_ids\": all_input_ids[0],\n                \"attention_mask\": all_attention_masks[0],\n            }\n\n        return {\n            \"input_ids\": all_input_ids,\n            \"attention_mask\": all_attention_masks,\n        }\n\n    def decode(self, token_ids: Union[List[int], torch.Tensor], skip_special_tokens: bool = True) -> str:\n        if isinstance(token_ids, torch.Tensor):\n            token_ids = token_ids.tolist()\n\n        words = []\n        for tid in token_ids:\n            if tid in self.id_to_word:\n                word = self.id_to_word[tid]\n                if skip_special_tokens and word in {\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"}:\n                    continue\n                words.append(word)\n\n        return \" \".join(words)\n\n    def convert_ids_to_tokens(self, ids: Union[List[int], torch.Tensor]) -> List[str]:\n        if isinstance(ids, torch.Tensor):\n            ids = ids.tolist()\n\n        return [self.id_to_word.get(tid, self.unk_token) for tid in ids]\n\n    def convert_tokens_to_ids(self, tokens: Union[str, List[str]]) -> Union[int, List[int]]:\n        if isinstance(tokens, str):\n            return self.word_to_id.get(tokens, self.unk_token_id)\n        return [self.word_to_id.get(tok, self.unk_token_id) for tok in tokens]\n\n    def __call__(self, text: Union[str, List[str]], **kwargs):\n        return self.encode(text, **kwargs)\n\n    def __len__(self):\n        return len(self.word_to_id)\n\n\nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, num_classes: int, smoothing: float = 0.1, ignore_index: int = -100):\n        super().__init__()\n        self.num_classes = num_classes\n        self.smoothing = smoothing\n        self.ignore_index = ignore_index\n        self.confidence = 1.0 - smoothing\n\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        if logits.dim() == 3:\n            logits = logits.reshape(-1, logits.size(-1))\n        if targets.dim() == 2:\n            targets = targets.reshape(-1)\n\n        mask = targets != self.ignore_index\n        targets = targets.masked_select(mask)\n        logits = logits[mask]\n\n        if targets.numel() == 0:\n            return torch.tensor(0.0, device=logits.device, requires_grad=True)\n\n        log_probs = F.log_softmax(logits, dim=-1)\n\n        nll_loss = -log_probs.gather(dim=-1, index=targets.unsqueeze(1)).squeeze(1)\n        smooth_loss = -log_probs.mean(dim=-1)\n\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n\n        return loss.mean()\n\n\nclass RDropLoss(nn.Module):\n    def __init__(self, alpha: float = 5.0):\n        super().__init__()\n        self.alpha = alpha\n\n    def forward(\n        self,\n        logits1: torch.Tensor,\n        logits2: torch.Tensor,\n        targets: torch.Tensor,\n        ignore_index: int = -100\n    ) -> torch.Tensor:\n        if logits1.dim() == 3:\n            logits1 = logits1.reshape(-1, logits1.size(-1))\n        if logits2.dim() == 3:\n            logits2 = logits2.reshape(-1, logits2.size(-1))\n        if targets.dim() == 2:\n            targets = targets.reshape(-1)\n\n        mask = targets != ignore_index\n\n        logits1 = logits1[mask]\n        logits2 = logits2[mask]\n\n        if logits1.numel() == 0:\n            return torch.tensor(0.0, device=logits1.device, requires_grad=True)\n\n        p1 = F.log_softmax(logits1, dim=-1)\n        p2 = F.log_softmax(logits2, dim=-1)\n\n        p1_probs = F.softmax(logits1, dim=-1)\n        p2_probs = F.softmax(logits2, dim=-1)\n\n        kl_1_2 = F.kl_div(p1, p2_probs, reduction='batchmean', log_target=False)\n        kl_2_1 = F.kl_div(p2, p1_probs, reduction='batchmean', log_target=False)\n\n        kl_loss = (kl_1_2 + kl_2_1) / 2.0\n\n        return self.alpha * kl_loss\n\n\nclass AttentionEntropyPenalty(nn.Module):\n    def __init__(self, lambda_entropy: float = 0.01):\n        super().__init__()\n        self.lambda_entropy = lambda_entropy\n\n    def forward(\n        self,\n        cross_attention_weights: torch.Tensor,\n        encoder_attention_mask: Optional[torch.Tensor] = None,\n    ) -> torch.Tensor:\n        if cross_attention_weights is None or cross_attention_weights.numel() == 0:\n            return torch.tensor(0.0, device=cross_attention_weights.device if cross_attention_weights is not None else 'cpu')\n\n        attn = cross_attention_weights.mean(dim=1)\n\n        if encoder_attention_mask is not None:\n            mask = encoder_attention_mask.unsqueeze(1)\n            attn = attn.masked_fill(mask == 0, 1e-12)\n\n        attn = attn / (attn.sum(dim=-1, keepdim=True) + 1e-12)\n\n        entropy = -(attn * torch.log(attn + 1e-12)).sum(dim=-1)\n\n        avg_entropy = entropy.mean()\n\n        return self.lambda_entropy * avg_entropy\n\n\ndef _special_token_cache_key(tokenizer) -> str:\n    name = getattr(tokenizer, \"name_or_path\", None) or getattr(tokenizer, \"name\", None)\n    if not name:\n        name = \"unknown_tokenizer\"\n    vocab = None\n    if hasattr(tokenizer, \"vocab_size\"):\n        try:\n            vocab = int(getattr(tokenizer, \"vocab_size\"))\n        except Exception:\n            vocab = None\n    elif hasattr(tokenizer, \"get_vocab\") and callable(getattr(tokenizer, \"get_vocab\")):\n        try:\n            vocab = len(tokenizer.get_vocab())\n        except Exception:\n            vocab = None\n    return f\"{name}__vocab={vocab}\"\n\ndef get_tokenizer_vocab_size(tokenizer) -> int:\n    cache_key = _special_token_cache_key(tokenizer)\n\n    if cache_key in _VOCAB_SIZE_CACHE:\n        return _VOCAB_SIZE_CACHE[cache_key]\n\n    vocab_size = _MBART_VOCAB_SIZE\n\n    try:\n        if hasattr(tokenizer, \"__len__\"):\n            vocab_size = len(tokenizer)\n        elif hasattr(tokenizer, \"vocab_size\"):\n            vocab_size = int(tokenizer.vocab_size)\n        elif hasattr(tokenizer, \"get_vocab\"):\n            vocab_size = len(tokenizer.get_vocab())\n    except Exception:\n        pass\n\n    _VOCAB_SIZE_CACHE[cache_key] = vocab_size\n    return vocab_size\n\ndef get_tokenizer_special_tokens(tokenizer) -> Set[str]:\n    cache_key = _special_token_cache_key(tokenizer)\n    with _SPECIAL_TOKENS_LOCK:\n        if cache_key in _SPECIAL_TOKENS_CACHE:\n            return _SPECIAL_TOKENS_CACHE[cache_key]\n\n        special_tokens: Set[str] = set()\n        try:\n            if hasattr(tokenizer, \"all_special_tokens\"):\n                try:\n                    result = getattr(tokenizer, \"all_special_tokens\")\n                    if isinstance(result, (list, tuple, set)):\n                        special_tokens.update(x for x in result if x)\n                except Exception:\n                    pass\n            if hasattr(tokenizer, \"additional_special_tokens\"):\n                try:\n                    result = getattr(tokenizer, \"additional_special_tokens\")\n                    if isinstance(result, (list, tuple, set)):\n                        special_tokens.update(x for x in result if x)\n                except Exception:\n                    pass\n            for attr in (\"pad_token\", \"unk_token\", \"bos_token\", \"eos_token\",\n                         \"cls_token\", \"sep_token\", \"mask_token\"):\n                if hasattr(tokenizer, attr):\n                    try:\n                        tok = getattr(tokenizer, attr)\n                        if tok:\n                            special_tokens.add(tok)\n                    except Exception:\n                        pass\n            try:\n                stm = (\n                    getattr(tokenizer, \"special_tokens_map\", None)\n                    or getattr(tokenizer, \"special_tokens_map_extended\", None)\n                )\n                if isinstance(stm, dict):\n                    for v in stm.values():\n                        if isinstance(v, str) and v:\n                            special_tokens.add(v)\n            except Exception:\n                pass\n        except Exception:\n            special_tokens = set()\n\n        special_tokens.update({\n            f\"__{_SOURCE_LANG}__\", f\"__{_TARGET_LANG}__\",\n            \"</s>\", \"<pad>\", \"<s>\", \"<unk>\",\n            \"[PAD]\", \"[EOS]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\",\n        })\n\n        try:\n            vocab = tokenizer.get_vocab() if hasattr(tokenizer, \"get_vocab\") else {}\n            special_tokens = {\n                tok\n                for tok in special_tokens\n                if tok in vocab or tok in {\"</s>\", \"<pad>\", \"<s>\", \"<unk>\"}\n            }\n        except Exception:\n            pass\n\n        _SPECIAL_TOKENS_CACHE[cache_key] = special_tokens\n        return special_tokens\n\ndef get_cached_special_tokens(tokenizer) -> Set[str]:\n    return get_tokenizer_special_tokens(tokenizer)\n\ndef _normalize_offset_mapping_for_batchencoding(enc):\n    try:\n        if \"offset_mapping\" in enc and enc[\"offset_mapping\"] is not None:\n            off = enc[\"offset_mapping\"]\n            try:\n                if hasattr(off, \"tolist\"):\n                    arr = off.tolist()\n                    if isinstance(arr, list) and len(arr) > 0 and isinstance(arr[0], list):\n                        enc[\"offset_mapping\"] = [\n                            (x[0], x[1])\n                            if (isinstance(x, (list, tuple)) and len(x) >= 2)\n                            else (None, None)\n                            for x in arr[0]\n                        ]\n                        return enc\n                if isinstance(off, (list, tuple)):\n                    if len(off) > 0 and isinstance(off[0], (list, tuple)):\n                        enc[\"offset_mapping\"] = [\n                            (x[0], x[1])\n                            if (isinstance(x, (list, tuple)) and len(x) >= 2)\n                            else (None, None)\n                            for x in off[0]\n                        ]\n                        return enc\n            except Exception:\n                pass\n    except Exception:\n        pass\n\n    try:\n        data = getattr(enc, \"data\", None)\n        if (\n            data\n            and isinstance(data, dict)\n            and \"offset_mapping\" in data\n            and data[\"offset_mapping\"] is not None\n        ):\n            om = data[\"offset_mapping\"]\n            if isinstance(om, (list, tuple)) and len(om) > 0 and isinstance(om[0], (list, tuple)):\n                enc[\"offset_mapping\"] = [\n                    (x[0], x[1])\n                    if (isinstance(x, (list, tuple)) and len(x) >= 2)\n                    else (None, None)\n                    for x in om[0]\n                ]\n                return enc\n    except Exception:\n        pass\n\n    try:\n        seq_len = 0\n        if \"input_ids\" in enc:\n            input_ids = enc[\"input_ids\"]\n            if hasattr(input_ids, \"shape\") and len(input_ids.shape) > 0:\n                seq_len = int(input_ids.shape[-1])\n            elif (\n                isinstance(input_ids, (list, tuple))\n                and len(input_ids) > 0\n                and isinstance(input_ids[0], (list, tuple))\n            ):\n                seq_len = len(input_ids[0])\n        enc[\"offset_mapping\"] = [(None, None)] * seq_len\n    except Exception:\n        enc[\"offset_mapping\"] = []\n\n    return enc\n\ndef safe_offsets_tokenize(\n    tokenizer,\n    text: str,\n    max_length: Optional[int] = None,\n    include_special_tokens: bool = False,\n) -> dict:\n    if max_length is None:\n        max_length = SAFE_OFFSET_MAX_LEN\n    eff_max = int(max_length)\n\n    try:\n        if not isinstance(text, str):\n            text = \"\" if text is None else str(text)\n    except Exception:\n        if _DEBUG_VERBOSE:\n            print(\"[WARN] Failed to convert input to string, using empty string\")\n        text = \"\"\n\n    char_limit = min(eff_max * 30, 8000)\n    sample_text = text[:char_limit]\n\n    is_fast = getattr(tokenizer, \"is_fast\", False)\n\n    vocab_size = get_tokenizer_vocab_size(tokenizer)\n\n    tokenize_kwargs = {\n        \"return_tensors\": \"pt\",\n        \"truncation\": True,\n        \"padding\": False,\n        \"max_length\": eff_max,\n        \"add_special_tokens\": include_special_tokens,\n    }\n\n    try:\n        if hasattr(tokenizer, 'src_lang'):\n            tokenizer.src_lang = _SOURCE_LANG\n    except Exception:\n        pass\n\n    if is_fast:\n        try:\n            tokenize_kwargs[\"return_offsets_mapping\"] = True\n            enc = tokenizer(sample_text, **tokenize_kwargs)\n            enc = _normalize_offset_mapping_for_batchencoding(enc)\n\n            if \"input_ids\" in enc and isinstance(enc[\"input_ids\"], torch.Tensor):\n                enc[\"input_ids\"] = torch.clamp(enc[\"input_ids\"], 0, vocab_size - 1)\n\n            return enc\n        except Exception:\n            pass\n\n    try:\n        enc = tokenizer(sample_text, **tokenize_kwargs)\n\n        if \"input_ids\" in enc and isinstance(enc[\"input_ids\"], torch.Tensor):\n            enc[\"input_ids\"] = torch.clamp(enc[\"input_ids\"], 0, vocab_size - 1)\n\n    except Exception as e:\n        if _DEBUG_VERBOSE:\n            print(f\"[WARN] Tokenization failed: {e}, returning empty encoding\")\n        pad_id = getattr(tokenizer, \"pad_token_id\", 0)\n        enc = {\n            \"input_ids\": torch.tensor([[pad_id]], dtype=torch.long),\n            \"attention_mask\": torch.tensor([[1]], dtype=torch.long),\n        }\n        enc = _normalize_offset_mapping_for_batchencoding(enc)\n        return enc\n\n    try:\n        input_ids = None\n        try:\n            input_ids = enc[\"input_ids\"][0].tolist()\n        except Exception:\n            if hasattr(enc, \"data\") and \"input_ids\" in enc.data:\n                input_ids = enc.data[\"input_ids\"][0]\n\n        tokens: List[str] = []\n        if input_ids is not None:\n            try:\n                tokens = tokenizer.convert_ids_to_tokens(input_ids)\n            except Exception:\n                tokens = []\n\n        offsets_list: List[Tuple[Optional[int], Optional[int]]] = []\n        src = sample_text\n        cur_pos = 0\n        for tok in tokens:\n            token_text = (tok or \"\").replace(\"▁\", \"\").replace(\"##\", \"\").replace(\"Ġ\", \"\").strip()\n            if not token_text:\n                offsets_list.append((None, None))\n                continue\n            idx = src.find(token_text, cur_pos)\n            if idx == -1:\n                idx = src.lower().find(token_text.lower(), cur_pos)\n            if idx == -1:\n                offsets_list.append((None, None))\n            else:\n                start = int(idx)\n                end = int(idx + len(token_text))\n                offsets_list.append((start, end))\n                cur_pos = end\n\n        enc[\"offset_mapping\"] = offsets_list\n        enc = _normalize_offset_mapping_for_batchencoding(enc)\n        return enc\n    except Exception:\n        enc = _normalize_offset_mapping_for_batchencoding(enc)\n        return enc\n\ndef reconstruct_word_spans(\n    tokenizer,\n    text: str,\n    max_length: Optional[int] = None,\n) -> Tuple[Dict[int, str], List[str]]:\n    global _LANGUAGE_WARNING_COUNT\n\n    if max_length is None:\n        max_length = SAFE_OFFSET_MAX_LEN\n    eff_max = int(max_length)\n\n    if not isinstance(text, str) or len(text.strip()) == 0:\n        return {}, []\n\n    has_bengali = any(\"\\u0980\" <= c <= \"\\u09FF\" for c in text)\n    has_english = any(\"a\" <= c.lower() <= \"z\" for c in text)\n\n    if _DEBUG_VERBOSE and _DEBUG_DISCOVERY:\n        bengali_pct = (\n            sum(1 for c in text if \"\\u0980\" <= c <= \"\\u09FF\")\n            / max(1, len(text))\n            * 100.0\n        )\n        print(f\"[TOKENIZER] Text sample: {text[:50]}\")\n        print(\n            f\"[TOKENIZER] Bengali: {has_bengali} ({bengali_pct:.1f}%), \"\n            f\"English: {has_english}\"\n        )\n\n    if not has_bengali and has_english and _LANGUAGE_WARNING_COUNT < _MAX_LANGUAGE_WARNINGS:\n        if _DEBUG_DISCOVERY:\n            print(\"[TOKENIZER WARNING] Text appears to be ENGLISH, not BENGALI\")\n            print(f\"  Sample: {text[:80]}\")\n        _LANGUAGE_WARNING_COUNT += 1\n        if _LANGUAGE_WARNING_COUNT == _MAX_LANGUAGE_WARNINGS:\n            print(\"[TOKENIZER] Suppressing further language warnings\")\n\n    char_limit = min(eff_max * 30, 8000)\n    text = text[:char_limit]\n    text_len = len(text)\n\n    special_tokens = get_tokenizer_special_tokens(tokenizer)\n    vocab_size = get_tokenizer_vocab_size(tokenizer)\n\n    try:\n        current_lang = SOURCE_LANGUAGE\n    except NameError:\n        current_lang = _SOURCE_LANG\n\n    try:\n        encoded = safe_offsets_tokenize(\n            tokenizer, text, max_length=eff_max, include_special_tokens=False\n        )\n    except Exception:\n        return {}, []\n\n    offsets = encoded.get(\"offset_mapping\", [])\n    try:\n        input_ids = encoded[\"input_ids\"][0].tolist()\n        input_ids = [min(max(0, tid), vocab_size - 1) for tid in input_ids]\n    except Exception:\n        input_ids = []\n    try:\n        tokens = tokenizer.convert_ids_to_tokens(input_ids) if input_ids else []\n    except Exception:\n        tokens = []\n\n    if isinstance(offsets, list) and len(offsets) > 0 and all(\n        isinstance(x, tuple) for x in offsets\n    ):\n        offsets_list = offsets\n    elif isinstance(offsets, list) and len(offsets) > 0 and isinstance(\n        offsets[0], (list, tuple)\n    ):\n        offsets_list = [\n            (x[0], x[1])\n            if (isinstance(x, (list, tuple)) and len(x) >= 2)\n            else (None, None)\n            for x in offsets[0]\n        ]\n    else:\n        offsets_list = [(None, None)] * len(tokens)\n\n    token_word_map: Dict[int, str] = {}\n    words: List[str] = []\n\n    used_any_offset = any(\n        isinstance(o, tuple) and o[0] is not None and o[1] is not None\n        for o in offsets_list\n    )\n    if used_any_offset:\n        word_start: Optional[int] = None\n        word_end: Optional[int] = None\n        current_accumulated_word = \"\"\n\n        for idx, (off, tok) in enumerate(zip(offsets_list, tokens)):\n            try:\n                off_start = int(off[0]) if off[0] is not None else None\n                off_end = int(off[1]) if off[1] is not None else None\n            except Exception:\n                off_start, off_end = None, None\n\n            if off_start is not None and off_end is not None:\n                if off_start < 0 or off_end < 0:\n                    if _DEBUG_VERBOSE:\n                        print(\n                            f\"[WARN] Negative offset detected: \"\n                            f\"({off_start}, {off_end}), skipping\"\n                        )\n                    off_start, off_end = None, None\n                else:\n                    off_start = max(0, min(off_start, text_len))\n                    off_end = max(off_start, min(off_end, text_len))\n\n            if off_start is None or off_end is None:\n                if current_accumulated_word:\n                    token_word_map[idx] = current_accumulated_word\n\n                if word_start is not None and word_end is not None:\n                    try:\n                        wtext = text[word_start:word_end].strip()\n                        if wtext:\n                            words.append(wtext)\n                    except Exception:\n                        pass\n                word_start = None\n                word_end = None\n                continue\n\n            if tok in special_tokens:\n                continue\n\n            if word_start is None:\n                word_start = off_start\n                word_end = off_end\n            else:\n                if off_start > word_end:\n                    try:\n                        wtext = text[word_start:word_end].strip()\n                        if wtext:\n                            words.append(wtext)\n                    except Exception:\n                        pass\n                    word_start = off_start\n                    word_end = off_end\n                else:\n                    word_end = max(word_end, off_end)\n\n            try:\n                current_word = text[word_start:word_end].strip()\n                if current_word:\n                    token_word_map[idx] = current_word\n                    current_accumulated_word = current_word\n            except Exception:\n                pass\n\n        if word_start is not None and word_end is not None:\n            try:\n                wtext = text[word_start:word_end].strip()\n                if wtext:\n                    words.append(wtext)\n            except Exception:\n                pass\n\n        if token_word_map:\n            words = [w for w in words if isinstance(w, str) and w.strip()]\n            return token_word_map, words\n\n    token_word_map = {}\n    assembled: List[str] = []\n    current_parts: List[str] = []\n    running_word = \"\"\n    max_word_len = 100\n\n    for i, tok in enumerate(tokens):\n        if tok in special_tokens:\n            continue\n\n        clean = (tok or \"\").replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n        if not clean:\n            continue\n\n        if tok.startswith(\"▁\") or tok.startswith(\"Ġ\"):\n            if current_parts:\n                word = \"\".join(current_parts)\n                if len(word) <= max_word_len:\n                    assembled.append(word)\n            current_parts = [clean]\n            running_word = clean\n        else:\n            current_parts.append(clean)\n            running_word = \"\".join(current_parts)\n            if len(running_word) > max_word_len:\n                if current_parts[:-1]:\n                    word = \"\".join(current_parts[:-1])\n                    assembled.append(word)\n                current_parts = [clean]\n                running_word = clean\n\n        if running_word:\n            token_word_map[i] = running_word\n\n    if current_parts:\n        word = \"\".join(current_parts)\n        if len(word) <= max_word_len:\n            assembled.append(word)\n\n    if token_word_map:\n        words = [w for w in assembled if w and w.strip()]\n        return token_word_map, words\n\n    try:\n        words_from_markers: List[str] = []\n        current_word_parts: List[str] = []\n\n        for tok in tokens:\n            if tok in special_tokens:\n                continue\n\n            clean = (tok or \"\").replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n            if not clean:\n                continue\n\n            if tok.startswith(\"▁\") or tok.startswith(\"Ġ\"):\n                if current_word_parts:\n                    words_from_markers.append(\"\".join(current_word_parts))\n                current_word_parts = [clean]\n            else:\n                current_word_parts.append(clean)\n\n        if current_word_parts:\n            words_from_markers.append(\"\".join(current_word_parts))\n\n        if words_from_markers:\n            word_list = words_from_markers\n        else:\n            word_list = [w for w in text.split() if w.strip()]\n\n        token_word_map = {}\n\n        if tokens and word_list:\n            word_idx = 0\n\n            for i, tok in enumerate(tokens):\n                clean = (tok or \"\").replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n                if not clean or tok in special_tokens:\n                    continue\n\n                if word_idx < len(word_list):\n                    current_word = word_list[word_idx]\n                    if clean in current_word or current_word.startswith(clean):\n                        token_word_map[i] = current_word\n                    else:\n                        word_idx = min(word_idx + 1, len(word_list) - 1)\n                        token_word_map[i] = word_list[word_idx]\n                else:\n                    if word_list:\n                        token_word_map[i] = word_list[-1]\n\n        return token_word_map, word_list\n    except Exception:\n        return {}, []\n\n_token_validation_cache: Dict[Tuple[str, str], bool] = {}\n_cache_lock = threading.Lock()\n_cache_max_size = 10000\n\ndef is_valid_token(\n    token,\n    special_tokens: Optional[Set[str]] = None,\n    tokenizer=None,\n    language: str = \"bn\",\n) -> bool:\n    token = \"\" if token is None else str(token)\n    cache_key = (token, language)\n    with _cache_lock:\n        if cache_key in _token_validation_cache:\n            return _token_validation_cache[cache_key]\n\n    clean = token.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n\n    if special_tokens and token in special_tokens:\n        result = False\n    else:\n        if len(clean) < _DSCD_MIN_LETTERS:\n            result = False\n        else:\n            has_bengali_chars = any(\"\\u0980\" <= c <= \"\\u09FF\" for c in clean)\n            if not has_bengali_chars:\n                result = False\n            else:\n                bengali_count = sum(1 for c in clean if \"\\u0980\" <= c <= \"\\u09FF\")\n                alphanum_count = sum(1 for c in clean if c.isalnum())\n                if alphanum_count == 0:\n                    result = False\n                else:\n                    result = (bengali_count / alphanum_count) >= _DSCD_MIN_LETTER_FRACTION\n\n    with _cache_lock:\n        if len(_token_validation_cache) < _cache_max_size:\n            _token_validation_cache[cache_key] = result\n    return result\n\ndef should_track_token(\n    token: str,\n    special_tokens: Optional[Set[str]] = None,\n    tokenizer=None,\n    language: str = \"bn\",\n) -> bool:\n    return is_valid_token(token, special_tokens, tokenizer, language)\n\ndef validate_tokenizer_vocab(tokenizer, expected_vocab_size: Optional[int] = None) -> bool:\n    actual_vocab_size = get_tokenizer_vocab_size(tokenizer)\n\n    print(f\"[TOKENIZER-VALIDATION] Actual vocab size: {actual_vocab_size}\")\n\n    if expected_vocab_size is not None:\n        if actual_vocab_size != expected_vocab_size:\n            print(f\"[TOKENIZER-VALIDATION] ❌ MISMATCH: Expected {expected_vocab_size}, got {actual_vocab_size}\")\n            return False\n        else:\n            print(f\"[TOKENIZER-VALIDATION] ✅ Vocab size matches: {actual_vocab_size}\")\n            return True\n\n    bn_token_str = f\"__{_SOURCE_LANG}__\"\n    en_token_str = f\"__{_TARGET_LANG}__\"\n\n    try:\n        bn_id = tokenizer.convert_tokens_to_ids(bn_token_str)\n        en_id = tokenizer.convert_tokens_to_ids(en_token_str)\n\n        print(f\"[TOKENIZER-VALIDATION] Language tokens:\")\n        print(f\"  {bn_token_str} → {bn_id}\")\n        print(f\"  {en_token_str} → {en_id}\")\n\n        if bn_id >= actual_vocab_size or en_id >= actual_vocab_size:\n            print(f\"[TOKENIZER-VALIDATION] ❌ Language token IDs exceed vocab size!\")\n            return False\n\n        if expected_vocab_size is None:\n            try:\n                if bn_id != _MBART_BN_TOKEN_ID or en_id != _MBART_EN_TOKEN_ID:\n                    print(f\"[TOKENIZER-VALIDATION] ⚠️  Language token IDs differ from Cell 0:\")\n                    print(f\"  Expected: bn={_MBART_BN_TOKEN_ID}, en={_MBART_EN_TOKEN_ID}\")\n                    print(f\"  Got: bn={bn_id}, en={en_id}\")\n                    print(f\"  → Update Cell 0 with correct values\")\n            except NameError:\n                pass\n\n        print(f\"[TOKENIZER-VALIDATION] ✅ Language tokens valid\")\n        return True\n\n    except Exception as e:\n        print(f\"[TOKENIZER-VALIDATION] ❌ Language token validation failed: {e}\")\n        return False\n\ndef test_tokenizer_utilities_quick(tokenizer=None) -> bool:\n    sample_bn = \"কাল আমি বাজারে যাব।\"\n    sample_en = \"Tomorrow I will go to the market.\"\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"TOKENIZER UTILITIES TEST\")\n    print(\"=\" * 60)\n\n    try:\n        if tokenizer is None:\n            print(\"No tokenizer provided: skipping test\")\n            return True\n\n        print(\"\\n[TEST 0] Vocabulary validation:\")\n        validate_tokenizer_vocab(tokenizer)\n\n        print(\"\\n[TEST 1] Bengali text processing:\")\n        print(f\"  Input: {sample_bn}\")\n        enc_bn = safe_offsets_tokenize(\n            tokenizer, sample_bn, max_length=32, include_special_tokens=False\n        )\n        enc_len = (\n            int(enc_bn[\"input_ids\"].shape[-1])\n            if isinstance(enc_bn, dict) and \"input_ids\" in enc_bn\n            else \"N/A\"\n        )\n        print(f\"  Encoded length: {enc_len}\")\n        offsets_bn = enc_bn.get(\"offset_mapping\") or []\n        print(f\"  Offsets (first 5): {offsets_bn[:5]}\")\n\n        token_map_bn, words_bn = reconstruct_word_spans(tokenizer, sample_bn, max_length=32)\n        print(f\"  Reconstructed words: {words_bn}\")\n        print(f\"  Token map sample: {dict(list(token_map_bn.items())[:3])}\")\n\n        has_bengali_words = any(\n            any(\"\\u0980\" <= c <= \"\\u09FF\" for c in w) for w in words_bn\n        )\n        print(f\"  Contains Bengali words: {has_bengali_words}\")\n\n        print(\"\\n[TEST 2] English text processing (should show warning):\")\n        print(f\"  Input: {sample_en}\")\n        token_map_en, words_en = reconstruct_word_spans(tokenizer, sample_en, max_length=32)\n        print(f\"  Reconstructed words: {words_en}\")\n\n        has_english_words = any(\n            any(\"a\" <= c.lower() <= \"z\" for c in w) for w in words_en\n        )\n        print(f\"  Contains English words: {has_english_words}\")\n\n        print(\"\\n[TEST 3] Token validation:\")\n        special_tokens = get_tokenizer_special_tokens(tokenizer)\n        test_tokens = [\"কাল\", \"▁আমি\", \"</s>\", \"##ing\", \"a\"]\n        for tok in test_tokens:\n            valid = is_valid_token(tok, special_tokens, tokenizer, \"bn\")\n            print(f\"  '{tok}': {'valid' if valid else 'invalid'}\")\n\n        print(\"\\n[TEST 4] mBART-50 language setting:\")\n        try:\n            if hasattr(tokenizer, 'src_lang'):\n                tokenizer.src_lang = \"bn_IN\"\n                print(\"  ✅ tokenizer.src_lang = 'bn_IN' successful\")\n            else:\n                print(\"  ⚠️  tokenizer.src_lang attribute not found\")\n        except Exception as e:\n            print(f\"  ❌ Language setting failed: {e}\")\n\n        if has_bengali_words and not any(\n            \"a\" <= c.lower() <= \"z\" for c in \"\".join(words_bn)\n        ):\n            print(\"\\nTest PASSED: Bengali processing works correctly\")\n            return True\n        else:\n            print(\"\\nTest WARNING: Check language detection logic\")\n            return False\n\n    except Exception as e:\n        print(f\"\\nTest FAILED: {repr(e)}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    finally:\n        print(\"=\" * 60 + \"\\n\")\n\nsafeoffsetstokenize = safe_offsets_tokenize\nreconstructwordspans = reconstruct_word_spans\ngettokenizerspecialtokens = get_tokenizer_special_tokens\ngetcachedspecialtokens = get_cached_special_tokens\nisvalidtoken = is_valid_token\nshouldtracktoken = should_track_token\ngettokenizervocabsize = get_tokenizer_vocab_size\nvalidatetokenizervocab = validate_tokenizer_vocab\n\nprint(\"=\" * 80)\nprint(\"Cell 1: DUAL-PATH Tokenizer Utilities + Training Losses - READY\")\nprint(\"=\" * 80)\nprint(\"VERIFICATION:\")\nprint(f\"  ✅ DSCD_MIN_LETTERS: {_DSCD_MIN_LETTERS}\")\nprint(f\"  ✅ DSCD_MIN_LETTER_FRACTION: {_DSCD_MIN_LETTER_FRACTION}\")\nprint(f\"  ✅ Token validation cache size: {_cache_max_size}\")\nprint(f\"  ✅ mBART-50 language tokens: bn_IN={_MBART_BN_TOKEN_ID}, en_XX={_MBART_EN_TOKEN_ID}\")\nprint(f\"  ✅ mBART-50 vocab size: {_MBART_VOCAB_SIZE:,}\")\nprint(f\"  ✅ Label Smoothing epsilon: {_LABEL_SMOOTHING_EPS}\")\nprint(f\"  ✅ R-Drop alpha: {_RDROP_ALPHA}\")\nprint(\"\\nDUAL-PATH COMPONENTS:\")\nprint(\"  ✅ BengaliWordTokenizer - Path 1 (word-level)\")\nprint(\"  ✅ mBART-50 utilities - Path 2 (subword)\")\nprint(\"  ✅ LabelSmoothingLoss - Path 2 training\")\nprint(\"  ✅ RDropLoss - Path 2 regularization\")\nprint(\"  ✅ AttentionEntropyPenalty - Modification #3\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"WZE9PkHyH4J1","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:39:56.519344Z","iopub.execute_input":"2026-02-18T08:39:56.519556Z","iopub.status.idle":"2026-02-18T08:39:56.609403Z","shell.execute_reply.started":"2026-02-18T08:39:56.519537Z","shell.execute_reply":"2026-02-18T08:39:56.608661Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCell 1: DUAL-PATH Tokenizer Utilities + Training Losses - READY\n================================================================================\nVERIFICATION:\n  ✅ DSCD_MIN_LETTERS: 3\n  ✅ DSCD_MIN_LETTER_FRACTION: 0.6\n  ✅ Token validation cache size: 10000\n  ✅ mBART-50 language tokens: bn_IN=250028, en_XX=250004\n  ✅ mBART-50 vocab size: 250,054\n  ✅ Label Smoothing epsilon: 0.1\n  ✅ R-Drop alpha: 0.0\n\nDUAL-PATH COMPONENTS:\n  ✅ BengaliWordTokenizer - Path 1 (word-level)\n  ✅ mBART-50 utilities - Path 2 (subword)\n  ✅ LabelSmoothingLoss - Path 2 training\n  ✅ RDropLoss - Path 2 regularization\n  ✅ AttentionEntropyPenalty - Modification #3\n================================================================================\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ==============================================================================\n# CELL 2: DUAL-PATH DATA LOADING - WORD + SUBWORD TOKENIZATION\n# ==============================================================================\n\nfrom typing import Optional, List, Tuple, Dict, Any\nfrom collections import defaultdict\nimport os\nimport time\nimport random\nimport traceback\nimport re\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, get_worker_info\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    import pandas as pd\n    _HAS_PANDAS = True\nexcept ImportError:\n    pd = None\n    _HAS_PANDAS = False\n    print(\"[CELL2] WARNING: pandas not available; CSV loading will fail!\")\n\ntry:\n    from datasets import load_dataset\n    _HAS_DATASETS = True\nexcept Exception:\n    load_dataset = None\n    _HAS_DATASETS = False\n\ntry:\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept NameError:\n    _VERBOSE_LOGGING = False\n\ntry:\n    _DEBUG_VERBOSE = bool(DEBUG_VERBOSE)\nexcept NameError:\n    _DEBUG_VERBOSE = False\n\ntry:\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept NameError:\n    _DEBUG_DISCOVERY = False\n\nDEBUG_CELL2 = bool(_VERBOSE_LOGGING) or bool(_DEBUG_VERBOSE) or bool(_DEBUG_DISCOVERY)\nDEBUG_LIMIT = 10\n_cell2_dbg_counts: Dict[str, int] = defaultdict(int)\n\ndef cell2_dbg(key: str, msg: str, limit: int = DEBUG_LIMIT) -> None:\n    if not DEBUG_CELL2:\n        return\n    _cell2_dbg_counts[key] += 1\n    if _cell2_dbg_counts[key] <= limit:\n        print(f\"[CELL2-DBG] {msg}\")\n\ntry:\n    _NUM_SAMPLES = int(NUM_SAMPLES)\nexcept Exception:\n    _NUM_SAMPLES = 50000\n    print(\"[CELL2] WARNING: NUM_SAMPLES not defined, using default 50000\")\n\ntry:\n    _MAX_LENGTH = int(MAX_LENGTH)\nexcept Exception:\n    _MAX_LENGTH = 64\n    print(\"[CELL2] WARNING: MAX_LENGTH not defined, using default 64\")\n\ntry:\n    _SOURCE_LANG = str(SOURCE_LANGUAGE)\n    _TARGET_LANG = str(TARGET_LANGUAGE)\nexcept NameError:\n    _SOURCE_LANG = \"bn_IN\"\n    _TARGET_LANG = \"en_XX\"\n    print(\"[CELL2] WARNING: SOURCE_LANGUAGE/TARGET_LANGUAGE not defined, using defaults bn_IN/en_XX\")\n\ntry:\n    _MBART_BN_TOKEN_ID = int(MBART50_BN_TOKEN_ID)\n    _MBART_EN_TOKEN_ID = int(MBART50_EN_TOKEN_ID)\nexcept NameError:\n    _MBART_BN_TOKEN_ID = 9\n    _MBART_EN_TOKEN_ID = 2\n    print(\"[CELL2] WARNING: mBART-50 token IDs not defined, using defaults\")\n\ntry:\n    _MBART_VOCAB_SIZE = int(MBART50_VOCAB_SIZE)\nexcept NameError:\n    _MBART_VOCAB_SIZE = 250054\n    print(\"[CELL2] WARNING: mBART-50 vocab size not defined, using default 250054\")\n\ntry:\n    _NUM_GPUS = int(NUM_GPUS)\n    _USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept NameError:\n    _NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    _USE_MULTI_GPU = _NUM_GPUS > 1\n    print(f\"[CELL2] WARNING: GPU config not defined, detected {_NUM_GPUS} GPUs\")\n\ntry:\n    _NUM_WORKERS = int(NUM_WORKERS)\nexcept NameError:\n    _NUM_WORKERS = 0\n    print(\"[CELL2] WARNING: NUM_WORKERS not defined, using 0\")\n\ntry:\n    _PIN_MEMORY = bool(PIN_MEMORY)\nexcept NameError:\n    _PIN_MEMORY = False\n\ntry:\n    _PREFETCH_FACTOR = int(PREFETCH_FACTOR)\nexcept NameError:\n    _PREFETCH_FACTOR = 2\n\ntry:\n    _DATASET_CSV_PATH = str(DATASET_CSV_PATH)\nexcept NameError:\n    _DATASET_CSV_PATH = \"/kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\"\n    print(f\"[CELL2] WARNING: DATASET_CSV_PATH not defined, using default: {_DATASET_CSV_PATH}\")\n\ntry:\n    _NTREX_BN_PATH = str(NTREX_BN_PATH)\nexcept NameError:\n    _NTREX_BN_PATH = \"/kaggle/input/datasets/manas00000003/paper-dataset/ntrex_ref_ben.txt\"\n    print(f\"[CELL2] WARNING: NTREX_BN_PATH not defined, using default: {_NTREX_BN_PATH}\")\n\ntry:\n    _NTREX_EN_PATH = str(NTREX_EN_PATH)\nexcept NameError:\n    _NTREX_EN_PATH = \"/kaggle/input/datasets/manas00000003/paper-dataset/ntrex_src_eng.txt\"\n    print(f\"[CELL2] WARNING: NTREX_EN_PATH not defined, using default: {_NTREX_EN_PATH}\")\n\ntry:\n    _USE_NTREX_DATASET = bool(USE_NTREX_DATASET)\nexcept NameError:\n    _USE_NTREX_DATASET = False\n    print(\"[CELL2] WARNING: USE_NTREX_DATASET not defined, using CSV dataset\")\n\ntry:\n    _TRAIN_DOMAIN = int(TRAIN_DOMAIN)\n    _TEST_DOMAIN = int(TEST_DOMAIN)\n    _USE_DOMAIN_LABELS = bool(USE_DOMAIN_LABELS)\nexcept NameError:\n    _TRAIN_DOMAIN = 0\n    _TEST_DOMAIN = 1\n    _USE_DOMAIN_LABELS = True\n    print(\"[CELL2] WARNING: Domain label config not found, using defaults (train=0, test=1)\")\n\ntry:\n    _VALIDATION_SPLIT = float(VALIDATION_SPLIT)\nexcept NameError:\n    _VALIDATION_SPLIT = 0.1\n    print(\"[CELL2] WARNING: VALIDATION_SPLIT not defined, using default 0.1 (10%)\")\n\n_has_normalize = (\"normalize_bengali\" in globals()) and (\"normalize_english\" in globals())\n_has_reconstruct_word_spans = \"reconstruct_word_spans\" in globals()\n_has_safe_offsets_tokenize = \"safe_offsets_tokenize\" in globals()\n\nif not _has_normalize:\n    print(\"[CELL2] WARNING: normalize_bengali/normalize_english not found; using simple .strip()\")\n\n_BENGALI_CHAR_RE = re.compile(r\"[\\u0980-\\u09FF]\")\n_BENGALI_PUNCT_SET = set(['।', '॥'])\n_COMMON_PUNCT_SET = set(['.', ',', ';', ':', '!', '?', '\"', \"'\", '-', '(', ')', '[', ']', '{', '}'])\n\ndef is_bengali_text(s: str) -> bool:\n    if s is None:\n        return False\n    if not isinstance(s, str) or not s:\n        return False\n    return bool(_BENGALI_CHAR_RE.search(s))\n\ndef separate_bengali_punctuation(text: str, language: str = \"bn\") -> str:\n    if not text or not isinstance(text, str):\n        return \"\"\n\n    text = text.strip()\n\n    if language in [\"bn\", \"hi\", \"te\", \"ta\", \"ml\", \"mr\", \"gu\", \"pa\"]:\n        text = re.sub(r'([।॥])', r' \\1 ', text)\n\n    text = re.sub(r'([,;:!?()\\[\\]{}])', r' \\1 ', text)\n\n    text = re.sub(r'\\s+', ' ', text)\n    return text.strip()\n\ndef clean_and_normalize_text(text: str, language: str = \"bn\") -> str:\n    if not text or not isinstance(text, str):\n        return \"\"\n\n    text = text.strip()\n    if not text:\n        return \"\"\n\n    text = separate_bengali_punctuation(text, language)\n\n    if _has_normalize:\n        if language in [\"bn\", \"bn_IN\"]:\n            text = normalize_bengali(text)\n        else:\n            text = normalize_english(text)\n    else:\n        text = text.strip()\n        if language in [\"en\", \"en_XX\"]:\n            text = text.lower()\n\n    return text\n\ndef is_punctuation_only(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n\n    clean = token.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n    if not clean:\n        return False\n\n    if clean in _BENGALI_PUNCT_SET:\n        return True\n\n    if clean in _COMMON_PUNCT_SET:\n        return True\n\n    if len(clean) == 1 and not clean.isalnum():\n        return True\n\n    return all(c in _BENGALI_PUNCT_SET or c in _COMMON_PUNCT_SET for c in clean)\n\ndef _dataloader_worker_init_fn(worker_id: int) -> None:\n    worker_info = get_worker_info()\n    dataset = worker_info.dataset if worker_info is not None else None\n    try:\n        if dataset is not None and hasattr(dataset, \"_tokenizer_name_or_path\") and dataset._tokenizer_name_or_path:\n            try:\n                from transformers import MBart50TokenizerFast\n                dataset.tokenizer = MBart50TokenizerFast.from_pretrained(dataset._tokenizer_name_or_path)\n                dataset.is_fast = getattr(dataset.tokenizer, \"is_fast\", False)\n                dataset.vocab_size = len(dataset.tokenizer)\n\n                try:\n                    dataset.tokenizer.src_lang = _SOURCE_LANG\n                except Exception:\n                    pass\n\n                if DEBUG_CELL2:\n                    print(f\"[CELL2-WORKER-{worker_id}] Tokenizer reloaded (vocab={dataset.vocab_size})\")\n            except Exception as e:\n                cell2_dbg(\"worker_tokenizer_reload\", f\"Worker {worker_id} tokenizer reload failed: {e}\")\n                dataset.tokenizer = None\n                dataset.is_fast = False\n                dataset.vocab_size = _MBART_VOCAB_SIZE\n    except Exception:\n        if DEBUG_CELL2:\n            print(f\"[CELL2-WORKER-INIT] Tokenizer rebind failed in worker {worker_id}\")\n\n    try:\n        base = int(os.environ.get(\"PYTHONHASHSEED\", \"0\"))\n        seed = (base ^ (worker_id + 1) ^ int(time.time())) & 0xFFFFFFFF\n        random.seed(seed)\n        np.random.seed(seed % (2**31 - 1))\n        torch.manual_seed(seed % (2**31 - 1))\n    except Exception:\n        pass\n\ndef load_ntrex_parallel_files(\n    bn_path: str,\n    en_path: str,\n    num_samples: Optional[int] = None,\n) -> List[Tuple[str, str]]:\n    print(f\"[CELL2-NTREX] Loading NTREX dataset:\")\n    print(f\"  Bengali: {bn_path}\")\n    print(f\"  English: {en_path}\")\n    \n    if not os.path.exists(bn_path):\n        print(f\"[CELL2-NTREX] ERROR: Bengali file not found: {bn_path}\")\n        return _get_fallback_dataset()\n    \n    if not os.path.exists(en_path):\n        print(f\"[CELL2-NTREX] ERROR: English file not found: {en_path}\")\n        return _get_fallback_dataset()\n    \n    try:\n        with open(bn_path, 'r', encoding='utf-8') as f_bn:\n            bn_lines = f_bn.readlines()\n        \n        with open(en_path, 'r', encoding='utf-8') as f_en:\n            en_lines = f_en.readlines()\n        \n        if len(bn_lines) != len(en_lines):\n            print(f\"[CELL2-NTREX] WARNING: Line count mismatch!\")\n            print(f\"  Bengali: {len(bn_lines)} lines\")\n            print(f\"  English: {len(en_lines)} lines\")\n            print(f\"  Using minimum: {min(len(bn_lines), len(en_lines))}\")\n        \n        total_lines = min(len(bn_lines), len(en_lines))\n        if num_samples is not None and num_samples > 0:\n            total_lines = min(total_lines, num_samples)\n        \n        print(f\"[CELL2-NTREX] Processing {total_lines} parallel lines...\")\n        \n        pairs: List[Tuple[str, str]] = []\n        skipped = 0\n        \n        for i in tqdm(range(total_lines), desc=\"Loading NTREX\"):\n            try:\n                bn_text = bn_lines[i].strip()\n                en_text = en_lines[i].strip()\n                \n                if not bn_text or not en_text:\n                    skipped += 1\n                    continue\n                \n                if not is_bengali_text(bn_text):\n                    skipped += 1\n                    cell2_dbg(\"ntrex_not_bengali\", f\"Line {i}: Bengali text check failed\")\n                    continue\n                \n                if not re.search(r\"[a-zA-Z]\", en_text):\n                    skipped += 1\n                    cell2_dbg(\"ntrex_not_english\", f\"Line {i}: English text check failed\")\n                    continue\n                \n                max_words = max(20, _MAX_LENGTH // 2)\n                if len(bn_text.split()) > max_words or len(en_text.split()) > max_words:\n                    skipped += 1\n                    cell2_dbg(\"ntrex_too_long\", f\"Line {i}: Text too long\")\n                    continue\n                \n                bn_norm = clean_and_normalize_text(bn_text, language=\"bn_IN\")\n                en_norm = clean_and_normalize_text(en_text, language=\"en_XX\")\n                \n                if not bn_norm or not en_norm:\n                    skipped += 1\n                    continue\n                \n                pairs.append((bn_norm, en_norm))\n                \n            except Exception as e:\n                skipped += 1\n                cell2_dbg(\"ntrex_line_exception\", f\"Line {i} exception: {type(e).__name__}\")\n                continue\n        \n        print(f\"[CELL2-NTREX] Loaded {len(pairs)} valid pairs, skipped {skipped} lines\")\n        \n        if len(pairs) == 0:\n            print(\"[CELL2-NTREX] ERROR: No valid pairs loaded!\")\n            return _get_fallback_dataset()\n        \n        if len(pairs) > 0:\n            print(f\"[CELL2-NTREX] Sample pair:\")\n            print(f\"  BN: {pairs[0][0][:80]}\")\n            print(f\"  EN: {pairs[0][1][:80]}\")\n        \n        return pairs\n    \n    except Exception as e:\n        print(f\"[CELL2-NTREX] ERROR: {type(e).__name__}: {str(e)}\")\n        traceback.print_exc()\n        return _get_fallback_dataset()\n\ndef load_and_preprocess_optimized(\n    num_samples: Optional[int] = None,\n    split: str = \"train\",\n) -> List[Tuple[str, str]]:\n    if num_samples is None:\n        num_samples = _NUM_SAMPLES\n    if num_samples <= 0:\n        raise ValueError(\"num_samples must be positive\")\n\n    if _USE_NTREX_DATASET:\n        print(f\"[CELL2] Using NTREX dataset (parallel text files)\")\n        return load_ntrex_parallel_files(\n            bn_path=_NTREX_BN_PATH,\n            en_path=_NTREX_EN_PATH,\n            num_samples=num_samples\n        )\n\n    print(f\"[CELL2] Loading up to {num_samples} samples from local CSV: {_DATASET_CSV_PATH}\")\n\n    if not _HAS_PANDAS:\n        print(\"[CELL2] ERROR: pandas not available; cannot load CSV!\")\n        print(\"[CELL2] Using fallback dataset for debugging.\")\n        return _get_fallback_dataset()\n\n    if not os.path.exists(_DATASET_CSV_PATH):\n        print(f\"[CELL2] ERROR: CSV file not found at: {_DATASET_CSV_PATH}\")\n        print(\"[CELL2] Using fallback dataset for debugging.\")\n        return _get_fallback_dataset()\n\n    try:\n        print(\"[CELL2] Reading CSV file...\")\n        df = pd.read_csv(_DATASET_CSV_PATH)\n        if df.empty:\n            print(\"[CELL2] ERROR: CSV file is empty\")\n            return _get_fallback_dataset()\n\n        if \"src\" not in df.columns or \"tgt\" not in df.columns:\n            print(f\"[CELL2] ERROR: CSV missing required columns. Found columns: {list(df.columns)}\")\n            print(\"[CELL2] Expected format: src (Bengali), tgt (English) OR src (English), tgt (Bengali)\")\n            return _get_fallback_dataset()\n\n        sample_size = min(10, len(df))\n        sample_rows = df.head(sample_size)\n\n        src_bengali_count = sum(1 for s in sample_rows[\"src\"] if is_bengali_text(str(s)))\n        tgt_bengali_count = sum(1 for s in sample_rows[\"tgt\"] if is_bengali_text(str(s)))\n\n        src_is_bengali = src_bengali_count > sample_size * 0.5\n        tgt_is_bengali = tgt_bengali_count > sample_size * 0.5\n\n        if not src_is_bengali and tgt_is_bengali:\n            print(\"[CELL2] Detected src=English, tgt=Bengali: Swapping columns for bn→en task.\")\n            df = df.rename(columns={\"src\": \"_temp_tgt\", \"tgt\": \"_temp_src\"})\n            df = df.rename(columns={\"_temp_src\": \"src\", \"_temp_tgt\": \"tgt\"})\n\n            sample_rows = df.head(sample_size)\n            src_bengali_count = sum(1 for s in sample_rows[\"src\"] if is_bengali_text(str(s)))\n            src_is_bengali = src_bengali_count > sample_size * 0.5\n\n            if not src_is_bengali:\n                print(\"[CELL2] ERROR: Swap failed, src is still not Bengali.\")\n                return _get_fallback_dataset()\n            else:\n                print(\"[CELL2] Swap successful: src=Bengali, tgt=English\")\n        elif not src_is_bengali:\n            print(\"[CELL2] WARNING: src column does not appear to be Bengali. Proceeding but output may be incorrect.\")\n\n        df = df.head(num_samples)\n        print(f\"[CELL2] Processing {len(df)} rows from CSV...\")\n\n        pairs: List[Tuple[str, str]] = []\n        skipped = 0\n\n        for row_tuple in tqdm(df.itertuples(index=False), total=len(df), desc=\"Loading dataset\"):\n            try:\n                src_val = row_tuple.src\n                tgt_val = row_tuple.tgt\n                if pd.isna(src_val) or pd.isna(tgt_val):\n                    skipped += 1\n                    cell2_dbg(\"nan_value\", \"NaN value detected\")\n                    continue\n                bn = str(src_val).strip()\n                en = str(tgt_val).strip()\n                if not bn or not en:\n                    skipped += 1\n                    cell2_dbg(\"empty_field\", \"Empty src/tgt field\")\n                    continue\n                if not is_bengali_text(bn):\n                    skipped += 1\n                    cell2_dbg(\"not_bengali_src\", \"src field not Bengali\")\n                    continue\n                if not re.search(r\"[a-zA-Z]\", en):\n                    skipped += 1\n                    cell2_dbg(\"not_english_tgt\", \"tgt field not English\")\n                    continue\n\n                max_words = max(20, _MAX_LENGTH // 2)\n                if len(bn.split()) > max_words or len(en.split()) > max_words:\n                    skipped += 1\n                    cell2_dbg(\"too_long\", \"Text too long\")\n                    continue\n\n                bn_norm = clean_and_normalize_text(bn, language=\"bn_IN\")\n                en_norm = clean_and_normalize_text(en, language=\"en_XX\")\n\n                if not bn_norm or not en_norm:\n                    skipped += 1\n                    cell2_dbg(\"empty_after_norm\", \"Empty after normalization\")\n                    continue\n\n                pairs.append((bn_norm, en_norm))\n            except Exception as e:\n                skipped += 1\n                cell2_dbg(\"row_exception\", f\"Row load exception: {type(e).__name__}\")\n                continue\n\n        print(f\"[CELL2] Loaded {len(pairs)} pairs from CSV, skipped {skipped} rows\")\n\n        if len(pairs) == 0:\n            print(\"[CELL2] ERROR: No valid pairs loaded from CSV!\")\n            print(\"[CELL2] Check that src column contains Bengali and tgt column contains English.\")\n            return _get_fallback_dataset()\n\n        return pairs\n\n    except pd.errors.EmptyDataError:\n        print(f\"[CELL2] ERROR: CSV file is empty: {_DATASET_CSV_PATH}\")\n        return _get_fallback_dataset()\n    except Exception as e:\n        print(f\"[CELL2] ERROR loading CSV: {type(e).__name__}: {str(e)}\")\n        traceback.print_exc()\n        print(\"[CELL2] Using fallback dataset\")\n        return _get_fallback_dataset()\n\ndef _get_fallback_dataset() -> List[Tuple[str, str]]:\n    print(\"[CELL2] Using fallback dataset (50 unique samples)\")\n    fallback_pairs = [\n        (\"আমি কল বন্ধ করেছি\", \"i turned off the tap\"),\n        (\"সে আমাকে পরে কল করবে\", \"he will call me later\"),\n        (\"আমরা প্রতিদিন তাজা ফল খাই\", \"we eat fresh fruits every day\"),\n        (\"তার কঠোর পরিশ্রমের ভালো ফল হয়েছে\", \"his hard work has brought good results\"),\n        (\"গাছে নতুন পাতাগুলো গজিয়েছে\", \"new leaves have sprouted on the tree\"),\n        (\"আমি বইয়ের পাতা উল্টাচ্ছি\", \"i am turning the pages of the book\"),\n        (\"কাল আমি বাজারে গিয়েছিলাম\", \"yesterday i went to the market\"),\n        (\"কাল আমি তোমার সাথে দেখা করব\", \"tomorrow i will meet you\"),\n        (\"তারা আকাশে উজ্জ্বল\", \"the stars are bright in the sky\"),\n        (\"তারা বাড়িতে নেই\", \"they are not at home\"),\n        (\"ব্যাংক নদীর ধারে ভেঙে গেছে\", \"the bank by the river has collapsed\"),\n        (\"আমি ব্যাংকে টাকা জমা দিয়েছি\", \"i deposited money in the bank\"),\n        (\"বার বার চেষ্টা করতে হবে\", \"you have to try again and again\"),\n        (\"আমি বার খুলে ভিতরে ঢুকলাম\", \"i opened the bar and entered\"),\n        (\"তার মাথা ব্যথা করছে\", \"his head is hurting\"),\n        (\"আমি মাথা নেড়ে সম্মতি দিলাম\", \"i nodded my head in agreement\"),\n        (\"সে হার মেনে নিয়েছে\", \"he accepted defeat\"),\n        (\"আমি গলায় সোনার হার পরেছি\", \"i am wearing a gold necklace\"),\n        (\"পানি খুব ঠান্ডা\", \"the water is very cold\"),\n        (\"আমি পানি খাচ্ছি\", \"i am drinking water\"),\n        (\"দল খেলায় জিতেছে\", \"the team won the game\"),\n        (\"আমি মাটি দল দিয়ে ফেললাম\", \"i trampled the soil\"),\n        (\"বাজার থেকে সবজি কিনলাম\", \"i bought vegetables from the market\"),\n        (\"বাজার অনেক ভিড় ছিল\", \"the market was very crowded\"),\n        (\"তার নাম আহমেদ\", \"his name is ahmed\"),\n        (\"নাম না করে কাজ করো\", \"work without making a name\"),\n        (\"কথা বলা বন্ধ করো\", \"stop talking\"),\n        (\"তার কথা শুনে ভালো লাগল\", \"i felt good hearing his words\"),\n        (\"বই পড়তে ভালো লাগে\", \"i like reading books\"),\n        (\"আমি একটি নতুন বই কিনেছি\", \"i bought a new book\"),\n        (\"ঘর পরিষ্কার করা হয়েছে\", \"the house has been cleaned\"),\n        (\"আমি ঘরে বসে আছি\", \"i am sitting at home\"),\n        (\"মন ভালো নেই\", \"my mind is not good\"),\n        (\"আমার মন চায় বেড়াতে যেতে\", \"my mind wants to go for a walk\"),\n        (\"হাত ধুয়ে নাও\", \"wash your hands\"),\n        (\"আমি তার হাত ধরলাম\", \"i held his hand\"),\n        (\"দিন কেটে যাচ্ছে\", \"the day is passing by\"),\n        (\"আজ কি দিন\", \"what day is today\"),\n        (\"রাত হয়ে এসেছে\", \"night has come\"),\n        (\"আমি রাত জেগে পড়েছি\", \"i studied staying up at night\"),\n        (\"জল খুব গরম\", \"the water is very hot\"),\n        (\"আমি জল দিয়ে গাছ সিঞ্চন করেছি\", \"i watered the plants\"),\n        (\"বাড়ি যাচ্ছি\", \"i am going home\"),\n        (\"আমার বাড়ি ঢাকায়\", \"my house is in dhaka\"),\n        (\"পার্কে অনেক মানুষ\", \"there are many people in the park\"),\n        (\"আমি প্রতিদিন পার্কে হাঁটি\", \"i walk in the park every day\"),\n        (\"নদী বইছে\", \"the river is flowing\"),\n        (\"আমি নদীর ধারে দাঁড়িয়ে আছি\", \"i am standing by the river\"),\n        (\"বন খুব সুন্দর\", \"the forest is very beautiful\"),\n        (\"আমি বন দেখতে গিয়েছিলাম\", \"i went to see the forest\"),\n    ]\n\n    processed_pairs = []\n    for bn, en in fallback_pairs:\n        bn_clean = clean_and_normalize_text(bn, \"bn_IN\")\n        en_clean = clean_and_normalize_text(en, \"en_XX\")\n        if bn_clean and en_clean:\n            processed_pairs.append((bn_clean, en_clean))\n\n    return processed_pairs\n\nclass DualPathDataset(Dataset):\n    def __init__(\n        self,\n        pairs: List[Tuple[str, str]],\n        tokenizer: Any = None,\n        max_length: Optional[int] = None,\n        split: str = \"train\",\n    ):\n        if max_length is None:\n            max_length = _MAX_LENGTH\n        self.max_length = int(max_length)\n        self.tokenizer = tokenizer\n        self.split = split\n        self.vocab_size = len(tokenizer) if tokenizer is not None else _MBART_VOCAB_SIZE\n        print(f\"[CELL2] Dataset vocab size: {self.vocab_size}\")\n\n        try:\n            self._tokenizer_name_or_path = getattr(tokenizer, \"name_or_path\", None)\n        except Exception:\n            self._tokenizer_name_or_path = None\n\n        try:\n            self.is_fast = getattr(self.tokenizer, \"is_fast\", False)\n        except Exception:\n            self.is_fast = False\n\n        self.pairs: List[Tuple[str, str]] = []\n        invalid = 0\n\n        for i, p in enumerate(pairs):\n            try:\n                if not isinstance(p, (list, tuple)) or len(p) != 2:\n                    invalid += 1\n                    cell2_dbg(\"init_badpair\", f\"Bad pair structure at idx={i}\")\n                    continue\n                src, tgt = p\n                if not isinstance(src, str) or not isinstance(tgt, str):\n                    invalid += 1\n                    cell2_dbg(\"init_badtype\", f\"Non-string src/tgt at idx={i}\")\n                    continue\n                if not src or not tgt:\n                    invalid += 1\n                    cell2_dbg(\"init_empty\", f\"Empty src/tgt at idx={i}\")\n                    continue\n                if len(src) > self.max_length * 20 or len(tgt) > self.max_length * 20:\n                    invalid += 1\n                    cell2_dbg(\"init_long\", f\"Extremely long text at idx={i}\")\n                    continue\n                self.pairs.append((src, tgt))\n            except Exception as e:\n                invalid += 1\n                cell2_dbg(\"init_exc\", f\"Init pair exception idx={i}: {type(e).__name__}\")\n\n        print(f\"[CELL2] Dataset initialized: {len(self.pairs)} valid pairs, {invalid} invalid, split={self.split}\")\n\n        try:\n            if \"get_tokenizer_special_tokens\" in globals():\n                self.special_tokens = get_tokenizer_special_tokens(self.tokenizer)\n            else:\n                self.special_tokens = set(getattr(self.tokenizer, \"all_special_tokens\", [])) if self.tokenizer is not None else set()\n        except Exception:\n            self.special_tokens = {\n                f\"__{_SOURCE_LANG}__\",\n                f\"__{_TARGET_LANG}__\",\n                \"</s>\",\n                \"<pad>\",\n                \"<s>\",\n                \"<unk>\",\n            }\n\n    def __getstate__(self):\n        state = self.__dict__.copy()\n        state[\"tokenizer\"] = None\n        state[\"_tokenizer_name_or_path\"] = getattr(self, \"_tokenizer_name_or_path\", None)\n        return state\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self.tokenizer = None\n        self.is_fast = False\n\n    def __len__(self) -> int:\n        return len(self.pairs)\n\n    def _encode_src(self, src_text: str):\n        src_text = src_text if isinstance(src_text, str) else str(src_text)\n        try:\n            if self.tokenizer is None:\n                self.tokenizer = globals().get(\"tokenizer\", None)\n                self.is_fast = getattr(self.tokenizer, \"is_fast\", False) if self.tokenizer is not None else False\n                self.vocab_size = len(self.tokenizer) if self.tokenizer is not None else _MBART_VOCAB_SIZE\n            if self.tokenizer is None:\n                raise RuntimeError(\"Tokenizer not available\")\n\n            try:\n                self.tokenizer.src_lang = _SOURCE_LANG\n            except Exception:\n                pass\n\n            if _has_safe_offsets_tokenize:\n                enc = safe_offsets_tokenize(\n                    self.tokenizer,\n                    src_text,\n                    max_length=self.max_length,\n                    include_special_tokens=True\n                )\n                try:\n                    if isinstance(enc[\"input_ids\"], torch.Tensor):\n                        input_ids = enc[\"input_ids\"].squeeze(0) if enc[\"input_ids\"].dim() > 1 else enc[\"input_ids\"]\n                    else:\n                        input_ids = torch.tensor(enc[\"input_ids\"][0]) if isinstance(enc[\"input_ids\"], list) and len(enc[\"input_ids\"]) > 0 else torch.tensor(enc[\"input_ids\"])\n                except Exception:\n                    input_ids = torch.tensor(enc.get(\"input_ids\", [[1]])[0] if enc.get(\"input_ids\") else [1])\n\n                attention_mask = enc.get(\"attention_mask\", None)\n                if attention_mask is None:\n                    attention_mask = torch.ones_like(input_ids)\n                elif isinstance(attention_mask, list):\n                    attention_mask = torch.tensor(attention_mask[0]) if attention_mask else torch.ones_like(input_ids)\n                elif isinstance(attention_mask, torch.Tensor):\n                    attention_mask = attention_mask.squeeze(0) if attention_mask.dim() > 1 else attention_mask\n\n                try:\n                    ids_list = input_ids.tolist() if isinstance(input_ids, torch.Tensor) else list(input_ids)\n                    tokens = self.tokenizer.convert_ids_to_tokens(ids_list)\n                except Exception:\n                    tokens = []\n            else:\n                enc = self.tokenizer(\n                    src_text,\n                    max_length=self.max_length,\n                    padding=\"max_length\",\n                    truncation=True,\n                    return_tensors=\"pt\",\n                    add_special_tokens=True,\n                )\n                input_ids = enc[\"input_ids\"].squeeze(0)\n                attention_mask = enc.get(\"attention_mask\", torch.ones_like(input_ids)).squeeze(0)\n                try:\n                    tokens = self.tokenizer.convert_ids_to_tokens(input_ids.tolist())\n                except Exception:\n                    tokens = []\n\n            input_ids = torch.clamp(input_ids, 0, self.vocab_size - 1)\n\n            token_word_map: Dict[int, str] = {}\n            if _has_reconstruct_word_spans:\n                try:\n                    wm, words = reconstruct_word_spans(self.tokenizer, src_text, max_length=self.max_length)\n                    if isinstance(wm, dict) and wm:\n                        token_word_map = wm\n                except Exception as e:\n                    cell2_dbg(\"wm_exc\", f\"reconstruct_word_spans failed: {e}\")\n\n            if not token_word_map and tokens:\n                try:\n                    current_word: List[str] = []\n                    for idx, tok in enumerate(tokens):\n                        if isinstance(tok, str) and tok not in self.special_tokens:\n                            if is_punctuation_only(tok):\n                                continue\n\n                            clean = tok.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n                            if clean:\n                                if tok.startswith(\"▁\") or tok.startswith(\"Ġ\"):\n                                    current_word = [clean]\n                                else:\n                                    current_word.append(clean)\n                                word_str = \"\".join(current_word)\n                                if not is_punctuation_only(word_str):\n                                    token_word_map[idx] = word_str\n                except Exception as e:\n                    cell2_dbg(\"fallback_wm\", f\"Fallback word map failed: {e}\")\n\n            return input_ids, attention_mask, tokens, token_word_map\n\n        except Exception as e:\n            cell2_dbg(\"encode_src_exc\", f\"Encoding source failed: {type(e).__name__}\")\n            pad_id = getattr(self.tokenizer, \"pad_token_id\", 1) if self.tokenizer is not None else 1\n            input_ids = torch.full((self.max_length,), int(pad_id), dtype=torch.long)\n            attention_mask = torch.zeros(self.max_length, dtype=torch.long)\n            return input_ids, attention_mask, [], {}\n\n    def _encode_tgt(self, tgt_text: str):\n        tgt_text = tgt_text if isinstance(tgt_text, str) else str(tgt_text)\n        try:\n            if self.tokenizer is None:\n                self.tokenizer = globals().get(\"tokenizer\", None)\n                self.vocab_size = len(self.tokenizer) if self.tokenizer is not None else _MBART_VOCAB_SIZE\n            if self.tokenizer is None:\n                raise RuntimeError(\"Tokenizer not available\")\n\n            try:\n                self.tokenizer.src_lang = _TARGET_LANG\n            except Exception:\n                pass\n\n            dec = self.tokenizer(\n                tgt_text,\n                max_length=self.max_length,\n                padding=\"max_length\",\n                truncation=True,\n                return_tensors=\"pt\",\n                add_special_tokens=True,\n            )\n            labels = dec[\"input_ids\"].squeeze(0)\n\n            labels = torch.clamp(labels, 0, self.vocab_size - 1)\n\n            pad_id = getattr(self.tokenizer, \"pad_token_id\", 1) if self.tokenizer is not None else 1\n\n            valid_before_mask = (labels != int(pad_id)).sum().item()\n            labels[labels == int(pad_id)] = -100\n            valid_after_mask = (labels != -100).sum().item()\n\n            if _DEBUG_DISCOVERY and valid_after_mask == 0:\n                cell2_dbg(\"encode_tgt_all_masked\", f\"[ENCODE_TGT] ❌ WARNING: All labels masked as -100! (before_mask={valid_before_mask}, after_mask={valid_after_mask})\")\n            elif _DEBUG_DISCOVERY and valid_after_mask < 3:\n                cell2_dbg(\"encode_tgt_few_valid\", f\"[ENCODE_TGT] ⚠️  Only {valid_after_mask} valid labels (most are padding)\")\n\n            return labels\n        except Exception as e:\n            cell2_dbg(\"encode_tgt_exc\", f\"Encoding tgt failed: {type(e).__name__}\")\n            return torch.full((self.max_length,), -100, dtype=torch.long)\n\n    def _make_safe_sample(self, reason: str = \"fallback\") -> Dict[str, Any]:\n        try:\n            src = \"আমি\"\n            tgt = \"i\"\n            input_ids, attention_mask, tokens, token_word_map = self._encode_src(src)\n            labels = self._encode_tgt(tgt)\n\n            domain_label = random.randint(_TRAIN_DOMAIN, _TEST_DOMAIN)\n\n            return {\n                \"input_ids\": input_ids,\n                \"attention_mask\": attention_mask,\n                \"labels\": labels,\n                \"token_word_map\": token_word_map,\n                \"src_text\": src,\n                \"tokens\": tokens,\n                \"domain_label\": domain_label,\n            }\n        except Exception:\n            pad_id = 1\n            domain_label = random.randint(_TRAIN_DOMAIN, _TEST_DOMAIN)\n            return {\n                \"input_ids\": torch.full((self.max_length,), int(pad_id), dtype=torch.long),\n                \"attention_mask\": torch.zeros(self.max_length, dtype=torch.long),\n                \"labels\": torch.full((self.max_length,), -100, dtype=torch.long),\n                \"token_word_map\": {},\n                \"src_text\": \"\",\n                \"tokens\": [],\n                \"domain_label\": domain_label,\n            }\n\n    def __getitem__(self, idx: int) -> Dict[str, Any]:\n        try:\n            if idx < 0 or idx >= len(self.pairs):\n                cell2_dbg(\"getitem_oob\", f\"Index out of range idx={idx}\")\n                return self._make_safe_sample(\"oob\")\n\n            src, tgt = self.pairs[idx]\n            if not isinstance(src, str) or not isinstance(tgt, str):\n                cell2_dbg(\"getitem_bad_types\", f\"Bad types at idx={idx}\")\n                return self._make_safe_sample(\"bad_types\")\n\n            if DEBUG_CELL2 and idx < 3:\n                has_bengali = is_bengali_text(src)\n                has_english = any(\"a\" <= c.lower() <= \"z\" for c in src)\n                print(f\"[CELL2-GETITEM-{idx}] src sample: {src[:50]}\")\n                print(f\"[CELL2-GETITEM-{idx}] Bengali: {has_bengali}, English: {has_english}\")\n                if not has_bengali:\n                    print(f\"[CELL2] WARNING: src_text is NOT Bengali at idx={idx}!\")\n\n            input_ids, attention_mask, tokens, token_word_map = self._encode_src(src)\n            labels = self._encode_tgt(tgt)\n\n            if _DEBUG_DISCOVERY and idx < 5:\n                valid_labels = (labels != -100).sum().item()\n                if valid_labels == 0:\n                    print(f\"[CELL2-GETITEM] ❌ WARNING: idx={idx} has ALL labels = -100!\")\n                elif valid_labels < 3:\n                    print(f\"[CELL2-GETITEM] ⚠️  idx={idx} has only {valid_labels} valid labels\")\n\n            domain_label = idx % 2\n\n            return {\n                \"input_ids\": input_ids,\n                \"attention_mask\": attention_mask,\n                \"labels\": labels,\n                \"token_word_map\": token_word_map,\n                \"src_text\": src,\n                \"tokens\": tokens,\n                \"domain_label\": domain_label,\n            }\n        except Exception as e:\n            cell2_dbg(\"getitem_exc\", f\"Unhandled __getitem__ exception idx={idx}: {type(e).__name__}\")\n            return self._make_safe_sample(\"unhandled\")\n\ndef _infer_pad_id_from_sample(sample: Dict[str, Any], default_pad_id: int = 1) -> int:\n    try:\n        tk = globals().get(\"tokenizer\", None)\n        if tk is not None:\n            pad = getattr(tk, \"pad_token_id\", None)\n            if pad is not None:\n                return int(pad)\n    except Exception:\n        cell2_dbg(\"infer_pad_exc\", \"infer pad id failed\")\n    return int(default_pad_id)\n\ndef _pad_or_truncate_array(tensor: torch.Tensor, length: int, pad_value: int) -> torch.Tensor:\n    if tensor is None:\n        return torch.full((length,), int(pad_value), dtype=torch.long)\n    t = tensor.view(-1).long()\n    L = t.size(0)\n    if L == length:\n        return t\n    if L < length:\n        pad = torch.full((length - L,), int(pad_value), dtype=t.dtype)\n        return torch.cat([t, pad], dim=0)\n    return t[:length]\n\ndef safe_collate(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n    valid = [b for b in batch if isinstance(b, dict) and \"input_ids\" in b and isinstance(b[\"input_ids\"], torch.Tensor)]\n\n    default_domain = _TRAIN_DOMAIN\n\n    if not valid:\n        pad = _infer_pad_id_from_sample({}, default_pad_id=1)\n        return {\n            \"input_ids\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"attention_mask\": torch.zeros(1, _MAX_LENGTH, dtype=torch.long),\n            \"labels\": torch.full((1, _MAX_LENGTH), -100, dtype=torch.long),\n            \"token_word_map\": [{}],\n            \"src_texts\": [\"\"],\n            \"tokens\": [[]],\n            \"domain_labels\": torch.tensor([default_domain], dtype=torch.long),\n        }\n\n    pad_id = _infer_pad_id_from_sample(valid[0], default_pad_id=1)\n\n    raw_inputs = []\n    raw_masks = []\n    raw_labs = []\n    twmaps = []\n    srcs = []\n    toks = []\n    domains = []\n\n    for i, s in enumerate(valid):\n        try:\n            in_ids = s[\"input_ids\"]\n            att = s.get(\"attention_mask\", None)\n            lab = s[\"labels\"]\n            domain = s.get(\"domain_label\", default_domain)\n\n            if att is None:\n                att = (in_ids != pad_id).long()\n            else:\n                try:\n                    att = att.view(-1).long()\n                except Exception:\n                    att = (in_ids != pad_id).long()\n\n            try:\n                in_ids = in_ids.view(-1)\n            except Exception:\n                in_ids = in_ids.flatten()\n\n            try:\n                lab = lab.view(-1)\n            except Exception:\n                lab = lab.flatten()\n\n            raw_inputs.append(in_ids)\n            raw_masks.append(att)\n            raw_labs.append(lab)\n            twmaps.append(s.get(\"token_word_map\", {}))\n            srcs.append(s.get(\"src_text\", \"\"))\n            toks.append(s.get(\"tokens\", []))\n            domains.append(domain)\n        except Exception as e:\n            cell2_dbg(\"collate_item_exc\", f\"Collate item exception idx={i}: {type(e).__name__}\")\n            continue\n\n    if not raw_inputs:\n        pad = _infer_pad_id_from_sample({}, default_pad_id=1)\n        return {\n            \"input_ids\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"attention_mask\": torch.zeros(1, _MAX_LENGTH, dtype=torch.long),\n            \"labels\": torch.full((1, _MAX_LENGTH), -100, dtype=torch.long),\n            \"token_word_map\": [{}],\n            \"src_texts\": [\"\"],\n            \"tokens\": [[]],\n            \"domain_labels\": torch.tensor([default_domain], dtype=torch.long),\n        }\n\n    max_input_len = max(t.size(0) for t in raw_inputs)\n    max_label_len = max(t.size(0) for t in raw_labs)\n    actual_max_len = max(max_input_len, max_label_len)\n    actual_max_len = min(actual_max_len, _MAX_LENGTH)\n\n    inputs = []\n    masks = []\n    labs = []\n\n    for in_ids, att, lab in zip(raw_inputs, raw_masks, raw_labs):\n        in_ids_padded = _pad_or_truncate_array(in_ids, actual_max_len, pad_id)\n        att_padded = _pad_or_truncate_array(att, actual_max_len, 0)\n        lab_padded = _pad_or_truncate_array(lab, actual_max_len, -100)\n\n        inputs.append(in_ids_padded)\n        masks.append(att_padded)\n        labs.append(lab_padded)\n\n    input_ids = torch.stack(inputs, dim=0)\n    attention_mask = torch.stack(masks, dim=0)\n    labels = torch.stack(labs, dim=0)\n\n    try:\n        domain_labels = torch.tensor(domains, dtype=torch.long)\n    except Exception:\n        domain_labels = torch.full((len(inputs),), default_domain, dtype=torch.long)\n\n    unique_domains = len(set(domains))\n    if unique_domains == 1 and DEBUG_CELL2:\n        print(f\"[COLLATE] ⚠️  WARNING: All {len(domains)} samples have domain_label={domains[0]}\")\n        print(f\"[COLLATE]    ASBN cannot learn with identical domain labels!\")\n        print(f\"[COLLATE]    Forcing 50/50 split...\")\n        half = len(domains) // 2\n        for j in range(half):\n            domains[j] = 0\n        for j in range(half, len(domains)):\n            domains[j] = 1\n        domain_labels = torch.tensor(domains, dtype=torch.long)\n        print(f\"[COLLATE]    ✓ Fixed: domain_0={domain_labels.eq(0).sum().item()}, domain_1={domain_labels.eq(1).sum().item()}\")\n\n    if _DEBUG_DISCOVERY:\n        batch_size = labels.size(0)\n        total_label_positions = labels.numel()\n        valid_labels = (labels != -100).sum().item()\n        padding_labels = total_label_positions - valid_labels\n\n        if valid_labels == 0:\n            print(f\"[COLLATE] ❌ CRITICAL WARNING: ALL labels are -100! Decoder won't train!\")\n            print(f\"[COLLATE]   batch_size={batch_size}, total_positions={total_label_positions}\")\n            print(f\"[COLLATE]   This means target texts are empty or all padding!\")\n        elif valid_labels < batch_size * 2:\n            print(f\"[COLLATE] ⚠️  WARNING: Very few valid labels!\")\n            print(f\"[COLLATE]   batch_size={batch_size}, valid_labels={valid_labels}, padding={padding_labels}\")\n            print(f\"[COLLATE]   Average valid labels per sample: {valid_labels/batch_size:.1f}\")\n        else:\n            avg_valid = valid_labels / batch_size\n            print(f\"[COLLATE] ✓ Labels OK: {valid_labels}/{total_label_positions} valid ({avg_valid:.1f} per sample)\")\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels,\n        \"token_word_map\": twmaps,\n        \"src_texts\": srcs,\n        \"tokens\": toks,\n        \"domain_labels\": domain_labels,\n    }\n\ndef validation_collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n    valid = [b for b in batch if isinstance(b, dict) and \"input_ids\" in b and isinstance(b[\"input_ids\"], torch.Tensor)]\n\n    default_domain = _TRAIN_DOMAIN\n\n    if not valid:\n        pad = _infer_pad_id_from_sample({}, default_pad_id=1)\n        return {\n            \"input_ids\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"attention_mask\": torch.zeros(1, _MAX_LENGTH, dtype=torch.long),\n            \"labels\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"token_word_map\": [{}],\n            \"src_texts\": [\"\"],\n            \"tokens\": [[]],\n            \"domain_labels\": torch.tensor([default_domain], dtype=torch.long),\n        }\n\n    pad_id = _infer_pad_id_from_sample(valid[0], default_pad_id=1)\n\n    raw_inputs = []\n    raw_masks = []\n    raw_labs = []\n    twmaps = []\n    srcs = []\n    toks = []\n    domains = []\n\n    for i, s in enumerate(valid):\n        try:\n            in_ids = s[\"input_ids\"]\n            att = s.get(\"attention_mask\", None)\n            lab = s[\"labels\"]\n            domain = s.get(\"domain_label\", default_domain)\n\n            if att is None:\n                att = (in_ids != pad_id).long()\n            else:\n                try:\n                    att = att.view(-1).long()\n                except Exception:\n                    att = (in_ids != pad_id).long()\n\n            try:\n                in_ids = in_ids.view(-1)\n            except Exception:\n                in_ids = in_ids.flatten()\n\n            try:\n                lab = lab.view(-1)\n            except Exception:\n                lab = lab.flatten()\n\n            lab_no_mask = lab.clone()\n            lab_no_mask[lab_no_mask == -100] = pad_id\n\n            raw_inputs.append(in_ids)\n            raw_masks.append(att)\n            raw_labs.append(lab_no_mask)\n            twmaps.append(s.get(\"token_word_map\", {}))\n            srcs.append(s.get(\"src_text\", \"\"))\n            toks.append(s.get(\"tokens\", []))\n            domains.append(domain)\n        except Exception as e:\n            cell2_dbg(\"val_collate_item_exc\", f\"Val collate item exception idx={i}: {type(e).__name__}\")\n            continue\n\n    if not raw_inputs:\n        pad = _infer_pad_id_from_sample({}, default_pad_id=1)\n        return {\n            \"input_ids\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"attention_mask\": torch.zeros(1, _MAX_LENGTH, dtype=torch.long),\n            \"labels\": torch.full((1, _MAX_LENGTH), pad, dtype=torch.long),\n            \"token_word_map\": [{}],\n            \"src_texts\": [\"\"],\n            \"tokens\": [[]],\n            \"domain_labels\": torch.tensor([default_domain], dtype=torch.long),\n        }\n\n    max_input_len = max(t.size(0) for t in raw_inputs)\n    max_label_len = max(t.size(0) for t in raw_labs)\n    actual_max_len = max(max_input_len, max_label_len)\n    actual_max_len = min(actual_max_len, _MAX_LENGTH)\n\n    inputs = []\n    masks = []\n    labs = []\n\n    for in_ids, att, lab in zip(raw_inputs, raw_masks, raw_labs):\n        in_ids_padded = _pad_or_truncate_array(in_ids, actual_max_len, pad_id)\n        att_padded = _pad_or_truncate_array(att, actual_max_len, 0)\n        lab_padded = _pad_or_truncate_array(lab, actual_max_len, pad_id)\n\n        inputs.append(in_ids_padded)\n        masks.append(att_padded)\n        labs.append(lab_padded)\n\n    input_ids = torch.stack(inputs, dim=0)\n    attention_mask = torch.stack(masks, dim=0)\n    labels = torch.stack(labs, dim=0)\n\n    try:\n        domain_labels = torch.tensor(domains, dtype=torch.long)\n    except Exception:\n        domain_labels = torch.full((len(inputs),), default_domain, dtype=torch.long)\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels,\n        \"token_word_map\": twmaps,\n        \"src_texts\": srcs,\n        \"tokens\": toks,\n        \"domain_labels\": domain_labels,\n    }\n\ndef create_optimized_dataloader(\n    dataset: Dataset,\n    batch_size: Optional[int] = None,\n    shuffle: bool = True,\n    split: str = \"train\",\n) -> DataLoader:\n    if batch_size is None:\n        try:\n            batch_size = int(BATCH_SIZE)\n        except NameError:\n            batch_size = 8\n\n    batch_size = int(batch_size)\n    original_batch_size = batch_size\n    adjusted = False\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 0 and batch_size % _NUM_GPUS != 0:\n        new_batch_size = (batch_size // _NUM_GPUS) * _NUM_GPUS\n        if new_batch_size == 0:\n            if DEBUG_CELL2:\n                print(f\"[CELL2] WARNING: batch_size {batch_size} < num_gpus {_NUM_GPUS}. Keeping original.\")\n        else:\n            batch_size = new_batch_size\n            adjusted = batch_size != original_batch_size\n\n    if adjusted:\n        print(f\"[CELL2] Adjusted batch size {original_batch_size} to {batch_size} (DP-divisible, GPUs={_NUM_GPUS})\")\n\n    num_workers = 0\n    pin_memory = False\n\n    loader_kwargs: Dict[str, Any] = {\n        \"dataset\": dataset,\n        \"batch_size\": batch_size,\n        \"shuffle\": shuffle,\n        \"num_workers\": num_workers,\n        \"pin_memory\": pin_memory,\n        \"collate_fn\": safe_collate,\n        \"drop_last\": False,\n    }\n\n    try:\n        dataloader = DataLoader(**loader_kwargs)\n    except Exception as e:\n        print(f\"[CELL2] DataLoader init failed: {type(e).__name__}\")\n        print(\"[CELL2] This should not happen with num_workers=0\")\n        raise\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 0:\n        per_gpu = batch_size // _NUM_GPUS if _NUM_GPUS > 0 else batch_size\n        print(f\"[CELL2] DataLoader created ({split}): total_batch={batch_size}, per_gpu={per_gpu}, workers={num_workers}, pin_memory={pin_memory}\")\n    else:\n        print(f\"[CELL2] DataLoader created ({split}): batch_size={batch_size}, workers={num_workers}, pin_memory={pin_memory}\")\n\n    return dataloader\n\nMemoryEfficientDataset = DualPathDataset\n\nprint(\"=\" * 80)\nprint(\"Cell 2: Loading dataset and creating train/validation split...\")\nprint(\"=\" * 80)\n\ntry:\n    if \"tokenizer\" not in globals():\n        print(\"[CELL2] ERROR: tokenizer not found in global scope!\")\n        print(\"[CELL2] Make sure Cell 1 (tokenizer initialization) has been executed before Cell 2.\")\n        print(\"[CELL2] Attempting to load tokenizer...\")\n        try:\n            from transformers import MBart50TokenizerFast\n            print(\"[CELL2] Loading mBART-50 tokenizer...\")\n            tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n            tokenizer.src_lang = _SOURCE_LANG\n            tokenizer.tgt_lang = _TARGET_LANG\n            print(f\"[CELL2] ✓ Tokenizer loaded: vocab_size={len(tokenizer)}\")\n        except Exception as tok_e:\n            print(f\"[CELL2] CRITICAL ERROR: Cannot load tokenizer: {tok_e}\")\n            raise RuntimeError(\"Cell 1 must be executed before Cell 2!\")\n    \n    all_data = load_and_preprocess_optimized(num_samples=_NUM_SAMPLES, split=\"all\")\n    print(f\"\\n[CELL2] Total samples loaded: {len(all_data)}\")\n    \n    if len(all_data) < 10:\n        print(\"[CELL2] WARNING: Very few samples! Using all for training, skipping validation split.\")\n        train_data = all_data\n        val_data = all_data[:min(5, len(all_data))]\n    else:\n        train_data, val_data = train_test_split(\n            all_data,\n            test_size=_VALIDATION_SPLIT,\n            random_state=42,\n            shuffle=True\n        )\n    \n    print(f\"[CELL2] ✅ Train samples: {len(train_data)}\")\n    print(f\"[CELL2] ✅ Validation samples: {len(val_data)}\")\n    \n    try:\n        train_dataset = DualPathDataset(\n            train_data,\n            tokenizer,\n            max_length=_MAX_LENGTH,\n            split=\"train\"\n        )\n        \n        val_dataset = DualPathDataset(\n            val_data,\n            tokenizer,\n            max_length=_MAX_LENGTH,\n            split=\"validation\"\n        )\n        \n        try:\n            train_batch_size = int(BATCH_SIZE)\n        except NameError:\n            train_batch_size = 8\n        \n        val_batch_size = train_batch_size * 2\n        \n        train_loader = create_optimized_dataloader(\n            train_dataset,\n            batch_size=train_batch_size,\n            shuffle=True,\n            split=\"train\"\n        )\n        \n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=val_batch_size,\n            shuffle=False,\n            num_workers=0,\n            pin_memory=False,\n            collate_fn=validation_collate_fn,\n            drop_last=False,\n        )\n        \n        print(f\"\\n[CELL2] ✅ Train batches: {len(train_loader)}\")\n        print(f\"[CELL2] ✅ Validation batches: {len(val_loader)}\")\n        print(f\"[CELL2] ✅ Validation collator: NO -100 masking (labels preserved for BLEU)\")\n        \n        print(\"\\n\" + \"=\" * 80)\n        print(\"Cell 2: Dual-path data loading ready - WORD + SUBWORD TOKENIZATION\")\n        print(\"=\" * 80)\n        print(\"CONFIGURATION:\")\n        print(f\"  ✅ mBART-50 tokenizer (handles both word/subword)\")\n        print(f\"  ✅ Language codes: {_SOURCE_LANG} → {_TARGET_LANG}\")\n        print(f\"  ✅ Token IDs: bn={_MBART_BN_TOKEN_ID}, en={_MBART_EN_TOKEN_ID}\")\n        print(f\"  ✅ Vocab size: {_MBART_VOCAB_SIZE:,}\")\n        print(f\"  ✅ Train/Val split: {100*(1-_VALIDATION_SPLIT):.0f}% / {100*_VALIDATION_SPLIT:.0f}%\")\n        print(f\"  ✅ Train samples: {len(train_data):,} ({len(train_loader)} batches)\")\n        print(f\"  ✅ Validation samples: {len(val_data):,} ({len(val_loader)} batches)\")\n        print(f\"  ✅ DataLoader: num_workers=0, pin_memory=False (DEADLOCK-SAFE)\")\n        print(f\"  ✅ Domain labels: idx % 2 (alternating 0/1)\")\n        print(f\"  ✅ Train collate: Masks padding with -100\")\n        print(f\"  ✅ Val collate: Preserves labels (NO -100) for BLEU\")\n        print(f\"  ✅ Ready for dual-path training with proper validation\")\n        print(\"=\" * 80 + \"\\n\")\n        \n    except Exception as e:\n        print(f\"[CELL2] ERROR creating datasets/loaders: {type(e).__name__}: {str(e)}\")\n        traceback.print_exc()\n        raise\n\nexcept Exception as e:\n    print(f\"[CELL2] CRITICAL ERROR in data loading: {type(e).__name__}: {str(e)}\")\n    traceback.print_exc()\n    raise\n","metadata":{"id":"5MkHgCN7H4J1","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:39:56.610788Z","iopub.execute_input":"2026-02-18T08:39:56.610979Z","iopub.status.idle":"2026-02-18T08:40:03.869674Z","shell.execute_reply.started":"2026-02-18T08:39:56.610963Z","shell.execute_reply":"2026-02-18T08:40:03.869030Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCell 2: Loading dataset and creating train/validation split...\n================================================================================\n[CELL2] ERROR: tokenizer not found in global scope!\n[CELL2] Make sure Cell 1 (tokenizer initialization) has been executed before Cell 2.\n[CELL2] Attempting to load tokenizer...\n[CELL2] Loading mBART-50 tokenizer...\n[CELL2] ✓ Tokenizer loaded: vocab_size=250054\n[CELL2] Loading up to 100000 samples from local CSV: /kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\n[CELL2] Reading CSV file...\n[CELL2] Detected src=English, tgt=Bengali: Swapping columns for bn→en task.\n[CELL2] Swap successful: src=Bengali, tgt=English\n[CELL2] Processing 100000 rows from CSV...\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 100000/100000 [00:02<00:00, 41959.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"[CELL2] Loaded 100000 pairs from CSV, skipped 0 rows\n\n[CELL2] Total samples loaded: 100000\n[CELL2] ✅ Train samples: 90000\n[CELL2] ✅ Validation samples: 10000\n[CELL2] Dataset vocab size: 250054\n[CELL2] Dataset initialized: 90000 valid pairs, 0 invalid, split=train\n[CELL2] Dataset vocab size: 250054\n[CELL2] Dataset initialized: 10000 valid pairs, 0 invalid, split=validation\n[CELL2] DataLoader created (train): batch_size=4, workers=0, pin_memory=False\n\n[CELL2] ✅ Train batches: 22500\n[CELL2] ✅ Validation batches: 1250\n[CELL2] ✅ Validation collator: NO -100 masking (labels preserved for BLEU)\n\n================================================================================\nCell 2: Dual-path data loading ready - WORD + SUBWORD TOKENIZATION\n================================================================================\nCONFIGURATION:\n  ✅ mBART-50 tokenizer (handles both word/subword)\n  ✅ Language codes: bn_IN → en_XX\n  ✅ Token IDs: bn=250028, en=250004\n  ✅ Vocab size: 250,054\n  ✅ Train/Val split: 90% / 10%\n  ✅ Train samples: 90,000 (22500 batches)\n  ✅ Validation samples: 10,000 (1250 batches)\n  ✅ DataLoader: num_workers=0, pin_memory=False (DEADLOCK-SAFE)\n  ✅ Domain labels: idx % 2 (alternating 0/1)\n  ✅ Train collate: Masks padding with -100\n  ✅ Val collate: Preserves labels (NO -100) for BLEU\n  ✅ Ready for dual-path training with proper validation\n================================================================================\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ==============================================================================\n# CELL 3: DSCD MODULE - WORD-LEVEL HOMOGRAPH DISAMBIGUATION\n# ==============================================================================\n\nimport threading\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport gc\nfrom collections import deque\nimport unicodedata\nfrom typing import Optional, Dict, List, Any, Set, Tuple\n\nPRINT_INTERVAL = 200\n\ntry:\n    from scipy.cluster.hierarchy import linkage, fcluster\n    from scipy.spatial.distance import pdist\n    HAS_CLUSTERING = True\nexcept Exception:\n    HAS_CLUSTERING = False\n    print(\"[CELL3] WARNING: scipy not available\")\n\ntry:\n    from sklearn.cluster import KMeans\n    HAS_KMEANS = True\nexcept Exception:\n    HAS_KMEANS = False\n    print(\"[CELL3] WARNING: sklearn not available\")\n\ntry:\n    DSCD_MAX_PROTOS = int(DSCD_MAX_PROTOS)\n    DSCD_BUFFER_SIZE = int(DSCD_BUFFER_SIZE)\n    DSCD_N_MIN = int(DSCD_N_MIN)\n    DSCD_DISPERSION_THRESHOLD = float(DSCD_DISPERSION_THRESHOLD)\n    DSCD_NEWSENSE_LAMBDA = float(DSCD_NEWSENSE_LAMBDA)\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\n    DSCD_ENABLE_TRAINING_CLUSTERING = bool(DSCD_ENABLE_TRAINING_CLUSTERING)\n    DSCD_MIN_LETTERS = int(DSCD_MIN_LETTERS)\n    DSCD_MIN_LETTER_FRACTION = float(DSCD_MIN_LETTER_FRACTION)\nexcept (NameError, ValueError, TypeError):\n    DSCD_MAX_PROTOS = 3\n    DSCD_BUFFER_SIZE = 20\n    DSCD_N_MIN = 3\n    DSCD_DISPERSION_THRESHOLD = 0.25\n    DSCD_NEWSENSE_LAMBDA = 1.2\n    VERBOSE_LOGGING = False\n    DSCD_ENABLE_TRAINING_CLUSTERING = True\n    DSCD_MIN_LETTERS = 3\n    DSCD_MIN_LETTER_FRACTION = 0.6\n    print(\"[CELL3] WARNING: Using default DSCD config\")\n\ntry:\n    DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept NameError:\n    DEBUG_DISCOVERY = False\n\ntry:\n    MAX_TOKENS_PER_DISCOVERY = int(globals().get('MAX_TOKENS_PER_DISCOVERY', 150))\nexcept Exception:\n    MAX_TOKENS_PER_DISCOVERY = 150\n\ntry:\n    HOMOGRAPH_REFERENCE_LIST_BN = set(HOMOGRAPH_REFERENCE_LIST_BN)\n    print(f\"[CELL3] Loaded reference list for evaluation: {len(HOMOGRAPH_REFERENCE_LIST_BN)} words\")\nexcept (NameError, TypeError):\n    HOMOGRAPH_REFERENCE_LIST_BN = {\n        'কল', 'কাল', 'পাতা', 'ফল', 'বার', 'হার', 'তারা',\n        'পড়া', 'দেখা', 'চলা', 'ধরা', 'অর্থ', 'শব্দ', 'মুখ',\n        'তোলা', 'বাঁচা', 'মারা', 'উত্তর', 'পাত্র', 'বেলা', 'গান',\n        'নাম', 'বল', 'চাল', 'কলা', 'ধারা', 'পত্র', 'রাগ', 'রস',\n        'তীর', 'জমা', 'মান', 'দাবি', 'আসন', 'সাড়া', 'বসা', 'পদ',\n        'অংশ', 'মোড়', 'ঘর', 'মন', 'ব্যাংক'\n    }\n    print(\"[CELL3] Using default reference list\")\n\nDSCD_MAX_CLUSTERING_POINTS = 500\n\nBENGALI_PUNCT_SET = set(['।', '॥'])\nCOMMON_PUNCT_SET = set(['.', ',', '!', '?', ';', ':', '-', '—', '\"', \"'\", '(', ')', '[', ']', '{', '}'])\nPUNCT_SET = BENGALI_PUNCT_SET | COMMON_PUNCT_SET\n\ndef is_punctuation_only(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n    clean = token.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n    if not clean:\n        return False\n    if clean in BENGALI_PUNCT_SET:\n        return True\n    if clean in COMMON_PUNCT_SET:\n        return True\n    if len(clean) == 1 and not clean.isalnum():\n        return True\n    return all(c in PUNCT_SET for c in clean)\n\ndef clean_token_for_dscd(token: str) -> str:\n    if not token or not isinstance(token, str):\n        return \"\"\n    cleaned = token.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n    for punct in list(PUNCT_SET):\n        cleaned = cleaned.replace(punct, \"\")\n    return cleaned.lower()\n\ndef normalize_token_key(token: str) -> str:\n    return clean_token_for_dscd(token)\n\ndef is_word_token(token: str, min_letters: int = 2, min_letter_fraction: float = 0.6) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n    token = token.strip()\n    if not token:\n        return False\n    letters = 0\n    total = 0\n    for ch in token:\n        cat = unicodedata.category(ch)\n        if cat.startswith('L'):\n            letters += 1\n        if not ch.isspace():\n            total += 1\n    if total == 0:\n        return False\n    if letters < min_letters:\n        return False\n    if (letters / total) < min_letter_fraction:\n        return False\n    return True\n\ndef is_indic_subword_fragment(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n\n    token = token.strip()\n    if not token:\n        return False\n\n    only_vowel_marks = True\n    only_combining_marks = True\n    has_virama = False\n    letter_count = 0\n\n    for ch in token:\n        cat = unicodedata.category(ch)\n\n        if cat.startswith('L'):\n            letter_count += 1\n            only_vowel_marks = False\n            only_combining_marks = False\n\n        if cat not in ('Mn', 'Mc'):\n            only_combining_marks = False\n\n        virama_chars = [\n            '\\u094D',\n            '\\u09CD',\n            '\\u0A4D',\n            '\\u0ACD',\n            '\\u0B4D',\n            '\\u0BCD',\n            '\\u0C4D',\n            '\\u0CCD',\n            '\\u0D4D'\n        ]\n        if ch in virama_chars:\n            has_virama = True\n\n    if only_vowel_marks or only_combining_marks:\n        return True\n\n    if has_virama and len(token) <= 2:\n        return True\n\n    if letter_count == 0:\n        return True\n\n    vowel_modifier_ranges = [\n        ('\\u093E', '\\u094C'),\n        ('\\u09BE', '\\u09CC'),\n        ('\\u0ABE', '\\u0ACC'),\n        ('\\u0BBE', '\\u0BCC'),\n        ('\\u0C3E', '\\u0C4C'),\n        ('\\u0CBE', '\\u0CCC'),\n    ]\n\n    modifier_count = 0\n    for ch in token:\n        for start, end in vowel_modifier_ranges:\n            if start <= ch <= end:\n                modifier_count += 1\n                break\n\n    if modifier_count > 0 and modifier_count == len(token):\n        return True\n\n    if len(token) <= 2 and modifier_count > 0:\n        return True\n\n    return False\n\nclass MemoryEfficientPrototypeStore:\n    def __init__(self, embed_dim, max_protos: Optional[int] = None):\n        if max_protos is None:\n            max_protos = DSCD_MAX_PROTOS\n        self.embed_dim = embed_dim\n        self.max_protos = int(max_protos)\n        self.centroids: List[torch.Tensor] = []\n        self.counts: List[int] = []\n        self.creation_time: List[float] = []\n        self.distances: List[float] = []\n        self.mu = 0.0\n        self.tau = 1e-6\n        self.alpha = 0.1\n        self.labels: Optional[torch.Tensor] = None\n\n    def add_prototype(self, vector: torch.Tensor, current_time: Optional[float] = None, count: int = 1) -> None:\n        if current_time is None:\n            current_time = time.time()\n        v = vector.detach().cpu().clone()\n        if len(self.centroids) < self.max_protos:\n            self.centroids.append(v)\n            self.counts.append(int(count))\n            self.creation_time.append(float(current_time))\n        else:\n            min_idx = int(np.argmin(self.counts)) if len(self.counts) > 0 else 0\n            self.centroids[min_idx] = v\n            self.counts[min_idx] = int(count)\n            self.creation_time[min_idx] = float(current_time)\n\n    def update_prototype(self, idx: int, vector: torch.Tensor, eta: float = 0.05, assignment_distance: Optional[float] = None) -> None:\n        if idx < 0 or idx >= len(self.centroids):\n            self.add_prototype(vector, time.time(), count=1)\n            return\n        old_centroid = self.centroids[idx]\n        new_vector = vector.detach().cpu()\n        self.centroids[idx] = (1.0 - eta) * old_centroid + eta * new_vector\n        self.counts[idx] = int(self.counts[idx]) + 1\n        if assignment_distance is not None:\n            self.update_rolling_stats(float(assignment_distance))\n\n    def update_rolling_stats(self, d: float) -> None:\n        if not self.distances:\n            self.mu = float(d)\n            self.tau = max(1e-6, float(d) * 0.1)\n            self.distances = [float(d)]\n            return\n        prev_mu = self.mu\n        self.mu = (1 - self.alpha) * self.mu + self.alpha * float(d)\n        self.tau = (1 - self.alpha) * self.tau + self.alpha * abs(float(d) - prev_mu)\n        self.distances.append(float(d))\n        if len(self.distances) > 50:\n            self.distances.pop(0)\n\n    def get_adaptive_threshold(self, lam: float = 1.0) -> float:\n        return float(self.mu + lam * max(self.tau, 1e-4))\n\n    def size(self) -> int:\n        return len(self.centroids)\n\n    def ensure_consistency(self) -> None:\n        n = len(self.centroids)\n        if len(self.counts) != n:\n            self.counts = self.counts[:n] if len(self.counts) > n else self.counts + [1] * (n - len(self.counts))\n        if len(self.creation_time) != n:\n            self.creation_time = self.creation_time[:n] if len(self.creation_time) > n else self.creation_time + [time.time()] * (n - len(self.creation_time))\n\nclass MemoryEfficientDSCDOnline(nn.Module):\n    def __init__(\n        self,\n        embed_dim: int,\n        tokenizer=None,\n        buffer_size: Optional[int] = None,\n        max_protos: Optional[int] = None,\n        n_min: Optional[int] = None,\n        dispersion_threshold: Optional[float] = None,\n        language: str = \"bn\",\n        enable_training_clustering: Optional[bool] = None,\n        max_clustering_points: Optional[int] = None,\n        max_candidates_per_step: int = 2,\n        dscd_min_letters: int = 3,\n        dscd_min_letter_fraction: float = 0.6,\n    ):\n        super().__init__()\n        if buffer_size is None:\n            buffer_size = DSCD_BUFFER_SIZE\n        if max_protos is None:\n            max_protos = DSCD_MAX_PROTOS\n        if n_min is None:\n            n_min = DSCD_N_MIN\n        if dispersion_threshold is None:\n            dispersion_threshold = DSCD_DISPERSION_THRESHOLD\n        if max_clustering_points is None:\n            max_clustering_points = DSCD_MAX_CLUSTERING_POINTS\n        if enable_training_clustering is None:\n            enable_training_clustering = DSCD_ENABLE_TRAINING_CLUSTERING\n\n        self.embed_dim = int(embed_dim)\n        self.buffer_size = int(buffer_size)\n        self.max_protos = int(max_protos)\n        self.n_min = int(n_min)\n        self.dispersion_threshold = float(dispersion_threshold)\n        self.language = language\n        self.tokenizer = tokenizer\n        self.dscd_min_letters = int(dscd_min_letters)\n        self.dscd_min_letter_fraction = float(dscd_min_letter_fraction)\n\n        try:\n            if tokenizer is not None and 'get_tokenizer_special_tokens' in globals():\n                self.special_tokens = get_tokenizer_special_tokens(tokenizer)\n            else:\n                self.special_tokens = set(getattr(tokenizer, 'all_special_tokens', [])) if tokenizer is not None else set()\n        except Exception:\n            self.special_tokens = set()\n\n        self.dscd_allowed_tokens: Set[str] = set()\n        self.dscd_ignored_tokens: Set[str] = set()\n        self.dscd_cache_max_size = 10000\n\n        self.prototype_stores: Dict[str, MemoryEfficientPrototypeStore] = {}\n        self.buffers: Dict[str, deque] = {}\n        self.discovered_log: List[Dict[str, Any]] = []\n        self.discovered_homographs: Set[str] = set()\n\n        self.last_periodic_check = 0\n        self.cleanup_counter = 0\n\n        self.dispersion_cache: Dict[str, float] = {}\n        self.dispersion_last_updated: Dict[str, float] = {}\n        self.dispersion_lock = threading.Lock()\n        self.clustering_lock = threading.Lock()\n        self.buffer_lock = threading.Lock()\n\n        from collections import deque as thread_deque\n        self.active_threads = thread_deque(maxlen=100)\n        self.thread_lock = threading.Lock()\n\n        self.last_cluster_time: Dict[str, float] = {}\n        self.cluster_cooldown_seconds = 5.0\n\n        self.enable_training_clustering = bool(enable_training_clustering)\n        self.discovery_count = 0\n        self.discovery_times: List[float] = []\n        self.clustered_tokens: Set[str] = set()\n\n        self.cluster_stats: Dict[str, Dict[str, Any]] = {}\n\n        self.span_head = nn.Sequential(\n            nn.Linear(self.embed_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(64, 1),\n        )\n\n        self.sigma_net = nn.Sequential(\n            nn.Linear(self.embed_dim, 16),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(16, 1),\n        )\n\n        self.gate_w = nn.Parameter(torch.tensor(1.0))\n        self.gate_b = nn.Parameter(torch.tensor(0.4))\n        self.gamma = nn.Parameter(torch.tensor(0.3))\n\n        self.max_clustering_points = int(max_clustering_points)\n        self.max_candidates_per_step = int(max_candidates_per_step)\n\n        try:\n            self.homograph_reference_list = set(str(w).lower() for w in HOMOGRAPH_REFERENCE_LIST_BN)\n        except Exception:\n            self.homograph_reference_list = set()\n\n    def state_dict(self, destination=None, prefix='', keep_vars=False):\n        state = super().state_dict(destination, prefix, keep_vars)\n\n        plain_stores = {}\n        for token, store in self.prototype_stores.items():\n            plain_stores[token] = {\n                'centroids': [c.cpu() for c in store.centroids] if hasattr(store, 'centroids') else [],\n                'counts': list(store.counts) if hasattr(store, 'counts') else [],\n                'creation_time': list(store.creation_time) if hasattr(store, 'creation_time') else [],\n                'mu': float(store.mu) if hasattr(store, 'mu') else 0.0,\n                'tau': float(store.tau) if hasattr(store, 'tau') else 0.0,\n                'size': int(store.size()) if hasattr(store, 'size') else 0,\n            }\n\n        state[prefix + 'prototype_stores_data'] = plain_stores\n        state[prefix + 'discovered_homographs'] = list(self.discovered_homographs)\n        return state\n\n    def load_state_dict(self, state_dict, strict=True):\n        prefix = ''\n        plain_stores = state_dict.pop('prototype_stores_data', {})\n        discovered = state_dict.pop('discovered_homographs', [])\n\n        super().load_state_dict(state_dict, strict=strict)\n\n        if not plain_stores:\n            print(\"[DSCD] WARNING: Empty prototype_stores in checkpoint\")\n            return\n\n        self.prototype_stores = {}\n        self.discovered_homographs = set(discovered)\n\n        for token, store_dict in plain_stores.items():\n            store = MemoryEfficientPrototypeStore(embed_dim=self.embed_dim, max_protos=self.max_protos)\n\n            centroids_data = store_dict.get('centroids', [])\n            store.centroids = []\n            for c in centroids_data:\n                if isinstance(c, torch.Tensor):\n                    store.centroids.append(c)\n                else:\n                    store.centroids.append(torch.tensor(c))\n\n            store.counts = store_dict.get('counts', [])\n            store.creation_time = store_dict.get('creation_time', [])\n            store.mu = store_dict.get('mu', 0.0)\n            store.tau = store_dict.get('tau', 0.0)\n\n            store.ensure_consistency()\n            self.prototype_stores[token] = store\n\n        print(f\"[DSCD] Loaded {len(self.prototype_stores)} tokens, {sum(s.size() for s in self.prototype_stores.values())} prototypes\")\n\n    @staticmethod\n    def clean_token(token):\n        return clean_token_for_dscd(str(token))\n\n    def is_valid_multi_sense(self, token):\n        if token not in self.prototype_stores:\n            return False\n        store = self.prototype_stores[token]\n        total_occurrences = sum(store.counts) if hasattr(store, 'counts') else 0\n        min_per_proto = min(store.counts) if hasattr(store, 'counts') and store.counts else 0\n        return store.size() >= 2 and total_occurrences >= 10 and min_per_proto >= 2\n\n    def is_multi_sense_store(self, store: MemoryEfficientPrototypeStore) -> bool:\n        k = store.size()\n        if k < 2:\n            return False\n\n        counts = store.counts if store.counts else [1] * k\n        strong = sum(1 for c in counts if c >= max(2, self.n_min // 2))\n        if strong < 2:\n            return False\n\n        try:\n            cents = []\n            for c in store.centroids:\n                if isinstance(c, torch.Tensor):\n                    cents.append(c.cpu().numpy())\n                else:\n                    cents.append(np.asarray(c, dtype=np.float32))\n\n            if len(cents) < 2:\n                return False\n\n            cents = np.stack(cents, axis=0)\n            dists = np.linalg.norm(cents[:, None, :] - cents[None, :, :], axis=-1)\n            tri = dists[np.triu_indices(len(cents), k=1)]\n\n            if tri.size == 0:\n                return False\n\n            min_dist = float(tri.min())\n            base = max(store.tau, 1e-3)\n            return min_dist > base * DSCD_NEWSENSE_LAMBDA\n        except Exception:\n            return True\n\n    def get_sense_prototypes_for_conditioning(self) -> Dict[str, Dict[str, Any]]:\n        prototypes_data: Dict[str, Dict[str, Any]] = {}\n\n        try:\n            with self.clustering_lock:\n                for token, store in self.prototype_stores.items():\n                    if store.size() == 0:\n                        continue\n\n                    try:\n                        clean_tok = clean_token_for_dscd(token)\n                        if not clean_tok:\n                            continue\n\n                        centroids_list = []\n                        for centroid in store.centroids:\n                            if isinstance(centroid, torch.Tensor):\n                                centroids_list.append(centroid.clone().cpu())\n                            else:\n                                centroids_list.append(torch.from_numpy(np.asarray(centroid, dtype=np.float32)))\n\n                        if not centroids_list:\n                            continue\n\n                        counts_list = list(store.counts) if hasattr(store, 'counts') and store.counts else [1] * len(centroids_list)\n                        \n                        prototypes_data[clean_tok] = {\n                            'token': token,\n                            'num_senses': len(centroids_list),\n                            'prototypes': centroids_list,\n                            'counts': counts_list,\n                            'mu': float(store.mu) if hasattr(store, 'mu') else 0.0,\n                            'tau': float(store.tau) if hasattr(store, 'tau') else 0.0,\n                            'is_multi_sense': self.is_multi_sense_store(store),\n                        }\n                    except Exception:\n                        continue\n\n        except Exception:\n            pass\n\n        return prototypes_data\n\n    def discover_homographs_for_tokens(\n        self,\n        token_names: List[str],\n        min_cluster_samples: int,\n        dispersion_threshold: float,\n        global_step: int,\n    ) -> int:\n        discovered_in_run: List[str] = []\n\n        for idx, token in enumerate(token_names):\n            try:\n                if is_punctuation_only(token):\n                    continue\n\n                success = self.cluster_buffer_to_prototypes_hierarchical(token)\n\n                if success:\n                    store = self.prototype_stores.get(token)\n                    if store and store.size() >= 2:\n                        clean_token = normalize_token_key(token)\n                        self.discovered_homographs.add(clean_token)\n                        discovered_in_run.append(clean_token)\n            except Exception:\n                continue\n\n        try:\n            self.discovered_log.append({\n                'timestamp': time.time(),\n                'global_step': global_step,\n                'candidates_processed': len(token_names),\n                'discovered_count': len(discovered_in_run),\n                'homographs': discovered_in_run,\n                'total_discovered': len(self.discovered_homographs),\n            })\n        except Exception:\n            pass\n\n        return len(discovered_in_run)\n\n    def discover_homographs(\n        self,\n        min_cluster_samples: Optional[int] = None,\n        dispersion_threshold: Optional[float] = None,\n        max_candidates: int = 500,\n    ) -> int:\n        if min_cluster_samples is None:\n            min_cluster_samples = self.n_min\n        if dispersion_threshold is None:\n            dispersion_threshold = self.dispersion_threshold\n\n        candidates: List[Tuple[str, float, int, float]] = []\n\n        with self.buffer_lock:\n            for token, buffer in self.buffers.items():\n                if is_punctuation_only(token):\n                    continue\n\n                buffer_size = len(buffer)\n                if buffer_size >= max(min_cluster_samples + 2, 10):\n                    clean_token = clean_token_for_dscd(token)\n\n                    if clean_token in HOMOGRAPH_REFERENCE_LIST_BN:\n                        dispersion = max(self.get_dispersion(token), dispersion_threshold * 1.15)\n                        if DEBUG_DISCOVERY:\n                            print(f\"[DSCD-PRIORITY] Boosting reference homograph '{token}' dispersion to {dispersion:.3f}\")\n                    else:\n                        dispersion = self.get_dispersion(token)\n\n                    if dispersion >= dispersion_threshold:\n                        rank_score = dispersion * buffer_size\n                        candidates.append((token, rank_score, buffer_size, dispersion))\n\n        if not candidates:\n            return 0\n\n        candidates.sort(key=lambda x: x[1], reverse=True)\n        candidates = candidates[:max_candidates]\n\n        discovered: List[str] = []\n\n        for token, score, buf_size, disp in candidates:\n            try:\n                with self.clustering_lock:\n                    success = self.cluster_buffer_to_prototypes_hierarchical(token)\n\n                    if success:\n                        store = self.prototype_stores.get(token)\n                        if store and store.size() >= 2:\n                            clean_token = normalize_token_key(token)\n                            self.discovered_homographs.add(clean_token)\n                            discovered.append(clean_token)\n            except Exception:\n                continue\n\n        try:\n            self.discovered_log.append({\n                'timestamp': time.time(),\n                'candidates': len(candidates),\n                'discovered': len(discovered),\n                'homographs': discovered[:20],\n            })\n        except Exception:\n            pass\n\n        return len(discovered)\n\n    def get_dispersion(self, token_type: str) -> float:\n        with self.dispersion_lock:\n            if token_type in self.dispersion_cache:\n                try:\n                    last_update = self.dispersion_last_updated.get(token_type, 0.0)\n                    if time.time() - last_update < 3600:\n                        return self.dispersion_cache[token_type]\n                except Exception:\n                    pass\n\n        with self.buffer_lock:\n            if token_type not in self.buffers:\n                return 0.0\n\n            buf_len = len(self.buffers[token_type])\n            if buf_len < 2:\n                return 0.05 if buf_len == 1 else 0.0\n\n            try:\n                embeddings: List[np.ndarray] = []\n                for emb in self.buffers[token_type]:\n                    try:\n                        if isinstance(emb, torch.Tensor):\n                            embeddings.append(emb.cpu().numpy())\n                        else:\n                            embeddings.append(np.asarray(emb, dtype=np.float32))\n                    except Exception:\n                        continue\n\n                if len(embeddings) < 2:\n                    return 0.05 if len(embeddings) == 1 else 0.0\n\n                embeddings_np = np.stack(embeddings, axis=0)\n                centroid = embeddings_np.mean(axis=0)\n                distances = np.linalg.norm(embeddings_np - centroid[None, :], axis=1)\n                dispersion = float(distances.std())\n\n                with self.dispersion_lock:\n                    self.dispersion_cache[token_type] = dispersion\n                    self.dispersion_last_updated[token_type] = time.time()\n\n                return dispersion\n            except Exception:\n                return 0.0\n\n    def validate_prototypes(\n        self,\n        homograph_list: Optional[List[str]] = None,\n        cluster_missing: bool = True,\n    ) -> Dict[str, Any]:\n        if homograph_list is None:\n            try:\n                homograph_list = list(HOMOGRAPH_REFERENCE_LIST_BN)\n            except Exception:\n                homograph_list = ['কল', 'পাতা', 'ফল', 'মান']\n\n        print(\"=\" * 80)\n        print(\"DSCD-VALIDATION: Prototype Quality Check\")\n        print(\"=\" * 80)\n\n        validation_results: Dict[str, Any] = {\n            'total_tokens': len(self.prototype_stores),\n            'total_prototypes': 0,\n            'multi_sense_tokens': 0,\n            'homographs_found': 0,\n            'homographs_missing': [],\n            'avg_prototypes_per_token': 0.0,\n            'avg_samples_per_prototype': 0.0,\n            'quality_score': 0.0,\n        }\n\n        total_samples = 0\n        for token, store in self.prototype_stores.items():\n            num_protos = len(store.centroids)\n            validation_results['total_prototypes'] += num_protos\n\n            if self.is_multi_sense_store(store):\n                validation_results['multi_sense_tokens'] += 1\n\n            try:\n                total_samples += sum(store.counts)\n            except Exception:\n                pass\n\n        if validation_results['total_tokens'] > 0:\n            validation_results['avg_prototypes_per_token'] = validation_results['total_prototypes'] / validation_results['total_tokens']\n\n        if validation_results['total_prototypes'] > 0:\n            validation_results['avg_samples_per_prototype'] = total_samples / validation_results['total_prototypes']\n\n        print(\"VALIDATION: Reference Homograph Coverage\")\n        print(\"-\" * 80)\n\n        missing_tokens_to_cluster: List[str] = []\n\n        for homograph in homograph_list:\n            clean_h = clean_token_for_dscd(homograph)\n            found = False\n            found_key = None\n            found_protos = 0\n\n            for key in self.prototype_stores.keys():\n                clean_key = clean_token_for_dscd(str(key))\n\n                if clean_key == clean_h:\n                    found = True\n                    found_key = key\n                    found_protos = len(self.prototype_stores[key].centroids)\n                    break\n\n            if found and self.is_multi_sense_store(self.prototype_stores[found_key]):\n                validation_results['homographs_found'] += 1\n                try:\n                    counts = self.prototype_stores[found_key].counts\n                    print(f\"  ✓ {homograph} - {found_protos} prototypes (counts={counts})\")\n                except Exception:\n                    print(f\"  ✓ {homograph} - {found_protos} prototypes\")\n            elif found and found_protos == 1:\n                validation_results['homographs_missing'].append(homograph)\n                print(f\"  ⚠ {homograph} - Only 1 prototype\")\n                if cluster_missing:\n                    missing_tokens_to_cluster.append(found_key)\n            else:\n                validation_results['homographs_missing'].append(homograph)\n                print(f\"  ✗ {homograph} - NOT FOUND\")\n                if cluster_missing:\n                    for buf_key in self.buffers.keys():\n                        clean_buf_key = clean_token_for_dscd(str(buf_key))\n                        if clean_buf_key == clean_h:\n                            if len(self.buffers[buf_key]) >= max(self.n_min + 2, 10):\n                                print(f\"      - Found in buffer, will cluster\")\n                                missing_tokens_to_cluster.append(buf_key)\n                            break\n\n        if cluster_missing and missing_tokens_to_cluster:\n            print(f\"\\nVALIDATION: Clustering {len(missing_tokens_to_cluster)} missing tokens...\")\n            for token in missing_tokens_to_cluster:\n                try:\n                    with self.clustering_lock:\n                        self.cluster_buffer_to_prototypes_hierarchical(token)\n                        if token in self.prototype_stores and self.is_multi_sense_store(self.prototype_stores[token]):\n                            print(f\"  ✓ Successfully clustered: {token}\")\n                except Exception as e:\n                    print(f\"  ✗ Failed to cluster {token}: {e}\")\n\n        homograph_coverage = validation_results['homographs_found'] / len(homograph_list) if homograph_list else 0.0\n        multi_sense_ratio = validation_results['multi_sense_tokens'] / validation_results['total_tokens'] if validation_results['total_tokens'] > 0 else 0.0\n        validation_results['quality_score'] = (homograph_coverage * 0.6) + (multi_sense_ratio * 0.4)\n\n        print(\"-\" * 80)\n        print(\"VALIDATION: Summary\")\n        print(f\"  - Total tokens: {validation_results['total_tokens']}\")\n        print(f\"  - Total prototypes: {validation_results['total_prototypes']}\")\n        print(f\"  - Multi-sense tokens: {validation_results['multi_sense_tokens']}\")\n        print(f\"  - Reference found: {validation_results['homographs_found']}/{len(homograph_list)}\")\n        print(f\"  - Quality Score: {validation_results['quality_score']*100:.2f}%\")\n        print(\"=\" * 80)\n\n        return validation_results\n\n    def should_track_token(self, token_text: str) -> bool:\n        if not token_text or not isinstance(token_text, str):\n            return False\n\n        if len(self.dscd_allowed_tokens) > self.dscd_cache_max_size:\n            self.dscd_allowed_tokens.clear()\n        if len(self.dscd_ignored_tokens) > self.dscd_cache_max_size:\n            self.dscd_ignored_tokens.clear()\n\n        if token_text in self.dscd_allowed_tokens:\n            return True\n        if token_text in self.dscd_ignored_tokens:\n            return False\n\n        if not getattr(self, 'training', False):\n            if token_text in self.prototype_stores:\n                self.dscd_allowed_tokens.add(token_text)\n                return True\n            clean = clean_token_for_dscd(token_text)\n            if clean and clean in self.prototype_stores:\n                self.dscd_allowed_tokens.add(token_text)\n                return True\n\n        if token_text in self.special_tokens:\n            self.dscd_ignored_tokens.add(token_text)\n            return False\n\n        if is_punctuation_only(token_text):\n            self.dscd_ignored_tokens.add(token_text)\n            return False\n\n        clean = clean_token_for_dscd(token_text)\n        if not clean:\n            self.dscd_ignored_tokens.add(token_text)\n            return False\n\n        if len(clean) < self.dscd_min_letters:\n            self.dscd_ignored_tokens.add(token_text)\n            return False\n\n        if not any(c.isalpha() for c in clean):\n            self.dscd_ignored_tokens.add(token_text)\n            return False\n\n        if clean.isdigit():\n            self.dscd_ignored_tokens.add(token_text)\n            return False\n\n        try:\n            indic_range_1 = any('\\u0900' <= c <= '\\u0DFF' for c in clean)\n            indic_range_2 = any('\\u0980' <= c <= '\\u09FF' for c in clean)\n            has_indic = indic_range_1 or indic_range_2\n\n            if has_indic:\n                if len(clean) >= self.dscd_min_letters:\n                    self.dscd_allowed_tokens.add(token_text)\n                    return True\n                else:\n                    self.dscd_ignored_tokens.add(token_text)\n                    return False\n        except Exception:\n            pass\n\n        if is_word_token(\n            clean,\n            min_letters=self.dscd_min_letters,\n            min_letter_fraction=self.dscd_min_letter_fraction,\n        ):\n            self.dscd_allowed_tokens.add(token_text)\n            return True\n\n        self.dscd_ignored_tokens.add(token_text)\n        return False\n\n    def canonical_token_key(\n        self,\n        raw_token: str,\n        token_word_map: Optional[Dict[int, Optional[str]]],\n        idx: int,\n    ) -> Optional[str]:\n        canonical: Optional[str] = None\n\n        try:\n            if token_word_map and isinstance(token_word_map, dict) and idx in token_word_map and token_word_map[idx]:\n                word = str(token_word_map[idx]).strip()\n                canonical = clean_token_for_dscd(word)\n                if canonical and len(canonical) >= self.dscd_min_letters:\n                    indic_range_1 = any('\\u0900' <= c <= '\\u0DFF' for c in canonical)\n                    indic_range_2 = any('\\u0980' <= c <= '\\u09FF' for c in canonical)\n                    has_indic = indic_range_1 or indic_range_2\n                    if has_indic:\n                        return canonical\n        except Exception:\n            pass\n\n        canonical = clean_token_for_dscd(raw_token)\n\n        if not canonical or len(canonical) < self.dscd_min_letters:\n            return None\n\n        indic_range_1 = any('\\u0900' <= c <= '\\u0DFF' for c in canonical)\n        indic_range_2 = any('\\u0980' <= c <= '\\u09FF' for c in canonical)\n        has_indic = indic_range_1 or indic_range_2\n        if not has_indic:\n            return None\n\n        if is_indic_subword_fragment(canonical):\n            return None\n\n        return canonical\n\n    def cleanup_threads(self) -> None:\n        try:\n            with self.thread_lock:\n                alive = [th for th in list(self.active_threads) if th.is_alive()]\n                self.active_threads.clear()\n                self.active_threads.extend(alive)\n        except Exception:\n            pass\n\n    def cleanup_memory(self) -> None:\n        try:\n            for token_type, buffer in list(self.buffers.items()):\n                if len(buffer) > int(self.buffer_size * 1.5):\n                    while len(buffer) > self.buffer_size:\n                        buffer.popleft()\n\n            try:\n                now = time.time()\n                expired = [k for k, v in self.dispersion_last_updated.items() if now - v > 3600]\n                for k in expired:\n                    self.dispersion_cache.pop(k, None)\n                    self.dispersion_last_updated.pop(k, None)\n            except Exception:\n                pass\n\n            if gc.isenabled():\n                gc.collect()\n        except Exception:\n            pass\n\n    def forward(\n        self,\n        token_embeddings=None,\n        token_types=None,\n        train_mode: bool = True,\n        token_word_map=None,\n        h_all=None,\n        input_ids=None,\n        attention_mask=None,\n    ):\n        if token_embeddings is None and h_all is not None:\n            token_embeddings = h_all\n\n        if token_embeddings is None:\n            raise ValueError(\"MemoryEfficientDSCDOnline.forward requires token_embeddings or h_all\")\n\n        if input_ids is not None and token_types is None:\n            batch_size, seq_len = input_ids.shape\n            token_types = []\n            for b in range(batch_size):\n                if self.tokenizer is not None:\n                    try:\n                        token_types.append(\n                            self.tokenizer.convert_ids_to_tokens(input_ids[b].tolist())\n                        )\n                    except Exception:\n                        token_types.append([f\"tok{i}\" for i in range(seq_len)])\n                else:\n                    token_types.append([f\"tok{i}\" for i in range(seq_len)])\n\n        self.cleanup_counter += 1\n        if self.cleanup_counter % 50 == 0:\n            self.cleanup_counter = 0\n            self.cleanup_memory()\n            self.cleanup_threads()\n\n        device = token_embeddings.device\n        batch_size = int(token_embeddings.size(0))\n        seq_len = int(token_embeddings.size(1))\n\n        all_outputs: Dict[str, List[Any]] = {\n            'proto_assignments': [],\n            'proto_probs': [],\n            'uncertainties': [],\n            'span_preds': [],\n            'gates': [],\n            'h_augmented': [],\n        }\n\n        for b in range(batch_size):\n            word_map = token_word_map[b] if token_word_map and len(token_word_map) > b else None\n\n            batch_outputs = self.process_sequence(\n                token_embeddings[b],\n                token_types[b] if token_types and len(token_types) > b else [f\"tok{i}\" for i in range(seq_len)],\n                device,\n                word_map=word_map,\n                train_mode=train_mode,\n            )\n\n            for k in all_outputs:\n                all_outputs[k].append(batch_outputs[k])\n\n        try:\n            h_aug_list: List[torch.Tensor] = []\n            max_seq_len = seq_len\n\n            for b in range(batch_size):\n                h_batch_list = all_outputs['h_augmented'][b]\n\n                if len(h_batch_list) > 0 and isinstance(h_batch_list[0], torch.Tensor):\n                    h_batch = torch.stack(h_batch_list, dim=0)\n\n                    if h_batch.size(0) < max_seq_len:\n                        pad = max_seq_len - h_batch.size(0)\n                        h_batch = F.pad(h_batch, (0, 0, 0, pad), value=0)\n                    elif h_batch.size(0) > max_seq_len:\n                        h_batch = h_batch[:max_seq_len]\n                else:\n                    h_batch = token_embeddings[b].clone()\n\n                h_aug_list.append(h_batch)\n\n            all_outputs['h_augmented'] = torch.stack(h_aug_list, dim=0)\n        except Exception:\n            all_outputs['h_augmented'] = token_embeddings\n\n        try:\n            proto_assign_tensor = []\n            for row in all_outputs['proto_assignments']:\n                try:\n                    stacked = torch.stack(\n                        [x if isinstance(x, torch.Tensor) else torch.tensor(x) for x in row],\n                        dim=0,\n                    )\n                    proto_assign_tensor.append(stacked)\n                except Exception:\n                    proto_assign_tensor.append(\n                        torch.tensor(\n                            [int(x) if not isinstance(x, torch.Tensor) else int(x.item()) for x in row],\n                            dtype=torch.long,\n                        )\n                    )\n            all_outputs['proto_assignments'] = proto_assign_tensor\n        except Exception:\n            pass\n\n        return all_outputs\n\n    def process_sequence(\n        self,\n        token_embeddings: torch.Tensor,\n        token_types: List[Any],\n        device: torch.device,\n        word_map: Optional[Dict[int, Optional[str]]] = None,\n        train_mode: bool = True,\n    ) -> Dict[str, List[Any]]:\n        seq_len = int(token_embeddings.size(0))\n\n        outputs: Dict[str, List[Any]] = {\n            'proto_assignments': [],\n            'proto_probs': [],\n            'uncertainties': [],\n            'span_preds': [],\n            'gates': [],\n            'h_augmented': [],\n        }\n\n        for j in range(seq_len):\n            raw_tok = token_types[j] if j < len(token_types) else f\"tok{j}\"\n            if not isinstance(raw_tok, str):\n                raw_tok = str(raw_tok) if raw_tok is not None else f\"tok{j}\"\n\n            token_key = self.canonical_token_key(raw_tok, word_map, j)\n            h_j = token_embeddings[j]\n\n            if not token_key:\n                outputs['proto_assignments'].append(torch.tensor(-1))\n                outputs['proto_probs'].append([])\n                outputs['uncertainties'].append(0.0)\n                outputs['span_preds'].append(0.0)\n                outputs['gates'].append(0.0)\n                outputs['h_augmented'].append(h_j)\n                continue\n\n            if not self.should_track_token(token_key):\n                outputs['proto_assignments'].append(torch.tensor(-1))\n                outputs['proto_probs'].append([])\n                outputs['uncertainties'].append(0.0)\n                outputs['span_preds'].append(0.0)\n                outputs['gates'].append(0.0)\n                outputs['h_augmented'].append(h_j)\n                continue\n\n            with self.buffer_lock:\n                if token_key not in self.buffers:\n                    self.buffers[token_key] = deque(maxlen=self.buffer_size)\n                    self.prototype_stores[token_key] = MemoryEfficientPrototypeStore(\n                        self.embed_dim, self.max_protos\n                    )\n\n                try:\n                    self.buffers[token_key].append(h_j.detach().clone().cpu())\n                except Exception:\n                    try:\n                        self.buffers[token_key].append(h_j.cpu())\n                    except Exception:\n                        pass\n\n            buffer_len = len(self.buffers[token_key])\n\n            try:\n                if self.enable_training_clustering and buffer_len >= max(self.n_min + 2, 10):\n                    now = time.time()\n                    last_t = self.last_cluster_time.get(token_key, 0.0)\n\n                    if now - last_t >= self.cluster_cooldown_seconds:\n                        self.last_cluster_time[token_key] = now\n\n                        def bg_cluster(tok: str = token_key) -> None:\n                            try:\n                                with self.clustering_lock:\n                                    self.cluster_buffer_to_prototypes_hierarchical(tok)\n                            except Exception:\n                                pass\n\n                        th = threading.Thread(target=bg_cluster, daemon=True)\n                        th.start()\n                        with self.thread_lock:\n                            self.active_threads.append(th)\n            except Exception:\n                pass\n\n            store = self.prototype_stores[token_key]\n\n            centroids_snapshot: Optional[List[torch.Tensor]] = None\n            with self.clustering_lock:\n                try:\n                    if hasattr(store, 'centroids') and len(store.centroids) > 0:\n                        centroids_snapshot = []\n                        for c in store.centroids:\n                            try:\n                                if isinstance(c, torch.Tensor):\n                                    centroids_snapshot.append(c.clone().cpu())\n                                else:\n                                    centroids_snapshot.append(\n                                        torch.from_numpy(\n                                            np.asarray(c, dtype=np.float32)\n                                        ).cpu()\n                                    )\n                            except Exception:\n                                continue\n                        if not centroids_snapshot:\n                            centroids_snapshot = None\n                except Exception:\n                    centroids_snapshot = None\n\n            assignment = -1\n            prob_list: List[float] = []\n            uncertainty = 0.0\n            span_pred = 0.0\n            gate_val = 0.0\n            h_aug = h_j\n\n            if centroids_snapshot and len(centroids_snapshot) >= 1:\n                try:\n                    try:\n                        h_cpu = h_j.detach().cpu().numpy()\n                    except Exception:\n                        h_cpu = h_j.cpu().numpy()\n\n                    try:\n                        cents_np = np.stack([c.numpy() for c in centroids_snapshot], axis=0)\n                    except Exception:\n                        cents_np = np.stack([np.asarray(c, dtype=np.float32) for c in centroids_snapshot], axis=0)\n\n                    dists_np = np.linalg.norm(cents_np - h_cpu[None, :], axis=1)\n\n                    if dists_np.size > 0:\n                        min_dist = float(dists_np.min())\n                        min_idx = int(np.argmin(dists_np))\n\n                        if len(centroids_snapshot) >= 2:\n                            mean_dist = float(np.mean(dists_np))\n                            std_dist = float(np.std(dists_np))\n                            span_pred = float(np.clip(std_dist / (mean_dist + 1e-6), 0.0, 1.0))\n                        else:\n                            span_pred = float(np.clip((min_dist - store.mu) / (1e-3), 0.0, 1.0))\n\n                        base_threshold = max(store.tau, 1e-3) if store.size() > 0 else 0.3\n                        uncertainty_dist = float(np.clip(min_dist / (base_threshold * 2), 0.0, 1.0))\n\n                        if len(centroids_snapshot) >= 2:\n                            precisions = 1.0 / (dists_np**2 + 1e-6)\n                            gate_weights = precisions / (np.sum(precisions) + 1e-6)\n                            gate_val = float(np.max(gate_weights))\n                        else:\n                            gate_val = float(np.clip(1.0 - (min_dist - store.mu) / (1e-3), 0.0, 1.0))\n\n                        if store.size() < self.max_protos and min_dist > store.get_adaptive_threshold(DSCD_NEWSENSE_LAMBDA):\n                            store.add_prototype(h_j, time.time(), count=1)\n                            assignment = store.size() - 1\n                            centroids_snapshot.append(h_j.cpu())\n                            cents_np = np.vstack([cents_np, h_cpu[None, :]])\n                        else:\n                            assignment = min_idx\n                            try:\n                                store.update_rolling_stats(min_dist)\n                            except Exception:\n                                pass\n\n                        try:\n                            dist_tensor = torch.from_numpy(dists_np).to(device)\n                            probs_tensor = F.softmax(-dist_tensor, dim=0)\n                            prob_list = probs_tensor.tolist()\n\n                            entropy = -torch.sum(probs_tensor * torch.log(probs_tensor + 1e-10))\n                            max_entropy = np.log(len(dists_np))\n                            uncertainty_entropy = float(entropy.item() / max_entropy) if max_entropy > 0 else 0.0\n                        except Exception:\n                            exps = np.exp(-dists_np - np.max(-dists_np)) if dists_np.size > 0 else np.array([])\n                            if exps.size > 0:\n                                probs = exps / (exps.sum() + 1e-12)\n                                prob_list = probs.tolist()\n                                entropy_val = -np.sum(probs * np.log(probs + 1e-10))\n                                max_entropy = np.log(len(dists_np))\n                                uncertainty_entropy = float(entropy_val / max_entropy) if max_entropy > 0 else 0.0\n                            else:\n                                prob_list = []\n                                uncertainty_entropy = 0.0\n\n                        if len(centroids_snapshot) >= 2:\n                            uncertainty = 0.4 * uncertainty_dist + 0.6 * uncertainty_entropy\n                        else:\n                            uncertainty = uncertainty_dist\n\n                        if gate_val > 0.3 and 0 <= assignment < len(centroids_snapshot):\n                            try:\n                                centroid_t = centroids_snapshot[assignment]\n\n                                if device != torch.device('cpu'):\n                                    try:\n                                        centroid_t = centroid_t.to(device)\n                                    except Exception:\n                                        pass\n\n                                blend_weight = 0.3 if gate_val > 0.7 else 0.15\n                                h_aug = h_j + blend_weight * (centroid_t - h_j)\n                            except Exception:\n                                h_aug = h_j\n\n                except Exception as e:\n                    if DEBUG_DISCOVERY:\n                        print(f\"[DSCD] Assignment error for {token_key}: {str(e)[:200]}\")\n\n            outputs['proto_assignments'].append(torch.tensor(assignment))\n            outputs['proto_probs'].append(prob_list)\n            outputs['uncertainties'].append(uncertainty)\n            outputs['span_preds'].append(span_pred)\n            outputs['gates'].append(gate_val)\n            outputs['h_augmented'].append(h_aug)\n\n        try:\n            if not train_mode and len(self.prototype_stores) > 0 and VERBOSE_LOGGING:\n                if self.last_periodic_check % PRINT_INTERVAL == 0:\n                    self.print_clusters_summary()\n                self.last_periodic_check += 1\n        except Exception:\n            pass\n\n        return outputs\n\n    def print_clusters_summary(self) -> None:\n        try:\n            items: List[Tuple[str, int, int, float, float, int]] = []\n\n            for token, store in self.prototype_stores.items():\n                if is_punctuation_only(token):\n                    continue\n\n                try:\n                    proto_sample_count = sum(getattr(store, 'counts', []) or [])\n                except Exception:\n                    proto_sample_count = 0\n\n                buffer_len = len(self.buffers.get(token, [])) if token in self.buffers else 0\n                total_count = proto_sample_count if proto_sample_count > 0 else buffer_len\n                protos = store.size()\n                mu = getattr(store, 'mu', 0.0)\n                tau = getattr(store, 'tau', 0.0)\n\n                items.append((token, total_count, protos, mu, tau, buffer_len))\n\n            items.sort(key=lambda x: x[1], reverse=True)\n            top_5 = items[:5]\n\n            if VERBOSE_LOGGING:\n                print(\"\\n[CLUSTER] Top 5 clusters:\")\n                print(\"-\" * 90)\n                print(f\"{'Rank':<6} {'Token':<14} {'Count':<12} {'Protos':<10} {'Mu':<14} {'Tau':<12}\")\n                print(\"-\" * 90)\n                for rank, (tok, cnt, prot, mu, tau, buf_len) in enumerate(top_5, 1):\n                    tok_str = str(tok)[:14]\n                    print(f\"{rank:<6} {tok_str:<14} {cnt:<12} {prot:<10} {mu:<14.6f} {tau:<12.6f}\")\n                print(\"-\" * 90)\n        except Exception as e:\n            try:\n                if VERBOSE_LOGGING:\n                    print(f\"[CLUSTER] Error printing summary: {str(e)[:200]}\")\n            except Exception:\n                pass\n\n    def cluster_buffer_to_prototypes_hierarchical(self, token_type: str) -> bool:\n        try:\n            if is_punctuation_only(token_type):\n                if DEBUG_DISCOVERY:\n                    print(f\"[DSCD-CLUSTER] Skipping punctuation token: {token_type}\")\n                return False\n\n            if not self.should_track_token(token_type):\n                if DEBUG_DISCOVERY:\n                    print(f\"[DSCD-CLUSTER] Skipping non-word token: {token_type}\")\n                return False\n\n            with self.buffer_lock:\n                if token_type not in self.buffers:\n                    return False\n\n                buf_snapshot = [e.clone() if isinstance(e, torch.Tensor) else e for e in self.buffers[token_type]]\n\n            if len(buf_snapshot) < max(self.n_min + 2, 10):\n                if DEBUG_DISCOVERY:\n                    print(f\"[DSCD-CLUSTER] {token_type}: buffer={len(buf_snapshot)} < min={max(self.n_min + 2, 10)}\")\n                return False\n\n            emb_list: List[np.ndarray] = []\n            for e in buf_snapshot:\n                try:\n                    if isinstance(e, torch.Tensor):\n                        try:\n                            emb_list.append(e.numpy())\n                        except Exception:\n                            emb_list.append(e.cpu().numpy())\n                    else:\n                        emb_list.append(np.asarray(e, dtype=np.float32))\n                except Exception:\n                    continue\n\n            if len(emb_list) == 0:\n                return False\n\n            if len(emb_list) > self.max_clustering_points:\n                idxs = np.random.choice(len(emb_list), size=self.max_clustering_points, replace=False)\n                embeddings = np.stack([emb_list[i] for i in idxs], axis=0)\n            else:\n                embeddings = np.stack(emb_list, axis=0)\n\n            if embeddings.shape[0] < 2:\n                return False\n\n            norms = np.linalg.norm(embeddings, axis=1)\n            if np.all(norms < 1e-6):\n                if DEBUG_DISCOVERY:\n                    print(f\"[DSCD-CLUSTER] {token_type}: all zero vectors, skipping\")\n                return False\n\n            if DEBUG_DISCOVERY:\n                print(\n                    f\"[DSCD-CLUSTER] {token_type}: buf={len(buf_snapshot)} \"\n                    f\"sampled={embeddings.shape[0]} mean_norm={norms.mean():.4f}\"\n                )\n\n            store = self.prototype_stores[token_type]\n\n            protos_added = 0\n            new_centroids: List[torch.Tensor] = []\n            new_counts: List[int] = []\n            new_times: List[float] = []\n\n            if HAS_CLUSTERING:\n                try:\n                    condensed = pdist(embeddings, metric='euclidean')\n                    if condensed.size > 0:\n                        Z = linkage(condensed, method='average')\n                        max_dist = condensed.max() if condensed.size > 0 else 1.0\n                        relative_threshold = self.dispersion_threshold\n                        absolute_threshold = relative_threshold * max_dist\n                        clusters = fcluster(Z, t=absolute_threshold, criterion='distance') - 1\n\n                        if clusters.size > 0:\n                            max_c = int(clusters.max())\n                            for c_id in range(max_c + 1):\n                                mask = (clusters == c_id)\n                                cluster_size = int(mask.sum())\n\n                                if cluster_size >= self.n_min:\n                                    centroid = embeddings[mask].mean(axis=0).astype(np.float32)\n                                    centroid_tensor = torch.from_numpy(centroid)\n                                    new_centroids.append(centroid_tensor)\n                                    new_counts.append(cluster_size)\n                                    new_times.append(time.time())\n                                    protos_added += 1\n\n                            if len(new_centroids) > self.max_protos:\n                                sorted_indices = np.argsort(new_counts)[-1:-self.max_protos-1:-1]\n                                new_centroids = [new_centroids[i] for i in sorted_indices]\n                                new_counts = [new_counts[i] for i in sorted_indices]\n                                new_times = [new_times[i] for i in sorted_indices]\n                                protos_added = len(new_centroids)\n\n                            store.centroids = new_centroids\n                            store.counts = new_counts\n                            store.creation_time = new_times\n                            store.labels = torch.tensor(clusters)\n\n                            if DEBUG_DISCOVERY and protos_added > 0:\n                                print(f\"[DSCD-CLUSTER] Hierarchical created {protos_added} prototypes for {token_type}\")\n                except Exception as e:\n                    if DEBUG_DISCOVERY:\n                        print(f\"[DSCD-CLUSTER] Hierarchical failed for {token_type}: {type(e).__name__} {str(e)[:200]}\")\n\n            if protos_added == 0 and HAS_KMEANS:\n                try:\n                    min_k = 1\n                    max_k = min(self.max_protos, len(embeddings) // self.n_min)\n                    if max_k < min_k:\n                        max_k = min_k\n\n                    if len(embeddings) >= 20:\n                        k_guess = min(max_k, max(2, int(np.sqrt(len(embeddings)) / 2)))\n                    elif len(embeddings) >= 10:\n                        k_guess = min(max_k, 2)\n                    else:\n                        k_guess = 1\n\n                    k_guess = max(min_k, min(k_guess, len(embeddings)))\n\n                    if k_guess >= 1 and len(embeddings) >= k_guess:\n                        km = KMeans(n_clusters=k_guess, random_state=0, n_init=10).fit(embeddings)\n                        labels = km.labels_\n\n                        new_centroids = []\n                        new_counts = []\n                        new_times = []\n\n                        for c in range(k_guess):\n                            mask = (labels == c)\n                            cluster_size = int(mask.sum())\n\n                            if cluster_size >= self.n_min:\n                                centroid = embeddings[mask].mean(axis=0).astype(np.float32)\n                                centroid_tensor = torch.from_numpy(centroid)\n                                new_centroids.append(centroid_tensor)\n                                new_counts.append(cluster_size)\n                                new_times.append(time.time())\n                                protos_added += 1\n\n                        store.centroids = new_centroids\n                        store.counts = new_counts\n                        store.creation_time = new_times\n                        store.labels = torch.tensor(labels)\n\n                        if DEBUG_DISCOVERY and protos_added > 0:\n                            print(f\"[DSCD-CLUSTER] KMeans created {protos_added} prototypes for {token_type}\")\n                except Exception as e:\n                    if DEBUG_DISCOVERY:\n                        print(f\"[DSCD-CLUSTER] KMeans failed for {token_type}: {type(e).__name__} {str(e)[:200]}\")\n\n            if DEBUG_DISCOVERY:\n                print(\n                    f\"[DSCD-CLUSTER] {token_type}: final={store.size()} protos, \"\n                    f\"counts={store.counts}\"\n                )\n\n            try:\n                if store.centroids:\n                    counts = store.counts if store.counts else [1] * len(store.centroids)\n                    total_count = sum(counts)\n                    mean_count = float(total_count) / max(1, len(counts))\n\n                    self.cluster_stats[str(token_type)] = {\n                        'num_prototypes': len(store.centroids),\n                        'counts': [int(c) for c in counts],\n                        'total_samples': int(total_count),\n                        'mean_count': float(mean_count),\n                        'mu': float(store.mu),\n                        'tau': float(store.tau),\n                    }\n            except Exception:\n                pass\n\n            return store.size() > 0\n\n        except Exception as e:\n            if DEBUG_DISCOVERY:\n                print(f\"[DSCD-ERROR] Clustering error for {token_type}: {type(e).__name__} {str(e)[:200]}\")\n            return False\n\n    def get_explanations(self, threshold_span: float = 0.3) -> List[Dict[str, Any]]:\n        expl: List[Dict[str, Any]] = []\n        for token_type, store in self.prototype_stores.items():\n            if store.size() >= 2:\n                expl.append({'token': str(token_type), 'protos': store.size()})\n        return expl\n\n    def periodic_discovery_check(self, global_step: int, frequency: int) -> int:\n        try:\n            candidates: List[Tuple[str, float, int]] = []\n            buffer_snapshot = {}\n            already_clustered = set()\n\n            with self.buffer_lock:\n                for token in list(self.buffers.keys()):\n                    buffer_snapshot[token] = len(self.buffers.get(token, []))\n\n            with self.clustering_lock:\n                for token in self.prototype_stores.keys():\n                    if self.prototype_stores[token].size() >= 2:\n                        already_clustered.add(token)\n\n            for token, buffer_size in buffer_snapshot.items():\n                if is_punctuation_only(token):\n                    continue\n\n                if token in already_clustered:\n                    continue\n\n                if buffer_size >= max(self.n_min + 2, 10):\n                    try:\n                        dispersion = self.get_dispersion(token)\n                        if dispersion >= self.dispersion_threshold:\n                            rank_score = dispersion * buffer_size\n                            candidates.append((token, rank_score, buffer_size))\n                    except:\n                        continue\n\n            if not candidates:\n                return 0\n\n            candidates.sort(key=lambda x: x[1], reverse=True)\n            candidates_to_process = candidates[:min(MAX_TOKENS_PER_DISCOVERY, len(candidates))]\n\n            return self.discover_homographs_for_tokens(\n                [c[0] for c in candidates_to_process],\n                self.n_min,\n                self.dispersion_threshold,\n                global_step,\n            )\n\n        except Exception as e:\n            if DEBUG_DISCOVERY:\n                print(f\"[DSCD] periodic_discovery_check failed: {e}\")\n            return 0\n\n    def get_prototype_summary(self) -> Dict[str, Any]:\n        try:\n            total_tokens = len(self.prototype_stores)\n            total_prototypes = sum(s.size() for s in self.prototype_stores.values())\n            homographs = sum(1 for s in self.prototype_stores.values() if s.size() >= 2)\n\n            return {\n                'total_tokens': total_tokens,\n                'total_prototypes': total_prototypes,\n                'num_homographs': homographs,\n                'discovered_homographs': len(self.discovered_homographs),\n            }\n        except Exception:\n            return {\n                'total_tokens': 0,\n                'total_prototypes': 0,\n                'num_homographs': 0,\n                'discovered_homographs': 0,\n            }\n\n    def get_discovered_homographs(self) -> Set[str]:\n        return self.discovered_homographs.copy()\n\nprint(\"=\" * 80)\nprint(\"Cell 3: DSCD (Word-Level Homograph Disambiguation) - READY\")\nprint(\"=\" * 80)\nprint(\"CONFIGURATION:\")\nprint(f\"  ✅ Model-agnostic (works with any encoder)\")\nprint(f\"  ✅ Operates on token embeddings (hidden states)\")\nprint(f\"  ✅ Cache size: 10000 (aligned with Cell 1)\")\nprint(f\"  ✅ Parameters: max_protos={DSCD_MAX_PROTOS}, n_min={DSCD_N_MIN}\")\nprint(f\"  ✅ Thread-safe clustering (hierarchical + KMeans)\")\nprint(f\"  ✅ Bengali Unicode validation (language-agnostic)\")\nprint(\"=\" * 80)\nprint(\"NEW FEATURE:\")\nprint(f\"  ✅ get_sense_prototypes_for_conditioning() method added\")\nprint(\"=\" * 80)\nprint(\"NO CHANGES NEEDED:\")\nprint(f\"  ✅ No tokenizer-specific code\")\nprint(f\"  ✅ No vocab size dependencies\")\nprint(f\"  ✅ Works with mBART-50, M2M100, XLM-R equally\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"L25pcKUPH4J2","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:03.870878Z","iopub.execute_input":"2026-02-18T08:40:03.871113Z","iopub.status.idle":"2026-02-18T08:40:04.371133Z","shell.execute_reply.started":"2026-02-18T08:40:03.871092Z","shell.execute_reply":"2026-02-18T08:40:04.370388Z"}},"outputs":[{"name":"stdout","text":"[CELL3] Loaded reference list for evaluation: 42 words\n================================================================================\nCell 3: DSCD (Word-Level Homograph Disambiguation) - READY\n================================================================================\nCONFIGURATION:\n  ✅ Model-agnostic (works with any encoder)\n  ✅ Operates on token embeddings (hidden states)\n  ✅ Cache size: 10000 (aligned with Cell 1)\n  ✅ Parameters: max_protos=5, n_min=5\n  ✅ Thread-safe clustering (hierarchical + KMeans)\n  ✅ Bengali Unicode validation (language-agnostic)\n================================================================================\nNEW FEATURE:\n  ✅ get_sense_prototypes_for_conditioning() method added\n================================================================================\nNO CHANGES NEEDED:\n  ✅ No tokenizer-specific code\n  ✅ No vocab size dependencies\n  ✅ Works with mBART-50, M2M100, XLM-R equally\n================================================================================\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ==============================================================================\n# CELL 4: ASBN MODULE - ADVERSARIAL SELECTIVE BATCH NORMALIZATION\n# ==============================================================================\n\nimport traceback\nfrom typing import Any, List, Tuple, Optional, Dict\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ntry:\n    _MAX_LENGTH = int(MAX_LENGTH)\nexcept Exception:\n    _MAX_LENGTH = 48\n\ntry:\n    _ENABLE_ASBN_TRAINING = bool(ENABLE_ASBN_TRAINING)\nexcept Exception:\n    _ENABLE_ASBN_TRAINING = True\n\ntry:\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept Exception:\n    _VERBOSE_LOGGING = False\n\ntry:\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept Exception:\n    _DEBUG_DISCOVERY = False\n\ntry:\n    _DEBUG_TIMING = bool(DEBUG_TIMING)\nexcept Exception:\n    _DEBUG_TIMING = False\n\ntry:\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept Exception:\n    _SOURCE_LANGUAGE = \"bn\"\n\ntry:\n    _GRL_ALPHA_START = float(GRL_ALPHA_START)\n    _GRL_ALPHA_END = float(GRL_ALPHA_END)\n    _GRL_ALPHA_SCHEDULE = str(GRL_ALPHA_SCHEDULE)\n    try:\n        _GRL_ALPHA_STEPS = int(GRL_ALPHA_STEPS)\n    except Exception:\n        _GRL_ALPHA_STEPS = 10000\nexcept Exception:\n    _GRL_ALPHA_START = 0.1\n    _GRL_ALPHA_END = 1.0\n    _GRL_ALPHA_SCHEDULE = \"linear\"\n    _GRL_ALPHA_STEPS = 10000\n\n_has_is_valid_token = False\n_has_get_tokenizer_special_tokens = False\n_has_should_track_token = False\n_is_valid_token_fn = None\n_get_tokenizer_special_tokens_fn = None\n_should_track_token_fn = None\n\ntry:\n    if 'is_valid_token' in dir():\n        _is_valid_token_fn = is_valid_token\n        _has_is_valid_token = True\n    elif 'is_valid_token' in globals():\n        _is_valid_token_fn = globals()['is_valid_token']\n        _has_is_valid_token = True\nexcept Exception:\n    pass\n\ntry:\n    if 'get_tokenizer_special_tokens' in dir():\n        _get_tokenizer_special_tokens_fn = get_tokenizer_special_tokens\n        _has_get_tokenizer_special_tokens = True\n    elif 'get_tokenizer_special_tokens' in globals():\n        _get_tokenizer_special_tokens_fn = globals()['get_tokenizer_special_tokens']\n        _has_get_tokenizer_special_tokens = True\nexcept Exception:\n    pass\n\ntry:\n    if 'should_track_token' in dir():\n        _should_track_token_fn = should_track_token\n        _has_should_track_token = True\n    elif 'should_track_token' in globals():\n        _should_track_token_fn = globals()['should_track_token']\n        _has_should_track_token = True\nexcept Exception:\n    pass\n\n\nclass GradientReversalFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = float(alpha)\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        return -ctx.alpha * grad_output, None\n\n\ndef gradient_reversal(x, alpha: float = 1.0):\n    return GradientReversalFunction.apply(x, alpha)\n\n\nclass LightweightDiscriminator(nn.Module):\n    def __init__(self, input_dim: int):\n        super().__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(64, 2),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.classifier(x)\n\n\nclass DomainDiscriminator(nn.Module):\n    def __init__(self, input_dim: int):\n        super().__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(input_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 2),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.classifier(x)\n\n\nclass MemoryEfficientASBNModule(nn.Module):\n    def __init__(\n        self,\n        embed_dim: int,\n        tokenizer=None,\n        language: str = \"bn\",\n        freq_threshold: float = 0.7,\n        uncertainty_threshold: float = 0.3,\n        gate_threshold: float = 0.5,\n        warmup_steps: int = 50,\n        encoder_grl_scale: float = 1.0,\n    ):\n        super().__init__()\n        self.language = language\n        self.tokenizer = tokenizer\n        self.embed_dim = int(embed_dim)\n\n        self.bn_source = nn.BatchNorm1d(self.embed_dim, track_running_stats=True)\n        self.bn_target = nn.BatchNorm1d(self.embed_dim, track_running_stats=True)\n\n        self.d_domain = DomainDiscriminator(self.embed_dim)\n        self.d_freq = LightweightDiscriminator(self.embed_dim + 2)\n        self.d_ctx = LightweightDiscriminator(self.embed_dim + 2)\n        self.d_xl = LightweightDiscriminator(self.embed_dim)\n\n        self.freq_threshold = float(freq_threshold)\n        self.uncertainty_threshold = float(uncertainty_threshold)\n        self.gate_threshold = float(gate_threshold)\n        self.warmup_steps = int(warmup_steps)\n        self.current_step = 0\n\n        self.lambda_base = {\"freq\": 1.0, \"ctx\": 1.0, \"xl\": 1.0, \"domain\": 1.0}\n        self.lambda_max = 2.0\n        self.encoder_grl_scale = float(encoder_grl_scale)\n\n        self.stats_reset_interval = 100\n        self.stats = {\n            \"domain_loss\": 0.0,\n            \"domain_accuracy\": 0.0,\n            \"source_accuracy\": 0.0,\n            \"target_accuracy\": 0.0,\n            \"asbn_loss\": 0.0,\n            \"num_updates\": 0,\n        }\n\n        try:\n            if tokenizer is not None:\n                if _has_get_tokenizer_special_tokens and _get_tokenizer_special_tokens_fn is not None:\n                    self.special_tokens = _get_tokenizer_special_tokens_fn(tokenizer)\n                else:\n                    self.special_tokens = set(getattr(tokenizer, \"all_special_tokens\", []))\n            else:\n                self.special_tokens = set()\n        except Exception:\n            self.special_tokens = set()\n\n        if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n            print(\"[ASBN-INIT] Initialized MemoryEfficientASBNModule:\")\n            print(f\"  - embed_dim: {self.embed_dim}\")\n            print(f\"  - warmup_steps: {self.warmup_steps}\")\n            print(f\"  - encoder_grl_scale: {self.encoder_grl_scale}\")\n            print(f\"  - GRL_ALPHA: {_GRL_ALPHA_START} → {_GRL_ALPHA_END} over {_GRL_ALPHA_STEPS} steps\")\n            print(f\"  - thresholds: freq={self.freq_threshold}, uncert={self.uncertainty_threshold}, gate={self.gate_threshold}\")\n            print(f\"  - Function availability: should_track={_has_should_track_token}, is_valid={_has_is_valid_token}\")\n\n    def get_grl_alpha(self, global_step: Optional[int] = None) -> float:\n        if global_step is None:\n            global_step = self.current_step\n        step = max(0, int(global_step))\n\n        if _GRL_ALPHA_SCHEDULE == \"linear\":\n            progress = min(1.0, float(step) / float(_GRL_ALPHA_STEPS))\n            alpha = _GRL_ALPHA_START + progress * (_GRL_ALPHA_END - _GRL_ALPHA_START)\n        elif _GRL_ALPHA_SCHEDULE == \"exponential\":\n            progress = min(1.0, float(step) / float(_GRL_ALPHA_STEPS))\n            ratio = _GRL_ALPHA_END / max(1e-8, _GRL_ALPHA_START if _GRL_ALPHA_START > 0 else 1e-3)\n            alpha = _GRL_ALPHA_START * (ratio ** progress)\n        else:\n            alpha = _GRL_ALPHA_END\n\n        return float(alpha)\n\n    def get_asbn_stats(self) -> Dict[str, float]:\n        return self.get_detailed_stats()\n\n    def get_detailed_stats(self) -> Dict[str, float]:\n        if self.stats[\"num_updates\"] > 0:\n            n = float(self.stats[\"num_updates\"])\n            return {\n                \"domain_loss\": self.stats[\"domain_loss\"] / n,\n                \"domain_accuracy\": self.stats[\"domain_accuracy\"] / n,\n                \"source_accuracy\": self.stats[\"source_accuracy\"] / n,\n                \"target_accuracy\": self.stats[\"target_accuracy\"] / n,\n                \"asbn_loss\": self.stats[\"asbn_loss\"] / n,\n                \"num_updates\": self.stats[\"num_updates\"],\n            }\n        return {\n            \"domain_loss\": 0.0,\n            \"domain_accuracy\": 0.0,\n            \"source_accuracy\": 0.0,\n            \"target_accuracy\": 0.0,\n            \"asbn_loss\": 0.0,\n            \"num_updates\": 0,\n        }\n\n    def reset_stats(self) -> None:\n        self.stats = {\n            \"domain_loss\": 0.0,\n            \"domain_accuracy\": 0.0,\n            \"source_accuracy\": 0.0,\n            \"target_accuracy\": 0.0,\n            \"asbn_loss\": 0.0,\n            \"num_updates\": 0,\n        }\n\n    def critic_parameters(self):\n        return (\n            list(self.d_domain.parameters())\n            + list(self.d_freq.parameters())\n            + list(self.d_ctx.parameters())\n            + list(self.d_xl.parameters())\n        )\n\n    def _ensure_discriminators_on_device(self, device: torch.device) -> None:\n        try:\n            for mod in (\n                self.d_domain,\n                self.d_freq,\n                self.d_ctx,\n                self.d_xl,\n                self.bn_source,\n                self.bn_target,\n            ):\n                try:\n                    p = next(mod.parameters())\n                    if p.device != device:\n                        mod.to(device)\n                except StopIteration:\n                    mod.to(device)\n                except Exception:\n                    pass\n        except Exception:\n            if _VERBOSE_LOGGING:\n                try:\n                    print(\"[ASBN] Device migration failed:\", traceback.format_exc().splitlines()[-1])\n                except Exception:\n                    print(\"[ASBN] Device migration failed\")\n\n    def _expand_domain_labels(self, domain_labels: Optional[torch.Tensor], batch_size: int) -> Optional[torch.Tensor]:\n        if domain_labels is None:\n            return None\n\n        if domain_labels.dim() == 0:\n            domain_labels = domain_labels.unsqueeze(0)\n\n        if domain_labels.size(0) == 1 and batch_size > 1:\n            domain_labels = domain_labels.expand(batch_size).contiguous()\n        elif domain_labels.size(0) != batch_size:\n            if _DEBUG_DISCOVERY:\n                print(f\"[ASBN] Domain label size mismatch: {domain_labels.size(0)} vs batch {batch_size}, using first label\")\n            domain_labels = domain_labels[0].unsqueeze(0).expand(batch_size).contiguous()\n\n        return domain_labels\n\n    def _parse_proto_probs_matrix(self, proto_probs: Any, batch_size: int, seq_len: int, device: torch.device) -> torch.Tensor:\n        pmax = torch.full((batch_size, seq_len), 0.5, dtype=torch.float32, device=device)\n\n        try:\n            if proto_probs is None:\n                return pmax\n\n            if isinstance(proto_probs, torch.Tensor):\n                if proto_probs.dim() == 3:\n                    B, T, K = proto_probs.shape\n                    p = proto_probs.detach().to(device)\n                    b_max = min(batch_size, B)\n                    t_max = min(seq_len, T)\n                    pmax[:b_max, :t_max] = p[:b_max, :t_max].max(dim=2)[0]\n                    return pmax\n\n                if proto_probs.dim() == 2:\n                    p = proto_probs.detach().to(device)\n                    if batch_size >= 1:\n                        t_max = min(seq_len, p.size(0))\n                        pmax[0, :t_max] = p[:t_max].max(dim=1)[0]\n                        return pmax\n\n            if isinstance(proto_probs, (list, tuple)):\n                if len(proto_probs) == batch_size:\n                    for b in range(batch_size):\n                        row = proto_probs[b]\n                        if isinstance(row, torch.Tensor) and row.dim() == 2:\n                            t_max = min(seq_len, row.size(0))\n                            pmax[b, :t_max] = row[:t_max].max(dim=1)[0].to(device)\n                        elif isinstance(row, (list, tuple)):\n                            for t in range(min(seq_len, len(row))):\n                                try:\n                                    val = row[t]\n                                    if isinstance(val, torch.Tensor):\n                                        pmax[b, t] = float(val.max().item())\n                                    else:\n                                        arr = np.asarray(val, dtype=np.float32)\n                                        pmax[b, t] = float(np.max(arr))\n                                except Exception:\n                                    pmax[b, t] = 0.5\n                else:\n                    if batch_size == 1:\n                        row = proto_probs\n                        for t in range(min(seq_len, len(row))):\n                            try:\n                                val = row[t]\n                                if isinstance(val, torch.Tensor):\n                                    pmax[0, t] = float(val.max().item())\n                                else:\n                                    pmax[0, t] = float(np.max(np.asarray(val, dtype=np.float32)))\n                            except Exception:\n                                pmax[0, t] = 0.5\n\n        except Exception as e:\n            if _VERBOSE_LOGGING:\n                print(f\"[ASBN] parse_proto_probs exception: {e}\")\n\n        return pmax\n\n    def _parse_scalar_matrix(self, mat: Any, batch_size: int, seq_len: int, device: torch.device,\n                            default: float = 0.0) -> torch.Tensor:\n        out = torch.full((batch_size, seq_len), float(default), dtype=torch.float32, device=device)\n\n        try:\n            if mat is None:\n                return out\n\n            if isinstance(mat, torch.Tensor):\n                if mat.dim() == 3:\n                    B, T, _ = mat.shape\n                    b_max = min(batch_size, B)\n                    t_max = min(seq_len, T)\n                    out[:b_max, :t_max] = mat[:b_max, :t_max, 0].to(device)\n                elif mat.dim() == 2:\n                    if mat.size(0) == batch_size:\n                        t_max = min(seq_len, mat.size(1))\n                        out[:, :t_max] = mat[:, :t_max].to(device)\n                    elif batch_size == 1:\n                        t_max = min(seq_len, mat.size(0))\n                        out[0, :t_max] = mat[:t_max].to(device)\n                elif mat.dim() == 1 and batch_size == 1:\n                    t_max = min(seq_len, mat.size(0))\n                    out[0, :t_max] = mat[:t_max].to(device)\n\n            elif isinstance(mat, (list, tuple)):\n                if len(mat) == batch_size:\n                    for b in range(batch_size):\n                        row = mat[b]\n                        if isinstance(row, torch.Tensor) and row.dim() >= 1:\n                            t_max = min(seq_len, row.size(0))\n                            for t in range(t_max):\n                                out[b, t] = float(row[t].item())\n                        elif isinstance(row, (list, tuple, np.ndarray)):\n                            t_max = min(seq_len, len(row))\n                            for t in range(t_max):\n                                try:\n                                    v = row[t]\n                                    out[b, t] = (float(v.item()) if isinstance(v, torch.Tensor) else float(v))\n                                except Exception:\n                                    out[b, t] = float(default)\n                elif batch_size == 1:\n                    row = mat\n                    t_max = min(seq_len, len(row))\n                    for t in range(t_max):\n                        try:\n                            v = row[t]\n                            out[0, t] = (float(v.item()) if isinstance(v, torch.Tensor) else float(v))\n                        except Exception:\n                            out[0, t] = float(default)\n\n        except Exception:\n            if _VERBOSE_LOGGING:\n                try:\n                    print(\"[ASBN] parse_scalar_matrix exception:\", traceback.format_exc().splitlines()[-1])\n                except Exception:\n                    pass\n\n        return out\n\n    def compute_lambda_scaled_tensor(self, pmax: torch.Tensor, uncertainty: torch.Tensor,\n                                    gate: torch.Tensor, lambda_type: str) -> torch.Tensor:\n        base = float(self.lambda_base.get(lambda_type, 1.0))\n        lam = base * torch.ones_like(pmax)\n        lam = torch.clamp(lam, min=0.1, max=float(self.lambda_max))\n        lam = lam.contiguous()\n        lam = torch.where(torch.isfinite(lam), lam, torch.ones_like(lam))\n        return lam\n\n    def forward(\n        self,\n        h: torch.Tensor,\n        proto_probs: Any = None,\n        uncertainties: Any = None,\n        gates: Any = None,\n        token_word_map: Optional[List[Dict[int, str]]] = None,\n        domain_labels: Optional[torch.Tensor] = None,\n        global_step: Optional[int] = None,\n    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n\n        if global_step is not None:\n            self.current_step = int(global_step)\n\n        if not isinstance(h, torch.Tensor) or h.dim() != 3:\n            dev = h.device if isinstance(h, torch.Tensor) else torch.device(\"cpu\")\n            zero = torch.tensor(0.0, device=dev)\n            return h, {\n                \"encoder_loss\": zero,\n                \"adversarial_loss\": zero,\n                \"domain_loss\": zero,\n                \"domain_accuracy\": zero,\n            }\n\n        B, T, H = h.size()\n        device = h.device\n\n        domain_labels = self._expand_domain_labels(domain_labels, B)\n\n        h_normalized = h.clone()\n\n        if domain_labels is not None and B * T >= 2:\n            try:\n                self._ensure_discriminators_on_device(device)\n                h_flat = h.view(B * T, H)\n                domain_expanded = domain_labels.unsqueeze(1).expand(B, T).reshape(-1)\n\n                source_mask = domain_expanded == 0\n                target_mask = domain_expanded == 1\n\n                h_norm_flat = h_flat.clone()\n\n                source_count = source_mask.sum().item()\n                target_count = target_mask.sum().item()\n\n                if source_count >= 2:\n                    self.bn_source.train(self.training)\n                    h_norm_flat[source_mask] = self.bn_source(h_flat[source_mask])\n                elif source_count == 1:\n                    self.bn_source.eval()\n                    with torch.no_grad():\n                        h_norm_flat[source_mask] = self.bn_source(h_flat[source_mask])\n\n                if target_count >= 2:\n                    self.bn_target.train(self.training)\n                    h_norm_flat[target_mask] = self.bn_target(h_flat[target_mask])\n                elif target_count == 1:\n                    self.bn_target.eval()\n                    with torch.no_grad():\n                        h_norm_flat[target_mask] = self.bn_target(h_flat[target_mask])\n\n                h_normalized = h_norm_flat.view(B, T, H)\n\n                if _DEBUG_DISCOVERY and self.current_step % 500 == 0:\n                    print(f\"[ASBN-BN] Applied BN: {source_count} source, {target_count} target tokens\")\n\n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[ASBN] BN failed: {e}\")\n                h_normalized = h\n\n        if self.current_step < self.warmup_steps:\n            if _DEBUG_DISCOVERY and self.current_step % 50 == 0:\n                print(f\"[ASBN] Warmup: {self.current_step}/{self.warmup_steps}\")\n            zero = torch.tensor(0.0, device=device)\n            return h_normalized, {\n                \"encoder_loss\": zero,\n                \"adversarial_loss\": zero,\n                \"domain_loss\": zero,\n                \"domain_accuracy\": zero,\n            }\n\n        if not self.training or not _ENABLE_ASBN_TRAINING:\n            zero = torch.tensor(0.0, device=device)\n            return h_normalized, {\n                \"encoder_loss\": zero,\n                \"adversarial_loss\": zero,\n                \"domain_loss\": zero,\n                \"domain_accuracy\": zero,\n            }\n\n        self._ensure_discriminators_on_device(device)\n        self.d_domain.train()\n        self.d_freq.train()\n        self.d_ctx.train()\n        self.d_xl.train()\n\n        pmax_mat = self._parse_proto_probs_matrix(proto_probs, B, T, device)\n        U_mat = self._parse_scalar_matrix(uncertainties, B, T, device, default=0.1)\n        G_mat = self._parse_scalar_matrix(gates, B, T, device, default=0.0)\n\n        sel_mask = torch.ones((B, T), dtype=torch.bool, device=device)\n        batch_indices = torch.arange(B, device=device).unsqueeze(1).expand(B, T)\n\n        if token_word_map:\n            try:\n                for b in range(min(B, len(token_word_map))):\n                    wm = token_word_map[b] or {}\n                    for t in range(T):\n                        if t in wm:\n                            try:\n                                token_str = wm[t]\n                                tracked = True\n\n                                if _has_should_track_token and _should_track_token_fn is not None:\n                                    tracked = bool(_should_track_token_fn(token_str, self.special_tokens, self.tokenizer, self.language))\n                                elif _has_is_valid_token and _is_valid_token_fn is not None:\n                                    tracked = bool(_is_valid_token_fn(token_str, self.special_tokens, self.tokenizer, self.language))\n\n                                if not tracked:\n                                    sel_mask[b, t] = False\n                            except Exception:\n                                pass\n            except Exception:\n                if _VERBOSE_LOGGING:\n                    try:\n                        print(\"[ASBN] Token filtering failed:\", traceback.format_exc().splitlines()[-1])\n                    except Exception:\n                        pass\n\n        sel_idx = sel_mask.view(-1).nonzero(as_tuple=False).squeeze(1)\n        batch_idx = batch_indices.view(-1)[sel_idx]\n\n        if sel_idx.numel() == 0:\n            if _DEBUG_DISCOVERY:\n                print(\"[ASBN] No valid tokens after filtering\")\n            zero = torch.tensor(0.0, device=device)\n            return h_normalized, {\n                \"encoder_loss\": zero,\n                \"adversarial_loss\": zero,\n                \"domain_loss\": zero,\n                \"domain_accuracy\": zero,\n            }\n\n        h_flat = h_normalized.view(B * T, H)\n        sel_emb = h_flat[sel_idx]\n\n        pmax_flat = pmax_mat.view(-1)[sel_idx]\n        U_flat = U_mat.view(-1)[sel_idx]\n        G_flat = G_mat.view(-1)[sel_idx]\n\n        seq_len_feature = float(T) / max(int(_MAX_LENGTH), 1)\n        freq_feature = torch.stack([pmax_flat, U_flat], dim=1).to(device)\n        ctx_feature = torch.stack([G_flat, torch.full_like(G_flat, seq_len_feature)], dim=1).to(device)\n        xl_input = sel_emb\n\n        grl_alpha = self.get_grl_alpha(global_step)\n\n        freq_input = torch.cat([sel_emb, freq_feature], dim=1)\n        ctx_input = torch.cat([sel_emb, ctx_feature], dim=1)\n\n        xl_input_grl = gradient_reversal(xl_input, alpha=grl_alpha)\n        freq_input_grl = gradient_reversal(freq_input, alpha=grl_alpha)\n        ctx_input_grl = gradient_reversal(ctx_input, alpha=grl_alpha)\n\n        freq_logits = self.d_freq(freq_input_grl)\n        ctx_logits = self.d_ctx(ctx_input_grl)\n        xl_logits = self.d_xl(xl_input_grl)\n\n        freq_label = (pmax_flat > self.freq_threshold).long().to(device)\n        ctx_label = (U_flat < self.uncertainty_threshold).long().to(device)\n        xl_label = (G_flat > self.gate_threshold).long().to(device)\n\n        loss_freq = F.cross_entropy(freq_logits, freq_label, reduction=\"none\")\n        loss_ctx = F.cross_entropy(ctx_logits, ctx_label, reduction=\"none\")\n        loss_xl = F.cross_entropy(xl_logits, xl_label, reduction=\"none\")\n\n        lam_freq = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"freq\")\n        lam_ctx = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"ctx\")\n        lam_xl = self.compute_lambda_scaled_tensor(pmax_flat, U_flat, G_flat, \"xl\")\n\n        weighted = lam_freq * loss_freq + lam_ctx * loss_ctx + lam_xl * loss_xl\n        mean_weighted = torch.mean(weighted)\n\n        domain_loss = torch.tensor(0.0, device=device)\n        domain_accuracy = torch.tensor(0.0, device=device)\n\n        if domain_labels is not None:\n            try:\n                domain_flat = domain_labels[batch_idx]\n\n                domain_input = gradient_reversal(sel_emb, alpha=grl_alpha)\n                domain_logits = self.d_domain(domain_input)\n\n                domain_loss = F.cross_entropy(domain_logits, domain_flat)\n\n                with torch.no_grad():\n                    domain_preds = torch.argmax(domain_logits, dim=1)\n                    domain_accuracy = (domain_preds == domain_flat).float().mean()\n\n                    source_mask = domain_flat == 0\n                    target_mask = domain_flat == 1\n\n                    if source_mask.any():\n                        source_acc = ((domain_preds[source_mask] == domain_flat[source_mask]).float().mean())\n                        self.stats[\"source_accuracy\"] += float(source_acc.item())\n\n                    if target_mask.any():\n                        target_acc = ((domain_preds[target_mask] == domain_flat[target_mask]).float().mean())\n                        self.stats[\"target_accuracy\"] += float(target_acc.item())\n\n            except Exception as e:\n                if _VERBOSE_LOGGING:\n                    print(f\"[ASBN] Domain loss failed: {e}\")\n\n        encoder_loss = self.encoder_grl_scale * (mean_weighted + domain_loss)\n\n        try:\n            with torch.no_grad():\n                self.stats[\"domain_loss\"] += float(domain_loss.item())\n                self.stats[\"domain_accuracy\"] += float(domain_accuracy.item())\n                self.stats[\"asbn_loss\"] += float(encoder_loss.item())\n                self.stats[\"num_updates\"] += 1\n\n                if self.stats[\"num_updates\"] >= self.stats_reset_interval:\n                    if _DEBUG_DISCOVERY:\n                        stats = self.get_detailed_stats()\n                        print(f\"\\n[ASBN-STATS] After {stats['num_updates']} updates:\")\n                        print(f\"  Domain loss: {stats['domain_loss']:.4f}\")\n                        print(f\"  Domain acc: {stats['domain_accuracy']:.2%}\")\n                        print(f\"  Source acc: {stats['source_accuracy']:.2%}\")\n                        print(f\"  Target acc: {stats['target_accuracy']:.2%}\")\n                        print(f\"  ASBN loss: {stats['asbn_loss']:.4f}\")\n                    self.reset_stats()\n        except Exception:\n            pass\n\n        if _DEBUG_DISCOVERY and self.current_step % 500 == 0:\n            print(f\"\\n[ASBN-STEP-{self.current_step}]\")\n            print(f\"  GRL alpha: {grl_alpha:.3f}\")\n            print(f\"  Encoder loss: {encoder_loss.item():.4f}\")\n            print(f\"  Domain loss: {domain_loss.item():.4f}\")\n            print(f\"  Domain acc: {domain_accuracy.item():.2%}\")\n\n        return h_normalized, {\n            \"encoder_loss\": encoder_loss,\n            \"adversarial_loss\": mean_weighted,\n            \"domain_loss\": domain_loss,\n            \"domain_accuracy\": domain_accuracy,\n        }\n\n    def test_asbn(self, batch_size: int = 2, seq_len: int = 10) -> bool:\n        print(\"\\n\" + \"=\" * 60)\n        print(\"[ASBN-TEST] Testing ASBN module\")\n        print(\"=\" * 60)\n\n        try:\n            try:\n                device = next(self.parameters()).device\n            except StopIteration:\n                device = torch.device(\"cpu\")\n\n            h = torch.randn(batch_size, seq_len, self.embed_dim, device=device)\n            domain_labels = torch.randint(0, 2, (batch_size,), device=device)\n\n            h_out, losses = self.forward(h, domain_labels=domain_labels)\n            assert h_out.shape == h.shape, \"Forward output shape mismatch\"\n            assert \"domain_loss\" in losses, \"Missing domain_loss\"\n            print(\"  ✓ forward() with domain_labels passed\")\n\n            proto_probs = torch.rand(batch_size, seq_len, 3, device=device)\n            uncertainties = torch.rand(batch_size, seq_len, device=device)\n            gates = torch.rand(batch_size, seq_len, device=device)\n\n            self.train()\n            self.current_step = self.warmup_steps + 1\n\n            h_out, losses = self.forward(\n                h,\n                proto_probs=proto_probs,\n                uncertainties=uncertainties,\n                gates=gates,\n                domain_labels=domain_labels,\n                global_step=self.current_step,\n            )\n\n            assert losses[\"encoder_loss\"].item() >= 0.0, \"Encoder loss negative\"\n            assert 0.0 <= losses[\"domain_accuracy\"].item() <= 1.0, \"Domain accuracy out of range\"\n            print(\"  ✓ forward() with full inputs passed\")\n\n            stats = self.get_detailed_stats()\n            assert \"domain_loss\" in stats, \"Missing domain_loss in stats\"\n            print(\"  ✓ Statistics tracking passed\")\n\n            print(\"\\n✓ All ASBN tests passed\")\n            print(\"=\" * 60 + \"\\n\")\n            return True\n\n        except Exception as e:\n            print(f\"\\n✗ ASBN test failed: {e}\")\n            traceback.print_exc()\n            print(\"=\" * 60 + \"\\n\")\n            return False\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 4: ASBN Module - VERIFIED CORRECT\")\nprint(\"=\" * 80)\nprint(\"Configuration:\")\nprint(f\"  - Warmup Steps: 50\")\nprint(f\"  - GRL Alpha: {_GRL_ALPHA_START:.3f} → {_GRL_ALPHA_END:.3f} over {_GRL_ALPHA_STEPS} steps\")\nprint(f\"  - GRL Schedule: {_GRL_ALPHA_SCHEDULE}\")\nprint(f\"  - Encoder GRL Scale: 1.0\")\nprint(f\"  - Stats Reset Interval: 100\")\nprint(f\"  - ASBN Training: {'ENABLED' if _ENABLE_ASBN_TRAINING else 'DISABLED'}\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"XrNq18UsH4J3","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:04.373119Z","iopub.execute_input":"2026-02-18T08:40:04.373749Z","iopub.status.idle":"2026-02-18T08:40:04.441721Z","shell.execute_reply.started":"2026-02-18T08:40:04.373727Z","shell.execute_reply":"2026-02-18T08:40:04.441024Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCell 4: ASBN Module - VERIFIED CORRECT\n================================================================================\nConfiguration:\n  - Warmup Steps: 50\n  - GRL Alpha: 0.100 → 1.000 over 500 steps\n  - GRL Schedule: linear\n  - Encoder GRL Scale: 1.0\n  - Stats Reset Interval: 100\n  - ASBN Training: ENABLED\n================================================================================\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==============================================================================\n# CELL 5: TRG MODULE - TRANSPARENT RATIONALE GENERATION\n# ==============================================================================\n\nfrom typing import List, Dict, Tuple, Optional, Set, Any\nfrom collections import deque\nimport traceback\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport threading\nimport time\n\ntry:\n    _TRG_EVIDENCE_K = int(TRG_EVIDENCE_K)\nexcept (NameError, ValueError, TypeError):\n    _TRG_EVIDENCE_K = 3\n\ntry:\n    _TRG_GEN_EMBED = int(TRG_GEN_EMBED)\nexcept (NameError, ValueError, TypeError):\n    _TRG_GEN_EMBED = 64\n\ntry:\n    _MAX_SILVER_BUFFER = int(MAX_SILVER_BUFFER)\nexcept (NameError, ValueError, TypeError):\n    _MAX_SILVER_BUFFER = 50\n\ntry:\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept NameError:\n    _VERBOSE_LOGGING = False\n\ntry:\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept NameError:\n    _DEBUG_DISCOVERY = False\n\ntry:\n    _DEBUG_TIMING = bool(DEBUG_TIMING)\nexcept NameError:\n    _DEBUG_TIMING = False\n\ntry:\n    _ENABLE_TRG_INFERENCE = bool(ENABLE_TRG_INFERENCE)\nexcept NameError:\n    _ENABLE_TRG_INFERENCE = True\n\ntry:\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, TypeError):\n    _SOURCE_LANGUAGE = \"bn\"\n\ntry:\n    _TRG_UNCERTAINTY_THRESHOLD = float(TAU_LOW)\nexcept (NameError, ValueError, TypeError):\n    _TRG_UNCERTAINTY_THRESHOLD = 0.15\n\ntry:\n    _TRG_SPAN_THRESHOLD = float(SPAN_THRESHOLD)\nexcept (NameError, ValueError, TypeError):\n    _TRG_SPAN_THRESHOLD = 0.20\n\ntry:\n    _TAU_HIGH = float(TAU_HIGH)\nexcept (NameError, ValueError, TypeError):\n    _TAU_HIGH = 0.85\n\ntry:\n    _TAU_LOW = float(TAU_LOW)\nexcept (NameError, ValueError, TypeError):\n    _TAU_LOW = 0.15\n\ntry:\n    _TAU_ACCEPT = float(TAU_ACCEPT)\nexcept (NameError, ValueError, TypeError):\n    _TAU_ACCEPT = 0.80\n\ntry:\n    _TRG_TEMPERATURE = float(TRG_TEMPERATURE)\nexcept (NameError, ValueError, TypeError):\n    _TRG_TEMPERATURE = 1.0\n\ntry:\n    _MAX_EXPLANATIONS_PER_SENTENCE = (\n        int(MAX_EXPLANATIONS_PER_SENTENCE)\n        if \"MAX_EXPLANATIONS_PER_SENTENCE\" in globals()\n        else 10\n    )\nexcept Exception:\n    _MAX_EXPLANATIONS_PER_SENTENCE = 10\n\n_has_is_valid_token = False\n_has_get_tokenizer_special_tokens = False\n_has_get_cached_special_tokens = False\n_is_valid_token_fn = None\n_get_tokenizer_special_tokens_fn = None\n_get_cached_special_tokens_fn = None\n\ntry:\n    if 'is_valid_token' in dir():\n        _is_valid_token_fn = is_valid_token\n        _has_is_valid_token = True\n    elif 'is_valid_token' in globals():\n        _is_valid_token_fn = globals()['is_valid_token']\n        _has_is_valid_token = True\nexcept Exception:\n    pass\n\ntry:\n    if 'get_tokenizer_special_tokens' in dir():\n        _get_tokenizer_special_tokens_fn = get_tokenizer_special_tokens\n        _has_get_tokenizer_special_tokens = True\n    elif 'get_tokenizer_special_tokens' in globals():\n        _get_tokenizer_special_tokens_fn = globals()['get_tokenizer_special_tokens']\n        _has_get_tokenizer_special_tokens = True\nexcept Exception:\n    pass\n\ntry:\n    if 'get_cached_special_tokens' in dir():\n        _get_cached_special_tokens_fn = get_cached_special_tokens\n        _has_get_cached_special_tokens = True\n    elif 'get_cached_special_tokens' in globals():\n        _get_cached_special_tokens_fn = globals()['get_cached_special_tokens']\n        _has_get_cached_special_tokens = True\nexcept Exception:\n    pass\n\n_BENGALI_PUNCT_SET = set(['।', '॥'])\n_COMMON_PUNCT_SET = set(['.', ',', ';', ':', '!', '?', '\"', \"'\", '-', '(', ')', '[', ']', '{', '}', '/', '\\\\'])\n_TRG_PUNCT_SET = _BENGALI_PUNCT_SET | _COMMON_PUNCT_SET\n\n_FUNCTION_WORDS = {\n    'এবং', 'ও', 'কিন্তু', 'তবে', 'যদি', 'তাহলে', 'কারণ', 'যেমন',\n    'যখন', 'তখন', 'যেহেতু', 'সেহেতু', 'অথবা', 'কিংবা', 'বা',\n    'এই', 'সেই', 'ঐ', 'ওই', 'কোন', 'কোনো', 'কোনো', 'যে', 'যা', 'যিনি',\n    'একটি', 'একজন', 'কয়েকটি', 'অনেক', 'সব', 'সকল', 'কিছু', 'সবকিছু',\n    'আমি', 'তুমি', 'সে', 'তিনি', 'আমরা', 'তোমরা', 'তারা', 'আপনি', 'আপনারা',\n    'আমার', 'তোমার', 'তার', 'আমাদের', 'তোমাদের', 'তাদের', 'আপনার', 'আপনাদের',\n    'কি', 'কী', 'কে', 'কেন', 'কখন', 'কোথায', 'কীভাবে', 'কতটা',\n    'না', 'নয়', 'নেই', 'নি', 'আছে', 'ছিল', 'হবে', 'হয়',\n    'থেকে', 'পর্যন্ত', 'জন্য', 'সঙ্গে', 'সাথে', 'দিয়ে', 'মধ্যে', 'উপর',\n    'করা', 'করে', 'করেন', 'করছে', 'করবে', 'করলে', 'হওয়া', 'হয়ে', 'হয়েছে'\n}\n\n\ndef _is_punctuation_only(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n\n    clean = (\n        token.replace(\"▁\", \"\")\n        .replace(\"Ġ\", \"\")\n        .replace(\"##\", \"\")\n        .replace(\"</w>\", \"\")\n        .strip()\n    )\n\n    if not clean:\n        return False\n\n    if clean in _BENGALI_PUNCT_SET:\n        return True\n\n    if clean in _COMMON_PUNCT_SET:\n        return True\n\n    if len(clean) == 1 and not clean.isalnum():\n        return True\n\n    return all(c in _TRG_PUNCT_SET for c in clean)\n\n\ndef _fallback_is_valid_token(\n    token: str, special_tokens: set, tokenizer=None, language: str = \"bn\"\n) -> bool:\n    if token is None:\n        return False\n\n    if not isinstance(token, str):\n        try:\n            token = str(token)\n        except Exception:\n            return False\n\n    token = token.strip()\n    if not token:\n        return False\n\n    if token in special_tokens:\n        return False\n\n    clean = (\n        token.replace(\"▁\", \"\")\n        .replace(\"Ġ\", \"\")\n        .replace(\"##\", \"\")\n        .replace(\"</w>\", \"\")\n        .strip()\n    )\n\n    if len(clean) < 2:\n        return False\n\n    if not any(c.isalpha() for c in clean):\n        return False\n\n    if _is_punctuation_only(token):\n        return False\n\n    if clean.isdigit():\n        return False\n\n    return True\n\n\ndef _is_word_start(raw_token: str, token_word_map: Optional[dict], idx: int) -> bool:\n    if not isinstance(raw_token, str):\n        return False\n\n    try:\n        if token_word_map is not None and isinstance(token_word_map, dict):\n            if idx in token_word_map:\n                w = token_word_map[idx]\n                if isinstance(w, str) and w.strip():\n                    return True\n\n        if raw_token.startswith(\"▁\") or raw_token.startswith(\"Ġ\"):\n            return True\n\n        clean = (\n            raw_token.replace(\"▁\", \"\")\n            .replace(\"Ġ\", \"\")\n            .replace(\"##\", \"\")\n            .replace(\"</w>\", \"\")\n            .strip()\n        )\n\n        if len(clean) < 2:\n            return False\n\n        if _is_punctuation_only(raw_token):\n            return False\n\n        if token_word_map is None and any(c.isalpha() for c in clean):\n            return True\n\n        return False\n\n    except Exception:\n        return False\n\n\nclass ComprehensiveTRGExplanationTemplate:\n    def __init__(self):\n        self.explanation_templates = {\n            \"high_confidence\": (\n                \"Chose '{sense}' with high confidence ({confidence:.1%}) based on: '{evidence}'.   \"\n                \"Pattern matches learned data.   {alternatives_text}\"\n            ),\n            \"medium_confidence\": (\n                \"Selected '{sense}' with moderate confidence ({confidence:.1%}). \"\n                \"Evidence: '{evidence}'. Some uncertainty ({uncertainty:.1%}).   {alternatives_text}\"\n            ),\n            \"low_confidence\": (\n                \"Uncertain; chose '{sense}' ({confidence:.1%}). \"\n                \"Evidence: '{evidence}'.   {alternatives_text} Review recommended.\"\n            ),\n            \"fallback\": (\"Token '{token}' analyzed.   Context: '{evidence}'.\"),\n        }\n\n    def generate_explanation(self, evidence: Dict) -> str:\n        if not evidence or not isinstance(evidence, dict):\n            return \"\"\n\n        token = (\n            str(evidence.get(\"token\", \"unknown\"))\n            .replace(\"▁\", \"\")\n            .replace(\"Ġ\", \"\")\n        )\n        sense_info = evidence.get(\"chosen_sense\", (\"unknown\", 0.5))\n\n        if isinstance(sense_info, (tuple, list)) and len(sense_info) >= 2:\n            sense_name, confidence = str(sense_info[0]), float(sense_info[1])\n        else:\n            sense_name, confidence = \"unknown\", 0.5\n\n        uncertainty = float(evidence.get(\"uncertainty\", 0.5))\n\n        evidence_tokens = evidence.get(\"evidence_tokens\", [])\n        evidence_str = (\n            \", \".join(\n                [\n                    str(tok).replace(\"▁\", \"\").replace(\"Ġ\", \"\")\n                    for tok in evidence_tokens[:_TRG_EVIDENCE_K]\n                ]\n            )\n            or \"limited context\"\n        )\n\n        alternatives = evidence.get(\"alternatives\", [])\n        alternatives_text = \"\"\n        if isinstance(alternatives, list) and len(alternatives) > 0:\n            alt_parts = []\n            for alt in alternatives[:2]:\n                if isinstance(alt, (tuple, list)) and len(alt) >= 2:\n                    alt_name, alt_conf = str(alt[0]), float(alt[1])\n                    alt_parts.append(f\"'{alt_name}' ({alt_conf:.1%})\")\n            if alt_parts:\n                alternatives_text = f\"Alternatives: {', '.join(alt_parts)}.\"\n\n        if confidence >= _TAU_ACCEPT:\n            template_key = \"high_confidence\"\n        elif confidence >= _TRG_UNCERTAINTY_THRESHOLD:\n            template_key = \"medium_confidence\"\n        else:\n            template_key = \"low_confidence\"\n\n        template = self.explanation_templates.get(\n            template_key, self.explanation_templates[\"fallback\"]\n        )\n\n        try:\n            return template.format(\n                sense=sense_name,\n                confidence=confidence,\n                uncertainty=uncertainty,\n                evidence=evidence_str,\n                alternatives_text=alternatives_text,\n                token=token,\n            )\n        except Exception:\n            return f\"Token '{token}' -> '{sense_name}' ({confidence:.1%}).\"\n\n\nclass MemoryEfficientTRGExtractor:\n    def __init__(self, tokenizer=None, language: str = \"bn\", dscd_module=None):\n        self.tokenizer = tokenizer\n        self.language = language\n        self.dscd_module = dscd_module\n        self.span_clamp_warnings = 0\n        self.last_warning_time = 0.0\n\n        if tokenizer is not None:\n            try:\n                if _has_get_tokenizer_special_tokens and _get_tokenizer_special_tokens_fn is not None:\n                    self.special_tokens = _get_tokenizer_special_tokens_fn(tokenizer)\n                elif _has_get_cached_special_tokens and _get_cached_special_tokens_fn is not None:\n                    self.special_tokens = _get_cached_special_tokens_fn(tokenizer)\n                else:\n                    self.special_tokens = set(tokenizer.all_special_tokens)\n            except Exception:\n                self.special_tokens = set()\n        else:\n            self.special_tokens = set()\n\n    def extract_evidence_from_target(\n        self,\n        token_idx: int,\n        span_start: int,\n        span_end: int,\n        tgt_preds: torch.Tensor,\n    ) -> Optional[List[str]]:\n        if not isinstance(token_idx, int) or token_idx < 0:\n            return None\n        if not isinstance(span_start, int) or not isinstance(span_end, int):\n            return None\n        if span_start < 0:\n            return None\n\n        if not isinstance(tgt_preds, (torch.Tensor, list)):\n            return None\n\n        seq_len = (\n            len(tgt_preds)\n            if isinstance(tgt_preds, list)\n            else int(tgt_preds.size(0))\n        )\n        if span_end > seq_len:\n            return None\n\n        if span_start >= span_end:\n            return None\n\n        if token_idx < span_start or token_idx >= span_end:\n            return None\n\n        if token_idx >= seq_len:\n            return None\n\n        try:\n            evidence_tokens: List[str] = []\n            for i in range(span_start, span_end):\n                if i == token_idx:\n                    continue\n\n                if isinstance(tgt_preds, list):\n                    evidence_tokens.append(str(tgt_preds[i]))\n                else:\n                    try:\n                        evidence_tokens.append(str(int(tgt_preds[i].item())))\n                    except Exception:\n                        evidence_tokens.append(f\"token_{i}\")\n\n            return evidence_tokens if evidence_tokens else None\n\n        except Exception:\n            return None\n\n    def extract_evidence_efficiently(\n        self,\n        token_idx: int,\n        tokens: List[str],\n        dscd_outputs: Dict,\n        token_word_map: Optional[dict] = None,\n        decoder_attention: Optional[torch.Tensor] = None,\n    ) -> Dict:\n        if not isinstance(tokens, list):\n            return self._create_fallback_evidence(token_idx, [])\n\n        if not isinstance(token_idx, int):\n            return self._create_fallback_evidence(0, tokens)\n\n        if token_idx < 0 or token_idx >= len(tokens):\n            return self._create_fallback_evidence(\n                max(0, min(token_idx, len(tokens) - 1)), tokens\n            )\n\n        raw_token = tokens[token_idx]\n\n        if _has_is_valid_token and _is_valid_token_fn is not None:\n            try:\n                is_valid = _is_valid_token_fn(\n                    raw_token,\n                    self.special_tokens,\n                    self.tokenizer,\n                    language=self.language,\n                )\n            except Exception:\n                is_valid = _fallback_is_valid_token(\n                    raw_token, self.special_tokens, self.tokenizer, self.language\n                )\n        else:\n            is_valid = _fallback_is_valid_token(\n                raw_token, self.special_tokens, self.tokenizer, self.language\n            )\n\n        if not is_valid:\n            return self._create_fallback_evidence(token_idx, tokens)\n\n        try:\n            proto_probs = self._safe_extract_proto_probs(token_idx, dscd_outputs)\n            uncertainty = self._safe_extract_uncertainty(token_idx, dscd_outputs)\n            gate = self._safe_extract_gate(token_idx, dscd_outputs)\n            span = self._safe_extract_span(token_idx, dscd_outputs)\n\n            evidence_tokens: Optional[List[str]] = None\n            if decoder_attention is not None and isinstance(\n                decoder_attention, torch.Tensor\n            ):\n                try:\n                    if decoder_attention.dim() == 4:\n                        if (\n                            decoder_attention.size(0) > 1\n                            and decoder_attention.size(1) > 1\n                        ):\n                            attn_avg = decoder_attention.mean(dim=(0, 1))\n                        elif decoder_attention.size(0) > 1:\n                            attn_avg = decoder_attention.mean(dim=1)\n                        else:\n                            attn_avg = decoder_attention.mean(dim=0)\n                        if attn_avg.dim() == 2 and token_idx < attn_avg.size(0):\n                            vec = attn_avg[token_idx]\n                        else:\n                            vec = attn_avg.reshape(-1)\n                    elif decoder_attention.dim() == 3:\n                        attn_avg = decoder_attention.mean(dim=0)\n                        if attn_avg.dim() == 2 and token_idx < attn_avg.size(0):\n                            vec = attn_avg[token_idx]\n                        else:\n                            vec = attn_avg.reshape(-1)\n                    elif decoder_attention.dim() == 2:\n                        if token_idx < decoder_attention.size(0):\n                            vec = decoder_attention[token_idx]\n                        else:\n                            vec = decoder_attention.reshape(-1)\n                    elif decoder_attention.dim() == 1:\n                        vec = decoder_attention\n                    else:\n                        vec = None\n\n                    if vec is not None and vec.numel() > 0:\n                        k = min(5, int(vec.size(0)))\n                        top_k_indices = torch.topk(vec, k=k).indices.cpu().numpy()\n                        evidence_tokens = []\n                        for i in top_k_indices:\n                            if i < len(tokens) and i != token_idx:\n                                evidence_tokens.append(tokens[int(i)])\n\n                except Exception:\n                    evidence_tokens = None\n\n            if evidence_tokens is None:\n                evidence_tokens = self._extract_context_window(\n                    token_idx, tokens, token_word_map\n                )\n\n            seen: Dict[str, bool] = {}\n            dedup_evidence: List[str] = []\n            for t in evidence_tokens:\n                if t not in seen:\n                    seen[t] = True\n                    dedup_evidence.append(t)\n            evidence_tokens = dedup_evidence[:_TRG_EVIDENCE_K]\n\n            top_senses = self._compute_sense_alternatives_fast(\n                proto_probs, temperature=_TRG_TEMPERATURE\n            )\n            chosen_sense = top_senses[0] if len(top_senses) > 0 else (\"unknown\", 0.5)\n            alternatives = top_senses[1:3] if len(top_senses) > 1 else []\n\n            if (\n                token_word_map\n                and token_idx in token_word_map\n                and isinstance(token_word_map[token_idx], str)\n                and token_word_map[token_idx].strip()\n            ):\n                token_value = token_word_map[token_idx]\n            else:\n                token_value = raw_token\n\n            return {\n                \"token\": token_value,\n                \"token_idx\": token_idx,\n                \"evidence_tokens\": evidence_tokens,\n                \"chosen_sense\": chosen_sense,\n                \"alternatives\": alternatives,\n                \"uncertainty\": float(uncertainty),\n                \"gate\": float(gate),\n                \"span\": float(span),\n            }\n\n        except Exception as e:\n            if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n                print(f\"[TRG] Evidence error @ {token_idx}: {e}\")\n            return self._create_fallback_evidence(token_idx, tokens)\n\n    def _extract_context_window(\n        self,\n        token_idx: int,\n        tokens: List[str],\n        token_word_map: Optional[dict],\n    ) -> List[str]:\n        context_window = 2\n        start_idx = max(0, token_idx - context_window)\n        end_idx = min(len(tokens), token_idx + context_window + 1)\n        evidence_tokens: List[str] = []\n\n        for i in range(start_idx, end_idx):\n            if i == token_idx or i >= len(tokens):\n                continue\n            rtok = tokens[i]\n            clean_token = (\n                str(rtok)\n                .replace(\"▁\", \"\")\n                .replace(\"Ġ\", \"\")\n                .replace(\"</w>\", \"\")\n                .strip()\n            )\n\n            if not _is_word_start(rtok, token_word_map, i):\n                if (\n                    token_word_map is None\n                    and len(clean_token) >= 2\n                    and any(c.isalpha() for c in clean_token)\n                ):\n                    pass\n                else:\n                    continue\n\n            if _has_is_valid_token and _is_valid_token_fn is not None:\n                try:\n                    ok = _is_valid_token_fn(\n                        rtok,\n                        self.special_tokens,\n                        self.tokenizer,\n                        language=self.language,\n                    )\n                except Exception:\n                    ok = _fallback_is_valid_token(\n                        rtok, self.special_tokens, self.tokenizer, self.language\n                    )\n            else:\n                ok = _fallback_is_valid_token(\n                    rtok, self.special_tokens, self.tokenizer, self.language\n                )\n\n            if ok and len(clean_token) > 0:\n                if (\n                    token_word_map\n                    and isinstance(token_word_map.get(i, \"\"), str)\n                    and token_word_map[i].strip()\n                ):\n                    evidence_tokens.append(token_word_map[i].strip())\n                else:\n                    evidence_tokens.append(clean_token)\n\n        return evidence_tokens\n\n    def _safe_extract_proto_probs(\n        self, token_idx: int, dscd_outputs: Dict\n    ) -> torch.Tensor:\n        try:\n            if not isinstance(dscd_outputs, dict):\n                return torch.tensor([1.0], dtype=torch.float32)\n\n            pp_all = dscd_outputs.get(\"proto_probs\", None)\n            if pp_all and len(pp_all) > 0:\n                row = pp_all[0]\n                if isinstance(row, torch.Tensor):\n                    if row.ndim == 2 and token_idx < row.shape[0]:\n                        return row[token_idx].detach().cpu().flatten()\n                    return row.detach().cpu().flatten()\n                if isinstance(row, (list, tuple)):\n                    if token_idx < len(row):\n                        val = row[token_idx]\n                        if isinstance(val, torch.Tensor):\n                            return val.detach().cpu().flatten()\n                        if isinstance(val, (list, tuple, np.ndarray)):\n                            return torch.as_tensor(\n                                val, dtype=torch.float32\n                            ).flatten()\n                        return torch.tensor([float(val)], dtype=torch.float32)\n                    if len(row) > 0:\n                        maybe = row[0]\n                        if isinstance(maybe, torch.Tensor):\n                            return maybe.detach().cpu().flatten()\n        except Exception:\n            if _VERBOSE_LOGGING:\n                print(f\"[TRG] Proto_probs extraction failed for token {token_idx}, using default [1.0]\")\n        return torch.tensor([1.0], dtype=torch.float32)\n\n    def _safe_extract_uncertainty(\n        self, token_idx: int, dscd_outputs: Dict\n    ) -> float:\n        try:\n            if not isinstance(dscd_outputs, dict):\n                return 0.5\n\n            U_all = dscd_outputs.get(\"uncertainties\", None)\n            if U_all and len(U_all) > 0:\n                row = U_all[0]\n                if isinstance(row, torch.Tensor):\n                    if row.ndim == 2 and token_idx < row.shape[0]:\n                        return float(row[token_idx].item())\n                    if row.ndim == 1 and token_idx < row.shape[0]:\n                        return float(row[token_idx].item())\n                if isinstance(row, (list, tuple)) and token_idx < len(row):\n                    val = row[token_idx]\n                    return (\n                        float(val.item())\n                        if isinstance(val, torch.Tensor)\n                        else float(val)\n                    )\n        except Exception:\n            pass\n        return 0.5\n\n    def _safe_extract_gate(self, token_idx: int, dscd_outputs: Dict) -> float:\n        try:\n            if not isinstance(dscd_outputs, dict):\n                return 0.0\n\n            G_all = dscd_outputs.get(\"gates\", None)\n            if G_all and len(G_all) > 0:\n                row = G_all[0]\n                if isinstance(row, torch.Tensor):\n                    if row.ndim == 2 and token_idx < row.shape[0]:\n                        return float(row[token_idx].item())\n                    if row.ndim == 1 and token_idx < row.shape[0]:\n                        return float(row[token_idx].item())\n                if isinstance(row, (list, tuple)) and token_idx < len(row):\n                    val = row[token_idx]\n                    return (\n                        float(val.item())\n                        if isinstance(val, torch.Tensor)\n                        else float(val)\n                    )\n        except Exception:\n            pass\n        return 0.0\n\n    def _safe_extract_span(self, token_idx: int, dscd_outputs: Dict) -> float:\n        try:\n            if not isinstance(dscd_outputs, dict):\n                return 0.0\n\n            S_all = dscd_outputs.get(\"span_preds\", None)\n            if S_all and len(S_all) > 0:\n                row = S_all[0]\n                if isinstance(row, torch.Tensor):\n                    if row.ndim == 2 and token_idx < row.shape[0]:\n                        span_val = float(row[token_idx].item())\n                    elif row.ndim == 1 and token_idx < row.shape[0]:\n                        span_val = float(row[token_idx].item())\n                    else:\n                        return 0.0\n                elif isinstance(row, (list, tuple)) and token_idx < len(row):\n                    val = row[token_idx]\n                    span_val = (\n                        float(val.item())\n                        if isinstance(val, torch.Tensor)\n                        else float(val)\n                    )\n                else:\n                    return 0.0\n\n                if span_val < 0.0 or span_val > 1.0:\n                    current_time = time.time()\n                    if self.span_clamp_warnings < 10 or (\n                        current_time - self.last_warning_time\n                    ) > 60.0:\n                        if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n                            print(f\"[TRG] Clamping span {span_val:.3f} -> [0.0, 1.0]\")\n                        self.span_clamp_warnings += 1\n                        self.last_warning_time = current_time\n\n                    span_val = max(0.0, min(1.0, float(span_val)))\n                return span_val\n\n        except Exception:\n            pass\n        return 0.0\n\n    def compute_span(self, sense_probs) -> float:\n        try:\n            if isinstance(sense_probs, dict):\n                probs = list(sense_probs.values())\n            else:\n                probs = sense_probs\n\n            if isinstance(probs, torch.Tensor):\n                probs = probs.cpu().numpy().flatten().tolist()\n\n            if isinstance(probs, (np.ndarray, list)):\n                probs = list(probs)\n\n            if len(probs) < 2:\n                return 0.0\n\n            sorted_probs = sorted([float(p) for p in probs], reverse=True)\n            span = float(sorted_probs[0]) - float(sorted_probs[1])\n\n            return max(0.0, min(1.0, span))\n\n        except Exception:\n            return 0.0\n\n    def _compute_sense_alternatives_fast(\n        self, proto_probs: torch.Tensor, temperature: float = 1.0\n    ) -> List[Tuple[str, float]]:\n        try:\n            if not isinstance(proto_probs, torch.Tensor):\n                proto_probs = torch.as_tensor(proto_probs, dtype=torch.float32)\n\n            probs = proto_probs.flatten().float()\n\n            if probs.numel() == 0:\n                return [(\"unknown\", 0.5)]\n\n            probs = torch.clamp(probs, min=1e-10, max=1.0)\n\n            if temperature != 1.0 and probs.numel() > 1:\n                log_probs = torch.log(probs)\n                scaled_log_probs = log_probs / float(temperature)\n                probs = torch.softmax(scaled_log_probs, dim=0)\n\n            if probs.numel() > 1:\n                probs_sorted, indices = torch.sort(probs, descending=True)\n                top_k = min(3, int(indices.numel()))\n                return [\n                    (f\"sense_{int(indices[i].item())}\", float(probs_sorted[i].item()))\n                    for i in range(top_k)\n                ]\n            else:\n                return [(\"sense_0\", float(probs[0].item()))]\n        except Exception:\n            return [(\"unknown\", 0.5)]\n\n    def _create_fallback_evidence(\n        self, token_idx: int, tokens: List[str]\n    ) -> Dict:\n        if isinstance(tokens, list) and 0 <= token_idx < len(tokens):\n            token = tokens[token_idx]\n        else:\n            token = \"UNK\"\n\n        return {\n            \"token\": token,\n            \"token_idx\": token_idx,\n            \"evidence_tokens\": [],\n            \"chosen_sense\": (\"unknown\", 0.5),\n            \"alternatives\": [],\n            \"uncertainty\": 0.5,\n            \"gate\": 0.0,\n            \"span\": 0.0,\n        }\n\n    def get_homograph_tokens_from_dscd(self) -> Set[str]:\n        homograph_tokens: Set[str] = set()\n        try:\n            if self.dscd_module is not None:\n                if hasattr(self.dscd_module, \"get_discovered_homographs\"):\n                    homograph_tokens = set(\n                        self.dscd_module.get_discovered_homographs()\n                    )\n                elif hasattr(self.dscd_module, \"prototype_stores\"):\n                    for token, store in self.dscd_module.prototype_stores.items():\n                        if hasattr(store, \"size\") and store.size() >= 2:\n                            clean = (\n                                str(token)\n                                .replace(\"▁\", \"\")\n                                .replace(\"Ġ\", \"\")\n                                .replace(\"##\", \"\")\n                                .strip()\n                            )\n                            homograph_tokens.add(clean)\n        except Exception:\n            pass\n        return homograph_tokens\n\n\nclass CompleteTRGWithExplanations(nn.Module):\n    def __init__(\n        self,\n        embed_dim: Optional[int] = None,\n        tokenizer=None,\n        language: str = \"bn\",\n        dscd_module=None,\n    ):\n        super().__init__()\n        self.embed_dim = int(embed_dim) if embed_dim is not None else int(\n            _TRG_GEN_EMBED\n        )\n        self.tokenizer = tokenizer\n        self.language = language\n        self.dscd_module = dscd_module\n\n        if dscd_module is None:\n            if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n                print(\"[TRG] No DSCD module - homograph detection disabled\")\n\n        if tokenizer is not None:\n            try:\n                if _has_get_tokenizer_special_tokens and _get_tokenizer_special_tokens_fn is not None:\n                    self.special_tokens = _get_tokenizer_special_tokens_fn(tokenizer)\n                elif _has_get_cached_special_tokens and _get_cached_special_tokens_fn is not None:\n                    self.special_tokens = _get_cached_special_tokens_fn(tokenizer)\n                else:\n                    self.special_tokens = set(tokenizer.all_special_tokens)\n            except Exception:\n                self.special_tokens = set()\n        else:\n            self.special_tokens = set()\n\n        self.template_system = ComprehensiveTRGExplanationTemplate()\n        self.evidence_extractor = MemoryEfficientTRGExtractor(\n            tokenizer, language=language, dscd_module=dscd_module\n        )\n\n        self.silver_buffer = deque(maxlen=int(_MAX_SILVER_BUFFER))\n        self._silver_lock = threading.Lock()\n\n        self.stats_reset_interval = 1000\n        self.stats = {\n            \"explanations_generated\": 0,\n            \"high_confidence_explanations\": 0,\n            \"low_confidence_explanations\": 0,\n            \"empty_evidence_count\": 0,\n            \"total_evidence_tokens\": 0,\n            \"tokens_filtered_word_start\": 0,\n            \"tokens_filtered_validity\": 0,\n            \"tokens_filtered_ambiguity\": 0,\n            \"dscd_homographs_explained\": 0,\n        }\n        self._stats_lock = threading.Lock()\n\n        if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n            print(\"[TRG] Initialized:\")\n            print(f\"  - Uncertainty: ADAPTIVE (base={_TRG_UNCERTAINTY_THRESHOLD:.2f})\")\n            print(f\"  - Span: ADAPTIVE (base={_TRG_SPAN_THRESHOLD:.2f})\")\n            print(f\"  - Temperature: {_TRG_TEMPERATURE:.2f}\")\n            print(\"  - Mode: DATA-DRIVEN + ADAPTIVE THRESHOLDS\")\n            print(f\"  - Function availability: is_valid={_has_is_valid_token}, get_special={_has_get_tokenizer_special_tokens}, get_cached={_has_get_cached_special_tokens}\")\n\n    def _update_stats(self, evidence: Dict, is_dscd_homograph: bool = False) -> None:\n        with self._stats_lock:\n            self.stats[\"explanations_generated\"] += 1\n\n            if is_dscd_homograph:\n                self.stats[\"dscd_homographs_explained\"] += 1\n\n            if not evidence.get(\"evidence_tokens\"):\n                self.stats[\"empty_evidence_count\"] += 1\n            else:\n                self.stats[\"total_evidence_tokens\"] += len(\n                    evidence[\"evidence_tokens\"]\n                )\n\n            confidence = 0.5\n            chosen = evidence.get(\"chosen_sense\")\n            if isinstance(chosen, (tuple, list)) and len(chosen) >= 2:\n                try:\n                    confidence = float(chosen[1])\n                except Exception:\n                    confidence = 0.5\n\n            if confidence >= _TAU_ACCEPT:\n                self.stats[\"high_confidence_explanations\"] += 1\n            elif confidence < _TRG_UNCERTAINTY_THRESHOLD:\n                self.stats[\"low_confidence_explanations\"] += 1\n\n            if self.stats[\"explanations_generated\"] >= self.stats_reset_interval:\n                if _DEBUG_DISCOVERY:\n                    current_stats = self.get_statistics()\n                    print(\n                        f\"\\n[TRG-STATS] After {self.stats['explanations_generated']}:\"\n                    )\n                    print(\n                        f\"  High conf: {current_stats['high_confidence_rate']:.2%}\"\n                    )\n                    print(\n                        f\"  DSCD: {current_stats['dscd_homograph_rate']:.2%}\"\n                    )\n                self.reset_statistics()\n\n    def _add_to_silver_buffer(\n        self, evidence: Dict, explanation: str, tokens: List[str]\n    ) -> None:\n        try:\n            conf = 0.5\n            chosen = evidence.get(\"chosen_sense\")\n            if isinstance(chosen, (tuple, list)) and len(chosen) >= 2:\n                conf = float(chosen[1])\n\n            entry = {\n                \"token\": str(evidence.get(\"token\", \"UNK\"))[:20],\n                \"explanation\": str(explanation)[:150],\n                \"confidence\": conf,\n            }\n\n            with self._silver_lock:\n                self.silver_buffer.append(entry)\n        except Exception:\n            pass\n\n    def generate_explanation_for_token(\n        self,\n        token_idx: int,\n        tokens: List[str],\n        dscd_outputs: Dict,\n        token_word_map: Optional[dict] = None,\n        decoder_attention: Optional[torch.Tensor] = None,\n        is_dscd_homograph: bool = False,\n    ) -> Tuple[str, Dict]:\n        if self.training or not _ENABLE_TRG_INFERENCE:\n            return \"\", {}\n\n        if not isinstance(tokens, list) or not isinstance(token_idx, int):\n            return \"\", {}\n\n        if token_idx < 0 or token_idx >= len(tokens):\n            return \"\", {}\n\n        raw_token = tokens[token_idx]\n        if _has_is_valid_token and _is_valid_token_fn is not None:\n            try:\n                is_valid = _is_valid_token_fn(\n                    raw_token,\n                    self.special_tokens,\n                    self.tokenizer,\n                    language=self.language,\n                )\n            except Exception:\n                is_valid = _fallback_is_valid_token(\n                    raw_token, self.special_tokens, self.tokenizer, self.language\n                )\n        else:\n            is_valid = _fallback_is_valid_token(\n                raw_token, self.special_tokens, self.tokenizer, self.language\n            )\n\n        if not is_valid:\n            return \"\", {}\n\n        try:\n            evidence = self.evidence_extractor.extract_evidence_efficiently(\n                token_idx,\n                tokens,\n                dscd_outputs,\n                token_word_map=token_word_map,\n                decoder_attention=decoder_attention,\n            )\n\n            explanation_text = self.template_system.generate_explanation(evidence)\n            self._update_stats(evidence, is_dscd_homograph=is_dscd_homograph)\n            self._add_to_silver_buffer(evidence, explanation_text, tokens)\n            return explanation_text, evidence\n        except Exception:\n            return \"\", {}\n\n    @staticmethod\n    def _to_list_helper(x: Any) -> List[float]:\n        if x is None:\n            return []\n\n        try:\n            if isinstance(x, torch.Tensor):\n                x = x.detach().cpu()\n\n                if x.ndim == 0:\n                    return [float(x.item())]\n                if x.ndim == 1:\n                    return [float(v.item()) for v in x]\n                if x.ndim == 2:\n                    if x.size(0) == 1:\n                        return [float(v.item()) for v in x[0]]\n                    else:\n                        return [float(v.item()) for v in x.flatten()]\n                if x.ndim >= 3:\n                    return [float(v.item()) for v in x.flatten()]\n\n            if isinstance(x, (list, tuple)):\n                out: List[float] = []\n                for v in x:\n                    if isinstance(v, torch.Tensor):\n                        v = v.detach().cpu()\n                        if v.ndim == 0:\n                            out.append(float(v.item()))\n                        elif v.numel() > 0:\n                            out.append(float(v.flatten()[0].item()))\n                        else:\n                            out.append(0.0)\n                    elif isinstance(v, (int, float, np.number)):\n                        out.append(float(v))\n                    else:\n                        try:\n                            out.append(float(v))\n                        except Exception:\n                            out.append(0.0)\n                return out\n\n            if isinstance(x, (int, float, np.number)):\n                return [float(x)]\n\n            return [float(x)]\n\n        except Exception:\n            return []\n\n    def compute_uncertainty_adaptive(\n        self, proto_probs: Any, uncertainties: Any\n    ) -> Tuple[float, float]:\n        try:\n            U = self._to_list_helper(uncertainties)\n\n            if not U or len(U) == 0:\n                return float(_TRG_UNCERTAINTY_THRESHOLD), float(_TRG_UNCERTAINTY_THRESHOLD)\n\n            U_arr = np.array(U, dtype=np.float32)\n            U_arr = U_arr[np.isfinite(U_arr)]\n\n            if len(U_arr) == 0:\n                return float(_TRG_UNCERTAINTY_THRESHOLD), float(_TRG_UNCERTAINTY_THRESHOLD)\n\n            median_u = float(np.median(U_arr))\n            std_u = float(np.std(U_arr))\n\n            adaptive_threshold = median_u + 0.5 * std_u\n            adaptive_threshold = max(0.05, min(0.50, adaptive_threshold))\n\n            return float(adaptive_threshold), float(median_u)\n\n        except Exception:\n            return float(_TRG_UNCERTAINTY_THRESHOLD), float(_TRG_UNCERTAINTY_THRESHOLD)\n\n    def compute_span_adaptive(self, span_preds: Any) -> Tuple[float, float]:\n        try:\n            S = self._to_list_helper(span_preds)\n\n            if not S or len(S) == 0:\n                return float(_TRG_SPAN_THRESHOLD), float(_TRG_SPAN_THRESHOLD)\n\n            S_arr = np.array(S, dtype=np.float32)\n            S_arr = S_arr[np.isfinite(S_arr)]\n\n            if len(S_arr) == 0:\n                return float(_TRG_SPAN_THRESHOLD), float(_TRG_SPAN_THRESHOLD)\n\n            median_s = float(np.median(S_arr))\n            percentile_75 = float(np.percentile(S_arr, 75))\n\n            adaptive_threshold = 0.5 * median_s + 0.5 * percentile_75\n            adaptive_threshold = max(0.02, min(0.30, adaptive_threshold))\n\n            return float(adaptive_threshold), float(median_s)\n\n        except Exception:\n            return float(_TRG_SPAN_THRESHOLD), float(_TRG_SPAN_THRESHOLD)\n\n    def process_sentence_for_explanations(\n        self,\n        tokens: List[str],\n        dscd_outputs: Dict,\n        token_word_map: Optional[dict] = None,\n        span_threshold: Optional[float] = None,\n        uncertainty_threshold: Optional[float] = None,\n        decoder_attention: Optional[torch.Tensor] = None,\n        max_explanations: int = _MAX_EXPLANATIONS_PER_SENTENCE,\n    ) -> List[Dict]:\n        if self.training or not _ENABLE_TRG_INFERENCE:\n            return []\n\n        if span_threshold is None:\n            span_threshold = float(_TRG_SPAN_THRESHOLD)\n\n        if uncertainty_threshold is None:\n            uncertainty_threshold = float(_TRG_UNCERTAINTY_THRESHOLD)\n\n        explanations: List[Dict] = []\n\n        try:\n            if not tokens or not isinstance(tokens, list):\n                return explanations\n\n            if not isinstance(dscd_outputs, dict) or not dscd_outputs:\n                return explanations\n\n            U_all = dscd_outputs.get(\"uncertainties\", [])\n            S_all = dscd_outputs.get(\"span_preds\", [])\n\n            if not U_all or not U_all[0]:\n                return explanations\n\n            U = self._to_list_helper(U_all[0])\n            S = (\n                self._to_list_helper(S_all[0])\n                if S_all and S_all[0]\n                else [0.0] * len(tokens)\n            )\n\n            seq_len = len(tokens)\n            if len(U) < seq_len:\n                U.extend([0.5] * (seq_len - len(U)))\n            elif len(U) > seq_len:\n                U = U[:seq_len]\n\n            if len(S) < seq_len:\n                S.extend([0.0] * (seq_len - len(S)))\n            elif len(S) > seq_len:\n                S = S[:seq_len]\n\n            if not U:\n                return explanations\n\n            adaptive_u_threshold, median_u = self.compute_uncertainty_adaptive(\n                dscd_outputs.get(\"proto_probs\", None), U_all[0]\n            )\n            adaptive_s_threshold, median_s = self.compute_span_adaptive(S_all[0] if S_all else None)\n\n            strict_uncertainty = max(adaptive_u_threshold, uncertainty_threshold)\n            strict_span = max(adaptive_s_threshold, span_threshold)\n\n            if _DEBUG_DISCOVERY:\n                print(f\"[TRG-ADAPTIVE] U: median={median_u:.3f}, thresh={strict_uncertainty:.3f}\")\n                print(f\"[TRG-ADAPTIVE] S: median={median_s:.3f}, thresh={strict_span:.3f}\")\n\n            dscd_homographs = self.evidence_extractor.get_homograph_tokens_from_dscd()\n\n            candidates: List[Tuple[int, float, float, str, int, int]] = []\n\n            local_stats = {\n                \"tokens_filtered_word_start\": 0,\n                \"tokens_filtered_validity\": 0,\n                \"tokens_filtered_ambiguity\": 0,\n            }\n\n            for idx in range(seq_len):\n                tok = tokens[idx]\n                clean_tok = tok.replace(\"▁\", \"\").replace(\"Ġ\", \"\").strip()\n\n                if _is_punctuation_only(tok):\n                    local_stats[\"tokens_filtered_validity\"] += 1\n                    continue\n\n                if not _is_word_start(tok, token_word_map, idx):\n                    local_stats[\"tokens_filtered_word_start\"] += 1\n                    continue\n\n                if _has_is_valid_token and _is_valid_token_fn is not None:\n                    try:\n                        valid = _is_valid_token_fn(\n                            tok,\n                            self.special_tokens,\n                            self.tokenizer,\n                            language=self.language,\n                        )\n                    except Exception:\n                        valid = _fallback_is_valid_token(\n                            tok, self.special_tokens, self.tokenizer, self.language\n                        )\n                else:\n                    valid = _fallback_is_valid_token(\n                        tok, self.special_tokens, self.tokenizer, self.language\n                    )\n\n                if not valid:\n                    local_stats[\"tokens_filtered_validity\"] += 1\n                    continue\n\n                if clean_tok in _FUNCTION_WORDS:\n                    local_stats[\"tokens_filtered_validity\"] += 1\n                    continue\n\n                if len(clean_tok) < 3 and not any('\\u0980' <= c <= '\\u09FF' for c in clean_tok):\n                    local_stats[\"tokens_filtered_validity\"] += 1\n                    continue\n\n                u = float(U[idx])\n                s = float(S[idx])\n\n                in_dscd = clean_tok in dscd_homographs\n\n                if in_dscd:\n                    priority = 1\n                elif s >= strict_span and u >= strict_uncertainty:\n                    priority = 2\n                elif s >= strict_span:\n                    priority = 3\n                elif u >= strict_uncertainty:\n                    priority = 4\n                else:\n                    local_stats[\"tokens_filtered_ambiguity\"] += 1\n                    continue\n\n                candidates.append((idx, u, s, clean_tok, priority, idx))\n\n            with self._stats_lock:\n                self.stats[\"tokens_filtered_word_start\"] += local_stats[\"tokens_filtered_word_start\"]\n                self.stats[\"tokens_filtered_validity\"] += local_stats[\"tokens_filtered_validity\"]\n                self.stats[\"tokens_filtered_ambiguity\"] += local_stats[\"tokens_filtered_ambiguity\"]\n\n            if not candidates:\n                return explanations\n\n            candidates.sort(key=lambda t: (t[4], -t[2], -t[1], t[5]))\n\n            for (token_idx, u, s, clean_tok, priority, _) in candidates[\n                : max_explanations\n            ]:\n                try:\n                    explanation_text, evidence = self.generate_explanation_for_token(\n                        token_idx,\n                        tokens,\n                        dscd_outputs,\n                        token_word_map=token_word_map,\n                        decoder_attention=decoder_attention,\n                        is_dscd_homograph=(priority == 1),\n                    )\n                    if explanation_text and evidence:\n                        explanations.append(\n                            {\n                                \"token_idx\": token_idx,\n                                \"token\": (\n                                    token_word_map[token_idx]\n                                    if token_word_map\n                                    and token_idx in token_word_map\n                                    else tokens[token_idx]\n                                    .replace(\"▁\", \"\")\n                                    .replace(\"Ġ\", \"\")\n                                ),\n                                \"explanation\": explanation_text,\n                                \"uncertainty\": u,\n                                \"span\": s,\n                                \"dscd_discovered\": (priority == 1),\n                                \"priority\": priority,\n                            }\n                        )\n                except Exception:\n                    continue\n\n        except Exception:\n            pass\n\n        return explanations\n\n    def get_statistics(self) -> Dict:\n        with self._stats_lock:\n            total = max(self.stats[\"explanations_generated\"], 1)\n            if self.stats[\"explanations_generated\"] > 0:\n                avg_evidence_tokens = (\n                    self.stats[\"total_evidence_tokens\"] / total\n                )\n            else:\n                avg_evidence_tokens = 0.0\n\n            return {\n                **self.stats.copy(),\n                \"high_confidence_rate\": self.stats[\n                    \"high_confidence_explanations\"\n                ]\n                / total,\n                \"low_confidence_rate\": self.stats[\n                    \"low_confidence_explanations\"\n                ]\n                / total,\n                \"empty_evidence_rate\": self.stats[\"empty_evidence_count\"]\n                / total,\n                \"avg_evidence_tokens\": avg_evidence_tokens,\n                \"silver_buffer_size\": len(self.silver_buffer),\n                \"dscd_homograph_rate\": self.stats[\n                    \"dscd_homographs_explained\"\n                ]\n                / total,\n            }\n\n    def reset_statistics(self) -> None:\n        with self._stats_lock:\n            self.stats = {\n                \"explanations_generated\": 0,\n                \"high_confidence_explanations\": 0,\n                \"low_confidence_explanations\": 0,\n                \"empty_evidence_count\": 0,\n                \"total_evidence_tokens\": 0,\n                \"tokens_filtered_word_start\": 0,\n                \"tokens_filtered_validity\": 0,\n                \"tokens_filtered_ambiguity\": 0,\n                \"dscd_homographs_explained\": 0,\n            }\n\n    def clear_silver_buffer(self) -> None:\n        with self._silver_lock:\n            self.silver_buffer.clear()\n\n    def test_trg(self, tokenizer=None) -> bool:\n        print(\"\\n\" + \"=\" * 60)\n        print(\"[TRG-TEST] Testing\")\n        print(\"=\" * 60)\n\n        if not _ENABLE_TRG_INFERENCE:\n            print(\"TRG inference disabled, enabling for test...\")\n\n        try:\n            tokens = [\"▁আমি\", \"▁কল\", \"▁বন্ধ\", \"▁করেছি\", \"।\"]\n\n            dscd_outputs = {\n                \"proto_probs\": [[torch.tensor([0.6, 0.4]) for _ in tokens]],\n                \"uncertainties\": [[0.1, 0.5, 0.2, 0.1, 0.0]],\n                \"span_preds\": [[0.05, 0.3, 0.1, 0.05, 0.0]],\n                \"gates\": [[0.2, 0.8, 0.3, 0.2, 0.0]],\n            }\n\n            token_word_map = {\n                0: \"আমি\",\n                1: \"কল\",\n                2: \"বন্ধ\",\n                3: \"করেছি\",\n                4: \"।\",\n            }\n\n            self.eval()\n\n            explanations = self.process_sentence_for_explanations(\n                tokens=tokens,\n                dscd_outputs=dscd_outputs,\n                token_word_map=token_word_map,\n                max_explanations=3,\n            )\n\n            print(f\"  ✓ Generated {len(explanations)} explanations\")\n\n            if len(explanations) > 0:\n                for i, expl in enumerate(explanations, 1):\n                    print(\n                        f\"    {i}. '{expl['token']}' (u={expl['uncertainty']:.2f})\"\n                    )\n\n            stats = self.get_statistics()\n            print(f\"  ✓ Stats: {stats['explanations_generated']} total\")\n\n            self.reset_statistics()\n            stats_after = self.get_statistics()\n            assert stats_after[\"explanations_generated\"] == 0\n            print(\"  ✓ Reset OK\")\n\n            print(\"\\n✓ All TRG tests passed\")\n            print(\"=\" * 60 + \"\\n\")\n            return True\n\n        except Exception as e:\n            print(f\"\\n✗ Test failed: {e}\")\n            try:\n                traceback.print_exc()\n            except Exception:\n                pass\n            print(\"=\" * 60 + \"\\n\")\n            return False\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 5: TRG Module - VERIFIED CORRECT\")\nprint(\"=\" * 80)\nprint(\"Configuration:\")\nprint(f\"  - Uncertainty: ADAPTIVE (base={_TRG_UNCERTAINTY_THRESHOLD:.2f})\")\nprint(f\"  - Span: ADAPTIVE (base={_TRG_SPAN_THRESHOLD:.2f})\")\nprint(f\"  - Temperature: {_TRG_TEMPERATURE:.2f}\")\nprint(f\"  - TAU_HIGH: {_TAU_HIGH:.2f}\")\nprint(f\"  - TAU_LOW: {_TAU_LOW:.2f}\")\nprint(f\"  - TAU_ACCEPT: {_TAU_ACCEPT:.2f}\")\nprint(f\"  - Evidence K: {_TRG_EVIDENCE_K}\")\nprint(f\"  - Max Explanations: {_MAX_EXPLANATIONS_PER_SENTENCE}\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"svk-wKO7H4J3","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:04.443133Z","iopub.execute_input":"2026-02-18T08:40:04.443400Z","iopub.status.idle":"2026-02-18T08:40:04.551841Z","shell.execute_reply.started":"2026-02-18T08:40:04.443380Z","shell.execute_reply":"2026-02-18T08:40:04.551281Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCell 5: TRG Module - VERIFIED CORRECT\n================================================================================\nConfiguration:\n  - Uncertainty: ADAPTIVE (base=0.15)\n  - Span: ADAPTIVE (base=0.20)\n  - Temperature: 1.00\n  - TAU_HIGH: 0.85\n  - TAU_LOW: 0.15\n  - TAU_ACCEPT: 0.70\n  - Evidence K: 3\n  - Max Explanations: 10\n================================================================================\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 6: DUAL-PATH TATN MODEL - PATH 1 (WORD-LEVEL) + PATH 2 (SUBWORD-LEVEL)\n# ===========================================================================================\n\nfrom typing import List, Dict, Optional, Any, Tuple, Union\nimport traceback\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import MBartForConditionalGeneration\nfrom transformers.modeling_outputs import BaseModelOutput\nimport threading\nimport gc\nimport time\nimport re\n\ntry:\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\n    _TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, TypeError):\n    _SOURCE_LANGUAGE = \"bn\"\n    _TARGET_LANGUAGE = \"en\"\n\n\ndef _get_int_global(name: str, default: int) -> int:\n    try:\n        val = globals().get(name)\n        if val is not None:\n            return int(val)\n    except (ValueError, TypeError):\n        pass\n    return default\n\n\ndef _get_float_global(name: str, default: float) -> float:\n    try:\n        val = globals().get(name)\n        if val is not None:\n            return float(val)\n    except (ValueError, TypeError):\n        pass\n    return default\n\n\ndef _get_bool_global(name: str, default: bool) -> bool:\n    try:\n        val = globals().get(name)\n        if val is not None:\n            return bool(val)\n    except (ValueError, TypeError):\n        pass\n    return default\n\n\n_DSCD_BUFFER_SIZE = _get_int_global(\"DSCD_BUFFER_SIZE\", 20)\n_DSCD_MAX_PROTOS = _get_int_global(\"DSCD_MAX_PROTOS\", 3)\n_DSCD_N_MIN = _get_int_global(\"DSCD_N_MIN\", 3)\n_DSCD_DISPERSION_THRESHOLD = _get_float_global(\"DSCD_DISPERSION_THRESHOLD\", 0.20)\n\n_ENABLE_ASBN_TRAINING = _get_bool_global(\"ENABLE_ASBN_TRAINING\", False)\n_ENABLE_ASBN_INFERENCE = _get_bool_global(\"ENABLE_ASBN_INFERENCE\", False)\n_ENABLE_TRG_INFERENCE = _get_bool_global(\"ENABLE_TRG_INFERENCE\", True)\n_MEMORY_CLEANUP_FREQUENCY = _get_int_global(\"MEMORY_CLEANUP_FREQUENCY\", 100)\n\n_NUM_GPUS = _get_int_global(\n    \"NUM_GPUS\",\n    torch.cuda.device_count() if torch.cuda.is_available() else 1,\n)\n_USE_GC = _get_bool_global(\"GRADIENT_CHECKPOINTING\", True)\n_DSCD_ENABLE_TRAINING_CLUSTERING = _get_bool_global(\n    \"DSCD_ENABLE_TRAINING_CLUSTERING\", True\n)\n\n_LAMBDA_ASBN = _get_float_global(\"LAMBDA_ASBN\", 0.0)\n_LAMBDA_DSCD = _get_float_global(\"LAMBDA_DSCD\", 0.15)\n_LAMBDA_TOKEN = _get_float_global(\"LAMBDA_TOKEN\", 0.25)\n_LAMBDA_CONFIDENCE = _get_float_global(\"LAMBDA_CONFIDENCE\", 0.15)\n_LAMBDA_LENGTH = _get_float_global(\"LAMBDA_LENGTH\", 0.05)\n\n_VERBOSE_LOGGING = _get_bool_global(\"VERBOSE_LOGGING\", False)\n\ntry:\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept (NameError, TypeError):\n    _DEBUG_DISCOVERY = False\n\ntry:\n    _DEBUG_TIMING = bool(DEBUG_TIMING)\nexcept (NameError, TypeError):\n    _DEBUG_TIMING = False\n\n_PERIODIC_DISCOVERY_FREQUENCY = _get_int_global(\n    \"PERIODIC_DISCOVERY_FREQUENCY\", 50\n)\n_VALIDATION_CHECK_INTERVAL = _get_int_global(\"VALIDATION_CHECK_INTERVAL\", 200)\n\n_SPAN_THRESHOLD = _get_float_global(\"SPAN_THRESHOLD\", 0.20)\n_UNCERTAINTY_THRESHOLD = _get_float_global(\"UNCERTAINTY_THRESHOLD\", 0.15)\n\n_TRG_UNCERTAINTY_THRESHOLD = _get_float_global(\n    \"TRG_UNCERTAINTY_THRESHOLD\", _get_float_global(\"TAU_LOW\", 0.15)\n)\n_TAU_LOW = _get_float_global(\"TAU_LOW\", 0.15)\n\n_TRAIN_DOMAIN = _get_int_global(\"TRAIN_DOMAIN\", 0)\n_TEST_DOMAIN = _get_int_global(\"TEST_DOMAIN\", 1)\n_USE_DOMAIN_LABELS = _get_bool_global(\"USE_DOMAIN_LABELS\", True)\n\ntry:\n    _MBART50_EN_TOKEN_ID = int(MBART50_EN_TOKEN_ID)\nexcept (NameError, ValueError, TypeError):\n    _MBART50_EN_TOKEN_ID = 2\n\ntry:\n    _MBART50_BN_TOKEN_ID = int(MBART50_BN_TOKEN_ID)\nexcept (NameError, ValueError, TypeError):\n    _MBART50_BN_TOKEN_ID = 9\n\ntry:\n    _LABEL_SMOOTHING_EPS = float(LABEL_SMOOTHING_EPS)\nexcept (NameError, ValueError, TypeError):\n    _LABEL_SMOOTHING_EPS = 0.15\n\ntry:\n    _RDROP_ALPHA = float(RDROP_ALPHA)\nexcept (NameError, ValueError, TypeError):\n    _RDROP_ALPHA = 0.0\n\n_has_reconstruct_word_spans = \"reconstruct_word_spans\" in globals()\n\n_BENGALI_PUNCT_SET = set(['।', '॥'])\n_COMMON_PUNCT_SET = set(['.', ',', ';', ':', '!', '?', '\"', \"'\", '-', '(', ')', '[', ']', '{', '}', '/', '\\\\'])\n_PUNCT_SET = _BENGALI_PUNCT_SET | _COMMON_PUNCT_SET\n\n\ndef _is_punctuation_only(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n\n    clean = (\n        token.replace(\"▁\", \"\")\n        .replace(\"Ġ\", \"\")\n        .replace(\"##\", \"\")\n        .replace(\"</w>\", \"\")\n        .strip()\n    )\n\n    if not clean:\n        return False\n\n    if clean in _BENGALI_PUNCT_SET:\n        return True\n\n    if clean in _COMMON_PUNCT_SET:\n        return True\n\n    if len(clean) == 1 and not clean.isalnum():\n        return True\n\n    return all(c in _PUNCT_SET for c in clean)\n\n\ndef _safe_get_last_hidden_state(enc_output):\n    if enc_output is None:\n        return None\n    if hasattr(enc_output, \"last_hidden_state\"):\n        return enc_output.last_hidden_state\n    if isinstance(enc_output, (list, tuple)) and len(enc_output) > 0:\n        return enc_output[0]\n    return None\n\n\ndef build_token_word_map_sentencepiece(\n    token_strings: List[str], fallback: bool = True\n) -> Dict[int, str]:\n    word_map: Dict[int, str] = {}\n    current_word = \"\"\n    start_idx = None\n\n    for i, token in enumerate(token_strings):\n        if not token or token.startswith(\"<\") or token.startswith(\"[\"):\n            continue\n\n        if token.startswith(\"▁\"):\n            if current_word and start_idx is not None:\n                clean = current_word.replace(\"▁\", \"\").strip()\n                if clean and len(clean) >= 2 and not _is_punctuation_only(current_word):\n                    word_map[start_idx] = clean\n            current_word = token\n            start_idx = i\n        else:\n            current_word += token\n\n    if current_word and start_idx is not None:\n        clean = current_word.replace(\"▁\", \"\").strip()\n        if clean and len(clean) >= 2 and not _is_punctuation_only(current_word):\n            word_map[start_idx] = clean\n\n    if fallback and not word_map:\n        for i, tok in enumerate(token_strings):\n            clean = tok.replace(\"▁\", \"\").strip()\n            if clean and len(clean) >= 2 and not _is_punctuation_only(tok):\n                word_map[i] = clean\n\n    return word_map\n\n\nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, num_classes: int, smoothing: float = 0.1, ignore_index: int = -100):\n        super().__init__()\n        self.num_classes = num_classes\n        self.smoothing = smoothing\n        self.ignore_index = ignore_index\n        self.confidence = 1.0 - smoothing\n\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        if logits.dim() == 3:\n            logits = logits.reshape(-1, logits.size(-1))\n        if targets.dim() == 2:\n            targets = targets.reshape(-1)\n\n        mask = (targets != self.ignore_index)\n        targets = targets.masked_select(mask)\n        logits = logits[mask]\n\n        if targets.numel() == 0:\n            return torch.tensor(0.0, device=logits.device, requires_grad=True)\n\n        log_probs = F.log_softmax(logits, dim=-1)\n        nll_loss = -log_probs.gather(dim=-1, index=targets.unsqueeze(1)).squeeze(1)\n        smooth_loss = -log_probs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()\n\n\nclass RDropLoss(nn.Module):\n    def __init__(self, alpha: float = 5.0):\n        super().__init__()\n        self.alpha = alpha\n\n    def forward(\n        self, logits1: torch.Tensor, logits2: torch.Tensor, targets: torch.Tensor, ignore_index: int = -100\n    ) -> torch.Tensor:\n        if logits1.dim() == 3:\n            logits1 = logits1.reshape(-1, logits1.size(-1))\n        if logits2.dim() == 3:\n            logits2 = logits2.reshape(-1, logits2.size(-1))\n        if targets.dim() == 2:\n            targets = targets.reshape(-1)\n\n        mask = (targets != ignore_index)\n        logits1 = logits1[mask]\n        logits2 = logits2[mask]\n\n        if logits1.numel() == 0:\n            return torch.tensor(0.0, device=logits1.device, requires_grad=True)\n\n        p1 = F.log_softmax(logits1, dim=-1)\n        p2 = F.log_softmax(logits2, dim=-1)\n        p1_probs = F.softmax(logits1, dim=-1)\n        p2_probs = F.softmax(logits2, dim=-1)\n\n        kl_12 = F.kl_div(p1, p2_probs, reduction='batchmean', log_target=False)\n        kl_21 = F.kl_div(p2, p1_probs, reduction='batchmean', log_target=False)\n\n        kl_loss = (kl_12 + kl_21) / 2.0\n        return self.alpha * kl_loss\n\n\nclass SensePrototypeConditioning(nn.Module):\n    def __init__(self, embed_dim: int, num_prototypes: int = 3):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_prototypes = num_prototypes\n        self.conditioning_weight = nn.Parameter(torch.tensor(0.3))\n\n    def forward(\n        self,\n        h: torch.Tensor,\n        proto_probs: List[List[torch.Tensor]],\n        proto_assignments: List[torch.Tensor],\n        prototype_stores: Optional[Dict] = None,\n    ) -> torch.Tensor:\n        if prototype_stores is None or len(prototype_stores) == 0:\n            return h\n\n        batch_size, seq_len, embed_dim = h.shape\n        device = h.device\n        h_conditioned = h.clone()\n\n        try:\n            for b in range(batch_size):\n                for t in range(seq_len):\n                    if (\n                        b < len(proto_assignments)\n                        and t < proto_assignments[b].size(0)\n                        and proto_assignments[b][t].item() >= 0\n                    ):\n                        proto_idx = int(proto_assignments[b][t].item())\n                        \n                        if (\n                            b < len(proto_probs)\n                            and t < len(proto_probs[b])\n                            and isinstance(proto_probs[b][t], torch.Tensor)\n                            and proto_probs[b][t].numel() > proto_idx\n                        ):\n                            weight = float(proto_probs[b][t][proto_idx].item())\n                            conditioning = self.conditioning_weight * weight\n                            h_conditioned[b, t] = h[b, t] * (1.0 - conditioning) + h[b, t] * conditioning\n        except Exception:\n            pass\n\n        return h_conditioned\n\n\nclass AdaptiveSenseGating(nn.Module):\n    def __init__(self, embed_dim: int):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.gate_network = nn.Sequential(\n            nn.Linear(embed_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(\n        self,\n        h: torch.Tensor,\n        uncertainties: List[List[torch.Tensor]],\n        gates: List[List[torch.Tensor]],\n    ) -> torch.Tensor:\n        batch_size, seq_len, embed_dim = h.shape\n        device = h.device\n\n        try:\n            gate_values = torch.zeros(batch_size, seq_len, 1, device=device)\n\n            for b in range(batch_size):\n                for t in range(seq_len):\n                    if b < len(gates) and t < len(gates[b]):\n                        try:\n                            g_val = float(gates[b][t].item()) if isinstance(gates[b][t], torch.Tensor) else float(gates[b][t])\n                            gate_values[b, t, 0] = g_val\n                        except Exception:\n                            gate_values[b, t, 0] = 0.0\n\n            adaptive_gates = self.gate_network(h)\n            combined_gates = 0.5 * gate_values + 0.5 * adaptive_gates\n            h_gated = h * combined_gates\n\n            return h_gated\n        except Exception:\n            return h\n\n\ndef _normalize_dscd_outputs(\n    raw: Dict[str, Any],\n    batch_size: int,\n    seq_len: int,\n    device: torch.device,\n    embed_dim: int,\n    fallback_h: Optional[torch.Tensor] = None,\n) -> Dict[str, Any]:\n    if fallback_h is None:\n        fallback_h_augmented = torch.zeros(\n            batch_size, seq_len, embed_dim, device=device, dtype=torch.float32\n        )\n    else:\n        fallback_h_augmented = fallback_h.detach().clone()\n\n    defaults = {\n        \"h_augmented\": fallback_h_augmented,\n        \"proto_probs\": [\n            [\n                torch.tensor([1.0], device=device, dtype=torch.float32)\n                for _ in range(seq_len)\n            ]\n            for _ in range(batch_size)\n        ],\n        \"uncertainties\": [\n            [\n                torch.tensor(0.0, device=device, dtype=torch.float32)\n                for _ in range(seq_len)\n            ]\n            for _ in range(batch_size)\n        ],\n        \"gates\": [\n            [\n                torch.tensor(0.0, device=device, dtype=torch.float32)\n                for _ in range(seq_len)\n            ]\n            for _ in range(batch_size)\n        ],\n        \"span_preds\": [\n            [\n                torch.tensor(0.0, device=device, dtype=torch.float32)\n                for _ in range(seq_len)\n            ]\n            for _ in range(batch_size)\n        ],\n        \"proto_assignments\": [\n            torch.zeros(seq_len, dtype=torch.long, device=device)\n            for _ in range(batch_size)\n        ],\n    }\n\n    if not isinstance(raw, dict):\n        return defaults\n\n    out = defaults.copy()\n\n    try:\n        if \"h_augmented\" in raw and raw[\"h_augmented\"] is not None:\n            h = raw[\"h_augmented\"]\n            if isinstance(h, torch.Tensor) and h.shape == (\n                batch_size,\n                seq_len,\n                embed_dim,\n            ):\n                out[\"h_augmented\"] = h.to(device)\n            else:\n                try:\n                    out[\"h_augmented\"] = (\n                        h.to(device).reshape(batch_size, seq_len, embed_dim)\n                    )\n                except Exception:\n                    out[\"h_augmented\"] = fallback_h_augmented\n    except Exception:\n        out[\"h_augmented\"] = fallback_h_augmented\n\n    for list_key in (\"proto_probs\", \"uncertainties\", \"gates\", \"span_preds\"):\n        if list_key in raw and raw[list_key] is not None:\n            try:\n                val = raw[list_key]\n                if isinstance(val, list) and len(val) == batch_size:\n                    safe_batch = []\n                    for b_row in val:\n                        if isinstance(b_row, list):\n                            safe_row = []\n                            for t_idx in range(seq_len):\n                                try:\n                                    if t_idx < len(b_row):\n                                        v = b_row[t_idx]\n                                        if isinstance(v, torch.Tensor):\n                                            safe_row.append(v.detach().to(device))\n                                        else:\n                                            safe_row.append(\n                                                torch.as_tensor(\n                                                    v,\n                                                    device=device,\n                                                    dtype=torch.float32,\n                                                )\n                                            )\n                                    else:\n                                        if list_key == \"proto_probs\":\n                                            safe_row.append(\n                                                torch.tensor(\n                                                    [1.0],\n                                                    device=device,\n                                                    dtype=torch.float32,\n                                                )\n                                            )\n                                        else:\n                                            safe_row.append(\n                                                torch.tensor(\n                                                    0.0,\n                                                    device=device,\n                                                    dtype=torch.float32,\n                                                )\n                                            )\n                                except Exception:\n                                    safe_row.append(\n                                        torch.tensor(\n                                            0.0,\n                                            device=device,\n                                            dtype=torch.float32,\n                                        )\n                                    )\n                            safe_batch.append(safe_row)\n                        else:\n                            if list_key == \"proto_probs\":\n                                safe_batch.append(\n                                    [\n                                        torch.tensor(\n                                            [1.0],\n                                            device=device,\n                                            dtype=torch.float32,\n                                        )\n                                        for _ in range(seq_len)\n                                    ]\n                                )\n                            else:\n                                safe_batch.append(\n                                    [\n                                        torch.tensor(\n                                            0.0,\n                                            device=device,\n                                            dtype=torch.float32,\n                                        )\n                                        for _ in range(seq_len)\n                                    ]\n                                )\n                    out[list_key] = safe_batch\n            except Exception:\n                pass\n\n    try:\n        if \"proto_assignments\" in raw and raw[\"proto_assignments\"] is not None:\n            pa = raw[\"proto_assignments\"]\n            if isinstance(pa, list) and len(pa) == batch_size:\n                safe_pa = []\n                for b_row in pa:\n                    try:\n                        if isinstance(b_row, torch.Tensor):\n                            safe_pa.append(b_row.detach().to(device).long())\n                        else:\n                            safe_pa.append(\n                                torch.tensor(\n                                    b_row, dtype=torch.long, device=device\n                                )\n                            )\n                    except Exception:\n                        safe_pa.append(\n                            torch.zeros(seq_len, dtype=torch.long, device=device)\n                        )\n                out[\"proto_assignments\"] = safe_pa\n    except Exception:\n        pass\n\n    return out\n\n\ndef _norm_scalar_matrix(uncertainties, gates, gate_threshold=0.01):\n    final_normalized = []\n    batch_size = len(uncertainties)\n\n    for b in range(batch_size):\n        u_row = uncertainties[b]\n        g_row = gates[b]\n        seq_len = len(u_row)\n\n        safe_row = []\n        for t in range(seq_len):\n            try:\n                u_val = float(u_row[t]) if t < len(u_row) else 0.0\n                g_val = float(g_row[t]) if t < len(g_row) else 0.0\n\n                if g_val < gate_threshold:\n                    norm_val = 0.0\n                else:\n                    norm_val = max(0.0, min(1.0, u_val))\n\n                safe_row.append(norm_val)\n            except Exception:\n                safe_row.append(0.0)\n\n        final_normalized.append(safe_row)\n\n    return final_normalized\n\n\ndef _norm_proto_probs(proto_probs):\n    return [\n        [pp if isinstance(pp, torch.Tensor) else torch.tensor([1.0]) for pp in row]\n        for row in proto_probs\n    ]\n\n\ndef _to_vec(x):\n    if isinstance(x, torch.Tensor):\n        return x.flatten().tolist()\n    elif isinstance(x, (list, tuple)):\n        return list(x)\n    elif isinstance(x, (int, float)):\n        return [float(x)]\n    else:\n        return [0.0]\n\n\ndef _extract_words_from_text(text: str) -> List[str]:\n    if not text or not isinstance(text, str):\n        return []\n\n    text = text.strip()\n    if not text:\n        return []\n\n    try:\n        words = re.findall(r'[\\u0980-\\u09FF]+|[a-zA-Z]+|\\d+', text)\n        words = [w for w in words if w and len(w) > 0 and not _is_punctuation_only(w)]\n        return words if words else []\n    except Exception:\n        return []\n\n\nclass MemoryOptimizedTATNWithExplanations(nn.Module):\n    def __init__(self, tokenizer):\n        super().__init__()\n        self.tokenizer = tokenizer\n\n        self.global_step = 0\n        self._step_lock = threading.Lock()\n        self.last_discovery_step = 0\n        self.last_validation_step = 0\n\n        self.mbart = MBartForConditionalGeneration.from_pretrained(\n            \"facebook/mbart-large-50-many-to-one-mmt\",\n            torch_dtype=torch.float32,\n            use_cache=False,\n        )\n        try:\n            self.mbart.config.use_cache = False\n        except Exception:\n            pass\n\n        tokenizer_vocab_size = len(self.tokenizer) if hasattr(self.tokenizer, \"__len__\") else getattr(self.tokenizer, \"vocab_size\", 250054)\n        model_vocab_size = int(getattr(self.mbart.config, \"vocab_size\", 250054))\n\n        if tokenizer_vocab_size != model_vocab_size:\n            print(f\"[TATN-INIT] ⚠️  Vocab size mismatch detected!\")\n            print(f\"  Tokenizer: {tokenizer_vocab_size}\")\n            print(f\"  Model: {model_vocab_size}\")\n\n            if tokenizer_vocab_size < model_vocab_size:\n                print(f\"[TATN-INIT] ✅ Using model's vocab size ({model_vocab_size})\")\n                print(f\"[TATN-INIT] Note: Tokenizer has {model_vocab_size - tokenizer_vocab_size} fewer tokens\")\n                print(f\"[TATN-INIT] Model embeddings preserved (no resize)\")\n                self.vocab_size = model_vocab_size\n            else:\n                print(f\"[TATN-INIT] ❌ ERROR: Tokenizer vocab ({tokenizer_vocab_size}) > Model vocab ({model_vocab_size})\")\n                raise RuntimeError(\n                    f\"Tokenizer has more tokens than model!\\n\"\n                    f\"  Tokenizer: {tokenizer_vocab_size}\\n\"\n                    f\"  Model: {model_vocab_size}\"\n                )\n        else:\n            print(f\"[TATN-INIT] ✅ Vocab sizes match: {model_vocab_size}\")\n            self.vocab_size = model_vocab_size\n\n        try:\n            if hasattr(self.tokenizer, \"get_lang_id\"):\n                en_token_id = self.tokenizer.get_lang_id(_TARGET_LANGUAGE)\n                bn_token_id = self.tokenizer.get_lang_id(_SOURCE_LANGUAGE)\n            elif hasattr(self.tokenizer, \"lang_code_to_id\"):\n                en_token_id = self.tokenizer.lang_code_to_id.get(\n                    _TARGET_LANGUAGE, _MBART50_EN_TOKEN_ID\n                )\n                bn_token_id = self.tokenizer.lang_code_to_id.get(\n                    _SOURCE_LANGUAGE, _MBART50_BN_TOKEN_ID\n                )\n            else:\n                en_token_id = _MBART50_EN_TOKEN_ID\n                bn_token_id = _MBART50_BN_TOKEN_ID\n\n            if en_token_id >= self.vocab_size or bn_token_id >= self.vocab_size:\n                raise ValueError(\n                    f\"Language token IDs out of vocabulary bounds!\\n\"\n                    f\"  EN token: {en_token_id} (vocab: {self.vocab_size})\\n\"\n                    f\"  BN token: {bn_token_id} (vocab: {self.vocab_size})\"\n                )\n\n            self.mbart.config.decoder_start_token_id = int(en_token_id)\n            self.mbart.config.forced_bos_token_id = None\n            self.en_token_id = int(en_token_id)\n            self.bn_token_id = int(bn_token_id)\n\n            if _DEBUG_DISCOVERY:\n                print(\n                    f\"[TATN-INIT] Language tokens: BN={bn_token_id}, EN={en_token_id}\"\n                )\n                print(f\"[TATN-INIT] ✅ Disabled forced_bos_token_id to prevent double BOS\")\n                if bn_token_id != _MBART50_BN_TOKEN_ID or en_token_id != _MBART50_EN_TOKEN_ID:\n                    print(f\"[TATN-INIT] ⚠️  Token IDs differ from Cell 0 defaults:\")\n                    print(f\"  Expected: BN={_MBART50_BN_TOKEN_ID}, EN={_MBART50_EN_TOKEN_ID}\")\n                    print(f\"  Got: BN={bn_token_id}, EN={en_token_id}\")\n\n        except Exception as e:\n            if _DEBUG_DISCOVERY:\n                print(f\"[TATN-INIT] Failed to set language tokens: {e}\")\n            raise RuntimeError(f\"Language token setup failed: {e}\")\n\n        try:\n            if _USE_GC and hasattr(self.mbart, \"gradient_checkpointing_enable\"):\n                self.mbart.gradient_checkpointing_enable()\n        except Exception:\n            pass\n\n        embed_dim = int(getattr(self.mbart.config, \"d_model\", 1024))\n\n        if _DEBUG_DISCOVERY:\n            print(f\"[TATN-INIT] Model embed_dim: {embed_dim}\")\n\n        dscd_cls = globals().get(\"MemoryEfficientDSCDOnline\", None)\n        if callable(dscd_cls):\n            try:\n                self.dscd = dscd_cls(\n                    embed_dim=embed_dim,\n                    tokenizer=tokenizer,\n                    buffer_size=_DSCD_BUFFER_SIZE,\n                    max_protos=_DSCD_MAX_PROTOS,\n                    n_min=_DSCD_N_MIN,\n                    language=_SOURCE_LANGUAGE,\n                    dispersion_threshold=_DSCD_DISPERSION_THRESHOLD,\n                    enable_training_clustering=_DSCD_ENABLE_TRAINING_CLUSTERING,\n                    max_clustering_points=500,\n                    max_candidates_per_step=1,\n                )\n\n                dscd_embed_dim = getattr(self.dscd, \"embed_dim\", None)\n                if dscd_embed_dim is not None and dscd_embed_dim != embed_dim:\n                    raise RuntimeError(\n                        f\"DSCD embed_dim mismatch! Expected {embed_dim}, got {dscd_embed_dim}\"\n                    )\n\n            except Exception as e:\n                raise RuntimeError(\n                    f\"Failed to instantiate MemoryEfficientDSCDOnline: {e}\"\n                )\n        else:\n            raise RuntimeError(\"MemoryEfficientDSCDOnline not found in globals()\")\n\n        asbn_cls = globals().get(\"MemoryEfficientASBNModule\", None)\n        if callable(asbn_cls):\n            try:\n                self.asbn = asbn_cls(\n                    embed_dim, tokenizer, language=_SOURCE_LANGUAGE\n                )\n\n                asbn_embed_dim = getattr(self.asbn, \"embed_dim\", None)\n                if asbn_embed_dim is not None and asbn_embed_dim != embed_dim:\n                    raise RuntimeError(\n                        f\"ASBN embed_dim mismatch! Expected {embed_dim}, got {asbn_embed_dim}\"\n                    )\n\n            except Exception as e:\n                print(f\"[TATN-INIT] ASBN init failed: {e}, using stub\")\n                self.asbn = self._build_stub_asbn()\n        else:\n            self.asbn = self._build_stub_asbn()\n\n        trg_cls = globals().get(\"CompleteTRGWithExplanations\", None)\n        if callable(trg_cls):\n            try:\n                self.trg = trg_cls(\n                    embed_dim,\n                    tokenizer,\n                    language=_SOURCE_LANGUAGE,\n                    dscd_module=self.dscd,\n                )\n            except Exception as e:\n                print(f\"[TATN-INIT] TRG init failed: {e}, using stub\")\n                self.trg = self._build_stub_trg()\n        else:\n            self.trg = self._build_stub_trg()\n\n        try:\n            self.label_smoothing_loss = LabelSmoothingLoss(\n                num_classes=self.vocab_size,\n                smoothing=_LABEL_SMOOTHING_EPS,\n                ignore_index=-100\n            )\n        except Exception as e:\n            print(f\"[TATN-INIT] LabelSmoothingLoss init failed: {e}, using None\")\n            self.label_smoothing_loss = None\n\n        try:\n            self.rdrop_loss = RDropLoss(alpha=_RDROP_ALPHA)\n        except Exception as e:\n            print(f\"[TATN-INIT] RDropLoss init failed: {e}, using None\")\n            self.rdrop_loss = None\n\n        try:\n            self.sense_conditioning = SensePrototypeConditioning(\n                embed_dim=embed_dim,\n                num_prototypes=_DSCD_MAX_PROTOS\n            )\n        except Exception as e:\n            print(f\"[TATN-INIT] SensePrototypeConditioning init failed: {e}, using None\")\n            self.sense_conditioning = None\n\n        try:\n            self.adaptive_gating = AdaptiveSenseGating(embed_dim=embed_dim)\n        except Exception as e:\n            print(f\"[TATN-INIT] AdaptiveSenseGating init failed: {e}, using None\")\n            self.adaptive_gating = None\n\n        embedding_layer = self.mbart.get_input_embeddings()\n        if embedding_layer is None:\n            raise RuntimeError(\"Model has no input embeddings layer!\")\n\n        actual_embed_dim = embedding_layer.embedding_dim\n        if actual_embed_dim != embed_dim:\n            raise RuntimeError(\n                f\"Embedding dimension mismatch! Config says {embed_dim}, \"\n                f\"but embedding layer has {actual_embed_dim}\"\n            )\n\n        if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n            print(\"[TATN-INIT] Initialized DUAL-PATH MemoryOptimizedTATNWithExplanations:\")\n            print(f\"  - Embed dim: {embed_dim}\")\n            print(f\"  - Vocab size: {self.vocab_size}\")\n            print(f\"  - Tokenizer vocab: {tokenizer_vocab_size}\")\n            print(f\"  - BN token: {self.bn_token_id}\")\n            print(f\"  - EN token: {self.en_token_id}\")\n            print(f\"  - DSCD buffer: {_DSCD_BUFFER_SIZE}\")\n            print(f\"  - DSCD n_min: {_DSCD_N_MIN}\")\n            print(f\"  - DSCD threshold: {_DSCD_DISPERSION_THRESHOLD}\")\n            print(f\"  - Discovery frequency: {_PERIODIC_DISCOVERY_FREQUENCY}\")\n            print(f\"  - Validation interval: {_VALIDATION_CHECK_INTERVAL}\")\n            print(f\"  - Lambda ASBN: {_LAMBDA_ASBN}\")\n            print(f\"  - Lambda DSCD: {_LAMBDA_DSCD}\")\n            print(f\"  - Lambda Token: {_LAMBDA_TOKEN}\")\n            print(f\"  - Lambda Confidence: {_LAMBDA_CONFIDENCE}\")\n            print(f\"  - Lambda Length: {_LAMBDA_LENGTH}\")\n            print(f\"  - Label Smoothing ε: {_LABEL_SMOOTHING_EPS}\")\n            print(f\"  - R-Drop α: {_RDROP_ALPHA}\")\n            print(f\"  - ASBN Training: {'DISABLED' if not _ENABLE_ASBN_TRAINING else 'ENABLED'}\")\n            print(f\"  - ASBN Inference: {'DISABLED' if not _ENABLE_ASBN_INFERENCE else 'ENABLED'}\")\n            print(f\"  - Path 1 (DSCD): WORD-level → DSCD → ASBN → NO decoder\")\n            print(f\"  - Path 2 (Translation): SUBWORD → Full MBART + LabelSmoothing + R-Drop\")\n            print(f\"  ✅ NEW: SensePrototypeConditioning enabled\")\n            print(f\"  ✅ NEW: AdaptiveSenseGating enabled\")\n\n    def _build_stub_asbn(self):\n        class _StubASBN(nn.Module):\n            def forward(self, h, **kwargs):\n                dev = h.device if isinstance(h, torch.Tensor) else torch.device(\"cpu\")\n                zero = torch.tensor(0.0, device=dev, requires_grad=True)\n                return h, {\n                    \"encoder_loss\": zero,\n                    \"adversarial_loss\": zero,\n                    \"domain_loss\": zero,\n                    \"domain_accuracy\": zero,\n                }\n\n            def critic_parameters(self):\n                return []\n\n            def reset_stats(self):\n                pass\n\n            def get_detailed_stats(self):\n                return {\n                    \"domain_loss\": 0.0,\n                    \"domain_accuracy\": 0.0,\n                    \"source_accuracy\": 0.0,\n                    \"target_accuracy\": 0.0,\n                    \"asbn_loss\": 0.0,\n                    \"num_updates\": 0,\n                }\n\n            def get_asbn_stats(self):\n                return self.get_detailed_stats()\n\n        return _StubASBN()\n\n    def _build_stub_trg(self):\n        class _StubTRG:\n            def process_sentence_for_explanations(self, *args, **kwargs):\n                return []\n\n            def get_statistics(self):\n                return {}\n\n            def reset_statistics(self):\n                pass\n\n        return _StubTRG()\n\n    @staticmethod\n    def _entropy_reg_from_proto_probs_static(\n        proto_probs_list, gates_list=None, min_gate: float = 0.01\n    ) -> torch.Tensor:\n        if not proto_probs_list or not isinstance(proto_probs_list, list):\n            return torch.tensor(0.0)\n\n        dev = None\n        for row in proto_probs_list:\n            if isinstance(row, list):\n                for p in row:\n                    if isinstance(p, torch.Tensor):\n                        dev = p.device\n                        break\n            if dev is not None:\n                break\n\n        if dev is None:\n            return torch.tensor(0.0)\n\n        total = torch.tensor(0.0, device=dev)\n        count = 0\n\n        for b, row in enumerate(proto_probs_list):\n            if not isinstance(row, list):\n                continue\n            gl = gates_list[b] if (gates_list and b < len(gates_list)) else None\n            for j, probs in enumerate(row):\n                if not isinstance(probs, torch.Tensor) or probs.numel() == 0:\n                    continue\n                if gl and j < len(gl):\n                    try:\n                        if float(gl[j]) < min_gate:\n                            continue\n                    except Exception:\n                        pass\n\n                try:\n                    p = torch.clamp(probs.to(dev).float(), 1e-8, 1.0)\n                    H = -torch.sum(p * torch.log(p))\n                    if torch.isfinite(H):\n                        total = total + H\n                        count += 1\n                except Exception:\n                    continue\n\n        if count == 0:\n            return torch.tensor(0.0, device=dev)\n        return total / count\n\n    def _extract_word_embeddings(\n        self,\n        src_texts: List[str],\n        device: torch.device,\n        embed_dim: int,\n    ) -> Tuple[torch.Tensor, List[Dict[int, str]], List[List[str]]]:\n\n        batch_size = len(src_texts)\n        word_embeddings_batch = []\n        token_word_map_batch = []\n        words_batch = []\n        max_words = 0\n\n        try:\n            embedding_layer = self.mbart.get_input_embeddings()\n        except Exception:\n            fallback_embs = torch.zeros(batch_size, 1, embed_dim, device=device)\n            fallback_maps = [{0: \"UNK\"} for _ in range(batch_size)]\n            fallback_words = [[\"UNK\"] for _ in range(batch_size)]\n            return fallback_embs, fallback_maps, fallback_words\n\n        for batch_idx, text in enumerate(src_texts):\n            if not text or not isinstance(text, str):\n                text = \"UNK\"\n\n            text = text.strip()\n            if not text:\n                text = \"UNK\"\n\n            words = _extract_words_from_text(text)\n\n            if not words or len(words) == 0:\n                words = [\"UNK\"]\n\n            words_batch.append(words)\n            word_embeddings = []\n            word_map = {}\n\n            for idx, word in enumerate(words):\n                try:\n                    if not word or len(word) == 0:\n                        word = \"UNK\"\n\n                    word_ids = self.tokenizer.encode(word, add_special_tokens=False)\n\n                    if not word_ids or len(word_ids) == 0:\n                        word_ids = [3]\n\n                    word_ids = [wid for wid in word_ids if 0 <= wid < self.vocab_size]\n\n                    if not word_ids:\n                        word_ids = [3]\n\n                    word_ids_tensor = torch.tensor([word_ids], dtype=torch.long, device=device)\n\n                    subword_embs = embedding_layer(word_ids_tensor)\n\n                    word_emb = subword_embs.mean(dim=1).squeeze(0)\n\n                    if torch.isnan(word_emb).any() or torch.isinf(word_emb).any():\n                        word_emb = torch.zeros(embed_dim, device=device)\n\n                    word_embeddings.append(word_emb)\n                    word_map[idx] = word\n\n                except Exception as e:\n                    fallback_emb = torch.zeros(embed_dim, device=device)\n                    word_embeddings.append(fallback_emb)\n                    word_map[idx] = word if word else \"UNK\"\n\n            if word_embeddings and len(word_embeddings) > 0:\n                try:\n                    word_embs_tensor = torch.stack(word_embeddings, dim=0)\n                    word_embeddings_batch.append(word_embs_tensor)\n                    token_word_map_batch.append(word_map)\n                    max_words = max(max_words, len(word_embeddings))\n                except Exception:\n                    fallback_emb = torch.zeros(1, embed_dim, device=device)\n                    word_embeddings_batch.append(fallback_emb)\n                    token_word_map_batch.append({0: \"UNK\"})\n                    max_words = max(max_words, 1)\n            else:\n                fallback_emb = torch.zeros(1, embed_dim, device=device)\n                word_embeddings_batch.append(fallback_emb)\n                token_word_map_batch.append({0: \"UNK\"})\n                max_words = max(max_words, 1)\n\n        if max_words == 0:\n            max_words = 1\n\n        try:\n            padded_word_embs = torch.zeros(batch_size, max_words, embed_dim, device=device)\n\n            for i, word_embs in enumerate(word_embeddings_batch):\n                try:\n                    length = word_embs.size(0)\n                    if length > max_words:\n                        length = max_words\n                    padded_word_embs[i, :length] = word_embs[:length]\n                except Exception:\n                    pass\n        except Exception:\n            padded_word_embs = torch.zeros(batch_size, 1, embed_dim, device=device)\n\n        return padded_word_embs, token_word_map_batch, words_batch\n\n    def _reconstruct_word_maps_before_dscd(\n        self,\n        input_ids: torch.Tensor,\n        batch_size: int,\n        seq_len: int,\n        src_texts: Optional[List[str]] = None,\n        token_word_map: Optional[List[dict]] = None,\n    ) -> List[dict]:\n        if token_word_map is not None and len(token_word_map) == batch_size:\n            valid_count = sum(\n                1 for m in token_word_map if isinstance(m, dict) and len(m) > 0\n            )\n            if valid_count == batch_size:\n                if _DEBUG_DISCOVERY:\n                    total_words = sum(len(m) for m in token_word_map)\n                    print(\n                        f\"[TATN-WORDMAP] Using provided word maps: {total_words} words\"\n                    )\n                return token_word_map\n\n        word_maps_batch: List[dict] = []\n\n        for b in range(batch_size):\n            try:\n                ids_b = input_ids[b].detach().cpu().tolist()\n                tokens = self.tokenizer.convert_ids_to_tokens(ids_b)\n                wm = build_token_word_map_sentencepiece(tokens, fallback=True)\n                if wm:\n                    word_maps_batch.append(wm)\n                else:\n                    word_maps_batch.append(\n                        {i: f\"tok{i}\" for i in range(min(5, seq_len))}\n                    )\n            except Exception:\n                word_maps_batch.append(\n                    {i: f\"tok{i}\" for i in range(min(5, seq_len))}\n                )\n\n        total_words = sum(len(m) for m in word_maps_batch)\n        if _DEBUG_DISCOVERY:\n            print(f\"[TATN-WORDMAP] Reconstructed {total_words} words\")\n\n        return word_maps_batch\n\n    def _extract_domain_labels(\n        self,\n        batch_size: int,\n        device: torch.device,\n        src_texts: Optional[List[str]] = None,\n    ) -> Optional[torch.Tensor]:\n        if not _USE_DOMAIN_LABELS:\n            return None\n\n        try:\n            if self.training:\n                return torch.full(\n                    (batch_size,),\n                    _TRAIN_DOMAIN,\n                    dtype=torch.long,\n                    device=device,\n                )\n            else:\n                return torch.full(\n                    (batch_size,),\n                    _TEST_DOMAIN,\n                    dtype=torch.long,\n                    device=device,\n                )\n        except Exception:\n            return None\n\n    @staticmethod\n    def _safe_take_key_static(\n        dscd_struct: Dict[str, Any],\n        key: str,\n        b_index: int,\n        seq_len: int,\n        device: torch.device,\n    ):\n        if key == \"proto_probs\":\n            out = [\n                torch.tensor([1.0], dtype=torch.float32, device=device)\n                for _ in range(seq_len)\n            ]\n        else:\n            out = [\n                torch.tensor(0.0, dtype=torch.float32, device=device)\n                for _ in range(seq_len)\n            ]\n\n        try:\n            val = dscd_struct.get(key, None)\n            if val is None:\n                return out\n\n            if key == \"proto_probs\":\n                if isinstance(val, list) and len(val) > b_index:\n                    row = val[b_index]\n                    if isinstance(row, list):\n                        for t in range(min(seq_len, len(row))):\n                            v = row[t]\n                            if isinstance(v, torch.Tensor):\n                                out[t] = v.detach().to(device)\n                            else:\n                                try:\n                                    out[t] = torch.as_tensor(\n                                        v,\n                                        dtype=torch.float32,\n                                        device=device,\n                                    ).flatten()\n                                except Exception:\n                                    pass\n                return out\n\n            if isinstance(val, list) and len(val) > b_index:\n                row = val[b_index]\n                if isinstance(row, list):\n                    for t in range(min(seq_len, len(row))):\n                        v = row[t]\n                        try:\n                            if isinstance(v, torch.Tensor):\n                                out[t] = v.detach().to(device)\n                            else:\n                                out[t] = torch.tensor(\n                                    float(v), device=device\n                                )\n                        except Exception:\n                            pass\n                elif isinstance(row, torch.Tensor):\n                    if row.dim() == 1:\n                        for t in range(min(seq_len, int(row.size(0)))):\n                            try:\n                                out[t] = torch.tensor(\n                                    float(row[t].item()), device=device\n                                )\n                            except Exception:\n                                pass\n                return out\n\n            if isinstance(val, torch.Tensor):\n                if val.dim() >= 2 and int(val.size(0)) > b_index:\n                    for t in range(min(seq_len, int(val.size(1)))):\n                        try:\n                            if val.dim() == 3:\n                                v = val[b_index, t]\n                                if v.numel() == 1:\n                                    out[t] = torch.tensor(\n                                        float(v.item()), device=device\n                                    )\n                                else:\n                                    out[t] = v.detach().to(device)\n                            else:\n                                v = val[b_index, t]\n                                out[t] = torch.tensor(\n                                    float(v.item()), device=device\n                                )\n                        except Exception:\n                            pass\n        except Exception:\n            pass\n\n        return out\n\n    def forward_path1(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        src_texts: Optional[List[str]] = None,\n        token_word_map: Optional[List[dict]] = None,\n        domain_labels: Optional[torch.Tensor] = None,\n    ) -> torch.Tensor:\n        with self._step_lock:\n            self.global_step += 1\n            current_step = self.global_step\n\n        if input_ids is None or attention_mask is None:\n            raise ValueError(\"input_ids and attention_mask cannot be None\")\n\n        batch_size, seq_len = int(input_ids.size(0)), int(input_ids.size(1))\n        device = input_ids.device\n        embed_dim = int(getattr(self.mbart.config, \"d_model\", 1024))\n\n        if src_texts is None or not isinstance(src_texts, list) or len(src_texts) != batch_size:\n            src_texts_extracted = []\n            for b in range(batch_size):\n                try:\n                    ids_b = input_ids[b].detach().cpu().tolist()\n                    text = self.tokenizer.decode(ids_b, skip_special_tokens=True)\n                    if not text or not text.strip():\n                        text = \"UNK\"\n                    src_texts_extracted.append(text.strip())\n                except Exception:\n                    src_texts_extracted.append(\"UNK\")\n            src_texts = src_texts_extracted\n\n        for i in range(len(src_texts)):\n            if not src_texts[i] or not isinstance(src_texts[i], str) or not src_texts[i].strip():\n                src_texts[i] = \"UNK\"\n\n        try:\n            h, token_word_map, words_batch = self._extract_word_embeddings(\n                src_texts, device, embed_dim\n            )\n        except Exception as e:\n            h = torch.zeros(batch_size, 1, embed_dim, device=device)\n            token_word_map = [{0: \"UNK\"} for _ in range(batch_size)]\n            words_batch = [[\"UNK\"] for _ in range(batch_size)]\n\n        max_words = h.size(1)\n\n        try:\n            h_detached = h.detach()\n            raw_dscd = self.dscd.forward(\n                h_detached,\n                token_types=None,\n                train_mode=self.training,\n                input_ids=None,\n                attention_mask=None,\n                token_word_map=token_word_map,\n            )\n        except Exception as e:\n            raw_dscd = {\n                \"h_augmented\": h.detach().clone(),\n                \"proto_probs\": [\n                    [\n                        torch.tensor([1.0], dtype=torch.float32, device=device)\n                        for _ in range(max_words)\n                    ]\n                    for _ in range(batch_size)\n                ],\n                \"uncertainties\": [\n                    [torch.tensor(0.0, device=device) for _ in range(max_words)]\n                    for _ in range(batch_size)\n                ],\n                \"gates\": [\n                    [torch.tensor(0.0, device=device) for _ in range(max_words)]\n                    for _ in range(batch_size)\n                ],\n            }\n\n        try:\n            dscd = _normalize_dscd_outputs(\n                raw_dscd, batch_size, max_words, device, embed_dim, fallback_h=h\n            )\n        except Exception:\n            dscd = {\n                \"h_augmented\": h.detach().clone(),\n                \"proto_probs\": [\n                    [torch.tensor([1.0], device=device) for _ in range(max_words)]\n                    for _ in range(batch_size)\n                ],\n                \"uncertainties\": [\n                    [torch.tensor(0.0, device=device) for _ in range(max_words)]\n                    for _ in range(batch_size)\n                ],\n                \"gates\": [\n                    [torch.tensor(0.0, device=device) for _ in range(max_words)]\n                    for _ in range(batch_size)\n                ],\n                \"proto_assignments\": [\n                    torch.zeros(max_words, dtype=torch.long, device=device)\n                    for _ in range(batch_size)\n                ],\n            }\n\n        h_aug = dscd.get(\"h_augmented\", h)\n\n        if self.sense_conditioning is not None:\n            try:\n                h_aug = self.sense_conditioning(\n                    h_aug,\n                    proto_probs=dscd.get(\"proto_probs\", []),\n                    proto_assignments=dscd.get(\"proto_assignments\", []),\n                    prototype_stores=getattr(self.dscd, 'prototype_stores', None)\n                )\n            except Exception:\n                pass\n\n        if self.adaptive_gating is not None:\n            try:\n                h_aug = self.adaptive_gating(\n                    h_aug,\n                    uncertainties=dscd.get(\"uncertainties\", []),\n                    gates=dscd.get(\"gates\", [])\n                )\n            except Exception:\n                pass\n\n        if domain_labels is None:\n            domain_labels = self._extract_domain_labels(batch_size=batch_size, device=device, src_texts=src_texts)\n\n        asbn_loss = torch.zeros(1, device=device, requires_grad=True)\n        if self.training and _ENABLE_ASBN_TRAINING and domain_labels is not None:\n            try:\n                h_asbn, asbn_losses = self.asbn.forward(\n                    h_aug,\n                    proto_probs=dscd.get(\"proto_probs\", None),\n                    uncertainties=dscd.get(\"uncertainties\", None),\n                    gates=dscd.get(\"gates\", None),\n                    token_word_map=token_word_map,\n                    domain_labels=domain_labels,\n                    global_step=current_step,\n                )\n\n                if isinstance(asbn_losses, dict):\n                    encoder_loss = asbn_losses.get(\"encoder_loss\", torch.zeros(1, device=device, requires_grad=True))\n                    if isinstance(encoder_loss, torch.Tensor) and torch.isfinite(encoder_loss):\n                        if encoder_loss.requires_grad:\n                            asbn_loss = encoder_loss\n                        else:\n                            asbn_loss = torch.tensor(float(encoder_loss.item()), device=device, requires_grad=True)\n            except Exception:\n                asbn_loss = torch.zeros(1, device=device, requires_grad=True)\n\n        dscd_reg = torch.zeros(1, device=device, requires_grad=True)\n        try:\n            dscd_reg_raw = self._entropy_reg_from_proto_probs_static(\n                dscd.get('proto_probs', []),\n                gates_list=dscd.get('gates', []),\n                min_gate=0.01,\n            )\n            if isinstance(dscd_reg_raw, torch.Tensor):\n                if torch.isfinite(dscd_reg_raw):\n                    if dscd_reg_raw.requires_grad:\n                        dscd_reg = torch.clamp(dscd_reg_raw.to(device), 0.0, 5.0)\n                    else:\n                        dscd_reg = torch.tensor(float(dscd_reg_raw.item()), device=device, requires_grad=True)\n                        dscd_reg = torch.clamp(dscd_reg, 0.0, 5.0)\n        except Exception:\n            dscd_reg = torch.zeros(1, device=device, requires_grad=True)\n\n        total_loss = _LAMBDA_ASBN * asbn_loss + _LAMBDA_DSCD * dscd_reg\n\n        if not isinstance(total_loss, torch.Tensor):\n            total_loss = torch.tensor(float(total_loss), device=device, requires_grad=True)\n\n        if not torch.isfinite(total_loss):\n            total_loss = torch.tensor(0.01, device=device, requires_grad=True)\n\n        if not total_loss.requires_grad:\n            total_loss = torch.tensor(float(total_loss.item()), device=device, requires_grad=True)\n\n        self._last_path1_asbn_loss = float(asbn_loss.item()) if isinstance(asbn_loss, torch.Tensor) else 0.0\n        self._last_path1_dscd_loss = float(dscd_reg.item()) if isinstance(dscd_reg, torch.Tensor) else 0.0\n\n        return total_loss\n\n    def forward_path2(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        labels: torch.Tensor,\n        src_texts: Optional[List[str]] = None,\n        token_word_map: Optional[List[dict]] = None,\n        use_rdrop: bool = True,\n    ) -> torch.Tensor:\n        with self._step_lock:\n            self.global_step += 1\n            current_step = self.global_step\n\n        if input_ids is None or attention_mask is None or labels is None:\n            raise ValueError(\"input_ids, attention_mask, and labels cannot be None\")\n\n        batch_size, seq_len = int(input_ids.size(0)), int(input_ids.size(1))\n        device = input_ids.device\n\n        if torch.any(input_ids >= self.vocab_size) or torch.any(input_ids < 0):\n            input_ids = torch.clamp(input_ids, 0, self.vocab_size - 1)\n\n        pad_id = getattr(self.tokenizer, 'pad_token_id', 1)\n        decoder_input_ids = labels.clone()\n        decoder_input_ids = torch.where(\n            decoder_input_ids == -100,\n            torch.full_like(decoder_input_ids, pad_id),\n            decoder_input_ids,\n        )\n\n        bos_column = torch.full(\n            (batch_size, 1),\n            int(self.mbart.config.decoder_start_token_id),\n            dtype=torch.long,\n            device=device,\n        )\n        decoder_input_ids = torch.cat([bos_column, decoder_input_ids[:, :-1]], dim=1)\n        decoder_attention_mask = (decoder_input_ids != pad_id).long()\n\n        seq_outputs = self.mbart(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n            labels=labels,\n            use_cache=False,\n            return_dict=True,\n        )\n\n        translation_loss = getattr(seq_outputs, \"loss\", None)\n        if translation_loss is None or not torch.isfinite(translation_loss):\n            translation_loss = torch.tensor(10.0, device=device, requires_grad=True)\n        else:\n            translation_loss = torch.clamp(translation_loss, 0.0, 100.0)\n\n        label_smoothing_loss_val = torch.tensor(0.0, device=device, requires_grad=True)\n        if self.label_smoothing_loss is not None:\n            try:\n                logits = seq_outputs.logits\n                label_smoothing_loss_val = self.label_smoothing_loss(logits, labels)\n                if torch.isfinite(label_smoothing_loss_val):\n                    translation_loss = label_smoothing_loss_val\n            except Exception:\n                pass\n\n        rdrop_loss_val = torch.tensor(0.0, device=device, requires_grad=True)\n        if use_rdrop and self.rdrop_loss is not None and self.training and _RDROP_ALPHA > 0:\n            try:\n                seq_outputs2 = self.mbart(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    decoder_input_ids=decoder_input_ids,\n                    decoder_attention_mask=decoder_attention_mask,\n                    labels=labels,\n                    use_cache=False,\n                    return_dict=True,\n                )\n\n                logits1 = seq_outputs.logits\n                logits2 = seq_outputs2.logits\n\n                rdrop_loss_val = self.rdrop_loss(logits1, logits2, labels)\n                if not torch.isfinite(rdrop_loss_val):\n                    rdrop_loss_val = torch.tensor(0.0, device=device, requires_grad=True)\n            except Exception:\n                rdrop_loss_val = torch.tensor(0.0, device=device, requires_grad=True)\n\n        total_loss = translation_loss + rdrop_loss_val\n\n        if not torch.isfinite(total_loss):\n            total_loss = translation_loss\n\n        if not total_loss.requires_grad:\n            total_loss = torch.tensor(float(total_loss.item()), device=device, requires_grad=True)\n\n        return total_loss\n\n    def forward(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        src_texts: Optional[List[str]] = None,\n        token_word_map: Optional[List[dict]] = None,\n        labels: Optional[torch.Tensor] = None,\n        use_dscd: bool = True,\n        use_asbn: bool = False,\n        return_dict: bool = True,\n        domain_labels: Optional[torch.Tensor] = None,\n        path: Optional[int] = None,\n        use_rdrop: bool = False,\n        **kwargs\n    ):\n        if path == 1:\n            return self.forward_path1(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                src_texts=src_texts,\n                token_word_map=token_word_map,\n                domain_labels=domain_labels,\n            )\n\n        elif path == 2:\n            if labels is not None and self.training:\n                return self.forward_path2(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels,\n                    src_texts=src_texts,\n                    token_word_map=token_word_map,\n                    use_rdrop=use_rdrop,\n                )\n\n        with self._step_lock:\n            self.global_step += 1\n            current_step = self.global_step\n\n        if input_ids is None or attention_mask is None:\n            raise ValueError(\"input_ids and attention_mask cannot be None\")\n        if input_ids.dim() != 2 or attention_mask.dim() != 2:\n            raise ValueError(\n                f\"Expected 2D tensors, got {input_ids.shape}, {attention_mask.shape}\"\n            )\n\n        batch_size, seq_len = int(input_ids.size(0)), int(input_ids.size(1))\n        device = input_ids.device\n\n        if torch.any(input_ids >= self.vocab_size) or torch.any(input_ids < 0):\n            invalid_count = torch.sum((input_ids >= self.vocab_size) | (input_ids < 0)).item()\n            print(f\"[TATN] ❌ CRITICAL: {invalid_count} input_ids out of vocab bounds!\")\n            print(f\"  Vocab size: {self.vocab_size}\")\n            print(f\"  Max input_id: {torch.max(input_ids).item()}\")\n            print(f\"  Min input_id: {torch.min(input_ids).item()}\")\n            input_ids = torch.clamp(input_ids, 0, self.vocab_size - 1)\n\n        if (\n            torch.cuda.is_available()\n            and _MEMORY_CLEANUP_FREQUENCY > 0\n            and current_step % _MEMORY_CLEANUP_FREQUENCY == 0\n        ):\n            for i in range(min(_NUM_GPUS, torch.cuda.device_count())):\n                try:\n                    with torch.cuda.device(i):\n                        torch.cuda.empty_cache()\n                except Exception:\n                    pass\n            if gc.isenabled():\n                gc.collect()\n\n        if self.training and _DSCD_ENABLE_TRAINING_CLUSTERING and use_dscd:\n            if (\n                current_step - self.last_discovery_step\n                >= _PERIODIC_DISCOVERY_FREQUENCY\n            ):\n                try:\n                    if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n                        print(\"\\n\" + \"=\" * 80)\n                        print(f\"[TATN] PERIODIC DISCOVERY @ step {current_step}\")\n                        print(\"=\" * 80)\n\n                    start_time = time.time()\n                    self.dscd.periodic_discovery_check(\n                        current_step, _PERIODIC_DISCOVERY_FREQUENCY\n                    )\n\n                    elapsed = time.time() - start_time\n                    self.last_discovery_step = current_step\n\n                    if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n                        summary = self.dscd.get_prototype_summary()\n                        print(f\"[TATN] Discovery completed in {elapsed:.2f}s\")\n                        print(\n                            f\"[TATN]   Homographs: {summary.get('num_homographs', 0)}\"\n                        )\n                        print(\n                            f\"[TATN]   Total prototypes: {summary.get('total_prototypes', 0)}\"\n                        )\n                        print(\"=\" * 80 + \"\\n\")\n\n                except Exception as e:\n                    if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n                        print(f\"[TATN] Discovery failed: {e}\")\n                        try:\n                            traceback.print_exc()\n                        except Exception:\n                            pass\n\n        if not self.training and _VALIDATION_CHECK_INTERVAL > 0:\n            if (\n                current_step - self.last_validation_step\n                >= _VALIDATION_CHECK_INTERVAL\n            ):\n                try:\n                    if _DEBUG_DISCOVERY:\n                        print(f\"\\n[TATN-VALIDATION] Step {current_step}\")\n                        summary = self.dscd.get_prototype_summary()\n                        print(f\"  - Tokens: {summary.get('total_tokens', 0)}\")\n                        print(\n                            f\"  - Prototypes: {summary.get('total_prototypes', 0)}\"\n                        )\n                        print(\n                            f\"  - Homographs: {summary.get('num_homographs', 0)}\"\n                        )\n                    self.last_validation_step = current_step\n                except Exception:\n                    pass\n\n        enc_outputs = None\n        try:\n            enc_outputs = self.mbart.model.encoder(\n                input_ids=input_ids, attention_mask=attention_mask\n            )\n        except Exception:\n            try:\n                enc_outputs = self.mbart.get_encoder()(\n                    input_ids=input_ids, attention_mask=attention_mask\n                )\n            except Exception as e:\n                if _DEBUG_DISCOVERY:\n                    print(f\"[TATN] Encoder failed: {e}\")\n                enc_outputs = None\n\n        h = _safe_get_last_hidden_state(enc_outputs)\n        if h is None:\n            try:\n                embedding_layer = self.mbart.get_input_embeddings()\n                if embedding_layer is None:\n                    raise RuntimeError(\"No embedding layer available\")\n                h = embedding_layer(input_ids).to(device)\n            except Exception as e:\n                if _DEBUG_DISCOVERY:\n                    print(f\"[TATN] Embedding fallback failed: {e}\")\n                h = torch.zeros(\n                    batch_size,\n                    seq_len,\n                    int(getattr(self.mbart.config, \"d_model\", 1024)),\n                    device=device,\n                )\n\n        embed_dim = int(h.size(-1))\n        training_mode = labels is not None and self.training\n\n        token_word_map = self._reconstruct_word_maps_before_dscd(\n            input_ids, batch_size, seq_len, src_texts, token_word_map\n        )\n\n        if domain_labels is None:\n            domain_labels = self._extract_domain_labels(batch_size=batch_size, device=device, src_texts=src_texts)\n\n        if use_dscd:\n            try:\n                h_detached = h.detach()\n                raw_dscd = self.dscd.forward(\n                    h_detached,\n                    token_types=None,\n                    train_mode=self.training,\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    token_word_map=token_word_map,\n                )\n            except Exception as e:\n                if _DEBUG_DISCOVERY:\n                    print(f\"[TATN] DSCD forward failed: {e}\")\n                raw_dscd = {\n                    \"h_augmented\": h.detach().clone(),\n                    \"proto_probs\": [\n                        [\n                            torch.tensor(\n                                [1.0],\n                                dtype=torch.float32,\n                                device=device,\n                            )\n                            for _ in range(seq_len)\n                        ]\n                        for _ in range(batch_size)\n                    ],\n                    \"uncertainties\": [\n                        [\n                            torch.tensor(0.0, device=device)\n                            for _ in range(seq_len)\n                        ]\n                        for _ in range(batch_size)\n                    ],\n                    \"gates\": [\n                        [\n                            torch.tensor(0.0, device=device)\n                            for _ in range(seq_len)\n                        ]\n                        for _ in range(batch_size)\n                    ],\n                    \"span_preds\": [\n                        [\n                            torch.tensor(0.0, device=device)\n                            for _ in range(seq_len)\n                        ]\n                        for _ in range(batch_size)\n                    ],\n                    \"proto_assignments\": [\n                        torch.zeros(\n                            seq_len, dtype=torch.long, device=device\n                        )\n                        for _ in range(batch_size)\n                    ],\n                }\n        else:\n            raw_dscd = {\n                \"h_augmented\": h.detach().clone(),\n                \"proto_probs\": [\n                    [\n                        torch.tensor(\n                            [1.0], dtype=torch.float32, device=device\n                        )\n                        for _ in range(seq_len)\n                    ]\n                    for _ in range(batch_size)\n                ],\n                \"uncertainties\": [\n                    [\n                        torch.tensor(0.0, device=device)\n                        for _ in range(seq_len)\n                    ]\n                    for _ in range(batch_size)\n                ],\n                \"gates\": [\n                    [\n                        torch.tensor(0.0, device=device)\n                        for _ in range(seq_len)\n                    ]\n                    for _ in range(batch_size)\n                ],\n                \"span_preds\": [\n                    [\n                        torch.tensor(0.0, device=device)\n                        for _ in range(seq_len)\n                    ]\n                    for _ in range(batch_size)\n                ],\n                \"proto_assignments\": [\n                    torch.zeros(seq_len, dtype=torch.long, device=device)\n                    for _ in range(batch_size)\n                ],\n            }\n\n        dscd = _normalize_dscd_outputs(\n            raw_dscd, batch_size, seq_len, device, embed_dim, fallback_h=h\n        )\n        h_aug = dscd.get(\"h_augmented\", h)\n\n        if self.sense_conditioning is not None:\n            try:\n                h_aug = self.sense_conditioning(\n                    h_aug,\n                    proto_probs=dscd.get(\"proto_probs\", []),\n                    proto_assignments=dscd.get(\"proto_assignments\", []),\n                    prototype_stores=getattr(self.dscd, 'prototype_stores', None)\n                )\n            except Exception:\n                pass\n\n        if self.adaptive_gating is not None:\n            try:\n                h_aug = self.adaptive_gating(\n                    h_aug,\n                    uncertainties=dscd.get(\"uncertainties\", []),\n                    gates=dscd.get(\"gates\", [])\n                )\n            except Exception:\n                pass\n\n        if not isinstance(h_aug, torch.Tensor) or h_aug.shape != h.shape:\n            if _DEBUG_DISCOVERY:\n                print(\n                    f\"[TATN] h_augmented shape mismatch \"\n                    f\"(expected {h.shape}, got {getattr(h_aug, 'shape', None)})\"\n                )\n            h_aug = h\n\n        asbn_loss = torch.tensor(0.0, device=device)\n        domain_loss = torch.tensor(0.0, device=device)\n        domain_accuracy = torch.tensor(0.0, device=device)\n\n        if training_mode and use_asbn and _ENABLE_ASBN_TRAINING and domain_labels is not None:\n            try:\n                if _DEBUG_DISCOVERY and current_step % 100 == 0:\n                    print(f\"\\n[TATN-ASBN] Applying ASBN at step {current_step}\")\n                    print(f\"  Domain labels: {domain_labels.tolist()}\")\n\n                h_asbn, asbn_losses = self.asbn.forward(\n                    h_aug,\n                    proto_probs=dscd.get(\"proto_probs\", None),\n                    uncertainties=dscd.get(\"uncertainties\", None),\n                    gates=dscd.get(\"gates\", None),\n                    token_word_map=token_word_map,\n                    domain_labels=domain_labels,\n                    global_step=current_step,\n                )\n\n                if isinstance(asbn_losses, dict):\n                    encoder_loss = asbn_losses.get(\"encoder_loss\", torch.tensor(0.0, device=device))\n                    domain_loss = asbn_losses.get(\"domain_loss\", torch.tensor(0.0, device=device))\n                    domain_accuracy = asbn_losses.get(\"domain_accuracy\", torch.tensor(0.0, device=device))\n\n                    if isinstance(encoder_loss, torch.Tensor) and torch.isfinite(encoder_loss):\n                        asbn_loss = encoder_loss\n                    else:\n                        asbn_loss = torch.tensor(0.0, device=device)\n                else:\n                    asbn_loss = torch.tensor(0.0, device=device)\n\n                if _DEBUG_DISCOVERY and current_step % 100 == 0:\n                    print(f\"  ASBN loss: {asbn_loss.item():.4f}\")\n                    print(f\"  Domain loss: {domain_loss.item():.4f}\")\n                    print(f\"  Domain accuracy: {domain_accuracy.item():.2%}\")\n\n            except Exception as e:\n                if _DEBUG_DISCOVERY:\n                    print(f\"[TATN-ASBN] ASBN forward failed: {e}\")\n                    try:\n                        traceback.print_exc()\n                    except Exception:\n                        pass\n                asbn_loss = torch.tensor(0.0, device=device)\n                domain_loss = torch.tensor(0.0, device=device)\n                domain_accuracy = torch.tensor(0.0, device=device)\n\n        try:\n            enc_for_decoder = BaseModelOutput(\n                last_hidden_state=h_aug,\n                hidden_states=(\n                    getattr(enc_outputs, \"hidden_states\", None)\n                    if enc_outputs\n                    else None\n                ),\n                attentions=(\n                    getattr(enc_outputs, \"attentions\", None)\n                    if enc_outputs\n                    else None\n                ),\n            )\n        except Exception:\n            enc_for_decoder = (h_aug,)\n\n        if training_mode:\n            try:\n                pad_id = getattr(self.tokenizer, 'pad_token_id', 1)\n\n                if labels is not None:\n                    decoder_input_ids = labels.clone()\n                    decoder_input_ids = torch.where(\n                        decoder_input_ids == -100,\n                        torch.full_like(\n                            decoder_input_ids,\n                            pad_id,\n                        ),\n                        decoder_input_ids,\n                    )\n\n                    bos_column = torch.full(\n                        (batch_size, 1),\n                        int(self.mbart.config.decoder_start_token_id),\n                        dtype=torch.long,\n                        device=device,\n                    )\n                    decoder_input_ids = torch.cat(\n                        [bos_column, decoder_input_ids[:, :-1]], dim=1\n                    )\n                    decoder_attention_mask = (\n                        decoder_input_ids != pad_id\n                    ).long()\n                else:\n                    decoder_input_ids = None\n                    decoder_attention_mask = None\n\n                seq_outputs = self.mbart(\n                    input_ids=None,\n                    attention_mask=attention_mask,\n                    encoder_outputs=enc_for_decoder,\n                    decoder_input_ids=decoder_input_ids,\n                    decoder_attention_mask=decoder_attention_mask,\n                    labels=labels,\n                    use_cache=False,\n                    return_dict=True,\n                )\n\n                translation_loss = getattr(seq_outputs, \"loss\", None)\n                if translation_loss is None or not torch.isfinite(translation_loss):\n                    translation_loss = torch.tensor(10.0, device=device)\n                else:\n                    translation_loss = torch.clamp(translation_loss, 0.0, 100.0)\n\n                token_penalty = torch.tensor(0.0, device=device)\n                confidence_penalty = torch.tensor(0.0, device=device)\n                length_penalty = torch.tensor(0.0, device=device)\n\n                try:\n                    logits = seq_outputs.logits\n                    predicted_ids = torch.argmax(logits, dim=-1)\n\n                    reference_ids = labels\n                    valid_mask = (reference_ids != -100) & (reference_ids != pad_id)\n\n                    if valid_mask.sum() > 0:\n                        mismatches = (predicted_ids != reference_ids) & valid_mask\n                        mismatch_rate = mismatches.float().sum() / valid_mask.float().sum()\n                        token_penalty = mismatch_rate * 2.0\n\n                        probs = torch.softmax(logits, dim=-1)\n                        max_probs = torch.max(probs, dim=-1)[0]\n                        wrong_positions = (predicted_ids != reference_ids) & valid_mask\n\n                        if wrong_positions.sum() > 0:\n                            wrong_confidences = max_probs[wrong_positions]\n                            confidence_penalty = wrong_confidences.mean() * 1.5\n\n                        pred_lengths = valid_mask.sum(dim=1).float()\n                        ref_lengths = (reference_ids != -100).sum(dim=1).float()\n                        length_diff = torch.abs(pred_lengths - ref_lengths) / torch.clamp(ref_lengths, min=1.0)\n                        length_penalty = length_diff.mean() * 0.5\n\n                except Exception as e:\n                    if _DEBUG_DISCOVERY:\n                        print(f\"⚠️ Penalty computation failed: {e}\")\n\n            except Exception as e:\n                if _DEBUG_DISCOVERY:\n                    print(f\"[TATN] Decoder forward failed: {e}\")\n                    try:\n                        traceback.print_exc()\n                    except Exception:\n                        pass\n                translation_loss = torch.tensor(10.0, device=device)\n                token_penalty = torch.tensor(0.0, device=device)\n                confidence_penalty = torch.tensor(0.0, device=device)\n                length_penalty = torch.tensor(0.0, device=device)\n\n            dscd_reg = torch.tensor(0.0, device=device)\n            try:\n                dscd_reg = self._entropy_reg_from_proto_probs_static(\n                    dscd.get('proto_probs', []),\n                    gates_list=dscd.get('gates', []),\n                    min_gate=0.01,\n                )\n                if not isinstance(dscd_reg, torch.Tensor):\n                    dscd_reg = torch.tensor(float(dscd_reg), device=device)\n                if not torch.isfinite(dscd_reg):\n                    dscd_reg = torch.tensor(0.0, device=device)\n                else:\n                    dscd_reg = torch.clamp(dscd_reg.to(device), 0.0, 5.0)\n            except Exception:\n                dscd_reg = torch.tensor(0.0, device=device)\n\n            self._last_translation_loss = float(translation_loss.item()) if isinstance(translation_loss, torch.Tensor) else 0.0\n            self._last_asbn_loss = float(asbn_loss.item()) if isinstance(asbn_loss, torch.Tensor) else 0.0\n            self._last_domain_loss = float(domain_loss.item()) if isinstance(domain_loss, torch.Tensor) else 0.0\n            self._last_domain_accuracy = float(domain_accuracy.item()) if isinstance(domain_accuracy, torch.Tensor) else 0.0\n            self._last_dscd_loss = float(dscd_reg.item()) if isinstance(dscd_reg, torch.Tensor) else 0.0\n            self._last_token_penalty = float(token_penalty.item()) if isinstance(token_penalty, torch.Tensor) else 0.0\n            self._last_confidence_penalty = float(confidence_penalty.item()) if isinstance(confidence_penalty, torch.Tensor) else 0.0\n            self._last_length_penalty = float(length_penalty.item()) if isinstance(length_penalty, torch.Tensor) else 0.0\n\n            total_loss = (\n                translation_loss +\n                _LAMBDA_ASBN * asbn_loss +\n                _LAMBDA_TOKEN * token_penalty +\n                _LAMBDA_CONFIDENCE * confidence_penalty +\n                _LAMBDA_LENGTH * length_penalty +\n                _LAMBDA_DSCD * dscd_reg\n            )\n\n            if not isinstance(total_loss, torch.Tensor):\n                total_loss = torch.tensor(float(total_loss), device=device)\n            if total_loss.numel() != 1:\n                total_loss = total_loss.mean()\n\n            if not torch.isfinite(total_loss):\n                if _DEBUG_DISCOVERY:\n                    print(\n                        f\"[TATN] NaN/Inf in total_loss ({total_loss}), using translation loss\"\n                    )\n                total_loss = translation_loss\n\n            if _DEBUG_DISCOVERY and current_step % 100 == 0:\n                print(f\"\\n{'='*60}\")\n                print(f\"LOSS BREAKDOWN (Step {current_step}):\")\n                print(f\"  Translation: {translation_loss.item():.4f}\")\n                print(f\"  ASBN Loss: {asbn_loss.item():.4f} (×{_LAMBDA_ASBN})\")\n                print(f\"  Domain Loss: {domain_loss.item():.4f}\")\n                print(f\"  Domain Accuracy: {domain_accuracy.item():.2%}\")\n                print(f\"  Token Penalty: {token_penalty.item():.4f} (×{_LAMBDA_TOKEN})\")\n                print(f\"  Confidence Penalty: {confidence_penalty.item():.4f} (×{_LAMBDA_CONFIDENCE})\")\n                print(f\"  Length Penalty: {length_penalty.item():.4f} (×{_LAMBDA_LENGTH})\")\n                print(f\"  DSCD Reg: {dscd_reg.item():.4f} (×{_LAMBDA_DSCD})\")\n                print(f\"  TOTAL: {total_loss.item():.4f}\")\n                print(f\"{'='*60}\\n\")\n\n            try:\n                del enc_outputs, h, raw_dscd\n            except Exception:\n                pass\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n            return total_loss\n\n        if not return_dict:\n            return h_aug\n\n        explanations_list: List[List[Dict[str, Any]]] = []\n\n        if _ENABLE_TRG_INFERENCE:\n            if _DEBUG_DISCOVERY:\n                print(\n                    f\"\\n[TATN-INFERENCE] Starting TRG for {batch_size} samples\"\n                )\n\n            tokens_batch: List[List[str]] = []\n\n            for b in range(batch_size):\n                try:\n                    ids_b = input_ids[b].detach().cpu().tolist()\n                    if hasattr(self.tokenizer, \"convert_ids_to_tokens\"):\n                        toks = self.tokenizer.convert_ids_to_tokens(ids_b)\n                    else:\n                        toks = []\n                    if not toks:\n                        toks = [\"UNK\"] * seq_len\n                    elif len(toks) < seq_len:\n                        toks = toks + [\"\"] * (seq_len - len(toks))\n                    elif len(toks) > seq_len:\n                        toks = toks[:seq_len]\n                except Exception:\n                    toks = [\"UNK\"] * seq_len\n\n                tokens_batch.append(toks)\n\n            decoder_attention = None\n\n            try:\n                total_explanations = 0\n                for b in range(batch_size):\n                    per_sent = {\n                        \"proto_probs\": self._safe_take_key_static(\n                            dscd, \"proto_probs\", b, seq_len, device\n                        ),\n                        \"uncertainties\": self._safe_take_key_static(\n                            dscd, \"uncertainties\", b, seq_len, device\n                        ),\n                        \"gates\": self._safe_take_key_static(\n                            dscd, \"gates\", b, seq_len, device\n                        ),\n                        \"span_preds\": self._safe_take_key_static(\n                            dscd, \"span_preds\", b, seq_len, device\n                        ),\n                    }\n\n                    try:\n                        exps = self.trg.process_sentence_for_explanations(\n                            tokens_batch[b],\n                            per_sent,\n                            token_word_map=(\n                                token_word_map[b]\n                                if token_word_map\n                                and b < len(token_word_map)\n                                else None\n                            ),\n                            uncertainty_threshold=_TRG_UNCERTAINTY_THRESHOLD,\n                            decoder_attention=decoder_attention,\n                        )\n                        batch_exps = exps if isinstance(exps, list) else []\n                        explanations_list.append(batch_exps)\n                        total_explanations += len(batch_exps)\n\n                        if _DEBUG_DISCOVERY and b < 2:\n                            print(\n                                f\"[TATN-INFERENCE] Sample {b}: \"\n                                f\"{len(batch_exps)} explanations\"\n                            )\n\n                    except Exception as e:\n                        if _DEBUG_DISCOVERY:\n                            print(\n                                f\"[TATN-INFERENCE] TRG failed for sample {b}: {e}\"\n                            )\n                        explanations_list.append([])\n\n                if _DEBUG_DISCOVERY:\n                    print(\n                        f\"\\n[TATN-INFERENCE] Total explanations: {total_explanations}\"\n                    )\n                    if total_explanations == 0:\n                        print(\"[TATN-INFERENCE] NO EXPLANATIONS GENERATED\")\n\n            except Exception as e:\n                if _DEBUG_DISCOVERY:\n                    print(f\"[TATN-INFERENCE] TRG generation failed: {e}\")\n                    try:\n                        traceback.print_exc()\n                    except Exception:\n                        pass\n                explanations_list = [[] for _ in range(batch_size)]\n        else:\n            explanations_list = [[] for _ in range(batch_size)]\n\n        outputs = {\n            \"encoder_outputs\": enc_for_decoder,\n            \"dscd_outputs\": dscd,\n            \"sense_augmented_embeddings\": h_aug,\n            \"explanations\": explanations_list,\n            \"asbn_loss\": asbn_loss,\n            \"domain_loss\": domain_loss,\n            \"domain_accuracy\": domain_accuracy,\n            \"ambiguity_signals\": {\n                \"span\": dscd.get(\"span_preds\", []),\n                \"uncertainty\": dscd.get(\"uncertainties\", []),\n                \"confidence\": [\n                    [\n                        1.0\n                        - (\n                            float(u)\n                            if isinstance(u, (float, int))\n                            else (\n                                float(u.item())\n                                if isinstance(u, torch.Tensor)\n                                else 1.0\n                            )\n                        )\n                        for u in row\n                    ]\n                    for row in dscd.get(\"uncertainties\", [])\n                ],\n                \"proto_probs\": dscd.get(\"proto_probs\", []),\n            },\n        }\n\n        try:\n            del h, raw_dscd\n        except Exception:\n            pass\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n        return outputs\n\n    def forward_with_explanations(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        src_texts: Optional[List[str]] = None,\n        token_word_map: Optional[List[dict]] = None,\n    ):\n        return self.forward(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            src_texts=src_texts,\n            token_word_map=token_word_map,\n            labels=None,\n        )\n\n    def forward_with_dscd_for_inference(\n        self,\n        input_ids: torch.Tensor,\n        attention_mask: torch.Tensor,\n        src_texts: Optional[List[str]] = None,\n        token_word_map: Optional[List[dict]] = None,\n    ) -> Tuple[Dict[str, Any], Dict[str, Any], torch.Tensor]:\n        was_training = self.training\n\n        try:\n            self.eval()\n\n            with torch.inference_mode():\n                out = self.forward(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    src_texts=src_texts,\n                    token_word_map=token_word_map,\n                    labels=None,\n                    use_dscd=True,\n                )\n\n            if not isinstance(out, dict):\n                empty_dict = {}\n                empty_tensor = torch.zeros(1, 1, 1024, device=input_ids.device)\n                return empty_dict, empty_dict, empty_tensor\n\n            dscd_outputs = out.get(\"dscd_outputs\", {})\n            asbn_outputs = {\n                \"asbn_loss\": out.get(\"asbn_loss\", torch.tensor(0.0)),\n                \"domain_loss\": out.get(\"domain_loss\", torch.tensor(0.0)),\n                \"domain_accuracy\": out.get(\"domain_accuracy\", torch.tensor(0.0)),\n            }\n            h_encoder = out.get(\"sense_augmented_embeddings\", None)\n\n            if h_encoder is None:\n                h_encoder = dscd_outputs.get(\"h_augmented\", torch.zeros(1, 1, 1024, device=input_ids.device))\n\n            return dscd_outputs, asbn_outputs, h_encoder\n\n        finally:\n            if was_training:\n                self.train()\n\n    def generate(\n        self,\n        input_ids: Optional[torch.Tensor] = None,\n        attention_mask: Optional[torch.Tensor] = None,\n        encoder_outputs: Optional[BaseModelOutput] = None,\n        max_length: int = 128,\n        num_beams: int = 5,\n        early_stopping: bool = True,\n        **kwargs,\n    ) -> torch.Tensor:\n\n        if encoder_outputs is not None:\n            enc_wrapped = encoder_outputs\n\n            if hasattr(enc_wrapped, \"last_hidden_state\"):\n                lhs = enc_wrapped.last_hidden_state\n                if lhs is not None and isinstance(lhs, torch.Tensor):\n                    if torch.isnan(lhs).any() or torch.isinf(lhs).any():\n                        raise RuntimeError(\"Encoder outputs contain NaN/Inf!\")\n                    if (lhs.abs() < 1e-8).all():\n                        raise RuntimeError(\"Encoder outputs are all zeros!\")\n        else:\n            if input_ids is None or attention_mask is None:\n                raise ValueError(\n                    \"Either encoder_outputs or (input_ids + attention_mask) must be provided\"\n                )\n\n            enc_outputs = self.mbart.model.encoder(\n                input_ids=input_ids, attention_mask=attention_mask\n            )\n\n            enc_wrapped = BaseModelOutput(\n                last_hidden_state=(\n                    enc_outputs.last_hidden_state\n                    if hasattr(enc_outputs, \"last_hidden_state\")\n                    else enc_outputs[0]\n                ),\n                hidden_states=getattr(enc_outputs, \"hidden_states\", None),\n                attentions=getattr(enc_outputs, \"attentions\", None),\n            )\n\n        decoder_start = int(self.en_token_id)\n\n        kwargs.pop('forced_bos_token_id', None)\n        kwargs.pop('decoder_start_token_id', None)\n\n        generated = self.mbart.generate(\n            input_ids=None,\n            attention_mask=attention_mask,\n            encoder_outputs=enc_wrapped,\n            max_length=max_length,\n            num_beams=num_beams,\n            early_stopping=early_stopping,\n            decoder_start_token_id=decoder_start,\n            forced_bos_token_id=None,\n            repetition_penalty=1.2,\n            no_repeat_ngram_size=2,\n            length_penalty=1.0,\n            do_sample=False,\n            pad_token_id=int(getattr(self.tokenizer, 'pad_token_id', 1)),\n            eos_token_id=int(getattr(self.tokenizer, 'eos_token_id', 2)),\n            **kwargs,\n        )\n\n        return generated\n\n    def get_component_stats(self) -> Dict[str, Any]:\n        stats: Dict[str, Any] = {\n            \"global_step\": self.global_step,\n            \"last_discovery_step\": self.last_discovery_step,\n            \"last_validation_step\": self.last_validation_step,\n        }\n\n        try:\n            if hasattr(self.dscd, \"get_prototype_summary\"):\n                stats[\"dscd\"] = self.dscd.get_prototype_summary()\n        except Exception:\n            pass\n\n        try:\n            if hasattr(self.asbn, \"get_detailed_stats\"):\n                stats[\"asbn\"] = self.asbn.get_detailed_stats()\n        except Exception:\n            pass\n\n        try:\n            if hasattr(self.trg, \"get_statistics\"):\n                stats[\"trg\"] = self.trg.get_statistics()\n        except Exception:\n            pass\n\n        return stats\n\n\nTATNModelWithDSCDAndASBN = MemoryOptimizedTATNWithExplanations\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 6: DUAL-PATH TATN MODEL - PATH 1 (WORD-LEVEL) + PATH 2 (SUBWORD-LEVEL)\")\nprint(\"=\" * 80)\nprint(\"✅ COMPLETE WITH ALL 7 CRITICAL FIXES:\")\nprint(\"  ✅ FIX 1: Added LabelSmoothingLoss class\")\nprint(\"  ✅ FIX 2: Added RDropLoss class\")\nprint(\"  ✅ FIX 3: Added SensePrototypeConditioning class\")\nprint(\"  ✅ FIX 4: Added AdaptiveSenseGating class\")\nprint(\"  ✅ FIX 5: Model loading (MBartForConditionalGeneration)\")\nprint(\"  ✅ FIX 6: Modified __init__() - Initialize all 4 classes\")\nprint(\"  ✅ FIX 7: Modified forward() - Apply conditioning & gating\")\nprint(\"  ✅ FIX 8: Updated total_loss - Proper loss integration\")\nprint(\"\")\nprint(\"Configuration:\")\nprint(f\"  - DSCD buffer: {_DSCD_BUFFER_SIZE}\")\nprint(f\"  - DSCD n_min: {_DSCD_N_MIN}\")\nprint(f\"  - DSCD threshold: {_DSCD_DISPERSION_THRESHOLD}\")\nprint(f\"  - Discovery frequency: {_PERIODIC_DISCOVERY_FREQUENCY}\")\nprint(f\"  - Label Smoothing ε: {_LABEL_SMOOTHING_EPS}\")\nprint(f\"  - R-Drop α: {_RDROP_ALPHA}\")\nprint(f\"  - ASBN Training: {'DISABLED' if not _ENABLE_ASBN_TRAINING else 'ENABLED'}\")\nprint(f\"  - Lambda ASBN: {_LAMBDA_ASBN}\")\nprint(f\"  - Lambda DSCD: {_LAMBDA_DSCD}\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"KZbMDpIYH4J4","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:04.552996Z","iopub.execute_input":"2026-02-18T08:40:04.553203Z","iopub.status.idle":"2026-02-18T08:40:04.733067Z","shell.execute_reply.started":"2026-02-18T08:40:04.553186Z","shell.execute_reply":"2026-02-18T08:40:04.732483Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCell 6: DUAL-PATH TATN MODEL - PATH 1 (WORD-LEVEL) + PATH 2 (SUBWORD-LEVEL)\n================================================================================\n✅ COMPLETE WITH ALL 7 CRITICAL FIXES:\n  ✅ FIX 1: Added LabelSmoothingLoss class\n  ✅ FIX 2: Added RDropLoss class\n  ✅ FIX 3: Added SensePrototypeConditioning class\n  ✅ FIX 4: Added AdaptiveSenseGating class\n  ✅ FIX 5: Model loading (MBartForConditionalGeneration)\n  ✅ FIX 6: Modified __init__() - Initialize all 4 classes\n  ✅ FIX 7: Modified forward() - Apply conditioning & gating\n  ✅ FIX 8: Updated total_loss - Proper loss integration\n\nConfiguration:\n  - DSCD buffer: 40\n  - DSCD n_min: 5\n  - DSCD threshold: 0.4\n  - Discovery frequency: 300\n  - Label Smoothing ε: 0.15\n  - R-Drop α: 0.0\n  - ASBN Training: ENABLED\n  - Lambda ASBN: 0.0\n  - Lambda DSCD: 0.01\n================================================================================\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 7: DUAL-PATH TRAINING LOOP - COMPLETE FIXED VERSION\n# ===========================================================================================\n\nimport os\nimport time\nimport math\nimport gc\nimport traceback\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom collections import defaultdict, deque\nfrom typing import Optional, Dict, Any, List\n\nimport numpy as np\nimport torch\nfrom torch.cuda.amp import GradScaler, autocast as cuda_amp_autocast\nfrom tqdm import tqdm\nfrom contextlib import nullcontext\nimport threading\n\ntry:\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, TypeError):\n    _VERBOSE_LOGGING = False\n\ntry:\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept (NameError, TypeError):\n    _DEBUG_DISCOVERY = False\n\nDEBUG_PRINT_INTERVAL = 400\n_cell7_dbg_counts = defaultdict(int)\n\n\ndef cell7_dbg(key: str, msg: str, limit: int = 10):\n    if not (_VERBOSE_LOGGING or _DEBUG_DISCOVERY):\n        return\n    _cell7_dbg_counts[key] += 1\n    if _cell7_dbg_counts[key] <= limit:\n        print(f\"[CELL7-DBG] {msg}\")\n\n\ntry:\n    _DEVICE = DEVICE\nexcept (NameError, TypeError):\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntry:\n    _EPOCHS = int(EPOCHS)\nexcept (NameError, ValueError, TypeError):\n    _EPOCHS = 1\n\ntry:\n    _BATCH_SIZE = int(BATCH_SIZE)\nexcept (NameError, ValueError, TypeError):\n    _BATCH_SIZE = 8\n\ntry:\n    _ACCUMULATION_STEPS = int(ACCUMULATION_STEPS)\nexcept (NameError, ValueError, TypeError):\n    _ACCUMULATION_STEPS = 1\n\ntry:\n    _GRAD_CLIP_NORM = float(GRAD_CLIP_NORM)\nexcept (NameError, ValueError, TypeError):\n    _GRAD_CLIP_NORM = 1.0\n\ntry:\n    _MEMORY_CLEANUP_FREQUENCY = int(MEMORY_CLEANUP_FREQUENCY)\nexcept (NameError, ValueError, TypeError):\n    _MEMORY_CLEANUP_FREQUENCY = 500\n\ntry:\n    _USE_MULTI_GPU = bool(USE_MULTI_GPU)\n    _NUM_GPUS = int(NUM_GPUS)\nexcept (NameError, ValueError, TypeError):\n    _NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    _USE_MULTI_GPU = _NUM_GPUS > 1\n\ntry:\n    _USE_AMP = bool(USE_AMP)\nexcept (NameError, TypeError):\n    _USE_AMP = True\n\ntry:\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\n    _TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, TypeError):\n    _SOURCE_LANGUAGE = \"bn\"\n    _TARGET_LANGUAGE = \"en\"\n\ntry:\n    _MAX_LENGTH = int(MAX_LENGTH)\nexcept (NameError, ValueError, TypeError):\n    _MAX_LENGTH = 48\n\ntry:\n    _VALIDATION_CHECK_INTERVAL = int(VALIDATION_CHECK_INTERVAL)\nexcept (NameError, ValueError, TypeError):\n    _VALIDATION_CHECK_INTERVAL = 500\n\ntry:\n    _PERIODIC_DISCOVERY_FREQUENCY = int(PERIODIC_DISCOVERY_FREQUENCY)\nexcept (NameError, ValueError, TypeError):\n    _PERIODIC_DISCOVERY_FREQUENCY = 200\n\ntry:\n    _TRAIN_DOMAIN = int(TRAIN_DOMAIN)\n    _TEST_DOMAIN = int(TEST_DOMAIN)\nexcept (NameError, ValueError, TypeError):\n    _TRAIN_DOMAIN = 0\n    _TEST_DOMAIN = 1\n\ntry:\n    _LAMBDA_TRG = float(LAMBDA_TRG)\nexcept (NameError, ValueError, TypeError):\n    _LAMBDA_TRG = 0.15\n\ntry:\n    _WARMUP_STEPS = int(WARMUP_STEPS)\nexcept (NameError, ValueError, TypeError):\n    _WARMUP_STEPS = 200\n\ntry:\n    _USE_LR_SCHEDULER = bool(USE_LR_SCHEDULER)\nexcept (NameError, TypeError):\n    _USE_LR_SCHEDULER = True\n\ntry:\n    _USE_DUAL_PATH_TRAINING = bool(USE_DUAL_PATH_TRAINING)\nexcept (NameError, TypeError):\n    _USE_DUAL_PATH_TRAINING = True\n\ntry:\n    _HOMOGRAPH_REFERENCE_LIST = set(str(w).lower() for w in HOMOGRAPH_REFERENCE_LIST_BN)\nexcept (NameError, TypeError):\n    _HOMOGRAPH_REFERENCE_LIST = {\n        \"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\", \"ফল\", \"মাথা\", \"বার\", \"হার\", \"তারা\",\n        \"পানি\", \"দল\", \"বাজার\", \"নাম\", \"কথা\", \"বই\", \"ঘর\", \"মন\", \"হাত\"\n    }\n    _HOMOGRAPH_REFERENCE_LIST = set(str(w).lower() for w in _HOMOGRAPH_REFERENCE_LIST)\n\n_BENGALI_PUNCT_SET = set(['।', '॥'])\n_COMMON_PUNCT_SET = set(['.', ',', ';', ':', '!', '?', '\"', \"'\", '-', '(', ')', '[', ']', '{', '}', '/', '\\\\'])\n_PUNCT_SET = _BENGALI_PUNCT_SET | _COMMON_PUNCT_SET\n\n\ndef _is_punctuation_only(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n\n    clean = (\n        token.replace(\"▁\", \"\")\n        .replace(\"Ġ\", \"\")\n        .replace(\"##\", \"\")\n        .replace(\"</w>\", \"\")\n        .strip()\n    )\n\n    if not clean:\n        return False\n\n    if clean in _BENGALI_PUNCT_SET:\n        return True\n\n    if clean in _COMMON_PUNCT_SET:\n        return True\n\n    if len(clean) == 1 and not clean.isalnum():\n        return True\n\n    return all(c in _PUNCT_SET for c in clean)\n\n\ndef clear_all_gpu_caches():\n    gc.collect()\n    if not torch.cuda.is_available():\n        return\n    try:\n        for i in range(torch.cuda.device_count()):\n            with torch.cuda.device(i):\n                try:\n                    torch.cuda.empty_cache()\n                except Exception:\n                    pass\n    except Exception:\n        pass\n\n\ndef get_amp_ctx():\n    if not _USE_AMP or not torch.cuda.is_available():\n        return nullcontext()\n    try:\n        return cuda_amp_autocast()\n    except Exception:\n        return nullcontext()\n\n\n_PROTOBUF_COMPAT_ERROR_SHOWN = globals().get(\"_PROTOBUF_COMPAT_ERROR_SHOWN\", False)\n\n\ndef _get_dscd_homographs(model: torch.nn.Module) -> set:\n    try:\n        core = model.module if hasattr(model, 'module') else model\n        dscd = getattr(core, 'dscd', None)\n        if dscd is None:\n            return set()\n\n        if hasattr(dscd, 'get_discovered_homographs'):\n            discovered = dscd.get_discovered_homographs()\n            return set(w for w in discovered if not _is_punctuation_only(w))\n\n        homographs = set()\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        stores_snapshot = {}\n        if lock:\n            with lock:\n                stores_snapshot = dict(dscd.prototype_stores.items())\n        else:\n            stores_snapshot = dict(dscd.prototype_stores.items())\n\n        for token, store in stores_snapshot.items():\n            try:\n                if store.size() >= 1:\n                    clean_token = str(token).replace('▁', '').replace('Ġ', '').replace('##', '').strip().lower()\n                    if clean_token and not _is_punctuation_only(clean_token):\n                        homographs.add(clean_token)\n            except Exception:\n                continue\n\n        return homographs\n    except Exception:\n        return set()\n\n\ndef comprehensive_epoch_validation(\n    model: torch.nn.Module,\n    tokenizer,\n    epoch: int,\n    global_step: int,\n    source_lang: str,\n    target_lang: str,\n    max_length: int,\n    device: torch.device,\n    val_loader: Optional[torch.utils.data.DataLoader] = None,\n) -> Dict[str, Any]:\n    global _PROTOBUF_COMPAT_ERROR_SHOWN\n\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"EPOCH {epoch} COMPREHENSIVE VALIDATION (Step {global_step})\")\n    print(\"=\" * 80)\n\n    core_model = model.module if hasattr(model, \"module\") else model\n    was_training = core_model.training\n\n    if not isinstance(device, torch.device):\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    dscd_homographs = _get_dscd_homographs(model)\n\n    validation_results = {\n        'epoch': epoch,\n        'step': global_step,\n        'translations_success': 0,\n        'translations_failed': 0,\n        'explanations_generated': 0,\n        'dscd_homographs_explained': 0,\n        'reference_homographs_explained': 0,\n        'avg_explanation_confidence': 0.0,\n        'dscd_quality_score': 0.0,\n        'dscd_multi_sense_tokens': 0,\n        'dscd_total_prototypes': 0,\n        'asbn_domain_loss': 0.0,\n        'asbn_domain_accuracy': 0.0,\n        'asbn_source_accuracy': 0.0,\n        'asbn_target_accuracy': 0.0,\n        'trg_total_explanations': 0,\n        'validation_completed': False,\n        'avg_loss': 0.0,\n        'bleu_score': 0.0,\n        'bleu_samples': 0,\n        'translation_examples': [],\n    }\n\n    try:\n        core_model.eval()\n\n        val_losses = []\n        confidences = []\n        dscd_homograph_words_detected = set()\n        reference_homograph_words_detected = set()\n\n        if val_loader is not None:\n            print(f\"\\n[VALIDATION] Using real validation data ({len(val_loader)} batches)\")\n            print(\"-\" * 80)\n\n            try:\n                tokenizer.src_lang = source_lang\n                tokenizer.tgt_lang = target_lang\n            except Exception as e:\n                print(f\"[VALIDATION] Warning: Could not set tokenizer languages: {type(e).__name__}\")\n\n            num_val_batches = min(len(val_loader), 10)\n            batch_iter = iter(val_loader)\n\n            with torch.no_grad():\n                for batch_idx in range(num_val_batches):\n                    try:\n                        batch = next(batch_iter)\n                        if batch is None:\n                            continue\n\n                        input_ids = batch.get(\"input_ids\", None)\n                        attention_mask = batch.get(\"attention_mask\", None)\n                        labels = batch.get(\"labels\", None)\n\n                        if input_ids is None or attention_mask is None or labels is None:\n                            continue\n\n                        input_ids = input_ids.to(device, non_blocking=True)\n                        attention_mask = attention_mask.to(device, non_blocking=True)\n                        labels = labels.to(device, non_blocking=True)\n\n                        valid_labels = int((labels != -100).sum().item())\n                        if batch_idx == 0:\n                            print(f\"[VALIDATION] Batch {batch_idx}: valid_labels={valid_labels}/{labels.numel()}\")\n\n                        if valid_labels == 0:\n                            print(f\"[VALIDATION] WARNING: Batch {batch_idx} has no valid labels (all -100)\")\n                            continue\n\n                        forward_kwargs = {\n                            \"input_ids\": input_ids,\n                            \"attention_mask\": attention_mask,\n                            \"labels\": labels,\n                            \"src_texts\": batch.get(\"src_text\", None) or batch.get(\"src_texts\", None),\n                            \"token_word_map\": batch.get(\"token_word_map\", None),\n                        }\n\n                        if hasattr(core_model, 'forward_path2'):\n                            if batch_idx == 0:\n                                print(f\"[VALIDATION] Batch {batch_idx}: Using forward_path2()\")\n                            outputs = core_model.forward_path2(**forward_kwargs, use_rdrop=False)\n                        else:\n                            if batch_idx == 0:\n                                print(f\"[VALIDATION] Batch {batch_idx}: Using model() with path=2\")\n                            forward_kwargs[\"path\"] = 2\n                            outputs = model(**forward_kwargs)\n\n                        loss_val = None\n\n                        if isinstance(outputs, torch.Tensor):\n                            if batch_idx == 0:\n                                print(f\"[VALIDATION] Batch {batch_idx}: outputs is Tensor, shape={outputs.shape}\")\n                            try:\n                                if outputs.numel() == 1:\n                                    loss_val = float(outputs.item())\n                                elif outputs.dim() == 0:\n                                    loss_val = float(outputs.item())\n                                else:\n                                    loss_val = float(outputs.mean().item())\n                            except Exception:\n                                try:\n                                    loss_val = float(outputs.detach().cpu().mean().item())\n                                except Exception:\n                                    loss_val = None\n\n                        elif isinstance(outputs, dict):\n                            if \"loss\" in outputs:\n                                loss_tensor = outputs[\"loss\"]\n                                if isinstance(loss_tensor, torch.Tensor):\n                                    if loss_tensor.numel() > 1:\n                                        loss_val = float(loss_tensor.mean().item())\n                                    else:\n                                        loss_val = float(loss_tensor.item())\n                                else:\n                                    try:\n                                        loss_val = float(loss_tensor)\n                                    except Exception:\n                                        loss_val = None\n\n                        elif isinstance(outputs, (list, tuple)) and len(outputs) > 0:\n                            first = outputs[0]\n                            if isinstance(first, torch.Tensor):\n                                if first.numel() > 1:\n                                    loss_val = float(first.mean().item())\n                                else:\n                                    loss_val = float(first.item())\n                            else:\n                                try:\n                                    loss_val = float(first)\n                                except Exception:\n                                    loss_val = None\n\n                        if loss_val is not None:\n                            if batch_idx == 0:\n                                print(f\"[VALIDATION] Batch {batch_idx}: raw_loss={loss_val:.4f}\")\n\n                            if not math.isnan(loss_val) and not math.isinf(loss_val):\n                                val_losses.append(loss_val)\n                                if batch_idx == 0:\n                                    print(f\"[VALIDATION] Batch {batch_idx}: loss accepted\")\n\n                        if torch.cuda.is_available():\n                            torch.cuda.synchronize()\n                            torch.cuda.empty_cache()\n\n                        if batch_idx > 0 and batch_idx % 5 == 0:\n                            print(f\"[VALIDATION] Processed {batch_idx}/{num_val_batches} batches...\")\n\n                    except StopIteration:\n                        break\n                    except Exception as e:\n                        if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n                            print(f\"[VALIDATION] Batch {batch_idx} error: {type(e).__name__}\")\n                        continue\n\n            if val_losses:\n                validation_results['avg_loss'] = float(np.mean(val_losses))\n                print(f\"[VALIDATION] Computed avg loss: {validation_results['avg_loss']:.4f} from {len(val_losses)} batches\")\n            else:\n                validation_results['avg_loss'] = 0.0\n                print(f\"[VALIDATION] WARNING: No valid losses computed!\")\n\n            try:\n                print(f\"\\n[VALIDATION] Computing BLEU score + generating 10 translations...\")\n                print(\"-\" * 80)\n\n                try:\n                    from sacrebleu import corpus_bleu\n                except ImportError:\n                    import subprocess\n                    subprocess.check_call(['pip', 'install', 'sacrebleu', '-q'])\n                    from sacrebleu import corpus_bleu\n\n                all_references = []\n                all_predictions = []\n                translation_examples = []\n                bleu_batch_iter = iter(val_loader)\n\n                print(f\"[VALIDATION] Processing up to 20 batches for BLEU...\")\n\n                for bleu_idx in range(min(20, len(val_loader))):\n                    try:\n                        batch = next(bleu_batch_iter)\n                        if batch is None:\n                            continue\n\n                        input_ids = batch.get('input_ids', None)\n                        attention_mask = batch.get('attention_mask', None)\n                        labels = batch.get('labels', None)\n                        \n                        src_texts = batch.get('src_texts', None) or batch.get('src_text', None) or []\n\n                        if input_ids is None:\n                            continue\n\n                        input_ids = input_ids.to(device, non_blocking=True)\n                        if attention_mask is not None:\n                            attention_mask = attention_mask.to(device, non_blocking=True)\n                        if labels is not None:\n                            labels = labels.to(device, non_blocking=True)\n\n                        batch_size = input_ids.size(0)\n                        \n                        if bleu_idx == 0:\n                            print(f\"[VALIDATION] Batch {bleu_idx}: batch_size={batch_size}\")\n                            print(f\"[VALIDATION] Batch {bleu_idx}: src_texts len={len(src_texts) if isinstance(src_texts, (list, tuple)) else 'N/A'}\")\n\n                        with torch.no_grad():\n                            try:\n                                tokenizer.src_lang = source_lang\n                                tokenizer.tgt_lang = target_lang\n                            except Exception:\n                                pass\n\n                            try:\n                                if hasattr(core_model, 'mbart'):\n                                    gen_model = core_model.mbart\n                                elif hasattr(core_model, 'model'):\n                                    gen_model = core_model.model\n                                else:\n                                    gen_model = core_model\n                                \n                                tgt_lang_id = None\n                                if hasattr(tokenizer, 'lang_code_to_id'):\n                                    tgt_lang_id = tokenizer.lang_code_to_id.get(target_lang, None)\n                                \n                                if tgt_lang_id is None:\n                                    try:\n                                        tgt_lang_id = tokenizer.convert_tokens_to_ids(f\"__{target_lang}__\")\n                                        if tgt_lang_id == tokenizer.unk_token_id:\n                                            tgt_lang_id = None\n                                    except:\n                                        pass\n                                \n                                gen_kwargs = {\n                                    'max_length': max_length,\n                                    'num_beams': 2,\n                                    'early_stopping': True,\n                                    'pad_token_id': tokenizer.pad_token_id,\n                                    'eos_token_id': tokenizer.eos_token_id,\n                                }\n                                \n                                if tgt_lang_id is not None:\n                                    gen_kwargs['forced_bos_token_id'] = tgt_lang_id\n                                \n                                if bleu_idx == 0:\n                                    print(f\"[VALIDATION] Generation config: beams=2, max_len={max_length}, forced_bos={tgt_lang_id}\")\n                                \n                                generated_ids = gen_model.generate(\n                                    input_ids,\n                                    attention_mask=attention_mask,\n                                    **gen_kwargs\n                                )\n                                \n                                if bleu_idx == 0:\n                                    print(f\"[VALIDATION] ✅ Generation successful: shape={generated_ids.shape}\")\n                                \n                            except TypeError as te:\n                                if bleu_idx == 0:\n                                    print(f\"[VALIDATION] TypeError: {str(te)[:150]}\")\n                                    print(f\"[VALIDATION] Trying fallback without forced_bos_token_id...\")\n                                \n                                try:\n                                    generated_ids = gen_model.generate(\n                                        input_ids,\n                                        attention_mask=attention_mask,\n                                        max_length=max_length,\n                                        num_beams=2,\n                                        early_stopping=True,\n                                        pad_token_id=tokenizer.pad_token_id,\n                                        eos_token_id=tokenizer.eos_token_id,\n                                    )\n                                    if bleu_idx == 0:\n                                        print(f\"[VALIDATION] ✅ Fallback generation successful\")\n                                except Exception as fallback_err:\n                                    if bleu_idx == 0:\n                                        print(f\"[VALIDATION] Fallback failed: {type(fallback_err).__name__}\")\n                                    continue\n                            \n                            except Exception as gen_err:\n                                if bleu_idx == 0:\n                                    print(f\"[VALIDATION] Generation failed: {type(gen_err).__name__}: {str(gen_err)[:150]}\")\n                                continue\n\n                        if generated_ids is None or generated_ids.size(0) == 0:\n                            continue\n\n                        for j in range(min(batch_size, generated_ids.size(0))):\n                            try:\n                                ref_text = None\n                                \n                                if labels is not None and j < labels.size(0):\n                                    valid_mask = (labels[j] != -100)\n                                    if valid_mask.sum() > 0:\n                                        ref_ids = labels[j][valid_mask].tolist()\n                                        ref_text = tokenizer.decode(ref_ids, skip_special_tokens=True).strip()\n                                \n                                if not ref_text:\n                                    if j < len(src_texts):\n                                        ref_text = f\"[SRC: {src_texts[j][:50]}]\"\n                                    else:\n                                        ref_text = \"[NO REFERENCE]\"\n\n                                pred_ids = generated_ids[j].tolist()\n                                pred_text = tokenizer.decode(pred_ids, skip_special_tokens=True).strip()\n\n                                if not pred_text:\n                                    pred_text = \"[EMPTY]\"\n\n                                if ref_text and pred_text:\n                                    all_references.append([ref_text])\n                                    all_predictions.append(pred_text)\n\n                                    if len(translation_examples) < 10:\n                                        src_text = src_texts[j] if j < len(src_texts) else \"[NO SOURCE]\"\n                                        translation_examples.append({\n                                            'source': src_text,\n                                            'prediction': pred_text,\n                                            'reference': ref_text,\n                                        })\n                            \n                            except Exception:\n                                continue\n\n                        if torch.cuda.is_available():\n                            torch.cuda.synchronize()\n                            torch.cuda.empty_cache()\n\n                    except StopIteration:\n                        break\n                    except Exception as e:\n                        if bleu_idx == 0:\n                            print(f\"[VALIDATION] Batch {bleu_idx} error: {type(e).__name__}\")\n                        continue\n\n                print(f\"[VALIDATION] Collection complete: refs={len(all_references)}, preds={len(all_predictions)}\")\n\n                if all_references and all_predictions:\n                    valid_pairs = [(ref, pred) for ref, pred in zip(all_references, all_predictions)\n                                  if not ref[0].startswith('[NO REFERENCE]') and not pred.startswith('[EMPTY')]\n                    \n                    if valid_pairs:\n                        valid_refs = [p[0] for p in valid_pairs]\n                        valid_preds = [p[1] for p in valid_pairs]\n                        bleu_result = corpus_bleu(valid_preds, valid_refs)\n                        validation_results['bleu_score'] = bleu_result.score\n                        validation_results['bleu_samples'] = len(valid_pairs)\n                        print(f\"[VALIDATION] ✅ BLEU Score: {bleu_result.score:.2f} (from {len(valid_pairs)} translations)\")\n                    else:\n                        validation_results['bleu_score'] = 0.0\n                else:\n                    print(f\"[VALIDATION] ⚠️  BLEU skipped (refs={len(all_references)}, preds={len(all_predictions)})\")\n                    validation_results['bleu_score'] = 0.0\n\n                if translation_examples:\n                    print(f\"\\n[VALIDATION] ✅ Translation Examples ({len(translation_examples)} samples):\")\n                    print(\"=\" * 80)\n                    for idx, ex in enumerate(translation_examples[:5], 1):\n                        print(f\"[{idx}] SRC: {ex['source'][:60]}\")\n                        print(f\"    PRD: {ex['prediction'][:60]}\")\n                        print(f\"    REF: {ex['reference'][:60]}\")\n                    print(\"=\" * 80)\n                    validation_results['translation_examples'] = translation_examples\n                else:\n                    print(f\"[VALIDATION] ⚠️  No translation examples generated\")\n\n            except Exception as e:\n                print(f\"[VALIDATION] BLEU error: {type(e).__name__}: {str(e)[:200]}\")\n                validation_results['bleu_score'] = 0.0\n\n            print(f\"[VALIDATION] Processed {num_val_batches} validation batches\")\n\n        print(\"\\n\" + \"-\" * 80)\n        print(\"[VALIDATION] DSCD Prototype Quality Check:\")\n        try:\n            dscd = core_model.dscd if hasattr(core_model, 'dscd') else None\n            if dscd and hasattr(dscd, 'validate_prototypes'):\n                lock = None\n                if hasattr(dscd, 'buffer_lock'):\n                    lock = dscd.buffer_lock\n                elif hasattr(dscd, 'clustering_lock'):\n                    lock = dscd.clustering_lock\n\n                if lock:\n                    with lock:\n                        quality_results = dscd.validate_prototypes(cluster_missing=False)\n                else:\n                    quality_results = dscd.validate_prototypes(cluster_missing=False)\n\n                validation_results['dscd_quality_score'] = quality_results.get('quality_score', 0.0)\n                validation_results['dscd_multi_sense_tokens'] = quality_results.get('multi_sense_tokens', 0)\n                validation_results['dscd_total_prototypes'] = quality_results.get('total_prototypes', 0)\n                print(f\"  - Quality Score: {validation_results['dscd_quality_score']:.1%}\")\n                print(f\"  - Multi-sense tokens: {validation_results['dscd_multi_sense_tokens']}\")\n                print(f\"  - Total prototypes: {validation_results['dscd_total_prototypes']}\")\n            else:\n                print(\"  - Validation not available\")\n        except Exception as e:\n            print(f\"  - Validation failed: {type(e).__name__}\")\n\n        print(\"\\n\" + \"-\" * 80)\n        print(\"[VALIDATION] ASBN Training Statistics:\")\n        try:\n            asbn = core_model.asbn if hasattr(core_model, 'asbn') else None\n            if asbn and hasattr(asbn, 'get_detailed_stats'):\n                asbn_stats = asbn.get_detailed_stats()\n                validation_results['asbn_domain_loss'] = asbn_stats.get('domain_loss', 0.0)\n                validation_results['asbn_domain_accuracy'] = asbn_stats.get('domain_accuracy', 0.0)\n                validation_results['asbn_source_accuracy'] = asbn_stats.get('source_accuracy', 0.0)\n                validation_results['asbn_target_accuracy'] = asbn_stats.get('target_accuracy', 0.0)\n                print(f\"  - Domain Loss: {validation_results['asbn_domain_loss']:.4f}\")\n                print(f\"  - Domain Accuracy: {validation_results['asbn_domain_accuracy']:.2%}\")\n                print(f\"  - Source Accuracy: {validation_results['asbn_source_accuracy']:.2%}\")\n                print(f\"  - Target Accuracy: {validation_results['asbn_target_accuracy']:.2%}\")\n            elif asbn and hasattr(asbn, 'get_asbn_stats'):\n                asbn_stats = asbn.get_asbn_stats()\n                validation_results['asbn_domain_loss'] = asbn_stats.get('domain_loss', 0.0)\n                validation_results['asbn_domain_accuracy'] = asbn_stats.get('domain_accuracy', 0.0)\n                print(f\"  - Domain Loss: {validation_results['asbn_domain_loss']:.4f}\")\n                print(f\"  - Domain Accuracy: {validation_results['asbn_domain_accuracy']:.2%}\")\n            else:\n                print(\"  - ASBN statistics not available\")\n        except Exception as e:\n            print(f\"  - ASBN stats retrieval failed: {type(e).__name__}\")\n\n        print(\"\\n\" + \"-\" * 80)\n        print(\"[VALIDATION] TRG Explanation Statistics:\")\n        try:\n            trg = core_model.trg if hasattr(core_model, 'trg') else None\n            if trg and hasattr(trg, 'get_statistics'):\n                trg_stats = trg.get_statistics()\n                validation_results['trg_total_explanations'] = trg_stats.get('explanations_generated', 0)\n                print(f\"  - Total explanations: {validation_results['trg_total_explanations']}\")\n                print(f\"  - High confidence rate: {trg_stats.get('high_confidence_rate', 0):.1%}\")\n                print(f\"  - DSCD homograph rate: {trg_stats.get('dscd_homograph_rate', 0):.1%}\")\n            else:\n                print(\"  - TRG statistics not available\")\n        except Exception as e:\n            print(f\"  - TRG stats retrieval failed: {type(e).__name__}\")\n\n        if confidences:\n            validation_results['avg_explanation_confidence'] = sum(confidences) / len(confidences)\n\n        print(\"-\" * 80)\n        print(\"\\n[VALIDATION] Summary:\")\n        total_attempts = validation_results['translations_success'] + validation_results['translations_failed']\n        print(f\"  - Translations: {validation_results['translations_success']}/{total_attempts} successful\")\n        print(f\"  - Explanations generated: {validation_results['explanations_generated']}\")\n        print(f\"  - Avg explanation confidence: {validation_results['avg_explanation_confidence']:.3f}\")\n        print(f\"  - Avg validation loss: {validation_results['avg_loss']:.4f}\")\n        print(f\"  - BLEU Score: {validation_results['bleu_score']:.2f}\")\n        print(f\"  - DSCD homographs explained: {validation_results['dscd_homographs_explained']}\")\n        print(f\"  - Reference homographs explained: {validation_results['reference_homographs_explained']}\")\n\n        if dscd_homograph_words_detected:\n            print(f\"  - DSCD homographs detected: {', '.join(sorted(dscd_homograph_words_detected))}\")\n\n        print(f\"  - DSCD Quality Score: {validation_results['dscd_quality_score']:.1%}\")\n        print(f\"  - Multi-sense tokens: {validation_results['dscd_multi_sense_tokens']}\")\n        print(f\"  - ASBN Domain Accuracy: {validation_results['asbn_domain_accuracy']:.2%}\")\n\n        warnings = []\n        if total_attempts > 0 and validation_results['translations_failed'] > total_attempts // 2:\n            warnings.append(\"High translation failure rate\")\n        if validation_results['explanations_generated'] == 0:\n            warnings.append(\"No explanations generated\")\n        if validation_results['dscd_quality_score'] < 0.3:\n            warnings.append(\"Low DSCD quality score\")\n        if validation_results['dscd_multi_sense_tokens'] < 10:\n            warnings.append(\"Very few multi-sense tokens\")\n\n        if warnings:\n            print(\"\\n[VALIDATION] Health Warnings:\")\n            for w in warnings:\n                print(f\"  - {w}\")\n        else:\n            print(\"\\n[VALIDATION] All systems healthy\")\n\n        validation_results['validation_completed'] = True\n\n    except Exception as e:\n        print(f\"\\n[VALIDATION] Critical error: {type(e).__name__}: {str(e)[:200]}\")\n        if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n            try:\n                traceback.print_exc()\n            except Exception:\n                pass\n        validation_results['validation_completed'] = False\n\n    finally:\n        if was_training:\n            core_model.train()\n        clear_all_gpu_caches()\n\n    print(\"=\" * 80 + \"\\n\")\n    return validation_results\n\n\ndef _print_gpu_mem(prefix: str = \"\"):\n    if not torch.cuda.is_available():\n        return\n    try:\n        lines = [f\"{prefix} GPU mem (GB):\"]\n        for i in range(torch.cuda.device_count()):\n            try:\n                alloc = torch.cuda.memory_allocated(i) / (1024**3)\n                resv = torch.cuda.memory_reserved(i) / (1024**3)\n                lines.append(f\"  GPU {i}: alloc={alloc:.2f} resv={resv:.2f}\")\n            except Exception:\n                lines.append(f\"  GPU {i}: mem query failed\")\n        print(\"\\n\".join(lines))\n    except Exception:\n        pass\n\n\ndef _get_cluster_count(model: torch.nn.Module) -> int:\n    try:\n        core = model\n        while hasattr(core, 'module'):\n            core = core.module\n\n        dscd = getattr(core, 'dscd', None)\n        if dscd is None:\n            return 0\n\n        stores = getattr(dscd, 'prototype_stores', None)\n        if stores is None:\n            return 0\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        if lock:\n            with lock:\n                return len(stores)\n        else:\n            return len(stores)\n\n    except Exception:\n        return 0\n\n\ndef _get_dscd_safe(model: torch.nn.Module):\n    try:\n        core = model\n        while hasattr(core, 'module'):\n            core = core.module\n        return getattr(core, 'dscd', None)\n    except Exception:\n        return None\n\n\ndef _print_top_clusters(model: torch.nn.Module, top_n: int = 5):\n    dscd = _get_dscd_safe(model)\n    if dscd is None:\n        return\n\n    try:\n        print(\"\\n[CLUSTER] Top 5 clusters:\")\n        print(\"-\" * 90)\n        print(f\"{'Rank':<6}{'Token':<15}{'Count':<12}{'Protos':<10}{'Mu':<15}{'Tau':<12}\")\n        print(\"-\" * 90)\n\n        dscd_homographs = _get_dscd_homographs(model)\n        items = []\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        if lock:\n            with lock:\n                stores_snapshot = list(dscd.prototype_stores.items())\n        else:\n            stores_snapshot = list(dscd.prototype_stores.items())\n\n        for token, store in stores_snapshot:\n            try:\n                total_count = sum(getattr(store, \"counts\", []) or [])\n                protos = store.size() if hasattr(store, \"size\") else len(getattr(store, \"centroids\", []))\n                clean_token = str(token).replace('▁', '').replace('Ġ', '').strip().lower()\n\n                if _is_punctuation_only(clean_token):\n                    continue\n\n                mu = getattr(store, 'mu', 0.0)\n                tau = getattr(store, 'tau', 0.0)\n\n                items.append((token, total_count, protos, mu, tau))\n            except Exception:\n                continue\n\n        items.sort(key=lambda x: x[1], reverse=True)\n\n        for i, (tok, cnt, prot, mu, tau) in enumerate(items[:top_n], 1):\n            token_display = str(tok)[:12]\n            print(f\"{i:<6}{token_display:<15}{cnt:<12}{prot:<10}{mu:<15.6f}{tau:<12.6f}\")\n        print(\"-\" * 90)\n\n    except Exception as e:\n        if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n            print(f\"[CLUSTER-DBG] _print_top_clusters error: {type(e).__name__}\")\n\n\ndef _check_discovery_status(model: torch.nn.Module, global_step: int):\n    try:\n        core = model\n        while hasattr(core, 'module'):\n            core = core.module\n\n        dscd = getattr(core, 'dscd', None)\n        if dscd is None:\n            return\n\n        if hasattr(dscd, 'get_prototype_summary'):\n            summary = dscd.get_prototype_summary()\n            if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n                print(f\"[DISCOVERY-STATUS] Step {global_step}:\")\n                print(f\"  - Total tokens: {summary.get('total_tokens', 0)}\")\n                print(f\"  - Homographs: {summary.get('num_homographs', 0)}\")\n                print(f\"  - Total prototypes: {summary.get('total_prototypes', 0)}\")\n                print(f\"  - Quality score: {summary.get('quality_score', 0.0):.1%}\")\n\n        if hasattr(dscd, 'discovered_log') and dscd.discovered_log:\n            total_discovered = len(dscd.discovered_log)\n\n            if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n                print(f\"[DISCOVERY-STATUS] Discovery events: {total_discovered}\")\n\n                recent = dscd.discovered_log[-3:] if len(dscd.discovered_log) >= 3 else dscd.discovered_log\n                for entry in recent:\n                    discovered = entry.get('discovered', 0)\n                    candidates = entry.get('candidates', 0)\n                    print(f\"  - {discovered}/{candidates} homographs discovered\")\n    except Exception as e:\n        if _DEBUG_DISCOVERY or _VERBOSE_LOGGING:\n            print(f\"[DISCOVERY-STATUS] Error: {e}\")\n\n\ndef _print_path_loss_summary(training_stats: Dict[str, Any], validate_every: int, global_step: int, use_dual_path: bool):\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"LOSS SUMMARY AT STEP {global_step}\")\n    print(\"=\" * 80)\n\n    lookback_window = min(validate_every, len(training_stats['path1_losses']), len(training_stats['path2_losses']))\n\n    if use_dual_path and lookback_window > 0:\n        recent_p1_fwd = training_stats['path1_losses'][-lookback_window:] if training_stats['path1_losses'] else []\n        recent_p2_fwd = training_stats['path2_losses'][-lookback_window:] if training_stats['path2_losses'] else []\n        recent_bwd = training_stats['backward_losses'][-lookback_window:] if training_stats['backward_losses'] else []\n\n        p1_fwd_avg = float(np.mean(recent_p1_fwd)) if recent_p1_fwd else 0.0\n        p2_fwd_avg = float(np.mean(recent_p2_fwd)) if recent_p2_fwd else 0.0\n        bwd_avg = float(np.mean(recent_bwd)) if recent_bwd else 0.0\n\n        p1_count = training_stats['path1_batches']\n        p2_count = training_stats['path2_batches']\n\n        print(f\"\\nPATH 1 (DSCD Word-Level):\")\n        print(f\"  - Forward Loss:  {p1_fwd_avg:.4f}\")\n        print(f\"  - Backward Loss: {bwd_avg:.4f}\")\n        print(f\"  - Total Batches: {p1_count}\")\n\n        print(f\"\\nPATH 2 (Translation Subword):\")\n        print(f\"  - Forward Loss:  {p2_fwd_avg:.4f}\")\n        print(f\"  - Backward Loss: {bwd_avg:.4f}\")\n        print(f\"  - Total Batches: {p2_count}\")\n\n        print(f\"\\nCOMBINED:\")\n        print(f\"  - Total Batches: {p1_count + p2_count}\")\n        print(f\"  - Optimizer Updates: {training_stats['optimizer_updates']}\")\n    else:\n        recent_fwd = training_stats['total_loss'][-lookback_window:] if training_stats['total_loss'] else []\n        recent_bwd = training_stats['backward_losses'][-lookback_window:] if training_stats['backward_losses'] else []\n\n        fwd_avg = float(np.mean(recent_fwd)) if recent_fwd else 0.0\n        bwd_avg = float(np.mean(recent_bwd)) if recent_bwd else 0.0\n\n        print(f\"\\nSINGLE PATH MODE (Path 2 Only):\")\n        print(f\"  - Forward Loss:  {fwd_avg:.4f}\")\n        print(f\"  - Backward Loss: {bwd_avg:.4f}\")\n        print(f\"  - Total Batches: {training_stats['batches_processed']}\")\n        print(f\"  - Optimizer Updates: {training_stats['optimizer_updates']}\")\n\n    print(\"=\" * 80 + \"\\n\")\n\n\ndef train_memory_efficient_tatn(\n    model: torch.nn.Module,\n    tokenizer,\n    train_loader: torch.utils.data.DataLoader,\n    optimizer: torch.optim.Optimizer,\n    phi_optimizer: Optional[torch.optim.Optimizer] = None,\n    epochs: Optional[int] = None,\n    accumulation_steps: Optional[int] = None,\n    validate_every: Optional[int] = None,\n    enable_validation: bool = True,\n    use_dual_path: bool = None,\n    val_loader: Optional[torch.utils.data.DataLoader] = None,\n) -> torch.nn.Module:\n    if epochs is None:\n        epochs = _EPOCHS\n    if accumulation_steps is None:\n        accumulation_steps = _ACCUMULATION_STEPS\n    if validate_every is None:\n        validate_every = _VALIDATION_CHECK_INTERVAL\n    if use_dual_path is None:\n        use_dual_path = _USE_DUAL_PATH_TRAINING\n\n    print(f\"[TRAIN] Starting training: epochs={epochs}, batch={_BATCH_SIZE}, accum_steps={accumulation_steps}\")\n    print(f\"[TRAIN] Validation: {'enabled' if enable_validation and validate_every > 0 else 'disabled'}\")\n    if enable_validation and val_loader is not None:\n        try:\n            print(f\"[TRAIN] Validation dataloader: {len(val_loader)} batches\")\n        except Exception:\n            print(f\"[TRAIN] Validation dataloader: provided\")\n    print(f\"[TRAIN] DP enabled: {_USE_MULTI_GPU}, GPUs: {_NUM_GPUS}, Device: {_DEVICE}\")\n    print(f\"[TRAIN] Discovery frequency: {_PERIODIC_DISCOVERY_FREQUENCY} steps\")\n    print(f\"[TRAIN] Dual-path training: {'ENABLED' if use_dual_path else 'DISABLED (default path=2)'}\")\n    print(\"[TRAIN] Checkpoints:\")\n    print(\"  - Final: /kaggle/working/tatn_final.pt\")\n    print(\"  - Best:  /kaggle/working/tatn_best.pt (based on validation loss)\\n\")\n\n    model.train()\n    clear_all_gpu_caches()\n    scaler = GradScaler(enabled=(_USE_AMP and torch.cuda.is_available()))\n\n    scheduler = None\n    plateau_scheduler = None\n    \n    if _USE_LR_SCHEDULER:\n        try:\n            from torch.optim.lr_scheduler import ReduceLROnPlateau\n            \n            try:\n                plateau_scheduler = ReduceLROnPlateau(\n                    optimizer,\n                    mode='min',\n                    factor=0.5,\n                    patience=2,\n                    verbose=True,\n                    min_lr=1e-6,\n                )\n            except TypeError:\n                plateau_scheduler = ReduceLROnPlateau(\n                    optimizer,\n                    mode='min',\n                    factor=0.5,\n                    patience=2,\n                    min_lr=1e-6,\n                )\n            \n            print(f\"[TRAIN] ✅ Validation-based LR scheduler created:\")\n            print(f\"[TRAIN]    - Type: ReduceLROnPlateau\")\n            print(f\"[TRAIN]    - Mode: Minimize validation loss\")\n            print(f\"[TRAIN]    - Factor: 0.5 (halves LR on plateau)\")\n            print(f\"[TRAIN]    - Patience: 2 validations\")\n            print(f\"[TRAIN]    - Min LR: 1e-6\")\n            print(f\"[TRAIN]    - Initial LR: {optimizer.param_groups[0]['lr']:.2e}\\n\")\n        except ImportError:\n            print(\"[TRAIN] ⚠️  WARNING: torch.optim.lr_scheduler not available\\n\")\n            plateau_scheduler = None\n        except Exception as e:\n            print(f\"[TRAIN] ⚠️  WARNING: ReduceLROnPlateau creation failed: {type(e).__name__}\")\n            print(f\"[TRAIN] Error details: {str(e)[:100]}\\n\")\n            plateau_scheduler = None\n    else:\n        print(\"[TRAIN] Learning rate scheduler disabled\\n\")\n\n    print(\"[TRAIN] ✅ Early stopping enabled:\")\n    print(\"[TRAIN]    - Patience: 3 validations without improvement\\n\")\n\n    print(\"[TRAIN] ✅ Best checkpoint saving enabled:\")\n    print(\"[TRAIN]    - Path: /kaggle/working/tatn_best.pt\\n\")\n\n    global_step = 0\n    accumulated_steps = 0\n    pending_validation = False\n    val_loss_latest = 0.0\n    best_val_loss = float('inf')\n    patience_counter = 0\n    patience = 3\n    best_checkpoint_path = \"/kaggle/working/tatn_best.pt\"\n    early_stop_triggered = False\n\n    training_stats: Dict[str, Any] = {\n        \"total_loss\": [],\n        \"epoch_losses\": [],\n        \"backward_losses\": [],\n        \"batches_processed\": 0,\n        \"optimizer_updates\": 0,\n        \"skipped_batches\": 0,\n        \"oom_errors\": 0,\n        \"runtime_errors\": 0,\n        \"exceptions\": 0,\n        \"epoch_validations\": [],\n        \"dscd_quality_history\": [],\n        \"multi_sense_ratio_history\": [],\n        \"asbn_domain_accuracy_history\": [],\n        \"asbn_domain_loss_history\": [],\n        \"trg_explanation_history\": [],\n        \"discovery_runs\": 0,\n        \"discovery_homographs_found\": 0,\n        \"learning_rates\": [],\n        \"path1_batches\": 0,\n        \"path2_batches\": 0,\n        \"path1_losses\": [],\n        \"path2_losses\": [],\n        \"lr_reductions\": 0,\n        \"best_val_loss\": float('inf'),\n        \"best_val_loss_epoch\": 0,\n        \"best_bleu\": 0.0,\n    }\n\n    last_forward_loss = 0.0\n    last_backward_loss = 0.0\n    cached_cluster_count = 0\n\n    for epoch in range(1, epochs + 1):\n        if early_stop_triggered:\n            print(f\"\\n[EARLY STOP] Training stopped at epoch {epoch}\")\n            break\n\n        epoch_start = time.time()\n        epoch_losses: List[float] = []\n        skip_reasons = defaultdict(int)\n\n        print(f\"\\n{'='*80}\")\n        print(f\"EPOCH {epoch}/{epochs} STARTED\")\n        print(f\"{'='*80}\\n\")\n\n        try:\n            core = model.module if hasattr(model, 'module') else model\n            trg = getattr(core, 'trg', None)\n            if trg and hasattr(trg, 'reset_statistics'):\n                try:\n                    trg.reset_statistics()\n                    print(f\"[TRAIN] TRG statistics reset for epoch {epoch}\")\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        try:\n            core = model.module if hasattr(model, 'module') else model\n            asbn = getattr(core, 'asbn', None)\n            if asbn and hasattr(asbn, 'reset_stats'):\n                try:\n                    asbn.reset_stats()\n                    print(f\"[TRAIN] ASBN statistics reset for epoch {epoch}\")\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n        try:\n            optimizer.zero_grad(set_to_none=True)\n        except Exception:\n            pass\n\n        progress = None\n        batch_idx = 0\n        train_loss_window = deque(maxlen=50)\n\n        try:\n            progress = tqdm(\n                total=len(train_loader),\n                desc=f\"Epoch {epoch}/{epochs}\",\n                ncols=145,\n                leave=False,\n                position=0,\n                file=sys.stdout\n            )\n\n            for batch in train_loader:\n                batch_idx += 1\n                global_step += 1\n                training_stats[\"batches_processed\"] += 1\n\n                if _PERIODIC_DISCOVERY_FREQUENCY and _PERIODIC_DISCOVERY_FREQUENCY > 0:\n                    if global_step % _PERIODIC_DISCOVERY_FREQUENCY == 0:\n                        try:\n                            core = model.module if hasattr(model, 'module') else model\n                            dscd = getattr(core, 'dscd', None)\n                            if dscd and hasattr(dscd, 'periodic_discovery_check'):\n                                print(f\"\\n[DISCOVERY] Running periodic check at step {global_step}...\")\n                                num_discovered = dscd.periodic_discovery_check(\n                                    global_step=global_step,\n                                    frequency=_PERIODIC_DISCOVERY_FREQUENCY,\n                                    cluster_missing=False\n                                )\n                                training_stats['discovery_runs'] += 1\n                                training_stats['discovery_homographs_found'] += num_discovered\n\n                                cached_cluster_count = _get_cluster_count(model)\n                        except Exception:\n                            pass\n\n                if enable_validation and validate_every and validate_every > 0 and (global_step % validate_every == 0):\n                    if accumulated_steps == 0:\n                        try:\n                            optimizer.zero_grad(set_to_none=True)\n                        except Exception:\n                            pass\n\n                        if torch.cuda.is_available():\n                            torch.cuda.synchronize()\n\n                        try:\n                            core = model.module if hasattr(model, 'module') else model\n                            dscd = getattr(core, 'dscd', None)\n                            if dscd and hasattr(dscd, 'cleanup_memory'):\n                                print(f\"[VALIDATION] Running DSCD cleanup before validation...\")\n                                dscd.cleanup_memory()\n                                if torch.cuda.is_available():\n                                    torch.cuda.synchronize()\n                                    torch.cuda.empty_cache()\n                        except Exception:\n                            pass\n\n                        _print_path_loss_summary(training_stats, validate_every, global_step, use_dual_path)\n\n                        val_result = comprehensive_epoch_validation(\n                            model,\n                            tokenizer,\n                            epoch,\n                            global_step,\n                            _SOURCE_LANGUAGE,\n                            _TARGET_LANGUAGE,\n                            _MAX_LENGTH,\n                            _DEVICE,\n                            val_loader=val_loader,\n                        )\n\n                        if val_result:\n                            training_stats['epoch_validations'].append(val_result)\n                            val_loss_latest = val_result.get('avg_loss', 0.0)\n                            current_bleu = val_result.get('bleu_score', 0.0)\n\n                            if plateau_scheduler is not None and val_loss_latest > 0.0:\n                                old_lr = optimizer.param_groups[0]['lr']\n                                plateau_scheduler.step(val_loss_latest)\n                                new_lr = optimizer.param_groups[0]['lr']\n                                \n                                if new_lr < old_lr:\n                                    training_stats['lr_reductions'] += 1\n                                    print(f\"\\n[LR SCHEDULER] 📉 LR reduced: {old_lr:.2e} → {new_lr:.2e}\\n\")\n\n                            if val_loss_latest > 0.0:\n                                if val_loss_latest < best_val_loss:\n                                    improvement = best_val_loss - val_loss_latest\n                                    best_val_loss = val_loss_latest\n                                    training_stats['best_val_loss'] = best_val_loss\n                                    training_stats['best_val_loss_epoch'] = epoch\n                                    training_stats['best_bleu'] = max(training_stats['best_bleu'], current_bleu)\n                                    patience_counter = 0\n\n                                    print(f\"\\n[EARLY STOP] ✅ New best val loss: {val_loss_latest:.4f} (improved by {improvement:.4f})\")\n                                    print(f\"[EARLY STOP] BLEU: {current_bleu:.2f}, Patience: 0/{patience}\\n\")\n\n                                    try:\n                                        print(f\"[CHECKPOINT] 💾 Saving BEST model...\")\n                                        \n                                        checkpoint_data = {\n                                            'epoch': epoch,\n                                            'global_step': global_step,\n                                            'val_loss': val_loss_latest,\n                                            'bleu_score': current_bleu,\n                                            'model_state_dict': (model.module if hasattr(model, 'module') else model).state_dict(),\n                                            'optimizer_state_dict': optimizer.state_dict(),\n                                            'scheduler_state_dict': plateau_scheduler.state_dict() if plateau_scheduler is not None else None,\n                                            'training_stats': training_stats,\n                                        }\n                                        \n                                        torch.save(checkpoint_data, best_checkpoint_path)\n                                        \n                                        file_size_mb = Path(best_checkpoint_path).stat().st_size / (1024**2)\n                                        print(f\"[CHECKPOINT] ✅ Saved: {file_size_mb:.2f} MB\")\n                                        print(f\"[CHECKPOINT] Val Loss: {val_loss_latest:.4f}, BLEU: {current_bleu:.2f}\\n\")\n                                    except Exception as e:\n                                        print(f\"[CHECKPOINT] ❌ Failed: {type(e).__name__}\\n\")\n                                \n                                else:\n                                    patience_counter += 1\n                                    print(f\"\\n[EARLY STOP] ⚠️  No improvement. Patience: {patience_counter}/{patience}\\n\")\n                                    \n                                    if patience_counter >= patience:\n                                        print(f\"[EARLY STOP] 🛑 Early stopping triggered!\\n\")\n                                        early_stop_triggered = True\n\n                            if len(training_stats['epoch_validations']) > 1:\n                                print(\"\\n\" + \"-\" * 80)\n                                print(\"[VALIDATION] Loss History:\")\n                                print(f\"{'Epoch':<8}{'Step':<10}{'Val Loss':<12}{'BLEU':<10}{'Trend':<15}{'LR':<12}\")\n                                print(\"-\" * 80)\n\n                                prev_loss = None\n                                for val_rec in training_stats['epoch_validations']:\n                                    ep = val_rec.get('epoch', 0)\n                                    step = val_rec.get('step', 0)\n                                    loss = val_rec.get('avg_loss', 0.0)\n                                    bleu = val_rec.get('bleu_score', 0.0)\n                                    \n                                    current_lr = optimizer.param_groups[0]['lr']\n                                    is_best = (loss == training_stats['best_val_loss'])\n\n                                    if prev_loss is not None and prev_loss > 0:\n                                        if loss < prev_loss:\n                                            trend = \"↓ Improving\" if not is_best else \"↓ BEST ⭐\"\n                                        elif loss > prev_loss:\n                                            trend = \"↑ Degrading\"\n                                        else:\n                                            trend = \"→ Stable\"\n                                    else:\n                                        trend = \"—\" if not is_best else \"BEST ⭐\"\n\n                                    print(f\"{ep:<8}{step:<10}{loss:<12.4f}{bleu:<10.2f}{trend:<15}{current_lr:<12.2e}\")\n                                    prev_loss = loss\n\n                                print(\"-\" * 80)\n                                print(f\"Best Val Loss: {training_stats['best_val_loss']:.4f} (Epoch {training_stats['best_val_loss_epoch']})\")\n                                print(f\"Best BLEU: {training_stats['best_bleu']:.2f}\")\n                                print(f\"Patience: {patience_counter}/{patience}\")\n                                print(\"=\" * 80)\n\n                        cached_cluster_count = _get_cluster_count(model)\n                    else:\n                        pending_validation = True\n\n                if batch is None:\n                    training_stats[\"skipped_batches\"] += 1\n                    skip_reasons[\"batch_none\"] += 1\n                    progress.update(1)\n                    continue\n\n                try:\n                    input_ids = batch[\"input_ids\"]\n                    attention_mask = batch[\"attention_mask\"]\n                    labels = batch[\"labels\"]\n\n                    batch_size = int(input_ids.size(0))\n\n                    domain_labels = batch.get(\"domain_labels\", None)\n                    if domain_labels is not None:\n                        if not isinstance(domain_labels, torch.Tensor):\n                            domain_labels = None\n                        elif domain_labels.dim() == 0:\n                            domain_labels = domain_labels.unsqueeze(0)\n\n                    if domain_labels is None:\n                        domain_labels = torch.full(\n                            (batch_size,),\n                            _TRAIN_DOMAIN,\n                            dtype=torch.long,\n                            device=torch.device('cpu')\n                        )\n\n                    if _USE_MULTI_GPU and _NUM_GPUS > 0:\n                        keep = (batch_size // _NUM_GPUS) * _NUM_GPUS\n                        if keep == 0:\n                            training_stats[\"skipped_batches\"] += 1\n                            skip_reasons[\"dp_keep_zero\"] += 1\n                            progress.update(1)\n                            continue\n                        if keep != batch_size:\n                            input_ids = input_ids[:keep]\n                            attention_mask = attention_mask[:keep]\n                            labels = labels[:keep]\n                            domain_labels = domain_labels[:keep]\n                            batch_size = keep\n\n                    input_ids = input_ids.to(_DEVICE, non_blocking=True)\n                    attention_mask = attention_mask.to(_DEVICE, non_blocking=True)\n                    labels = labels.to(_DEVICE, non_blocking=True)\n                    domain_labels = domain_labels.to(_DEVICE, non_blocking=True)\n\n                    if input_ids.size(0) == 0:\n                        training_stats[\"skipped_batches\"] += 1\n                        skip_reasons[\"empty_batch\"] += 1\n                        progress.update(1)\n                        continue\n\n                    if use_dual_path:\n                        selected_path = 1 if batch_idx % 2 == 1 else 2\n                    else:\n                        selected_path = 2\n\n                    if selected_path == 1:\n                        training_stats[\"path1_batches\"] += 1\n\n                        forward_kwargs = {\n                            \"input_ids\": input_ids,\n                            \"attention_mask\": attention_mask,\n                            \"src_texts\": batch.get(\"src_text\", None),\n                            \"token_word_map\": batch.get(\"token_word_map\", None),\n                            \"domain_labels\": domain_labels,\n                        }\n\n                        amp_ctx = get_amp_ctx()\n                        with amp_ctx:\n                            try:\n                                core = model.module if hasattr(model, 'module') else model\n                                if hasattr(core, 'forward_path1'):\n                                    forward_out = core.forward_path1(**forward_kwargs)\n                                else:\n                                    forward_kwargs[\"labels\"] = None\n                                    forward_kwargs[\"path\"] = 1\n                                    forward_out = model(**forward_kwargs)\n                            except Exception:\n                                forward_kwargs[\"labels\"] = None\n                                forward_kwargs[\"path\"] = 1\n                                forward_out = model(**forward_kwargs)\n\n                            if isinstance(forward_out, torch.Tensor):\n                                loss_tensor = forward_out\n                            elif isinstance(forward_out, dict):\n                                if \"loss\" in forward_out:\n                                    loss_tensor = forward_out[\"loss\"]\n                                elif \"asbn_loss\" in forward_out:\n                                    loss_tensor = forward_out[\"asbn_loss\"]\n                                else:\n                                    raise RuntimeError(\"Path 1 forward: no loss found\")\n                            elif isinstance(forward_out, (list, tuple)) and len(forward_out) > 0:\n                                loss_tensor = forward_out[0]\n                            else:\n                                raise RuntimeError(\"Path 1 forward: unrecognized output\")\n\n                            if not isinstance(loss_tensor, torch.Tensor):\n                                loss_tensor = torch.tensor(float(loss_tensor), device=_DEVICE)\n                            else:\n                                loss_tensor = loss_tensor.to(_DEVICE)\n\n                            if loss_tensor.numel() > 1:\n                                loss_val = float(loss_tensor.mean().item())\n                                loss_tensor = loss_tensor.mean()\n                            else:\n                                loss_val = float(loss_tensor.item())\n\n                            last_forward_loss = loss_val\n                            epoch_losses.append(loss_val)\n                            training_stats[\"total_loss\"].append(loss_val)\n                            training_stats[\"path1_losses\"].append(loss_val)\n\n                    else:\n                        training_stats[\"path2_batches\"] += 1\n\n                        forward_kwargs = {\n                            \"input_ids\": input_ids,\n                            \"attention_mask\": attention_mask,\n                            \"labels\": labels,\n                            \"src_texts\": batch.get(\"src_text\", None),\n                            \"token_word_map\": batch.get(\"token_word_map\", None),\n                        }\n\n                        amp_ctx = get_amp_ctx()\n                        with amp_ctx:\n                            try:\n                                core = model.module if hasattr(model, 'module') else model\n                                if hasattr(core, 'forward_path2'):\n                                    forward_out = core.forward_path2(**forward_kwargs, use_rdrop=True)\n                                else:\n                                    forward_kwargs[\"path\"] = 2\n                                    forward_out = model(**forward_kwargs)\n                            except Exception:\n                                forward_kwargs[\"path\"] = 2\n                                forward_out = model(**forward_kwargs)\n\n                            if isinstance(forward_out, torch.Tensor):\n                                loss_tensor = forward_out\n                            elif isinstance(forward_out, dict) and \"loss\" in forward_out:\n                                loss_tensor = forward_out[\"loss\"]\n                            elif isinstance(forward_out, (list, tuple)) and len(forward_out) > 0:\n                                loss_tensor = forward_out[0]\n                            else:\n                                raise RuntimeError(\"Model forward: no loss found\")\n\n                            if not isinstance(loss_tensor, torch.Tensor):\n                                loss_tensor = torch.tensor(float(loss_tensor), device=_DEVICE)\n                            else:\n                                loss_tensor = loss_tensor.to(_DEVICE)\n\n                            if loss_tensor.numel() > 1:\n                                loss_val = float(loss_tensor.mean().item())\n                                loss_tensor = loss_tensor.mean()\n                            else:\n                                loss_val = float(loss_tensor.item())\n\n                            last_forward_loss = loss_val\n                            epoch_losses.append(loss_val)\n                            training_stats[\"total_loss\"].append(loss_val)\n                            training_stats[\"path2_losses\"].append(loss_val)\n\n                    train_loss_window.append(loss_val)\n                    avg_train_loss = sum(train_loss_window) / len(train_loss_window) if train_loss_window else 0.0\n\n                    loss_scaled = loss_tensor / max(1, accumulation_steps)\n                    last_backward_loss = float(loss_scaled.item())\n                    training_stats[\"backward_losses\"].append(last_backward_loss)\n\n                    try:\n                        if scaler.is_enabled():\n                            scaler.scale(loss_scaled).backward()\n                        else:\n                            loss_scaled.backward()\n\n                        if torch.cuda.is_available():\n                            torch.cuda.empty_cache()\n\n                    except RuntimeError as e:\n                        if \"out of memory\" in str(e).lower():\n                            training_stats[\"oom_errors\"] += 1\n                            training_stats[\"skipped_batches\"] += 1\n                            skip_reasons[\"oom_backward\"] += 1\n                            print(f\"\\n[OOM] Step {global_step} - Cleanup\")\n                            try:\n                                optimizer.zero_grad(set_to_none=True)\n                            except Exception:\n                                pass\n                            for p in model.parameters():\n                                p.grad = None\n                            if torch.cuda.is_available():\n                                torch.cuda.empty_cache()\n                            gc.collect()\n                            accumulated_steps = 0\n                            progress.update(1)\n                            continue\n                        else:\n                            raise\n\n                    accumulated_steps += 1\n\n                    if accumulated_steps >= accumulation_steps:\n                        try:\n                            if scaler.is_enabled():\n                                scaler.unscale_(optimizer)\n                                torch.nn.utils.clip_grad_norm_(model.parameters(), _GRAD_CLIP_NORM)\n                                scaler.step(optimizer)\n                                scaler.update()\n                            else:\n                                torch.nn.utils.clip_grad_norm_(model.parameters(), _GRAD_CLIP_NORM)\n                                optimizer.step()\n\n                            current_lr = optimizer.param_groups[0]['lr']\n                            training_stats['learning_rates'].append(current_lr)\n\n                            optimizer.zero_grad(set_to_none=True)\n                            training_stats[\"optimizer_updates\"] += 1\n\n                            if torch.cuda.is_available():\n                                torch.cuda.empty_cache()\n\n                        except RuntimeError as e:\n                            if \"out of memory\" in str(e).lower():\n                                training_stats[\"oom_errors\"] += 1\n                                print(f\"\\n[OOM] Step {global_step}\")\n                                try:\n                                    optimizer.zero_grad(set_to_none=True)\n                                except Exception:\n                                    pass\n                                for p in model.parameters():\n                                    p.grad = None\n                                if torch.cuda.is_available():\n                                    torch.cuda.empty_cache()\n                                gc.collect()\n                                accumulated_steps = 0\n                                progress.update(1)\n                                continue\n                            else:\n                                training_stats[\"runtime_errors\"] += 1\n                        except Exception:\n                            training_stats[\"exceptions\"] += 1\n                        finally:\n                            accumulated_steps = 0\n\n                            if pending_validation:\n                                try:\n                                    optimizer.zero_grad(set_to_none=True)\n                                except Exception:\n                                    pass\n\n                                if torch.cuda.is_available():\n                                    torch.cuda.synchronize()\n\n                                _print_path_loss_summary(training_stats, validate_every, global_step, use_dual_path)\n\n                                val_result = comprehensive_epoch_validation(\n                                    model,\n                                    tokenizer,\n                                    epoch,\n                                    global_step,\n                                    _SOURCE_LANGUAGE,\n                                    _TARGET_LANGUAGE,\n                                    _MAX_LENGTH,\n                                    _DEVICE,\n                                    val_loader=val_loader,\n                                )\n\n                                if val_result:\n                                    training_stats['epoch_validations'].append(val_result)\n                                    val_loss_latest = val_result.get('avg_loss', 0.0)\n                                    current_bleu = val_result.get('bleu_score', 0.0)\n\n                                    if plateau_scheduler is not None and val_loss_latest > 0.0:\n                                        old_lr = optimizer.param_groups[0]['lr']\n                                        plateau_scheduler.step(val_loss_latest)\n                                        new_lr = optimizer.param_groups[0]['lr']\n                                        if new_lr < old_lr:\n                                            training_stats['lr_reductions'] += 1\n                                            print(f\"\\n[LR] Reduced: {old_lr:.2e} → {new_lr:.2e}\\n\")\n\n                                    if val_loss_latest > 0.0:\n                                        if val_loss_latest < best_val_loss:\n                                            improvement = best_val_loss - val_loss_latest\n                                            best_val_loss = val_loss_latest\n                                            training_stats['best_val_loss'] = best_val_loss\n                                            training_stats['best_val_loss_epoch'] = epoch\n                                            training_stats['best_bleu'] = max(training_stats['best_bleu'], current_bleu)\n                                            patience_counter = 0\n                                            print(f\"\\n[BEST] Val: {val_loss_latest:.4f}, BLEU: {current_bleu:.2f}\\n\")\n\n                                            try:\n                                                checkpoint_data = {\n                                                    'epoch': epoch,\n                                                    'global_step': global_step,\n                                                    'val_loss': val_loss_latest,\n                                                    'bleu_score': current_bleu,\n                                                    'model_state_dict': (model.module if hasattr(model, 'module') else model).state_dict(),\n                                                    'optimizer_state_dict': optimizer.state_dict(),\n                                                    'training_stats': training_stats,\n                                                }\n                                                torch.save(checkpoint_data, best_checkpoint_path)\n                                                print(f\"[CHECKPOINT] ✅ Saved best model\\n\")\n                                            except Exception:\n                                                pass\n                                        else:\n                                            patience_counter += 1\n                                            if patience_counter >= patience:\n                                                early_stop_triggered = True\n\n                                pending_validation = False\n                                cached_cluster_count = _get_cluster_count(model)\n\n                    if global_step % DEBUG_PRINT_INTERVAL == 0:\n                        _print_gpu_mem(\"[DEBUG]\")\n                        cached_cluster_count = _get_cluster_count(model)\n                        print(f\"[DEBUG] step={global_step} loss={last_forward_loss:.4f} clusters={cached_cluster_count}\")\n                        _print_top_clusters(model, top_n=5)\n\n                    if global_step % _MEMORY_CLEANUP_FREQUENCY == 0:\n                        clear_all_gpu_caches()\n\n                except RuntimeError as e:\n                    if \"out of memory\" in str(e).lower():\n                        training_stats[\"oom_errors\"] += 1\n                        training_stats[\"skipped_batches\"] += 1\n                        print(f\"\\n[OOM] Step {global_step}\")\n                        try:\n                            optimizer.zero_grad(set_to_none=True)\n                        except Exception:\n                            pass\n                        for p in model.parameters():\n                            p.grad = None\n                        if torch.cuda.is_available():\n                            torch.cuda.empty_cache()\n                        gc.collect()\n                        accumulated_steps = 0\n                        progress.update(1)\n                        continue\n                    else:\n                        training_stats[\"runtime_errors\"] += 1\n                        accumulated_steps = 0\n                        progress.update(1)\n                        continue\n                except Exception:\n                    training_stats[\"exceptions\"] += 1\n                    accumulated_steps = 0\n                    progress.update(1)\n                    continue\n\n                processed_batches = training_stats[\"batches_processed\"] - training_stats[\"skipped_batches\"]\n                expected_updates = max(1, math.floor(processed_batches / max(1, accumulation_steps)))\n                success_rate = 100.0 * training_stats[\"optimizer_updates\"] / expected_updates if expected_updates > 0 else 0.0\n\n                next_disc = 0\n                try:\n                    if _PERIODIC_DISCOVERY_FREQUENCY and _PERIODIC_DISCOVERY_FREQUENCY > 0:\n                        next_disc = _PERIODIC_DISCOVERY_FREQUENCY - (global_step % _PERIODIC_DISCOVERY_FREQUENCY)\n                except Exception:\n                    next_disc = 0\n\n                current_lr = optimizer.param_groups[0]['lr']\n\n                postfix = {\n                    'train_loss': f\"{avg_train_loss:.4f}\",\n                    'val_loss': f\"{val_loss_latest:.4f}\" if val_loss_latest else \"0.0000\",\n                    'rate': f\"{success_rate:.1f}%\",\n                    'disc': next_disc,\n                    'lr': f\"{current_lr:.1e}\",\n                    'patience': f\"{patience_counter}/{patience}\",\n                }\n\n                if use_dual_path:\n                    postfix['path'] = f\"{selected_path}\"\n\n                progress.set_postfix(postfix, refresh=False)\n                progress.update(1)\n\n                if early_stop_triggered:\n                    break\n\n        finally:\n            if progress is not None:\n                try:\n                    progress.close()\n                except Exception:\n                    pass\n\n        if accumulated_steps > 0:\n            try:\n                if scaler.is_enabled():\n                    scaler.step(optimizer)\n                    scaler.update()\n                else:\n                    optimizer.step()\n                optimizer.zero_grad(set_to_none=True)\n                training_stats[\"optimizer_updates\"] += 1\n            except Exception:\n                pass\n            finally:\n                accumulated_steps = 0\n\n        epoch_duration_min = (time.time() - epoch_start) / 60.0\n        avg_epoch_loss = float(np.mean(epoch_losses)) if epoch_losses else 0.0\n        training_stats[\"epoch_losses\"].append(avg_epoch_loss)\n\n        print(f\"\\n{'='*80}\")\n        print(f\"EPOCH {epoch}/{epochs} SUMMARY\")\n        print(f\"{'='*80}\")\n        print(f\"  Duration: {epoch_duration_min:.2f} min\")\n        print(f\"  Avg loss: {avg_epoch_loss:.6f}\")\n        print(f\"  Clusters: {cached_cluster_count}\")\n        print(f\"  Best val: {training_stats['best_val_loss']:.4f}\")\n        print(f\"  Best BLEU: {training_stats['best_bleu']:.2f}\")\n        print(f\"  Patience: {patience_counter}/{patience}\")\n        print(f\"{'='*80}\")\n\n    print(f\"\\n{'='*80}\")\n    print(\"TRAINING COMPLETE\")\n    print(f\"{'='*80}\")\n\n    try:\n        checkpoint_path = Path(\"/kaggle/working/tatn_final.pt\")\n        core_model = model.module if hasattr(model, 'module') else model\n\n        checkpoint_data = {\n            'epochs_trained': epoch,\n            'global_steps': global_step,\n            'best_val_loss': training_stats['best_val_loss'],\n            'best_bleu': training_stats['best_bleu'],\n            'model_state_dict': core_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'training_stats': training_stats,\n            'early_stopped': early_stop_triggered,\n        }\n\n        torch.save(checkpoint_data, checkpoint_path)\n        file_size_mb = checkpoint_path.stat().st_size / (1024**2)\n\n        print(f\"\\nFINAL CHECKPOINT:\")\n        print(f\"  Path: {checkpoint_path}\")\n        print(f\"  Size: {file_size_mb:.2f} MB\")\n        print(f\"  Best val: {training_stats['best_val_loss']:.4f}\")\n        print(f\"  Best BLEU: {training_stats['best_bleu']:.2f}\")\n        print(f\"{'='*80}\\n\")\n\n    except Exception as e:\n        print(f\"Checkpoint save failed: {type(e).__name__}\")\n\n    return model\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 7: COMPLETE FIXED VERSION\")\nprint(\"=\" * 80)\nprint(\"✅ Generation TypeError fixed (forced_bos_token_id + fallback)\")\nprint(\"✅ ReduceLROnPlateau fixed (verbose parameter handling)\")\nprint(\"✅ BLEU computation robust\")\nprint(\"✅ Early stopping active\")\nprint(\"✅ Best checkpoint saving active\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"coTb4Fi4H4J4","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:04.734470Z","iopub.execute_input":"2026-02-18T08:40:04.734717Z","iopub.status.idle":"2026-02-18T08:40:04.875874Z","shell.execute_reply.started":"2026-02-18T08:40:04.734698Z","shell.execute_reply":"2026-02-18T08:40:04.875234Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCell 7: COMPLETE FIXED VERSION\n================================================================================\n✅ Generation TypeError fixed (forced_bos_token_id + fallback)\n✅ ReduceLROnPlateau fixed (verbose parameter handling)\n✅ BLEU computation robust\n✅ Early stopping active\n✅ Best checkpoint saving active\n================================================================================\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 8: INFERENCE & EVALUATION PIPELINE (DUAL-PATH COMPATIBLE) - COMPLETE & FIXED\n# ===========================================================================================\nimport os\nimport time\nimport math\nimport torch\nimport traceback\nfrom typing import List, Dict, Any, Tuple, Optional\nfrom collections import defaultdict\nfrom transformers.modeling_outputs import BaseModelOutput\nimport threading\nimport gc\n\ntry:\n    SOURCE_LANG = str(SOURCE_LANGUAGE)\n    TARGET_LANG = str(TARGET_LANGUAGE)\nexcept (NameError, TypeError):\n    SOURCE_LANG = \"bn\"\n    TARGET_LANG = \"en\"\n\ntry:\n    MAXLEN = int(MAX_LENGTH)\nexcept (NameError, ValueError, TypeError):\n    MAXLEN = 128\n\ntry:\n    DEVICE = DEVICE\nexcept (NameError, TypeError):\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntry:\n    VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, TypeError):\n    VERBOSE_LOGGING = False\n\ntry:\n    DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept (NameError, TypeError):\n    DEBUG_DISCOVERY = False\n\ntry:\n    DEBUG_TIMING = bool(DEBUG_TIMING)\nexcept (NameError, TypeError):\n    DEBUG_TIMING = False\n\ntry:\n    USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept (NameError, TypeError):\n    USE_MULTI_GPU = torch.cuda.is_available() and (torch.cuda.device_count() > 1)\n\ntry:\n    SPAN_THRESHOLD = float(SPAN_THRESHOLD)\nexcept (NameError, ValueError, TypeError):\n    SPAN_THRESHOLD = 0.10\n\ntry:\n    UNCERTAINTY_THRESHOLD = float(UNCERTAINTY_THRESHOLD)\nexcept (NameError, ValueError, TypeError):\n    UNCERTAINTY_THRESHOLD = 0.10\n\ntry:\n    HOMOGRAPH_REFERENCE_LIST = set(str(w).lower() for w in HOMOGRAPH_REFERENCE_LIST_BN)\nexcept (NameError, TypeError):\n    HOMOGRAPH_REFERENCE_LIST = {\n        \"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\", \"ফল\", \"মাথা\", \"বার\", \"হার\", \"তারা\",\n        \"পানি\", \"দল\", \"বাজার\", \"নাম\", \"কথা\", \"বই\", \"ঘর\", \"মন\", \"হাত\"\n    }\n    HOMOGRAPH_REFERENCE_LIST = set(str(w).lower() for w in HOMOGRAPH_REFERENCE_LIST)\n\ntry:\n    MBART50_EN_TOKEN_ID = int(MBART50_EN_TOKEN_ID)\nexcept (NameError, ValueError, TypeError):\n    MBART50_EN_TOKEN_ID = 250004\n\ntry:\n    MBART50_BN_TOKEN_ID = int(MBART50_BN_TOKEN_ID)\nexcept (NameError, ValueError, TypeError):\n    MBART50_BN_TOKEN_ID = 250028\n\ntry:\n    TEST_DOMAIN = int(TEST_DOMAIN)\nexcept (NameError, ValueError, TypeError):\n    TEST_DOMAIN = 1\n\ntry:\n    EVAL_NUM_BEAMS = int(EVAL_NUM_BEAMS)\nexcept (NameError, ValueError, TypeError):\n    EVAL_NUM_BEAMS = 8\n\ntry:\n    EVAL_LENGTH_PENALTY = float(EVAL_LENGTH_PENALTY)\nexcept (NameError, ValueError, TypeError):\n    EVAL_LENGTH_PENALTY = 1.0\n\ntry:\n    EVAL_NO_REPEAT_NGRAM_SIZE = int(EVAL_NO_REPEAT_NGRAM_SIZE)\nexcept (NameError, ValueError, TypeError):\n    EVAL_NO_REPEAT_NGRAM_SIZE = 2\n\ntry:\n    EVAL_MIN_LENGTH = int(EVAL_MIN_LENGTH)\nexcept (NameError, ValueError, TypeError):\n    EVAL_MIN_LENGTH = 3\n\nBENGALI_PUNCT_SET = set(['।', '॥'])\nCOMMON_PUNCT_SET = set(['.', ',', ';', ':', '!', '?', '\"', \"'\", '-', '(', ')', '[', ']', '{', '}', '/', '\\\\'])\nPUNCT_SET = BENGALI_PUNCT_SET | COMMON_PUNCT_SET\n\n\ndef is_punctuation_only(token: str) -> bool:\n    if not token or not isinstance(token, str):\n        return False\n\n    clean = (\n        token.replace(\"▁\", \"\")\n        .replace(\"Ġ\", \"\")\n        .replace(\"##\", \"\")\n        .replace(\"</w>\", \"\")\n        .strip()\n    )\n\n    if not clean:\n        return False\n\n    if clean in BENGALI_PUNCT_SET:\n        return True\n\n    if clean in COMMON_PUNCT_SET:\n        return True\n\n    if len(clean) == 1 and not clean.isalnum():\n        return True\n\n    return all(c in PUNCT_SET for c in clean)\n\n\ndef clean_token(token: str) -> str:\n    if not isinstance(token, str):\n        return \"\"\n    cleaned = token.replace(\"▁\", \"\").replace(\"Ġ\", \"\").replace(\"##\", \"\").strip()\n    for punct in [\".\", \",\", \"!\", \"?\", \";\", \":\", \"-\"]:\n        cleaned = cleaned.replace(punct, \"\")\n    return cleaned.lower()\n\n\ndef get_dscd_homographs(model: torch.nn.Module) -> set:\n    try:\n        core = model.module if hasattr(model, 'module') else model\n        dscd = getattr(core, 'dscd', None)\n        if dscd is None:\n            return set()\n\n        if hasattr(dscd, 'get_discovered_homographs'):\n            try:\n                discovered = dscd.get_discovered_homographs()\n                return set(w for w in discovered if not is_punctuation_only(w))\n            except Exception:\n                pass\n\n        homographs = set()\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        if lock:\n            with lock:\n                for token, store in dscd.prototype_stores.items():\n                    try:\n                        if store.size() >= 2:\n                            clean_tok = clean_token(str(token))\n                            if clean_tok and not is_punctuation_only(str(token)):\n                                homographs.add(clean_tok)\n                    except Exception:\n                        continue\n        else:\n            for token, store in dscd.prototype_stores.items():\n                try:\n                    if store.size() >= 2:\n                        clean_tok = clean_token(str(token))\n                        if clean_tok and not is_punctuation_only(str(token)):\n                            homographs.add(clean_tok)\n                except Exception:\n                    continue\n\n        return homographs\n    except Exception:\n        return set()\n\n\nclass InferenceStatistics:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self.reset()\n\n    def reset(self):\n        with self._lock:\n            self.total_inferences = 0\n            self.successful_translations = 0\n            self.failed_translations = 0\n            self.total_explanations = 0\n            self.high_confidence_explanations = 0\n            self.low_confidence_explanations = 0\n            self.total_confidence = 0.0\n            self.dscd_homographs_explained = set()\n            self.reference_homographs_explained = set()\n            self.avg_span = 0.0\n            self.avg_uncertainty = 0.0\n            self.dscd_empty_warnings = 0\n            self.token_counts = defaultdict(int)\n            self.token_confidences = defaultdict(list)\n\n    def record_inference(self, result: Dict[str, Any], dscd_homographs: Optional[set] = None):\n        with self._lock:\n            self.total_inferences += 1\n\n            if result.get('translation') and result['translation'] != \"ERROR DURING TRANSLATION\":\n                self.successful_translations += 1\n            else:\n                self.failed_translations += 1\n\n            explanations = result.get('explanations', [])\n            self.total_explanations += len(explanations)\n\n            for exp in explanations:\n                try:\n                    conf = exp.get('confidence', 0.5)\n                    self.total_confidence += float(conf)\n\n                    if conf >= 0.65:\n                        self.high_confidence_explanations += 1\n                    elif conf < 0.4:\n                        self.low_confidence_explanations += 1\n\n                    word = str(exp.get('ambiguous_word', '')).strip()\n\n                    if is_punctuation_only(word):\n                        continue\n\n                    clean_word = clean_token(word)\n\n                    if not clean_word:\n                        continue\n\n                    self.token_counts[clean_word] += 1\n                    self.token_confidences[clean_word].append(float(conf))\n\n                    if dscd_homographs and clean_word in dscd_homographs:\n                        self.dscd_homographs_explained.add(clean_word)\n\n                    if clean_word in HOMOGRAPH_REFERENCE_LIST:\n                        self.reference_homographs_explained.add(clean_word)\n\n                    self.avg_span += float(exp.get('span', 0.0))\n                    self.avg_uncertainty += float(exp.get('uncertainty', 0.0))\n\n                except Exception:\n                    pass\n\n    def get_summary(self) -> Dict[str, Any]:\n        with self._lock:\n            total_exp = max(self.total_explanations, 1)\n\n            unique_tokens = len(self.token_counts)\n            diversity_ratio = unique_tokens / total_exp if total_exp > 0 else 0.0\n\n            return {\n                'total_inferences': self.total_inferences,\n                'successful_translations': self.successful_translations,\n                'failed_translations': self.failed_translations,\n                'success_rate': self.successful_translations / max(self.total_inferences, 1),\n                'total_explanations': self.total_explanations,\n                'explanations_per_inference': self.total_explanations / max(self.total_inferences, 1),\n                'high_confidence_rate': self.high_confidence_explanations / total_exp,\n                'low_confidence_rate': self.low_confidence_explanations / total_exp,\n                'avg_confidence': self.total_confidence / total_exp,\n                'avg_span': self.avg_span / total_exp,\n                'avg_uncertainty': self.avg_uncertainty / total_exp,\n                'dscd_homographs_explained': list(self.dscd_homographs_explained),\n                'reference_homographs_explained': list(self.reference_homographs_explained),\n                'dscd_empty_warnings': self.dscd_empty_warnings,\n                'unique_tokens_explained': unique_tokens,\n                'diversity_ratio': diversity_ratio,\n            }\n\n    def print_summary(self):\n        summary = self.get_summary()\n        print(\"\\n\" + \"=\" * 80)\n        print(\"INFERENCE STATISTICS SUMMARY\")\n        print(\"=\" * 80)\n        print(f\"Total inferences: {summary['total_inferences']}\")\n        print(f\"Success rate: {summary['success_rate']:.1%}\")\n        print(f\"Total explanations: {summary['total_explanations']}\")\n        print(f\"Explanations per inference: {summary['explanations_per_inference']:.2f}\")\n        print(f\"Unique tokens explained: {summary['unique_tokens_explained']}\")\n        print(f\"Diversity ratio: {summary['diversity_ratio']:.2%}\")\n        print(f\"Avg confidence: {summary['avg_confidence']:.3f}\")\n        print(f\"High confidence rate: {summary['high_confidence_rate']:.1%}\")\n        print(f\"Avg span: {summary['avg_span']:.3f}\")\n        print(f\"Avg uncertainty: {summary['avg_uncertainty']:.3f}\")\n\n        if summary['dscd_homographs_explained']:\n            print(f\"\\nDSCD homographs explained ({len(summary['dscd_homographs_explained'])})\")\n            print(f\"  {', '.join(summary['dscd_homographs_explained'])}\")\n\n        if summary['reference_homographs_explained']:\n            print(f\"\\nReference homographs explained ({len(summary['reference_homographs_explained'])})\")\n            print(f\"  {', '.join(summary['reference_homographs_explained'])}\")\n\n        if summary['dscd_empty_warnings'] > 0:\n            print(f\"\\nDSCD empty warnings: {summary['dscd_empty_warnings']}\")\n        print(\"=\" * 80 + \"\\n\")\n\n\nINFERENCE_STATS = InferenceStatistics()\n\n\ndef to_device_batch(enc: Any, device: torch.device):\n    try:\n        if hasattr(enc, \"to\") and callable(getattr(enc, \"to\")):\n            return enc.to(device)\n    except Exception:\n        pass\n\n    if isinstance(enc, dict):\n        out = {}\n        try:\n            for k, v in enc.items():\n                try:\n                    if isinstance(v, torch.Tensor):\n                        out[k] = v.to(device)\n                    elif isinstance(v, dict):\n                        out[k] = to_device_batch(v, device)\n                    elif isinstance(v, (list, tuple)):\n                        out[k] = [\n                            t.to(device) if isinstance(t, torch.Tensor) else t\n                            for t in v\n                        ]\n                    else:\n                        out[k] = v\n                except Exception:\n                    out[k] = v\n            return out\n        except Exception:\n            return enc\n\n    return enc\n\n\ndef extract_dscd_outputs(raw_out: Any) -> Dict[str, Any]:\n    if raw_out is None:\n        return {}\n\n    if isinstance(raw_out, dict):\n        if \"dscd_outputs\" in raw_out and isinstance(raw_out[\"dscd_outputs\"], dict):\n            return raw_out[\"dscd_outputs\"]\n        if \"dscd\" in raw_out and isinstance(raw_out[\"dscd\"], dict):\n            return raw_out[\"dscd\"]\n        if \"proto_probs\" in raw_out or \"uncertainties\" in raw_out:\n            return raw_out\n\n        for key in (\"dscd_outputs\", \"dscd\", \"dscd_out\"):\n            if key in raw_out and isinstance(raw_out[key], dict):\n                return raw_out[key]\n\n        return raw_out\n\n    if isinstance(raw_out, (list, tuple)):\n        for item in raw_out:\n            if isinstance(item, dict):\n                return extract_dscd_outputs(item)\n\n    return {}\n\n\ndef is_subword_token(token: str) -> bool:\n    if not token or len(token.strip()) == 0:\n        return True\n\n    token = token.strip()\n\n    if is_punctuation_only(token):\n        return True\n\n    if (\n        token.startswith(\"##\")\n        or token.startswith(\"▁▁\")\n        or token.startswith(\"@@\")\n        or token.startswith(\"▁\")\n    ):\n        return True\n\n    if len(token) < 2:\n        return True\n\n    if (len(token) == 1 and token in PUNCT_SET) or token.isdigit():\n        return True\n\n    return False\n\n\ndef should_filter_explanation(expl: Dict[str, Any], span_th: float, u_th: float) -> bool:\n    try:\n        token = expl.get('ambiguous_word', expl.get('token', ''))\n\n        if is_punctuation_only(str(token)):\n            return True\n\n        span = float(expl.get('span', 0.0))\n        uncertainty = float(expl.get('uncertainty', 0.0))\n\n        if is_subword_token(str(token)):\n            return True\n\n        if span < span_th and uncertainty < u_th:\n            return True\n\n        return False\n    except Exception:\n        return True\n\n\ndef has_bengali_chars(text: str) -> bool:\n    if not text or not isinstance(text, str):\n        return False\n    return any('\\u0980' <= c <= '\\u09FF' for c in text)\n\n\ndef _get_lang_token_id_from_tokenizer(tokenizer, candidates: List[str]) -> Optional[int]:\n    try:\n        if hasattr(tokenizer, \"lang_code_to_id\") and isinstance(tokenizer.lang_code_to_id, dict):\n            for c in candidates:\n                if c in tokenizer.lang_code_to_id:\n                    return int(tokenizer.lang_code_to_id[c])\n    except Exception:\n        pass\n\n    try:\n        if hasattr(tokenizer, \"get_lang_id\"):\n            for c in candidates:\n                try:\n                    lid = tokenizer.get_lang_id(c)\n                    if lid is not None and int(lid) >= 0:\n                        return int(lid)\n                except Exception:\n                    continue\n    except Exception:\n        pass\n\n    return None\n\n\ndef force_english_bos(tokenizer, mbart_model):\n    try:\n        lang_candidates = [\"en_XX\", \"en\"]\n        lang_id = _get_lang_token_id_from_tokenizer(tokenizer, lang_candidates)\n        if lang_id is not None and lang_id >= 0:\n            return int(lang_id)\n\n        if hasattr(mbart_model, 'config'):\n            try:\n                bos_id = getattr(mbart_model.config, 'forced_bos_token_id', None)\n                if bos_id is not None and int(bos_id) >= 0:\n                    return int(bos_id)\n            except Exception:\n                pass\n\n        return MBART50_EN_TOKEN_ID\n    except Exception:\n        return MBART50_EN_TOKEN_ID\n\n\n@torch.inference_mode()\ndef translate_with_explanations(\n    model,\n    tokenizer,\n    input_sentence: str,\n    source_lang: str = \"bn\",\n    target_lang: str = \"en\",\n    device: Optional[torch.device] = None,\n    max_length: Optional[int] = None,\n    span_threshold: Optional[float] = None,\n    uncertainty_threshold: Optional[float] = None,\n    track_stats: bool = True,\n) -> Dict[str, Any]:\n    device = DEVICE if device is None else device\n    max_len = MAXLEN if max_length is None else int(max_length)\n    span_th = SPAN_THRESHOLD if span_threshold is None else float(span_threshold)\n    u_th = UNCERTAINTY_THRESHOLD if uncertainty_threshold is None else float(uncertainty_threshold)\n\n    span_th = min(span_th, 0.10)\n    u_th = min(u_th, 0.10)\n\n    if not input_sentence or not input_sentence.strip():\n        return {\n            \"input_sentence\": input_sentence,\n            \"translation\": \"\",\n            \"ambiguous_words_detected\": 0,\n            \"explanations\": [],\n            \"quality_metrics\": {},\n            \"dscd_validated\": False,\n            \"error\": \"Empty input\"\n        }\n\n    if not has_bengali_chars(input_sentence):\n        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n            print(f\"[INF] WARNING: Input does not contain Bengali characters: {input_sentence[:50]}\")\n\n    try:\n        tokenizer.src_lang = source_lang\n        tokenizer.tgt_lang = target_lang\n        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n            print(f\"[INF] Tokenizer languages set: src={source_lang}, tgt={target_lang}\")\n    except Exception:\n        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n            print(\"[INF] Warning: Could not set tokenizer.src_lang / tgt_lang\")\n\n    if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n        print(f\"\\n[INF] Starting inference:\")\n        print(f\"[INF]   Input: {input_sentence[:60]}\")\n        print(f\"[INF]   Languages: {source_lang} -> {target_lang}\")\n        print(f\"[INF]   Thresholds: span={span_th:.2f}, uncertainty={u_th:.2f}\")\n\n    try:\n        core = model.module if (USE_MULTI_GPU and hasattr(model, \"module\")) else model\n        dscd = getattr(core, 'dscd', None)\n        if dscd and hasattr(dscd, 'cleanup_memory'):\n            if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                print(\"[INF] Running DSCD cleanup before inference...\")\n            dscd.cleanup_memory()\n    except Exception as e:\n        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n            print(f\"[INF] DSCD cleanup failed: {type(e).__name__}\")\n\n    dscd_homographs = get_dscd_homographs(model)\n\n    try:\n        enc = tokenizer(\n            input_sentence,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=max_len,\n        )\n        enc = to_device_batch(enc, device)\n\n        model.eval()\n        core = model.module if (USE_MULTI_GPU and hasattr(model, \"module\")) else model\n\n        src_texts = [input_sentence]\n\n        dscd_validated = False\n        try:\n            dscd = core.dscd if hasattr(core, 'dscd') else None\n            if dscd:\n                lock = getattr(dscd, 'buffer_lock', None) or getattr(dscd, 'clustering_lock', None)\n\n                num_stores = 0\n                multi_sense = 0\n\n                if lock:\n                    try:\n                        with lock:\n                            num_stores = len(dscd.prototype_stores)\n                            multi_sense = sum(\n                                1\n                                for store in dscd.prototype_stores.values()\n                                if hasattr(store, 'centroids') and len(store.centroids) >= 2\n                            )\n                    except Exception:\n                        pass\n                else:\n                    try:\n                        num_stores = len(dscd.prototype_stores)\n                        multi_sense = sum(\n                            1\n                            for store in dscd.prototype_stores.values()\n                            if hasattr(store, 'centroids') and len(store.centroids) >= 2\n                        )\n                    except Exception:\n                        pass\n\n                if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                    print(\n                        f\"[INF] DSCD state: {num_stores} tokens, \"\n                        f\"{multi_sense} multi-sense, {len(dscd_homographs)} discovered\"\n                    )\n\n                if num_stores == 0:\n                    if track_stats:\n                        INFERENCE_STATS.dscd_empty_warnings += 1\n                else:\n                    dscd_validated = True\n        except Exception as e:\n            if DEBUG_DISCOVERY:\n                print(f\"[INF] DSCD validation failed: {e}\")\n\n        with torch.inference_mode():\n            dscd_out_dict: Dict[str, Any] = {}\n\n            try:\n                if not hasattr(core, \"mbart\"):\n                    raise RuntimeError(\"Model backend missing .mbart\")\n\n                if DEBUG_DISCOVERY:\n                    print(\"[INF] Step 1: Running DSCD-augmented forward pass for explanations...\")\n\n                fwd_outputs = core(\n                    input_ids=enc.get(\"input_ids\"),\n                    attention_mask=enc.get(\"attention_mask\"),\n                    src_texts=src_texts,\n                    token_word_map=None,\n                    labels=None,\n                    return_dict=True,\n                    path=2\n                )\n\n                dscd_out_dict = extract_dscd_outputs(fwd_outputs)\n\n                if DEBUG_DISCOVERY:\n                    print(f\"[INF] DSCD outputs extracted: {list(dscd_out_dict.keys()) if isinstance(dscd_out_dict, dict) else 'NOT_DICT'}\")\n\n            except Exception as e:\n                if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                    print(f\"[INF] DSCD forward error: {e}\")\n                    try:\n                        traceback.print_exc()\n                    except Exception:\n                        pass\n                dscd_out_dict = {}\n\n            forced_id = force_english_bos(tokenizer, core.mbart)\n\n            model_vocab_size = getattr(core, 'vocab_size', None) or getattr(getattr(core, 'mbart', None), 'vocab_size', None) or 250054\n            try:\n                model_vocab_size = int(model_vocab_size)\n            except Exception:\n                model_vocab_size = 250054\n\n            if forced_id is None:\n                forced_id = MBART50_EN_TOKEN_ID\n\n            if forced_id >= model_vocab_size:\n                if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                    print(f\"[INF] ⚠️  forced_id ({forced_id}) >= vocab_size ({model_vocab_size}) -- clamping\")\n                forced_id = min(forced_id, model_vocab_size - 1)\n\n            if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                print(f\"[INF] Target language: {target_lang} -> Token ID: {forced_id}\")\n                print(f\"[INF] Vocab size: {model_vocab_size}, Token ID valid: {forced_id < model_vocab_size}\")\n\n            try:\n                if DEBUG_DISCOVERY:\n                    print(f\"[INF] Step 2: Running DSCD-augmented forward pass for translation...\")\n\n                with torch.no_grad():\n                    fwd_out = core(\n                        input_ids=enc.get(\"input_ids\"),\n                        attention_mask=enc.get(\"attention_mask\"),\n                        src_texts=src_texts,\n                        token_word_map=None,\n                        labels=None,\n                        return_dict=True,\n                        path=2\n                    )\n\n                h_sense = fwd_out.get('encoder_last_hidden_state', None)\n                if h_sense is None:\n                    h_sense = fwd_out.get('sense_augmented_embeddings', None)\n                if h_sense is None:\n                    h_sense = fwd_out.get('last_hidden_state', None)\n\n                if h_sense is None:\n                    raise ValueError(\"No encoder outputs found in forward pass\")\n\n                encoder_outputs_wrapped = BaseModelOutput(\n                    last_hidden_state=h_sense,\n                    hidden_states=None,\n                    attentions=None\n                )\n\n                old_forced_bos = getattr(core.mbart.config, 'forced_bos_token_id', None)\n                try:\n                    core.mbart.config.forced_bos_token_id = forced_id\n\n                    try:\n                        num_beam_groups = min(2, max(1, EVAL_NUM_BEAMS // 4))\n                        diversity_penalty = 0.5 if EVAL_NUM_BEAMS >= 4 else 0.0\n\n                        generated = core.mbart.generate(\n                            input_ids=None,\n                            encoder_outputs=encoder_outputs_wrapped,\n                            attention_mask=enc.get(\"attention_mask\"),\n                            max_length=max_len,\n                            min_length=EVAL_MIN_LENGTH,\n                            num_beams=EVAL_NUM_BEAMS,\n                            num_beam_groups=num_beam_groups,\n                            diversity_penalty=diversity_penalty,\n                            early_stopping=True,\n                            length_penalty=EVAL_LENGTH_PENALTY,\n                            no_repeat_ngram_size=EVAL_NO_REPEAT_NGRAM_SIZE,\n                            repetition_penalty=1.2,\n                            forced_bos_token_id=forced_id,\n                        )\n\n                    except RuntimeError as oom_err:\n                        if \"out of memory\" in str(oom_err).lower():\n                            if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                                print(\"[INF] OOM during generation, retrying with reduced settings\")\n                            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n\n                            with torch.no_grad():\n                                fwd_out = core(\n                                    input_ids=enc.get(\"input_ids\"),\n                                    attention_mask=enc.get(\"attention_mask\"),\n                                    src_texts=src_texts,\n                                    token_word_map=None,\n                                    labels=None,\n                                    return_dict=True,\n                                    path=2\n                                )\n\n                            h_sense = (\n                                fwd_out.get('encoder_last_hidden_state', None) or\n                                fwd_out.get('sense_augmented_embeddings', None) or\n                                fwd_out.get('last_hidden_state', None)\n                            )\n\n                            encoder_outputs_wrapped = BaseModelOutput(last_hidden_state=h_sense)\n\n                            reduced_beams = max(1, min(4, EVAL_NUM_BEAMS))\n                            num_beam_groups_reduced = min(2, max(1, reduced_beams // 2))\n                            diversity_penalty_reduced = 0.3 if reduced_beams >= 2 else 0.0\n\n                            generated = core.mbart.generate(\n                                input_ids=None,\n                                encoder_outputs=encoder_outputs_wrapped,\n                                attention_mask=enc.get(\"attention_mask\"),\n                                max_length=min(max_len, 128),\n                                min_length=EVAL_MIN_LENGTH,\n                                num_beams=reduced_beams,\n                                num_beam_groups=num_beam_groups_reduced,\n                                diversity_penalty=diversity_penalty_reduced,\n                                early_stopping=True,\n                                length_penalty=EVAL_LENGTH_PENALTY,\n                                no_repeat_ngram_size=EVAL_NO_REPEAT_NGRAM_SIZE,\n                                repetition_penalty=1.2,\n                                forced_bos_token_id=forced_id,\n                            )\n                        else:\n                            raise\n\n                finally:\n                    if old_forced_bos is not None:\n                        core.mbart.config.forced_bos_token_id = old_forced_bos\n\n                if generated is None:\n                    translation = \"\"\n                else:\n                    try:\n                        gen_ids = generated[0] if isinstance(generated, (list, tuple)) else generated[0]\n                        gen_ids = gen_ids.detach().cpu().numpy().tolist() if hasattr(gen_ids, \"detach\") else gen_ids\n                        translation = tokenizer.decode(gen_ids, skip_special_tokens=True)\n                    except Exception:\n                        try:\n                            translation = tokenizer.decode(generated[0], skip_special_tokens=True)\n                        except Exception:\n                            translation = \"\"\n\n                if DEBUG_DISCOVERY:\n                    print(f\"[INF] Translation: {translation[:60] if translation else 'EMPTY'}\")\n\n                if not translation or not translation.strip():\n                    error_msg = \"Empty generation result\"\n                    if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                        print(f\"[INF] ERROR: {error_msg}\")\n                    return {\n                        \"input_sentence\": input_sentence,\n                        \"translation\": \"\",\n                        \"ambiguous_words_detected\": 0,\n                        \"explanations\": [],\n                        \"quality_metrics\": {},\n                        \"dscd_validated\": dscd_validated,\n                        \"error\": error_msg\n                    }\n\n            except Exception as e:\n                if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                    print(f\"[INF] Generation error: {type(e).__name__}: {str(e)}\")\n                    try:\n                        traceback.print_exc()\n                    except Exception:\n                        pass\n\n                return {\n                    \"input_sentence\": input_sentence,\n                    \"translation\": \"\",\n                    \"ambiguous_words_detected\": 0,\n                    \"explanations\": [],\n                    \"quality_metrics\": {},\n                    \"dscd_validated\": dscd_validated,\n                    \"error\": f\"Generation failed: {type(e).__name__}\"\n                }\n\n            if DEBUG_DISCOVERY:\n                print(\"[INF] Step 5: Calling TRG to generate explanations...\")\n\n            out_explanations: List[Dict[str, Any]] = []\n\n            try:\n                trg = core.trg if hasattr(core, 'trg') else None\n\n                if trg and hasattr(trg, 'process_sentence_for_explanations'):\n                    try:\n                        tokens_list = tokenizer.convert_ids_to_tokens(enc['input_ids'][0].tolist())\n\n                        if DEBUG_DISCOVERY:\n                            print(f\"[INF] Calling TRG with {len(tokens_list)} tokens\")\n\n                        trg_explanations = trg.process_sentence_for_explanations(\n                            tokens=tokens_list,\n                            dscd_outputs=dscd_out_dict,\n                            token_word_map=None,\n                            uncertainty_threshold=u_th,\n                            decoder_attention=None\n                        )\n\n                        if DEBUG_DISCOVERY:\n                            print(f\"[INF] TRG returned {len(trg_explanations) if isinstance(trg_explanations, list) else 0} explanations\")\n\n                        if isinstance(trg_explanations, list):\n                            for exp in trg_explanations:\n                                try:\n                                    raw_word = exp.get('token', '')\n\n                                    if is_punctuation_only(str(raw_word)):\n                                        continue\n\n                                    clean_word = clean_token(str(raw_word)) if raw_word else ''\n\n                                    if not clean_word:\n                                        continue\n\n                                    if should_filter_explanation(exp, span_th, u_th):\n                                        continue\n\n                                    s = float(exp.get('span', 0.0))\n                                    u = float(exp.get('uncertainty', 0.0))\n                                    confidence = max(s, u)\n\n                                    expl_text = exp.get('explanation', '')\n                                    if not expl_text:\n                                        continue\n\n                                    out_explanations.append({\n                                        \"ambiguous_word\": clean_word,\n                                        \"position\": exp.get(\"token_idx\", \"N/A\"),\n                                        \"explanation\": expl_text,\n                                        \"uncertainty\": u,\n                                        \"span\": s,\n                                        \"confidence\": confidence,\n                                        \"is_real_amb\": bool((s > span_th) or (u > u_th)),\n                                    })\n                                except Exception as e:\n                                    if DEBUG_DISCOVERY:\n                                        print(f\"[INF] Error processing TRG explanation: {e}\")\n                                    continue\n\n                    except Exception as e:\n                        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                            print(f\"[INF] TRG processing failed: {e}\")\n                            try:\n                                traceback.print_exc()\n                            except Exception:\n                                pass\n                else:\n                    if DEBUG_DISCOVERY:\n                        print(\"[INF] TRG not available or missing process_sentence_for_explanations()\")\n\n            except Exception as e:\n                if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                    print(f\"[INF] TRG invocation error: {e}\")\n\n            real_amb_count = sum(1 for e in out_explanations if e.get('is_real_amb', False))\n\n            quality_metrics = {\n                'total_raw_explanations': len(out_explanations),\n                'filtered_explanations': 0,\n                'high_confidence_count': sum(1 for e in out_explanations if e.get('confidence', 0) >= 0.65),\n                'low_confidence_count': sum(1 for e in out_explanations if e.get('confidence', 0) < 0.4),\n                'avg_confidence': sum(e.get('confidence', 0) for e in out_explanations) / max(len(out_explanations), 1),\n                'avg_span': sum(e.get('span', 0) for e in out_explanations) / max(len(out_explanations), 1),\n                'avg_uncertainty': sum(e.get('uncertainty', 0) for e in out_explanations) / max(len(out_explanations), 1),\n            }\n\n            if DEBUG_DISCOVERY:\n                print(\n                    f\"[INF] Final: {len(out_explanations)} explanations \"\n                    f\"(real ambiguous: {real_amb_count})\"\n                )\n\n            result = {\n                \"input_sentence\": input_sentence,\n                \"translation\": translation,\n                \"ambiguous_words_detected\": int(real_amb_count),\n                \"explanations\": out_explanations,\n                \"quality_metrics\": quality_metrics,\n                \"dscd_validated\": dscd_validated,\n            }\n\n            if track_stats:\n                INFERENCE_STATS.record_inference(result, dscd_homographs=dscd_homographs)\n\n            return result\n\n    except Exception as e:\n        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n            print(f\"[INF] ERROR: {type(e).__name__}: {str(e)[:200]}\")\n            try:\n                traceback.print_exc()\n            except Exception:\n                pass\n\n        error_result = {\n            \"input_sentence\": input_sentence,\n            \"translation\": \"ERROR DURING TRANSLATION\",\n            \"ambiguous_words_detected\": 0,\n            \"explanations\": [],\n            \"quality_metrics\": {},\n            \"dscd_validated\": False,\n            \"error\": f\"{type(e).__name__}: {str(e)[:150]}\",\n        }\n\n        if track_stats:\n            INFERENCE_STATS.record_inference(error_result, dscd_homographs=dscd_homographs)\n\n        return error_result\n\n    finally:\n        try:\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n        except Exception:\n            pass\n\n        try:\n            if gc.isenabled():\n                gc.collect()\n        except Exception:\n            pass\n\n\ndef demonstrate_system(model, tokenizer, sentences: Optional[List[str]] = None):\n    if sentences is None:\n        sentences = [\n            \"আমি কল বন্ধ করেছি।\",\n            \"কাল আমি বই কিনব।\",\n            \"পাতা ঝরে পড়েছে।\",\n            \"তিনি ব্যাংক গেছেন।\",\n            \"আজ ভাল আবহাওয়া।\",\n        ]\n\n    print(\"=\" * 80)\n    print(\"TATN DEMO: Translation + Explanations\")\n    print(\"=\" * 80)\n\n    INFERENCE_STATS.reset()\n\n    for s in sentences:\n        print(f\"\\nInput: {s}\")\n        res = translate_with_explanations(model, tokenizer, s, source_lang=\"bn\", target_lang=\"en\")\n        print(\"Translation:\", res.get(\"translation\", \"\"))\n        print(\"Ambiguous words detected:\", res.get(\"ambiguous_words_detected\", 0))\n\n        quality = res.get(\"quality_metrics\", {})\n        if quality:\n            print(\n                f\"Quality: conf={quality.get('avg_confidence', 0):.3f}, \"\n                f\"high={quality.get('high_confidence_count', 0)}, \"\n                f\"low={quality.get('low_confidence_count', 0)}\"\n            )\n\n        if res.get(\"explanations\"):\n            for idx, ex in enumerate(res[\"explanations\"], 1):\n                print(\n                    f\"  {idx}. '{ex['ambiguous_word']}' \"\n                    f\"pos={ex['position']} conf={ex.get('confidence', 0):.3f}\"\n                )\n                print(\"     \", ex.get(\"explanation\", \"\")[:200])\n        else:\n            print(\"  No explanations\")\n\n    print(\"=\" * 80)\n    INFERENCE_STATS.print_summary()\n\n\ndef dscd_discovery_warmup(\n    model,\n    tokenizer,\n    num_sents: int = 8000,\n    batch_size: int = 64,\n    max_len: Optional[int] = None,\n):\n    if max_len is None:\n        max_len = MAXLEN\n\n    core = model.module if (USE_MULTI_GPU and hasattr(model, \"module\")) else model\n\n    try:\n        dscd = getattr(core, \"dscd\", None)\n        if dscd is None:\n            print(\"[WARMUP] Model has no dscd component\")\n            return\n\n        print(\"\\n\" + \"=\" * 80)\n        print(\"[WARMUP] Starting DSCD discovery warmup\")\n        print(\"=\" * 80)\n\n        orig_enable = getattr(dscd, \"enable_training_clustering\", False)\n        orig_n_min = getattr(dscd, \"n_min\", None)\n        orig_buffer = getattr(dscd, \"buffer_size\", None)\n\n        try:\n            if hasattr(dscd, \"enable_training_clustering\"):\n                dscd.enable_training_clustering = True\n            if hasattr(dscd, \"n_min\"):\n                dscd.n_min = max(3, int(getattr(dscd, \"n_min\", 5)))\n            if hasattr(dscd, \"buffer_size\"):\n                dscd.buffer_size = max(200, int(getattr(dscd, \"buffer_size\", 300)))\n        except Exception:\n            pass\n\n        texts: List[str] = []\n        try:\n            if \"load_and_preprocess_optimized\" in globals():\n                pairs = load_and_preprocess_optimized(num_sents)\n                texts = [bn for (bn, _) in pairs][:num_sents]\n            else:\n                base = [\n                    \"আমি কল বন্ধ করেছি।\",\n                    \"কাল আমি বই কিনব।\",\n                    \"পাতা ঝরে পড়েছে।\",\n                    \"তিনি ব্যাংক গেছেন।\",\n                ]\n                while len(texts) < num_sents:\n                    texts.extend(base)\n                texts = texts[:num_sents]\n        except Exception:\n            texts = [\"আমি কল বন্ধ করেছি।\"] * num_sents\n\n        processed = 0\n        core.eval()\n\n        print(f\"\\n[WARMUP] Processing {len(texts)} sentences (batch={batch_size})...\")\n\n        start_time = time.time()\n        last_print = start_time\n\n        with torch.inference_mode():\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i : i + batch_size]\n                try:\n                    enc = tokenizer(\n                        batch,\n                        return_tensors=\"pt\",\n                        padding=True,\n                        truncation=True,\n                        max_length=max_len,\n                    )\n                    enc = to_device_batch(enc, DEVICE)\n\n                    core(\n                        input_ids=enc.get(\"input_ids\"),\n                        attention_mask=enc.get(\"attention_mask\"),\n                        src_texts=batch,\n                        token_word_map=None,\n                        labels=None,\n                        return_dict=True,\n                        path=2\n                    )\n\n                    processed += len(batch)\n\n                    current_time = time.time()\n                    if (i // batch_size) % 10 == 0 or (current_time - last_print) > 5:\n                        elapsed = current_time - start_time\n                        rate = processed / elapsed if elapsed > 0 else 0\n                        eta = (len(texts) - processed) / rate if rate > 0 else 0\n                        print(\n                            f\"[WARMUP] {processed}/{len(texts)} \"\n                            f\"({processed/len(texts)*100:.1f}%) | \"\n                            f\"{rate:.1f} sent/s | ETA {eta:.0f}s\"\n                        )\n                        last_print = current_time\n\n                    del enc\n\n                except RuntimeError as e:\n                    if \"out of memory\" in str(e).lower():\n                        print(f\"[WARMUP] OOM at batch {i//batch_size}, cleaning up...\")\n                        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n                        gc.collect()\n                        continue\n                    else:\n                        print(f\"[WARMUP] Batch {i//batch_size} failed: {str(e)[:100]}\")\n                        continue\n                except Exception as e:\n                    print(f\"[WARMUP] Batch {i//batch_size} failed: {str(e)[:100]}\")\n                    continue\n\n        total_time = time.time() - start_time\n        print(\n            f\"\\n[WARMUP] Completed in {total_time:.1f}s \"\n            f\"({processed/total_time:.1f} sent/s)\"\n        )\n        print(\"-\" * 80)\n\n        try:\n            if dscd and hasattr(dscd, 'cleanup_memory'):\n                print(\"[WARMUP] Running DSCD cleanup after warmup...\")\n                dscd.cleanup_memory()\n        except Exception as e:\n            if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                print(f\"[WARMUP] DSCD cleanup failed: {type(e).__name__}\")\n\n        try:\n            lock = None\n            if hasattr(dscd, 'buffer_lock'):\n                lock = dscd.buffer_lock\n            elif hasattr(dscd, 'clustering_lock'):\n                lock = dscd.clustering_lock\n\n            if lock:\n                with lock:\n                    stores = dict(dscd.prototype_stores)\n            else:\n                stores = dict(dscd.prototype_stores)\n\n            num_types = len(stores)\n            total_protos = (\n                sum(store.size() for store in stores.values()) if stores else 0\n            )\n            multi = (\n                sum(1 for store in stores.values() if store.size() >= 2)\n                if stores\n                else 0\n            )\n\n            print(\"[WARMUP] Summary:\")\n            print(f\"  - Token types: {num_types}\")\n            print(f\"  - Total prototypes: {total_protos}\")\n            print(f\"  - Multi-sense tokens: {multi}\")\n\n            if num_types > 0:\n                print(f\"  - Multi-sense ratio: {multi/num_types:.1%}\")\n\n            dscd_homographs = get_dscd_homographs(model)\n\n            print(f\"\\n[WARMUP] Discovered Homographs: {len(dscd_homographs)}\")\n            if dscd_homographs:\n                print(f\"  Sample: {list(dscd_homographs)[:10]}\")\n\n            reference_found = dscd_homographs.intersection(HOMOGRAPH_REFERENCE_LIST)\n\n            print(f\"\\n[WARMUP] Reference List Comparison:\")\n            print(f\"  - Reference list: {len(HOMOGRAPH_REFERENCE_LIST)} words\")\n            print(f\"  - Found in DSCD: {len(reference_found)}\")\n            print(\n                f\"  - Coverage: {len(reference_found)/len(HOMOGRAPH_REFERENCE_LIST):.1%}\"\n            )\n\n            if num_types == 0:\n                print(\"\\n[WARMUP] CRITICAL: NO PROTOTYPES CREATED\")\n            elif len(reference_found) < len(HOMOGRAPH_REFERENCE_LIST) // 2:\n                print(\"\\n[WARMUP] WARNING: < 50% reference coverage\")\n            else:\n                print(\"\\n[WARMUP] SUCCESS\")\n\n        except Exception as e:\n            print(f\"[WARMUP] Validation failed: {e}\")\n\n    finally:\n        try:\n            if dscd is not None:\n                if hasattr(dscd, \"enable_training_clustering\"):\n                    dscd.enable_training_clustering = orig_enable\n                if hasattr(dscd, \"n_min\") and orig_n_min is not None:\n                    dscd.n_min = orig_n_min\n                if hasattr(dscd, \"buffer_size\") and orig_buffer is not None:\n                    dscd.buffer_size = orig_buffer\n        except Exception:\n            pass\n\n        try:\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n        except Exception:\n            pass\n\n        try:\n            if gc.isenabled():\n                gc.collect()\n        except Exception:\n            pass\n\n        print(\"=\" * 80 + \"\\n\")\n\n\ndef final_evaluation_with_bleu(\n    model,\n    tokenizer,\n    test_data: List[Tuple[str, str]],\n    device: Optional[torch.device] = None,\n    max_length: Optional[int] = None,\n    batch_size: int = 16,\n) -> Dict[str, Any]:\n    device = DEVICE if device is None else device\n    max_len = MAXLEN if max_length is None else int(max_length)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FINAL EVALUATION WITH BLEU/CHRF++\")\n    print(\"=\" * 80)\n    print(f\"Test samples: {len(test_data)}\")\n    print(f\"Batch size: {batch_size}\")\n    print(f\"Max length: {max_len}\")\n    print(\"=\" * 80 + \"\\n\")\n\n    try:\n        core = model.module if (USE_MULTI_GPU and hasattr(model, \"module\")) else model\n        dscd = getattr(core, 'dscd', None)\n        if dscd and hasattr(dscd, 'cleanup_memory'):\n            print(\"[EVAL] Running DSCD cleanup before evaluation...\")\n            dscd.cleanup_memory()\n    except Exception as e:\n        if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n            print(f\"[EVAL] DSCD cleanup failed: {type(e).__name__}\")\n\n    INFERENCE_STATS.reset()\n\n    predictions = []\n    references = []\n    translations_with_explanations = []\n\n    model.eval()\n\n    try:\n        from sacrebleu.metrics import BLEU, CHRF\n        bleu_metric = BLEU()\n        chrf_metric = CHRF()\n        metrics_available = True\n    except ImportError:\n        print(\"[EVAL] WARNING: sacrebleu not available, BLEU/CHRF scores will not be computed\")\n        metrics_available = False\n\n    start_time = time.time()\n\n    with torch.inference_mode():\n        for i in range(0, len(test_data), batch_size):\n            batch = test_data[i:i+batch_size]\n\n            for src, ref in batch:\n                try:\n                    result = translate_with_explanations(\n                        model,\n                        tokenizer,\n                        src,\n                        source_lang=\"bn\",\n                        target_lang=\"en\",\n                        device=device,\n                        max_length=max_len,\n                        track_stats=True\n                    )\n\n                    translation = result.get('translation', '')\n\n                    predictions.append(translation)\n                    references.append(ref)\n                    translations_with_explanations.append({\n                        'source': src,\n                        'reference': ref,\n                        'translation': translation,\n                        'explanations': result.get('explanations', []),\n                        'ambiguous_words': result.get('ambiguous_words_detected', 0)\n                    })\n\n                except Exception as e:\n                    if DEBUG_DISCOVERY or VERBOSE_LOGGING:\n                        print(f\"[EVAL] Translation failed for: {src[:50]} - {type(e).__name__}\")\n                    predictions.append(\"\")\n                    references.append(ref)\n                    translations_with_explanations.append({\n                        'source': src,\n                        'reference': ref,\n                        'translation': \"ERROR\",\n                        'explanations': [],\n                        'ambiguous_words': 0\n                    })\n\n            if (i // batch_size) % 10 == 0:\n                elapsed = time.time() - start_time\n                processed = min(i + batch_size, len(test_data))\n                rate = processed / elapsed if elapsed > 0 else 0\n                eta = (len(test_data) - processed) / rate if rate > 0 else 0\n                print(f\"[EVAL] {processed}/{len(test_data)} ({processed/len(test_data)*100:.1f}%) | {rate:.1f} sent/s | ETA {eta:.0f}s\")\n\n    total_time = time.time() - start_time\n    print(f\"\\n[EVAL] Translation completed in {total_time:.1f}s ({len(test_data)/total_time:.1f} sent/s)\")\n\n    results = {\n        'total_samples': len(test_data),\n        'successful_translations': sum(1 for p in predictions if p and p != \"ERROR\"),\n        'failed_translations': sum(1 for p in predictions if not p or p == \"ERROR\"),\n        'total_time': total_time,\n        'throughput': len(test_data) / total_time,\n        'predictions': predictions,\n        'references': references,\n        'translations_with_explanations': translations_with_explanations,\n    }\n\n    if metrics_available and predictions and references:\n        try:\n            valid_preds = []\n            valid_refs = []\n            for p, r in zip(predictions, references):\n                if p and p != \"ERROR\" and r:\n                    valid_preds.append(p)\n                    valid_refs.append(r)\n\n            if valid_preds:\n                bleu_score = bleu_metric.corpus_score(valid_preds, [valid_refs])\n                chrf_score = chrf_metric.corpus_score(valid_preds, [valid_refs])\n\n                results['bleu'] = float(bleu_score.score)\n                results['chrf'] = float(chrf_score.score)\n\n                print(\"\\n\" + \"=\" * 80)\n                print(\"METRIC SCORES\")\n                print(\"=\" * 80)\n                print(f\"BLEU:    {results['bleu']:.2f}\")\n                print(f\"CHRF++:  {results['chrf']:.2f}\")\n                print(f\"Valid samples: {len(valid_preds)}/{len(predictions)}\")\n                print(\"=\" * 80)\n            else:\n                print(\"[EVAL] WARNING: No valid translations for BLEU/CHRF computation\")\n                results['bleu'] = 0.0\n                results['chrf'] = 0.0\n        except Exception as e:\n            print(f\"[EVAL] Metric computation failed: {type(e).__name__}: {str(e)[:100]}\")\n            results['bleu'] = 0.0\n            results['chrf'] = 0.0\n    else:\n        results['bleu'] = 0.0\n        results['chrf'] = 0.0\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"EVALUATION SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"Total samples: {results['total_samples']}\")\n    print(f\"Successful: {results['successful_translations']}\")\n    print(f\"Failed: {results['failed_translations']}\")\n    print(f\"Success rate: {results['successful_translations']/results['total_samples']:.1%}\")\n    print(f\"Throughput: {results['throughput']:.1f} sent/s\")\n    print(\"=\" * 80 + \"\\n\")\n\n    INFERENCE_STATS.print_summary()\n\n    return results\n\n\ndef load_checkpoint_for_resume(\n    model: torch.nn.Module, optimizer, checkpoint_path: str\n) -> Tuple[bool, int, int, float]:\n    if not os.path.exists(checkpoint_path):\n        print(f\"[CHECKPOINT] Not found: {checkpoint_path}\")\n        return False, 0, 0, 0.0\n\n    try:\n        ckpt = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)\n    except Exception as e:\n        print(f\"[CHECKPOINT] Load failed: {e}\")\n        return False, 0, 0, 0.0\n\n    core = model.module if (USE_MULTI_GPU and hasattr(model, \"module\")) else model\n\n    state = ckpt.get(\"model_state_dict\", ckpt)\n    try:\n        core.load_state_dict(state, strict=False)\n    except Exception as e:\n        print(f\"[CHECKPOINT] model.load_state_dict failed: {e}\")\n\n        try:\n            if isinstance(state, dict):\n                new_state = {}\n                for k, v in state.items():\n                    new_key = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n                    new_state[new_key] = v\n                core.load_state_dict(new_state, strict=False)\n        except Exception:\n            pass\n\n    try:\n        if optimizer is not None and \"optimizer_state_dict\" in ckpt:\n            optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n    except Exception as e:\n        print(f\"[CHECKPOINT] optimizer.load_state_dict failed: {e}\")\n\n    try:\n        if \"dscd_state\" in ckpt and ckpt[\"dscd_state\"]:\n            dscd_state = ckpt[\"dscd_state\"]\n\n            print(\"[CHECKPOINT] Restoring DSCD...\")\n            dscd = core.dscd if hasattr(core, 'dscd') else None\n\n            if dscd and hasattr(dscd, 'load_state_dict'):\n                lock = None\n                if hasattr(dscd, 'buffer_lock'):\n                    lock = dscd.buffer_lock\n                elif hasattr(dscd, 'clustering_lock'):\n                    lock = dscd.clustering_lock\n\n                if lock:\n                    with lock:\n                        dscd.load_state_dict(dscd_state)\n                        num_tokens = len(dscd.prototype_stores)\n                        total_protos = sum(\n                            store.size() for store in dscd.prototype_stores.values()\n                        )\n                        multi_sense = sum(\n                            1\n                            for store in dscd.prototype_stores.values()\n                            if store.size() >= 2\n                        )\n                else:\n                    dscd.load_state_dict(dscd_state)\n                    num_tokens = len(dscd.prototype_stores)\n                    total_protos = sum(\n                        store.size() for store in dscd.prototype_stores.values()\n                    )\n                    multi_sense = sum(\n                        1\n                        for store in dscd.prototype_stores.values()\n                        if store.size() >= 2\n                    )\n\n                print(\"[CHECKPOINT] DSCD restored:\")\n                print(f\"  - Tokens: {num_tokens}\")\n                print(f\"  - Prototypes: {total_protos}\")\n                print(f\"  - Multi-sense: {multi_sense}\")\n\n                if num_tokens == 0:\n                    print(\n                        \"[CHECKPOINT] WARNING: DSCD state empty - consider running warmup\"\n                    )\n            else:\n                print(\"[CHECKPOINT] Model has no dscd.load_state_dict\")\n        else:\n            print(\"[CHECKPOINT] No DSCD state in checkpoint\")\n    except Exception as e:\n        print(f\"[CHECKPOINT] DSCD restore failed: {e}\")\n\n    epoch = int(ckpt.get(\"epochs_trained\", ckpt.get(\"epoch\", 0)))\n    step = int(\n        ckpt.get(\n            \"global_steps\", ckpt.get(\"global_step\", ckpt.get(\"step\", 0))\n        )\n    )\n    avg_loss = float(\n        ckpt.get(\n            \"final_train_loss\",\n            ckpt.get(\"avg_epoch_loss\", ckpt.get(\"avg_loss\", 0.0)),\n        )\n    )\n\n    print(f\"[CHECKPOINT] Loaded: epoch={epoch} step={step} loss={avg_loss:.6f}\")\n    return True, epoch, step, avg_loss\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 8: Inference & Evaluation Pipeline (DUAL-PATH COMPATIBLE) - COMPLETE & FIXED\")\nprint(\"=\" * 80)\nprint(\"Configuration:\")\nprint(f\"  - Source language: {SOURCE_LANG}\")\nprint(f\"  - Target language: {TARGET_LANG}\")\nprint(f\"  - Span threshold: {SPAN_THRESHOLD}\")\nprint(f\"  - Uncertainty threshold: {UNCERTAINTY_THRESHOLD}\")\nprint(f\"  - Max length: {MAXLEN}\")\nprint(f\"  - Device: {DEVICE}\")\nprint(f\"  - mBART-50 Bengali token ID (fallback): {MBART50_BN_TOKEN_ID}\")\nprint(f\"  - mBART-50 English token ID (fallback): {MBART50_EN_TOKEN_ID}\")\nprint(f\"  - Eval num beams: {EVAL_NUM_BEAMS}\")\nprint(f\"  - Eval length penalty: {EVAL_LENGTH_PENALTY}\")\nprint(f\"  - Eval no repeat ngram size: {EVAL_NO_REPEAT_NGRAM_SIZE}\")\nprint(f\"  - Eval min length: {EVAL_MIN_LENGTH}\")\nprint(\"\\n✅ FIXES APPLIED:\")\nprint(\"  ✅ Context-aware beam search with diversity_penalty\")\nprint(\"  ✅ Added num_beam_groups for diverse beam search\")\nprint(\"  ✅ Enhanced context awareness via proper attention mask\")\nprint(\"  ✅ Applied to both normal and OOM retry scenarios\")\nprint(\"  ✅ Adaptive parameters based on beam count\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"7Dxg7ck0H4J5","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:04.876967Z","iopub.execute_input":"2026-02-18T08:40:04.877175Z","iopub.status.idle":"2026-02-18T08:40:04.990309Z","shell.execute_reply.started":"2026-02-18T08:40:04.877158Z","shell.execute_reply":"2026-02-18T08:40:04.989764Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCell 8: Inference & Evaluation Pipeline (DUAL-PATH COMPATIBLE) - COMPLETE & FIXED\n================================================================================\nConfiguration:\n  - Source language: bn_IN\n  - Target language: en_XX\n  - Span threshold: 0.2\n  - Uncertainty threshold: 0.15\n  - Max length: 256\n  - Device: cuda\n  - mBART-50 Bengali token ID (fallback): 250028\n  - mBART-50 English token ID (fallback): 250004\n  - Eval num beams: 5\n  - Eval length penalty: 1.0\n  - Eval no repeat ngram size: 3\n  - Eval min length: 5\n\n✅ FIXES APPLIED:\n  ✅ Context-aware beam search with diversity_penalty\n  ✅ Added num_beam_groups for diverse beam search\n  ✅ Enhanced context awareness via proper attention mask\n  ✅ Applied to both normal and OOM retry scenarios\n  ✅ Adaptive parameters based on beam count\n================================================================================\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 9: COMPREHENSIVE TESTING & EVALUATION (DUAL-PATH COMPATIBLE)\n# ===========================================================================================\nfrom typing import Dict, List, Tuple, Optional, Any\nimport torch\nimport traceback\nimport time\nimport functools\nfrom collections import defaultdict\n\ntry:\n    _USE_MULTI_GPU = bool(USE_MULTI_GPU)\nexcept (NameError, TypeError):\n    _USE_MULTI_GPU = torch.cuda.is_available() and torch.cuda.device_count() > 1\n\ntry:\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\nexcept (NameError, TypeError):\n    _SOURCE_LANGUAGE = \"bn\"\n\ntry:\n    _TARGET_LANGUAGE = str(TARGET_LANGUAGE)\nexcept (NameError, TypeError):\n    _TARGET_LANGUAGE = \"en\"\n\ntry:\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\nexcept (NameError, TypeError):\n    _VERBOSE_LOGGING = False\n\ntry:\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept (NameError, TypeError):\n    _DEBUG_DISCOVERY = False\n\ntry:\n    _DEBUG_TIMING = bool(DEBUG_TIMING)\nexcept (NameError, TypeError):\n    _DEBUG_TIMING = False\n\ntry:\n    _SPAN_THRESHOLD = float(SPAN_THRESHOLD)\nexcept (NameError, ValueError, TypeError):\n    _SPAN_THRESHOLD = 0.10\n\ntry:\n    _UNCERTAINTY_THRESHOLD = float(UNCERTAINTY_THRESHOLD)\nexcept (NameError, ValueError, TypeError):\n    _UNCERTAINTY_THRESHOLD = 0.10\n\ntry:\n    _MAX_LENGTH = int(MAX_LENGTH)\nexcept (NameError, ValueError, TypeError):\n    _MAX_LENGTH = 64\n\ntry:\n    _DEVICE = DEVICE\nexcept (NameError, TypeError):\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntry:\n    _HOMOGRAPH_REFERENCE_LIST = set(str(w).lower() for w in HOMOGRAPH_REFERENCE_LIST_BN)\nexcept (NameError, TypeError):\n    _HOMOGRAPH_REFERENCE_LIST = {\n        \"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\", \"ফল\", \"মাথা\", \"বার\", \"হার\", \"তারা\",\n        \"পানি\", \"দল\", \"বাজার\", \"নাম\", \"কথা\", \"বই\", \"ঘর\", \"মন\", \"হাত\"\n    }\n    _HOMOGRAPH_REFERENCE_LIST = set(str(w).lower() for w in _HOMOGRAPH_REFERENCE_LIST)\n\n\ndef _get_cluster_count(model: torch.nn.Module) -> int:\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        dscd = getattr(core, \"dscd\", None)\n        if dscd is None:\n            return 0\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        if lock:\n            with lock:\n                stores = getattr(dscd, \"prototype_stores\", {}) or {}\n                return len(stores)\n        else:\n            stores = getattr(dscd, \"prototype_stores\", {}) or {}\n            return len(stores)\n    except Exception:\n        return 0\n\n\ndef _get_dscd_homographs(model: torch.nn.Module) -> set:\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        dscd = getattr(core, \"dscd\", None)\n        if dscd is None:\n            return set()\n\n        if hasattr(dscd, 'get_discovered_homographs'):\n            try:\n                return dscd.get_discovered_homographs()\n            except Exception:\n                pass\n\n        homographs = set()\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        if lock:\n            with lock:\n                prototype_stores = getattr(dscd, \"prototype_stores\", {}) or {}\n                for token, store in prototype_stores.items():\n                    try:\n                        if hasattr(store, 'size') and store.size() >= 1:\n                            clean_token = (\n                                str(token)\n                                .replace('▁', '')\n                                .replace('Ġ', '')\n                                .replace('##', '')\n                                .strip()\n                                .lower()\n                            )\n                            homographs.add(clean_token)\n                    except Exception:\n                        continue\n        else:\n            prototype_stores = getattr(dscd, \"prototype_stores\", {}) or {}\n            for token, store in prototype_stores.items():\n                try:\n                    if hasattr(store, 'size') and store.size() >= 1:\n                        clean_token = (\n                            str(token)\n                            .replace('▁', '')\n                            .replace('Ġ', '')\n                            .replace('##', '')\n                            .strip()\n                            .lower()\n                        )\n                        homographs.add(clean_token)\n                except Exception:\n                    continue\n\n        return homographs\n    except Exception:\n        return set()\n\n\ndef _print_top_clusters(model: torch.nn.Module, top_n: int = 5):\n    try:\n        core = model.module if hasattr(model, \"module\") else model\n        dscd = getattr(core, \"dscd\", None)\n        if dscd is None:\n            return\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        if lock:\n            with lock:\n                prototype_stores = dict(getattr(dscd, \"prototype_stores\", {}) or {})\n        else:\n            prototype_stores = dict(getattr(dscd, \"prototype_stores\", {}) or {})\n\n        if not prototype_stores:\n            print(\"[CLUSTER] No clusters found yet\")\n            return\n\n        cluster_info = []\n        for token, store in prototype_stores.items():\n            try:\n                total_count = sum(getattr(store, \"counts\", []))\n            except Exception:\n                total_count = 0\n            try:\n                n_protos = len(getattr(store, \"centroids\", []))\n            except Exception:\n                n_protos = 0\n            cluster_info.append({\n                'token': token,\n                'count': total_count,\n                'protos': n_protos,\n                'mu': getattr(store, \"mu\", 0.0),\n                'tau': getattr(store, \"tau\", 0.0)\n            })\n\n        cluster_info.sort(key=lambda x: x['count'], reverse=True)\n\n        print(f\"\\n[CLUSTER] Top {min(top_n, len(cluster_info))} clusters:\")\n        print(\"-\" * 90)\n        print(f\"{'Rank':<6}{'Token':<15}{'Count':<12}{'Protos':<10}{'Mu':<15}{'Tau':<12}\")\n        print(\"-\" * 90)\n\n        for rank, info in enumerate(cluster_info[:top_n], 1):\n            token_str = str(info['token'])\n            token_display = token_str[:12] if len(token_str) > 12 else token_str\n            print(\n                f\"{rank:<6}{token_display:<15}{info['count']:<12}{info['protos']:<10}\"\n                f\"{info['mu']:<15.6f}{info['tau']:<12.6f}\"\n            )\n\n        print(\"-\" * 90)\n\n    except Exception as e:\n        if _DEBUG_DISCOVERY:\n            print(f\"[CLUSTER] Error: {str(e)[:100]}\")\n\n\ndef _timed(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if _DEBUG_TIMING:\n            start = time.time()\n            result = func(*args, **kwargs)\n            elapsed = time.time() - start\n            print(f\"[TIMING] {func.__name__}: {elapsed:.2f}s\")\n            return result\n        else:\n            return func(*args, **kwargs)\n    return wrapper\n\n\n@torch.inference_mode()\n@_timed\ndef comprehensive_post_training_testing(\n    model: torch.nn.Module,\n    tokenizer,\n    run_warmup: bool = True,\n    compare_baseline: bool = False,\n    baseline_metrics: Optional[Dict[str, Any]] = None\n) -> Dict[str, Any]:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"COMPREHENSIVE POST-TRAINING EVALUATION\")\n    print(\"=\" * 80)\n\n    if 'translate_with_explanations' not in globals():\n        print(\"[EVAL] ERROR: translate_with_explanations not found!\")\n        print(\"[EVAL] Cell 8 must be executed first.\")\n        return {\n            \"error\": \"translate_with_explanations not found\",\n            \"total_tests\": 0,\n            \"successful_translations\": 0,\n        }\n\n    test_sentences: List[Tuple[str, str, str, List[str]]] = [\n        (\"আমি কল বন্ধ করেছি।\", \"I turned off the tap\", \"কল = tap/call\", [\"কল\"]),\n        (\"কাল আমি বই কিনব।\", \"Tomorrow I will buy a book\", \"কাল = tomorrow/yesterday\", [\"কাল\"]),\n        (\"কাল আমি বই কিনেছিলাম।\", \"Yesterday I bought a book\", \"কাল = tomorrow/yesterday\", [\"কাল\"]),\n        (\"পাতা ঝরে পড়েছে।\", \"The leaf has fallen\", \"পাতা = leaf/page\", [\"পাতা\"]),\n        (\"তিনি ব্যাংক গেছেন।\", \"He went to the bank\", \"ব্যাংক = bank/embankment\", [\"ব্যাংক\"]),\n        (\"ফল খুব সুস্বাদু।\", \"The fruit is delicious\", \"ফল = fruit/result\", [\"ফল\"]),\n        (\"মাথা ব্যথা করছে।\", \"Head is aching\", \"মাথা = head/top\", [\"মাথা\"]),\n        (\"কল থেকে কল এসেছে।\", \"A call came from the tap\", \"Multiple কল\", [\"কল\"]),\n        (\"কালকে কাল মেঘ দেখা গেছে।\", \"Yesterday black clouds were seen\", \"Multiple কাল\", [\"কাল\"]),\n        (\"আজ ভাল আবহাওয়া।\", \"Weather is good today\", \"Simple\", []),\n        (\"আমি ভালো আছি।\", \"I am fine\", \"Simple\", []),\n        (\"সে খুব মিষ্টি কথা বলে।\", \"She speaks sweetly\", \"Simple\", []),\n        (\"এটা আমার বই।\", \"This is my book\", \"Simple\", []),\n        (\"তিনি ব্যাংকে কাজ করেন এবং ব্যাংকে বসে থাকেন।\",\n         \"He works at the bank and sits on the embankment\",\n         \"Long with multiple\", [\"ব্যাংক\"]),\n    ]\n\n    core_model = model.module if (_USE_MULTI_GPU and hasattr(model, \"module\")) else model\n    core_model.eval()\n\n    quality_metrics = {\n        'total_confidence': 0.0,\n        'confidence_samples': 0,\n        'high_confidence_count': 0,\n        'medium_confidence_count': 0,\n        'low_confidence_count': 0,\n        'confidences': [],\n        'spans': [],\n        'uncertainties': [],\n    }\n\n    homograph_tracking = {\n        'test_expected_homographs': set(),\n        'dscd_discovered_homographs': set(),\n        'explained_homographs': set(),\n        'homograph_explanations': defaultdict(list),\n    }\n\n    error_tracking = {\n        'translation_failures': 0,\n        'dscd_failures': 0,\n        'trg_failures': 0,\n        'timeout_errors': 0,\n        'oom_errors': 0,\n        'other_errors': 0,\n        'error_details': [],\n        'per_test_status': [],\n    }\n\n    timing_metrics = {\n        'total_time': 0.0,\n        'per_test_times': [],\n        'avg_test_time': 0.0,\n    }\n\n    discovery_validated = False\n    try:\n        dscd = getattr(core_model, \"dscd\", None)\n        if dscd and hasattr(dscd, 'discovered_log'):\n            lock = None\n            if hasattr(dscd, 'buffer_lock'):\n                lock = dscd.buffer_lock\n            elif hasattr(dscd, 'clustering_lock'):\n                lock = dscd.clustering_lock\n\n            if lock:\n                with lock:\n                    discovered_log = getattr(dscd, 'discovered_log', [])\n                    if discovered_log:\n                        discovery_validated = True\n                        last_discovery = discovered_log[-1]\n                        discovered = last_discovery.get('discovered', 0)\n                        candidates = last_discovery.get('candidates', 0)\n                        if _DEBUG_DISCOVERY:\n                            print(f\"[EVAL] Discovery log: {discovered}/{candidates} homographs\")\n            else:\n                discovered_log = getattr(dscd, 'discovered_log', [])\n                if discovered_log:\n                    discovery_validated = True\n                    last_discovery = discovered_log[-1]\n                    discovered = last_discovery.get('discovered', 0)\n                    candidates = last_discovery.get('candidates', 0)\n                    if _DEBUG_DISCOVERY:\n                        print(f\"[EVAL] Discovery log: {discovered}/{candidates} homographs\")\n        else:\n            if _DEBUG_DISCOVERY:\n                print(f\"[EVAL] No discovery log found\")\n    except Exception as e:\n        if _DEBUG_DISCOVERY:\n            print(f\"[EVAL] Discovery validation failed: {e}\")\n\n    asbn_stats: Dict[str, Any] = {}\n    try:\n        asbn = getattr(core_model, \"asbn\", None)\n        if asbn:\n            if hasattr(asbn, 'get_detailed_stats'):\n                asbn_stats = asbn.get_detailed_stats()\n            elif hasattr(asbn, 'get_asbn_stats'):\n                asbn_stats = asbn.get_asbn_stats()\n\n            if asbn_stats and _DEBUG_DISCOVERY:\n                print(f\"[EVAL] ASBN: domain_acc={asbn_stats.get('domain_accuracy', 0):.2%}\")\n    except Exception as e:\n        if _DEBUG_DISCOVERY:\n            print(f\"[EVAL] ASBN stats failed: {e}\")\n\n    trg_stats: Dict[str, Any] = {}\n    try:\n        trg = getattr(core_model, \"trg\", None)\n        if trg and hasattr(trg, 'get_statistics'):\n            trg_stats = trg.get_statistics()\n            if _DEBUG_DISCOVERY:\n                print(f\"[EVAL] TRG: {trg_stats.get('explanations_generated', 0)} total\")\n    except Exception as e:\n        if _DEBUG_DISCOVERY:\n            print(f\"[EVAL] TRG stats failed: {e}\")\n\n    homograph_tracking['dscd_discovered_homographs'] = _get_dscd_homographs(core_model)\n    print(f\"[EVAL] DSCD discovered: {len(homograph_tracking['dscd_discovered_homographs'])} homographs\")\n    if homograph_tracking['dscd_discovered_homographs'] and _DEBUG_DISCOVERY:\n        print(f\"[EVAL] Sample: {list(homograph_tracking['dscd_discovered_homographs'])[:10]}\")\n\n    if run_warmup:\n        try:\n            dscd = getattr(core_model, \"dscd\", None)\n            if dscd is not None:\n                lock = None\n                if hasattr(dscd, 'buffer_lock'):\n                    lock = dscd.buffer_lock\n                elif hasattr(dscd, 'clustering_lock'):\n                    lock = dscd.clustering_lock\n\n                if lock:\n                    with lock:\n                        stores = getattr(dscd, \"prototype_stores\", None)\n                        store_count = len(stores) if stores else 0\n                else:\n                    stores = getattr(dscd, \"prototype_stores\", None)\n                    store_count = len(stores) if stores else 0\n\n                if store_count == 0 and 'dscd_discovery_warmup' in globals():\n                    print(\"[EVAL] Running warmup (num_sents=4000)...\")\n                    try:\n                        dscd_discovery_warmup(model, tokenizer, num_sents=4000, batch_size=64)\n                        homograph_tracking['dscd_discovered_homographs'] = _get_dscd_homographs(core_model)\n                    except Exception as e:\n                        print(f\"[EVAL] Warmup failed: {e}\")\n        except Exception:\n            if _DEBUG_DISCOVERY:\n                try:\n                    traceback.print_exc()\n                except Exception:\n                    pass\n\n    total_tests = len(test_sentences)\n    successful_translations = 0\n    total_explanations = 0\n    total_high_span = 0\n    total_real_ambiguous = 0\n\n    print(f\"\\n[EVAL] Running {total_tests} tests...\")\n    print(\"-\" * 80)\n\n    try:\n        tokenizer.src_lang = _SOURCE_LANGUAGE\n        tokenizer.tgt_lang = _TARGET_LANGUAGE\n    except Exception:\n        pass\n\n    def _is_real_amb(expl: Dict[str, Any]) -> bool:\n        try:\n            s = float(expl.get(\"span\", 0.0))\n            u = float(expl.get(\"uncertainty\", 0.0))\n            return (s > _SPAN_THRESHOLD) or (u > _UNCERTAINTY_THRESHOLD)\n        except Exception:\n            return False\n\n    def _compute_similarity(pred: str, expected: str) -> float:\n        try:\n            pred_words = set(pred.lower().split())\n            exp_words = set(expected.lower().split())\n            if not exp_words:\n                return 0.0\n            overlap = len(pred_words & exp_words)\n            return overlap / len(exp_words)\n        except Exception:\n            return 0.0\n\n    for _, _, _, expected_homos in test_sentences:\n        homograph_tracking['test_expected_homographs'].update([h.lower() for h in expected_homos])\n\n    eval_start = time.time()\n\n    for idx, (src_text, expected_translation, desc, expected_homos) in enumerate(test_sentences, 1):\n        test_start = time.time()\n\n        print(f\"\\nTest {idx}/{total_tests}: {desc}\")\n        print(\"=\" * 60)\n\n        test_status = {\n            'test_id': idx,\n            'success': False,\n            'translation_ok': False,\n            'explanations_count': 0,\n            'error': None,\n        }\n\n        try:\n            result = translate_with_explanations(\n                core_model if core_model is not None else model,\n                tokenizer,\n                src_text,\n                source_lang=_SOURCE_LANGUAGE,\n                target_lang=_TARGET_LANGUAGE,\n                device=_DEVICE,\n                max_length=_MAX_LENGTH,\n                span_threshold=_SPAN_THRESHOLD,\n                uncertainty_threshold=_UNCERTAINTY_THRESHOLD,\n                track_stats=False\n            )\n\n            if result is None or not isinstance(result, dict):\n                print(f\"[EVAL] Invalid result type: {type(result)}\")\n                error_tracking['translation_failures'] += 1\n                test_status['error'] = 'invalid_result'\n                error_tracking['per_test_status'].append(test_status)\n                continue\n\n            if 'error' in result and result['error']:\n                print(f\"[EVAL] Translation error: {result['error']}\")\n                error_tracking['translation_failures'] += 1\n                test_status['error'] = 'translation_error'\n                error_tracking['per_test_status'].append(test_status)\n                continue\n\n            translation = str(result.get(\"translation\", \"\") or \"\")\n            amb_count = int(result.get(\"ambiguous_words_detected\", 0))\n            explanations = result.get(\"explanations\", []) or []\n\n            similarity = _compute_similarity(translation, expected_translation)\n\n            print(f\"Input: {src_text}\")\n            print(f\"Expected: {expected_translation}\")\n            print(f\"Translation: {translation}\")\n            print(f\"Similarity: {similarity:.1%}\")\n            print(f\"Ambiguous: {amb_count}\")\n\n            if explanations:\n                print(\"\\nExplanations:\")\n                high_span_local = 0\n                real_amb_local = 0\n\n                for j, expl in enumerate(explanations, 1):\n                    span_val = float(expl.get(\"span\", 0.0))\n                    u_val = float(expl.get(\"uncertainty\", 0.0))\n                    conf_val = float(expl.get(\"confidence\", max(span_val, u_val)))\n\n                    marker = f\"[S>{_SPAN_THRESHOLD:.2f}]\" if span_val > _SPAN_THRESHOLD else \"          \"\n\n                    word = expl.get(\"ambiguous_word\", expl.get(\"token\", \"N/A\"))\n                    pos = expl.get(\"position\", expl.get(\"token_idx\", \"N/A\"))\n\n                    print(f\"  {j}. {marker} '{word}' @ {pos}\")\n                    print(f\"       conf={conf_val:.3f} | U={u_val:.3f} | S={span_val:.3f}\")\n                    text = str(expl.get(\"explanation\", \"\"))\n                    if len(text) > 120:\n                        text = text[:120] + \"...\"\n                    print(f\"       {text}\")\n\n                    quality_metrics['confidences'].append(conf_val)\n                    quality_metrics['spans'].append(span_val)\n                    quality_metrics['uncertainties'].append(u_val)\n                    quality_metrics['total_confidence'] = quality_metrics.get('total_confidence', 0.0) + conf_val\n                    quality_metrics['confidence_samples'] += 1\n\n                    if conf_val >= 0.65:\n                        quality_metrics['high_confidence_count'] += 1\n                    elif conf_val >= 0.4:\n                        quality_metrics['medium_confidence_count'] += 1\n                    else:\n                        quality_metrics['low_confidence_count'] += 1\n\n                    if span_val > _SPAN_THRESHOLD:\n                        high_span_local += 1\n                    if _is_real_amb(expl):\n                        real_amb_local += 1\n\n                    clean_word = str(word).replace('▁', '').replace('Ġ', '').strip().lower()\n                    homograph_tracking['explained_homographs'].add(clean_word)\n                    homograph_tracking['homograph_explanations'][clean_word].append({\n                        'sentence': src_text,\n                        'confidence': conf_val,\n                        'span': span_val,\n                        'uncertainty': u_val,\n                    })\n\n                total_explanations += len(explanations)\n                total_high_span += high_span_local\n                total_real_ambiguous += real_amb_local\n                test_status['explanations_count'] = len(explanations)\n            else:\n                print(\"No explanations\")\n\n            if translation and translation.strip() and translation not in (\n                \"Error occurred\",\n                \"Translation generation failed\",\n                \"ERROR DURING TRANSLATION\",\n            ):\n                successful_translations += 1\n                test_status['translation_ok'] = True\n                test_status['success'] = True\n                print(\"Success\")\n            else:\n                print(\"Translation failed\")\n                error_tracking['translation_failures'] += 1\n                test_status['error'] = 'translation_failed'\n\n            del result\n            if explanations:\n                del explanations\n\n        except RuntimeError as e:\n            error_str = str(e).lower()\n            if \"out of memory\" in error_str:\n                print(f\"[EVAL] OOM: {str(e)[:100]}\")\n                error_tracking['oom_errors'] += 1\n                test_status['error'] = 'oom'\n            elif \"timeout\" in error_str:\n                print(f\"[EVAL] Timeout: {str(e)[:100]}\")\n                error_tracking['timeout_errors'] += 1\n                test_status['error'] = 'timeout'\n            else:\n                print(f\"[EVAL] Runtime: {type(e).__name__}\")\n                error_tracking['other_errors'] += 1\n                test_status['error'] = 'runtime'\n            error_tracking['error_details'].append(f\"Test {idx}: {type(e).__name__}\")\n        except Exception as e:\n            print(f\"[EVAL] Error: {type(e).__name__}\")\n            error_tracking['other_errors'] += 1\n            test_status['error'] = type(e).__name__\n            error_tracking['error_details'].append(f\"Test {idx}: {type(e).__name__}\")\n            if _DEBUG_DISCOVERY:\n                try:\n                    traceback.print_exc()\n                except Exception:\n                    pass\n\n        error_tracking['per_test_status'].append(test_status)\n\n        test_time = time.time() - test_start\n        timing_metrics['per_test_times'].append(test_time)\n\n        print(\"-\" * 60)\n\n        if idx % 3 == 0 and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    timing_metrics['total_time'] = time.time() - eval_start\n    if timing_metrics['per_test_times']:\n        timing_metrics['avg_test_time'] = (\n            sum(timing_metrics['per_test_times']) / len(timing_metrics['per_test_times'])\n        )\n\n    if quality_metrics['confidence_samples'] > 0:\n        quality_metrics['avg_confidence'] = (\n            quality_metrics['total_confidence'] / quality_metrics['confidence_samples']\n        )\n        quality_metrics['avg_span'] = (\n            sum(quality_metrics['spans']) / len(quality_metrics['spans'])\n            if quality_metrics['spans']\n            else 0.0\n        )\n        quality_metrics['avg_uncertainty'] = (\n            sum(quality_metrics['uncertainties']) / len(quality_metrics['uncertainties'])\n            if quality_metrics['uncertainties']\n            else 0.0\n        )\n\n        if quality_metrics['confidences']:\n            sorted_conf = sorted(quality_metrics['confidences'])\n            quality_metrics['confidence_p25'] = sorted_conf[len(sorted_conf) // 4]\n            quality_metrics['confidence_p50'] = sorted_conf[len(sorted_conf) // 2]\n            quality_metrics['confidence_p75'] = sorted_conf[3 * len(sorted_conf) // 4]\n    else:\n        quality_metrics['avg_confidence'] = 0.0\n        quality_metrics['avg_span'] = 0.0\n        quality_metrics['avg_uncertainty'] = 0.0\n\n    explained_from_dscd = homograph_tracking['explained_homographs'].intersection(\n        homograph_tracking['dscd_discovered_homographs']\n    )\n\n    test_expected_discovered = homograph_tracking['test_expected_homographs'].intersection(\n        homograph_tracking['dscd_discovered_homographs']\n    )\n\n    reference_discovered = _HOMOGRAPH_REFERENCE_LIST.intersection(\n        homograph_tracking['dscd_discovered_homographs']\n    )\n\n    homograph_tracking['explained_from_dscd_rate'] = (\n        len(explained_from_dscd) / len(homograph_tracking['dscd_discovered_homographs'])\n        if homograph_tracking['dscd_discovered_homographs']\n        else 0.0\n    )\n    homograph_tracking['test_expected_discovery_rate'] = (\n        len(test_expected_discovered) / len(homograph_tracking['test_expected_homographs'])\n        if homograph_tracking['test_expected_homographs']\n        else 0.0\n    )\n    homograph_tracking['reference_discovery_rate'] = (\n        len(reference_discovered) / len(_HOMOGRAPH_REFERENCE_LIST)\n        if _HOMOGRAPH_REFERENCE_LIST\n        else 0.0\n    )\n\n    try:\n        dscd_stats = {\"total_words\": 0, \"multi_sense_words\": 0, \"total_prototypes\": 0}\n        dscd = getattr(core_model, \"dscd\", None)\n        if dscd is not None and hasattr(dscd, \"prototype_stores\"):\n            lock = None\n            if hasattr(dscd, 'buffer_lock'):\n                lock = dscd.buffer_lock\n            elif hasattr(dscd, 'clustering_lock'):\n                lock = dscd.clustering_lock\n\n            if lock:\n                with lock:\n                    stores = dict(getattr(dscd, \"prototype_stores\") or {})\n            else:\n                stores = dict(getattr(dscd, \"prototype_stores\") or {})\n\n            total_words = 0\n            multi = 0\n            total_protos = 0\n            for key, store in stores.items():\n                try:\n                    sz = int(store.size()) if hasattr(store, \"size\") else 0\n                except Exception:\n                    sz = 0\n                total_words += 1\n                total_protos += sz\n                if sz >= 2:\n                    multi += 1\n            dscd_stats = {\n                \"total_words\": total_words,\n                \"multi_sense_words\": multi,\n                \"total_prototypes\": total_protos,\n            }\n    except Exception as e:\n        if _DEBUG_DISCOVERY:\n            print(f\"[EVAL] DSCD stats failed: {e}\")\n        dscd_stats = {\"total_words\": 0, \"multi_sense_words\": 0, \"total_prototypes\": 0}\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"COMPREHENSIVE EVALUATION SUMMARY\")\n    print(\"=\" * 80)\n\n    print(f\"\\n[TRANSLATION QUALITY]\")\n    print(f\"  Total tests: {total_tests}\")\n    print(f\"  Successful: {successful_translations}\")\n    print(f\"  Success rate: {successful_translations / total_tests * 100:.1f}%\")\n\n    print(f\"\\n[AMBIGUITY DETECTION]\")\n    print(f\"  Total explanations: {total_explanations}\")\n    print(f\"  High-span (S>{_SPAN_THRESHOLD}): {total_high_span}\")\n    print(f\"  Real ambiguous: {total_real_ambiguous}\")\n    if total_tests > 0:\n        print(f\"  Avg explanations/test: {total_explanations / total_tests:.2f}\")\n\n    print(f\"\\n[EXPLANATION QUALITY]\")\n    print(f\"  Avg confidence: {quality_metrics['avg_confidence']:.3f}\")\n    print(f\"  Avg span: {quality_metrics['avg_span']:.3f}\")\n    print(f\"  Avg uncertainty: {quality_metrics['avg_uncertainty']:.3f}\")\n\n    if 'confidence_p50' in quality_metrics:\n        print(\n            f\"  Confidence P25/P50/P75: \"\n            f\"{quality_metrics.get('confidence_p25', 0):.3f} / \"\n            f\"{quality_metrics.get('confidence_p50', 0):.3f} / \"\n            f\"{quality_metrics.get('confidence_p75', 0):.3f}\"\n        )\n\n    print(f\"  High (>=0.65): {quality_metrics['high_confidence_count']}\")\n    print(f\"  Medium (0.4-0.65): {quality_metrics['medium_confidence_count']}\")\n    print(f\"  Low (<0.4): {quality_metrics['low_confidence_count']}\")\n\n    print(f\"\\n[HOMOGRAPH DISCOVERY]\")\n    print(f\"  DSCD discovered: {len(homograph_tracking['dscd_discovered_homographs'])}\")\n    print(f\"  Explained: {len(homograph_tracking['explained_homographs'])}\")\n    print(f\"  Explanation rate: {homograph_tracking['explained_from_dscd_rate']:.1%}\")\n    print(f\"  Test discovery rate: {homograph_tracking['test_expected_discovery_rate']:.1%}\")\n\n    if homograph_tracking['explained_homographs']:\n        print(f\"\\n  Explained homographs (top 10):\")\n        for homo in sorted(homograph_tracking['explained_homographs'])[:10]:\n            exps = homograph_tracking['homograph_explanations'].get(homo, [])\n            count = len(exps)\n            avg_conf = sum(e['confidence'] for e in exps) / len(exps) if exps else 0.0\n            in_dscd = \"[D]\" if homo in homograph_tracking['dscd_discovered_homographs'] else \"   \"\n            in_ref = \"[R]\" if homo in _HOMOGRAPH_REFERENCE_LIST else \"   \"\n            print(f\"    {in_dscd} {in_ref} '{homo}': {count} x conf={avg_conf:.3f}\")\n\n    print(f\"\\n[REFERENCE COMPARISON]\")\n    print(f\"  Reference: {len(_HOMOGRAPH_REFERENCE_LIST)} words\")\n    print(f\"  Discovered: {len(reference_discovered)}/{len(_HOMOGRAPH_REFERENCE_LIST)}\")\n    print(f\"  Coverage: {homograph_tracking['reference_discovery_rate']:.1%}\")\n\n    print(f\"\\n[DSCD PROTOTYPES]\")\n    print(f\"  Word types: {dscd_stats['total_words']}\")\n    print(f\"  Multi-sense: {dscd_stats['multi_sense_words']}\")\n    print(f\"  Total prototypes: {dscd_stats['total_prototypes']}\")\n    if dscd_stats['total_words'] > 0:\n        print(\n            f\"  Multi-sense ratio: \"\n            f\"{dscd_stats['multi_sense_words'] / dscd_stats['total_words']:.1%}\"\n        )\n\n    if asbn_stats:\n        print(f\"\\n[ASBN]\")\n        print(f\"  Domain accuracy: {asbn_stats.get('domain_accuracy', 0):.2%}\")\n        if 'source_accuracy' in asbn_stats:\n            print(f\"  Source accuracy: {asbn_stats['source_accuracy']:.2%}\")\n            print(f\"  Target accuracy: {asbn_stats['target_accuracy']:.2%}\")\n\n    if trg_stats:\n        print(f\"\\n[TRG]\")\n        print(f\"  Total explanations: {trg_stats.get('explanations_generated', 0)}\")\n        print(f\"  High confidence: {trg_stats.get('high_confidence_rate', 0):.1%}\")\n\n    print(f\"\\n[PERFORMANCE]\")\n    print(f\"  Total time: {timing_metrics['total_time']:.2f}s\")\n    print(f\"  Avg time/test: {timing_metrics['avg_test_time']:.2f}s\")\n\n    total_errors = sum([\n        error_tracking['translation_failures'],\n        error_tracking['dscd_failures'],\n        error_tracking['trg_failures'],\n        error_tracking['timeout_errors'],\n        error_tracking['oom_errors'],\n        error_tracking['other_errors'],\n    ])\n\n    if total_errors > 0:\n        print(f\"\\n[ERRORS]\")\n        print(f\"  Total: {total_errors}\")\n        print(f\"  Translation: {error_tracking['translation_failures']}\")\n        print(f\"  OOM: {error_tracking['oom_errors']}\")\n        print(f\"  Other: {error_tracking['other_errors']}\")\n\n    if compare_baseline and baseline_metrics and isinstance(baseline_metrics, dict):\n        print(f\"\\n[BASELINE COMPARISON]\")\n        try:\n            baseline_success = float(baseline_metrics.get('success_rate_pct', 0))\n            current_success = (\n                successful_translations / total_tests * 100.0\n            ) if total_tests > 0 else 0.0\n            success_delta = current_success - baseline_success\n\n            baseline_expl = int(baseline_metrics.get('total_explanations', 0))\n            expl_delta = total_explanations - baseline_expl\n\n            baseline_quality_dict = baseline_metrics.get('quality_metrics', {})\n            if isinstance(baseline_quality_dict, dict):\n                baseline_quality = float(baseline_quality_dict.get('avg_confidence', 0))\n            else:\n                baseline_quality = 0.0\n            quality_delta = quality_metrics['avg_confidence'] - baseline_quality\n\n            print(f\"  Translation: {current_success:.1f}% ({success_delta:+.1f}%)\")\n            print(f\"  Explanations: {total_explanations} ({expl_delta:+d})\")\n            print(\n                f\"  Confidence: {quality_metrics['avg_confidence']:.3f} \"\n                f\"({quality_delta:+.3f})\"\n            )\n\n            baseline_homo_dict = baseline_metrics.get('homograph_tracking', {})\n            if isinstance(baseline_homo_dict, dict):\n                baseline_homo_rate = float(baseline_homo_dict.get('explained_from_dscd_rate', 0))\n                homo_delta = (\n                    homograph_tracking['explained_from_dscd_rate'] - baseline_homo_rate\n                )\n                print(\n                    f\"  Explanation rate: \"\n                    f\"{homograph_tracking['explained_from_dscd_rate']:.1%} \"\n                    f\"({homo_delta:+.1%})\"\n                )\n        except Exception as e:\n            print(f\"  Comparison failed: {type(e).__name__}\")\n\n    warnings = []\n    if successful_translations < total_tests * 0.5:\n        warnings.append(\"High translation failure (>50%)\")\n    if total_explanations == 0:\n        warnings.append(\"No explanations generated\")\n    if dscd_stats['total_words'] < 100:\n        warnings.append(\"Very few prototypes (<100)\")\n    if quality_metrics['low_confidence_count'] > quality_metrics['high_confidence_count']:\n        warnings.append(\"More low than high confidence\")\n    if homograph_tracking['explained_from_dscd_rate'] < 0.3:\n        warnings.append(\"Low explanation rate (<30%)\")\n    if not discovery_validated:\n        warnings.append(\"Discovery log missing\")\n    if asbn_stats and asbn_stats.get('domain_accuracy', 0) < 0.5:\n        warnings.append(\"ASBN domain accuracy <50%\")\n\n    if warnings:\n        print(f\"\\n[WARNINGS]\")\n        for w in warnings:\n            print(f\"  - {w}\")\n    else:\n        print(f\"\\n[HEALTH] All systems nominal\")\n\n    print(\"=\" * 80)\n\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n    return {\n        \"total_tests\": total_tests,\n        \"successful_translations\": successful_translations,\n        \"success_rate_pct\": (successful_translations / total_tests * 100.0) if total_tests > 0 else 0.0,\n        \"total_explanations\": total_explanations,\n        \"total_high_span\": total_high_span,\n        \"total_real_ambiguous\": total_real_ambiguous,\n        \"dscd_stats\": dscd_stats,\n        \"quality_metrics\": quality_metrics,\n        \"homograph_tracking\": homograph_tracking,\n        \"error_tracking\": error_tracking,\n        \"asbn_stats\": asbn_stats,\n        \"trg_stats\": trg_stats,\n        \"discovery_validated\": discovery_validated,\n        \"timing_metrics\": timing_metrics,\n    }\n\n\ndef test_evaluation_pipeline(model, tokenizer) -> bool:\n    print(\"\\n\" + \"=\"*60)\n    print(\"[TEST] Testing evaluation pipeline\")\n    print(\"=\"*60)\n\n    try:\n        result = comprehensive_post_training_testing(\n            model,\n            tokenizer,\n            run_warmup=False,\n            compare_baseline=False\n        )\n\n        assert 'total_tests' in result\n        assert 'quality_metrics' in result\n        assert 'homograph_tracking' in result\n\n        print(\"Evaluation pipeline test passed\")\n        print(\"=\"*60 + \"\\n\")\n        return True\n\n    except Exception as e:\n        print(f\"Evaluation pipeline test failed: {e}\")\n        try:\n            traceback.print_exc()\n        except Exception:\n            pass\n        print(\"=\"*60 + \"\\n\")\n        return False\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 9: Testing & Evaluation (DUAL-PATH COMPATIBLE)\")\nprint(\"=\" * 80)\nprint(\"Evaluation metrics:\")\nprint(\"  - Translation quality (success rate)\")\nprint(\"  - Ambiguity detection (high-span, real ambiguous)\")\nprint(\"  - Explanation quality (confidence distribution)\")\nprint(\"  - Homograph discovery (DSCD vs reference)\")\nprint(\"  - DSCD prototype statistics\")\nprint(\"  - ASBN domain accuracy\")\nprint(\"  - TRG explanation statistics\")\nprint(\"  - Performance timing (total, avg per test)\")\nprint(\"  - Error tracking (OOM, timeout, other)\")\nprint()\nprint(f\"Configuration:\")\nprint(f\"  - Source language: {_SOURCE_LANGUAGE}\")\nprint(f\"  - Target language: {_TARGET_LANGUAGE}\")\nprint(f\"  - Span threshold: {_SPAN_THRESHOLD}\")\nprint(f\"  - Uncertainty threshold: {_UNCERTAINTY_THRESHOLD}\")\nprint(f\"  - Max length: {_MAX_LENGTH}\")\nprint(f\"  - Device: {_DEVICE}\")\nprint(f\"  - Reference list: {len(_HOMOGRAPH_REFERENCE_LIST)} words\")\nprint(\"\\n✅ DUAL-PATH COMPATIBILITY:\")\nprint(\"  ✅ Uses Cell 8 functions (already fixed)\")\nprint(\"  ✅ No direct model.forward() calls\")\nprint(\"  ✅ Only inspection functions (no API changes)\")\nprint(\"  ✅ Fully compatible with dual-path system\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"8uL574F8H4J5","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:04.991323Z","iopub.execute_input":"2026-02-18T08:40:04.991543Z","iopub.status.idle":"2026-02-18T08:40:05.065453Z","shell.execute_reply.started":"2026-02-18T08:40:04.991525Z","shell.execute_reply":"2026-02-18T08:40:05.064911Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCell 9: Testing & Evaluation (DUAL-PATH COMPATIBLE)\n================================================================================\nEvaluation metrics:\n  - Translation quality (success rate)\n  - Ambiguity detection (high-span, real ambiguous)\n  - Explanation quality (confidence distribution)\n  - Homograph discovery (DSCD vs reference)\n  - DSCD prototype statistics\n  - ASBN domain accuracy\n  - TRG explanation statistics\n  - Performance timing (total, avg per test)\n  - Error tracking (OOM, timeout, other)\n\nConfiguration:\n  - Source language: bn_IN\n  - Target language: en_XX\n  - Span threshold: 0.2\n  - Uncertainty threshold: 0.15\n  - Max length: 256\n  - Device: cuda\n  - Reference list: 42 words\n\n✅ DUAL-PATH COMPATIBILITY:\n  ✅ Uses Cell 8 functions (already fixed)\n  ✅ No direct model.forward() calls\n  ✅ Only inspection functions (no API changes)\n  ✅ Fully compatible with dual-path system\n================================================================================\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 10: TATN MAIN PIPELINE (DUAL-PATH COMPATIBLE)\n# ===========================================================================================\n\nimport os\nimport sys\nimport time\nimport traceback\nimport inspect\nfrom typing import Tuple, Optional, Dict, Any\nimport gc\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Subset\nfrom transformers.modeling_outputs import BaseModelOutput\nimport collections\n\ntry:\n    if hasattr(torch.serialization, 'add_safe_globals'):\n        torch.serialization.add_safe_globals([\n            collections.defaultdict,\n            collections.OrderedDict,\n            collections.deque\n        ])\n        print(\"✓ Registered safe globals for PyTorch 2.6+\")\nexcept (AttributeError, Exception):\n    pass\n\ndef _g(name, default):\n    return globals().get(name, default)\n\ntry:\n    _USE_MULTI_GPU = bool(_g(\"USE_MULTI_GPU\", False))\n    _NUM_GPUS = int(_g(\"NUM_GPUS\", torch.cuda.device_count() if torch.cuda.is_available() else 0))\n    _DEVICE = _g(\"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n    _SOURCE_LANGUAGE = str(_g(\"SOURCE_LANGUAGE\", \"bn\"))\n    _TARGET_LANGUAGE = str(_g(\"TARGET_LANGUAGE\", \"en\"))\n    _NUM_SAMPLES = int(_g(\"NUM_SAMPLES\", 30000))\n    _MAX_LENGTH = int(_g(\"MAX_LENGTH\", 52))\n    _BATCH_SIZE = int(_g(\"BATCH_SIZE\", 8))\n    _EPOCHS = int(_g(\"EPOCHS\", 1))\n    _ACCUMULATION_STEPS = int(_g(\"ACCUMULATION_STEPS\", 1))\n    _LR_NMT = float(_g(\"LR_NMT\", 2e-5))\n    _LR_PHI = float(_g(\"LR_PHI\", 5e-6))\n    _ENABLE_ASBN_TRAINING = bool(_g(\"ENABLE_ASBN_TRAINING\", False))\n    _VALIDATION_CHECK_INTERVAL = int(_g(\"VALIDATION_CHECK_INTERVAL\", 500))\n    _PERIODIC_DISCOVERY_FREQUENCY = int(_g(\"PERIODIC_DISCOVERY_FREQUENCY\", 50))\n    _DSCD_WARMUP_SAMPLES = int(_g(\"DSCD_WARMUP_SAMPLES\", 4000))\n    _SPAN_THRESHOLD = float(_g(\"SPAN_THRESHOLD\", 0.20))\n    _UNCERTAINTY_THRESHOLD = float(_g(\"UNCERTAINTY_THRESHOLD\", 0.15))\n    _HOMOGRAPH_REFERENCE_LIST_BN = set(_g(\"HOMOGRAPH_REFERENCE_LIST_BN\",\n        [\"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\", \"ফল\", \"মাথা\", \"বার\", \"হার\", \"তারা\"]))\n    HOMOGRAPH_REFERENCE_LIST_BN = _HOMOGRAPH_REFERENCE_LIST_BN\n    _FREEZE_ENCODER = bool(_g(\"FREEZE_ENCODER\", False))\n    _DEBUG_TIMING = bool(_g(\"DEBUG_TIMING\", False))\n    _DEBUG_DISCOVERY = bool(_g(\"DEBUG_DISCOVERY\", False))\n    _VALIDATION_SPLIT = float(_g(\"VALIDATION_SPLIT\", 0.10))\nexcept (ValueError, TypeError):\n    _NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    _USE_MULTI_GPU = _NUM_GPUS > 1\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = \"bn\"\n    _TARGET_LANGUAGE = \"en\"\n    _NUM_SAMPLES = 30000\n    _MAX_LENGTH = 52\n    _BATCH_SIZE = 8\n    _EPOCHS = 1\n    _ACCUMULATION_STEPS = 1\n    _LR_NMT = 2e-5\n    _LR_PHI = 5e-6\n    _ENABLE_ASBN_TRAINING = False\n    _VALIDATION_CHECK_INTERVAL = 500\n    _PERIODIC_DISCOVERY_FREQUENCY = 50\n    _DSCD_WARMUP_SAMPLES = 4000\n    _SPAN_THRESHOLD = 0.20\n    _UNCERTAINTY_THRESHOLD = 0.15\n    _HOMOGRAPH_REFERENCE_LIST_BN = {\"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\"}\n    HOMOGRAPH_REFERENCE_LIST_BN = _HOMOGRAPH_REFERENCE_LIST_BN\n    _FREEZE_ENCODER = False\n    _DEBUG_TIMING = False\n    _DEBUG_DISCOVERY = False\n    _VALIDATION_SPLIT = 0.10\n\n_CHECKPOINT_DIR = \"/content/drive/MyDrive/Samanantar dataset\"\n_CHECKPOINT_PATH = os.path.join(_CHECKPOINT_DIR, \"tatn_final.pt\")\n\n\ndef _safe_clear_gpu_caches():\n    try:\n        if \"clear_all_gpu_caches\" in globals():\n            globals()[\"clear_all_gpu_caches\"]()\n            return\n        if torch.cuda.is_available():\n            for i in range(torch.cuda.device_count()):\n                try:\n                    with torch.cuda.device(i):\n                        torch.cuda.empty_cache()\n                except Exception:\n                    pass\n        if gc.isenabled():\n            gc.collect()\n    except Exception:\n        pass\n\n\ndef _safe_get(d: dict, *keys, default=None):\n    if not isinstance(d, dict):\n        return default\n    result = d\n    for key in keys:\n        if not isinstance(result, dict):\n            return default\n        result = result.get(key, None)\n        if result is None:\n            return default\n    return result\n\n\ndef _safe_tokenizer_from_pretrained(model_name: str, local_files_only: bool = False):\n    try:\n        from transformers import MBart50TokenizerFast\n        tok = MBart50TokenizerFast.from_pretrained(\n            model_name,\n            src_lang=\"bn_IN\",\n            tgt_lang=\"en_XX\",\n            local_files_only=local_files_only\n        )\n        required = ['encode', 'decode', 'convert_ids_to_tokens', '__call__']\n        for method in required:\n            if not hasattr(tok, method):\n                raise RuntimeError(f\"Tokenizer missing: {method}\")\n        return tok\n    except Exception as e:\n        print(f\"[TOKENIZER] Load failed: {e}\")\n        raise\n\n\ndef _get_dscd_stores_safe(dscd):\n    try:\n        prototype_stores = getattr(dscd, 'prototype_stores', None)\n        if prototype_stores is None:\n            return {}\n\n        lock = None\n        if hasattr(dscd, 'buffer_lock'):\n            lock = dscd.buffer_lock\n        elif hasattr(dscd, 'clustering_lock'):\n            lock = dscd.clustering_lock\n\n        try:\n            if lock:\n                try:\n                    with lock:\n                        return dict(prototype_stores)\n                except Exception:\n                    return dict(prototype_stores)\n            else:\n                return dict(prototype_stores)\n        except Exception:\n            return {}\n    except Exception:\n        return {}\n\n\ndef _get_core_model(model):\n    return model.module if hasattr(model, \"module\") else model\n\n\ndef initialize_environment():\n    print(\"[PIPELINE] Initializing environment...\")\n    if torch.cuda.is_available():\n        gcnt = torch.cuda.device_count()\n        print(f\"[PIPELINE] GPUs: {gcnt}\")\n        for i in range(gcnt):\n            try:\n                name = torch.cuda.get_device_name(i)\n                mem = torch.cuda.get_device_properties(i).total_memory / 1024**3\n                print(f\"  GPU {i}: {name} ({mem:.1f} GB)\")\n            except Exception:\n                print(f\"  GPU {i}: Unknown\")\n        _safe_clear_gpu_caches()\n    else:\n        print(\"[PIPELINE] CPU only\")\n    return True\n\n\ndef validate_component_compatibility(model_core, tokenizer):\n    print(\"\\n[VALIDATION] Checking component compatibility...\")\n\n    issues = []\n\n    try:\n        model_vocab = model_core.vocab_size\n        tokenizer_vocab = len(tokenizer) if hasattr(tokenizer, \"__len__\") else getattr(tokenizer, \"vocab_size\", 0)\n\n        if model_vocab < tokenizer_vocab:\n            issues.append(f\"CRITICAL: model vocab ({model_vocab}) < tokenizer vocab ({tokenizer_vocab})\")\n        elif model_vocab > tokenizer_vocab:\n            print(f\"  ✅ Vocabulary: model={model_vocab}, tokenizer={tokenizer_vocab}\")\n            print(f\"     Note: Model has {model_vocab - tokenizer_vocab} extra tokens (preserves pretrained weights)\")\n        else:\n            print(f\"  ✅ Vocabulary: {model_vocab}\")\n    except Exception as e:\n        issues.append(f\"Vocab check failed: {e}\")\n\n    try:\n        model_embed_dim = int(getattr(model_core.mbart.config, \"d_model\", 1024))\n        print(f\"  ✅ Model embed_dim: {model_embed_dim}\")\n\n        if hasattr(model_core, 'dscd'):\n            dscd_embed_dim = getattr(model_core.dscd, 'embed_dim', None)\n            if dscd_embed_dim is not None and dscd_embed_dim != model_embed_dim:\n                issues.append(f\"DSCD embed_dim mismatch: {dscd_embed_dim} != {model_embed_dim}\")\n            else:\n                print(f\"  ✅ DSCD embed_dim: {dscd_embed_dim}\")\n\n        if hasattr(model_core, 'asbn'):\n            asbn_embed_dim = getattr(model_core.asbn, 'embed_dim', None)\n            if asbn_embed_dim is not None and asbn_embed_dim != model_embed_dim:\n                issues.append(f\"ASBN embed_dim mismatch: {asbn_embed_dim} != {model_embed_dim}\")\n            else:\n                print(f\"  ✅ ASBN embed_dim: {asbn_embed_dim}\")\n    except Exception as e:\n        issues.append(f\"Embed_dim check failed: {e}\")\n\n    try:\n        embedding_layer = model_core.mbart.get_input_embeddings()\n        if embedding_layer is None:\n            issues.append(\"Model has no input embeddings\")\n        else:\n            actual_embed_dim = embedding_layer.embedding_dim\n            actual_vocab_size = embedding_layer.num_embeddings\n            print(f\"  ✅ Embedding layer: dim={actual_embed_dim}, vocab={actual_vocab_size}\")\n    except Exception as e:\n        issues.append(f\"Embedding layer check failed: {e}\")\n\n    if issues:\n        print(\"\\n[VALIDATION] ❌ FAILED - Issues found:\")\n        for issue in issues:\n            print(f\"  - {issue}\")\n        raise RuntimeError(\"Component compatibility validation failed\")\n    else:\n        print(\"[VALIDATION] ✅ All components compatible\")\n\n    return True\n\n\ndef validate_dataset_compatibility(dataset, tokenizer, model_vocab_size):\n    print(\"\\n[VALIDATION] Checking dataset compatibility...\")\n\n    try:\n        sample_batch = []\n        for i in range(min(5, len(dataset))):\n            try:\n                sample_batch.append(dataset[i])\n            except Exception:\n                continue\n\n        if not sample_batch:\n            print(\"[VALIDATION] ⚠️  Could not load samples\")\n            return True\n\n        max_input_id = 0\n        min_input_id = float('inf')\n\n        for item in sample_batch:\n            input_ids = item.get('input_ids', None)\n            if input_ids is not None:\n                if isinstance(input_ids, torch.Tensor):\n                    max_input_id = max(max_input_id, input_ids.max().item())\n                    min_input_id = min(min_input_id, input_ids.min().item())\n                elif isinstance(input_ids, list):\n                    max_input_id = max(max_input_id, max(input_ids))\n                    min_input_id = min(min_input_id, min(input_ids))\n\n        print(f\"  Input IDs range: [{min_input_id}, {max_input_id}]\")\n        print(f\"  Model vocab size: {model_vocab_size}\")\n\n        if max_input_id >= model_vocab_size:\n            raise RuntimeError(\n                f\"Dataset contains out-of-bounds token IDs!\\n\"\n                f\"  Max ID: {max_input_id}\\n\"\n                f\"  Vocab size: {model_vocab_size}\\n\"\n                f\"  → Cell 2 tokenization error or vocab mismatch\"\n            )\n\n        if min_input_id < 0:\n            raise RuntimeError(f\"Dataset contains negative token IDs: {min_input_id}\")\n\n        print(\"[VALIDATION] ✅ Dataset token IDs valid\")\n        return True\n\n    except Exception as e:\n        print(f\"[VALIDATION] Dataset check failed: {e}\")\n        raise\n\n\ndef test_model_forward_pass(model, tokenizer, device):\n    print(\"\\n[VALIDATION] Testing model forward pass...\")\n\n    try:\n        core_model = model.module if hasattr(model, 'module') else model\n        was_training = core_model.training\n        core_model.eval()\n\n        test_text = \"আমি কল বন্ধ করেছি।\"\n\n        try:\n            tokenizer.src_lang = _SOURCE_LANGUAGE\n            tokenizer.tgt_lang = _TARGET_LANGUAGE\n        except Exception:\n            pass\n\n        inputs = tokenizer(\n            test_text,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=_MAX_LENGTH\n        )\n\n        test_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        input_ids = inputs['input_ids'].to(test_device)\n        attention_mask = inputs['attention_mask'].to(test_device)\n\n        original_device = next(core_model.parameters()).device\n        if test_device != original_device:\n            core_model = core_model.to(test_device)\n\n        try:\n            with torch.no_grad():\n                print(\"  [TEST 1] Testing forward pass (inference mode)...\")\n                outputs = core_model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    src_texts=[test_text],\n                    token_word_map=None,\n                    labels=None,\n                    return_dict=True,\n                    path=2\n                )\n\n            if isinstance(outputs, torch.Tensor):\n                print(\"  ✅ Forward pass successful (tensor output)\")\n                print(f\"  Output shape: {outputs.shape}\")\n            elif isinstance(outputs, dict):\n                print(\"  ✅ Forward pass successful (dict output)\")\n                print(f\"  Keys: {list(outputs.keys())}\")\n\n                print(\"\\n  [TEST 2] Validating DSCD-augmented generation capability...\")\n\n                h_augmented = outputs.get('sense_augmented_embeddings', None)\n                if h_augmented is not None and isinstance(h_augmented, torch.Tensor):\n                    print(f\"    ✅ DSCD embeddings: shape={h_augmented.shape}\")\n\n                    try:\n                        enc_wrapped = BaseModelOutput(\n                            last_hidden_state=h_augmented,\n                            hidden_states=None,\n                            attentions=None,\n                        )\n                        print(f\"    ✅ BaseModelOutput created successfully\")\n\n                        print(\"\\n  [TEST 3] Testing generate() with DSCD-augmented embeddings...\")\n                        generated = core_model.generate(\n                            input_ids=None,\n                            attention_mask=attention_mask,\n                            encoder_outputs=enc_wrapped,\n                            max_length=32,\n                            num_beams=3,\n                            early_stopping=True\n                        )\n\n                        if generated is not None and generated.numel() > 0:\n                            translation = tokenizer.decode(generated[0], skip_special_tokens=True)\n                            print(f\"    ✅ Generation successful: '{translation}'\")\n                            print(f\"    ✅ DSCD-AUGMENTED GENERATION WORKING!\")\n                        else:\n                            print(f\"    ⚠️  Generation returned empty output\")\n\n                    except Exception as e:\n                        print(f\"    ❌ DSCD-augmented generation failed: {e}\")\n                        raise RuntimeError(f\"DSCD-augmented generation validation failed: {e}\")\n                else:\n                    print(f\"    ⚠️  No DSCD embeddings in output\")\n            else:\n                print(f\"  ⚠️  Unexpected output type: {type(outputs)}\")\n\n            print(\"\\n[VALIDATION] ✅ Model forward pass and generation validated\")\n\n        finally:\n            if test_device != original_device:\n                core_model = core_model.to(original_device)\n            if was_training:\n                core_model.train()\n\n        return True\n\n    except Exception as e:\n        print(f\"[VALIDATION] ❌ Forward pass failed: {e}\")\n        try:\n            traceback.print_exc()\n        except Exception:\n            pass\n        raise RuntimeError(f\"Model forward pass validation failed: {e}\")\n\n\ndef main_pipeline() -> Tuple[object, object]:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"TATN MAIN PIPELINE (DUAL-PATH COMPATIBLE)\")\n    print(\"=\" * 80)\n    print(f\"Configuration:\")\n    print(f\"  - Span threshold: {_SPAN_THRESHOLD}\")\n    print(f\"  - Uncertainty threshold: {_UNCERTAINTY_THRESHOLD}\")\n    print(f\"  - Discovery frequency: {_PERIODIC_DISCOVERY_FREQUENCY}\")\n    print(f\"  - ASBN Training: {'DISABLED' if not _ENABLE_ASBN_TRAINING else 'ENABLED'}\")\n    print(f\"  - Epochs: {_EPOCHS}\")\n    print(f\"  - Batch size: {_BATCH_SIZE}\")\n    print(f\"  - Validation split: {_VALIDATION_SPLIT:.1%}\")\n    print(\"=\" * 80)\n\n    pipeline_start = time.time()\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    initialize_environment()\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Initialization: {time.time() - phase_start:.2f}s\")\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 1] Loading tokenizer...\")\n    tokenizer = _safe_tokenizer_from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n    try:\n        tokenizer.src_lang = _SOURCE_LANGUAGE\n        tokenizer.tgt_lang = _TARGET_LANGUAGE\n    except Exception:\n        pass\n\n    try:\n        if not hasattr(tokenizer, 'pad_token_id') or tokenizer.pad_token_id is None:\n            if hasattr(tokenizer, 'add_special_tokens'):\n                tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n    except Exception:\n        pass\n\n    vocab_size = getattr(tokenizer, 'vocab_size', None)\n    if vocab_size is None:\n        try:\n            vocab_size = len(tokenizer)\n        except Exception:\n            vocab_size = 128112\n\n    print(f\"[PHASE 1] Tokenizer loaded (vocab: {vocab_size})\")\n\n    if \"validate_tokenizer_vocab\" in globals():\n        try:\n            print(\"[PHASE 1] Validating tokenizer vocabulary...\")\n            validate_tokenizer_vocab(tokenizer, expected_vocab_size=None)\n        except Exception as e:\n            print(f\"[PHASE 1] Tokenizer validation warning: {e}\")\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Tokenizer: {time.time() - phase_start:.2f}s\")\n        phase_start = time.time()\n\n    print(f\"\\n[PHASE 2] Loading data ({_NUM_SAMPLES} samples)...\")\n    if \"load_and_preprocess_optimized\" in globals():\n        try:\n            pairs = load_and_preprocess_optimized(_NUM_SAMPLES)\n        except Exception as e:\n            print(f\"[PHASE 2] Data loading failed: {e}\")\n            pairs = [(\"আমি কল বন্ধ করেছি।\", \"I turned off the tap.\")]\n    else:\n        print(\"[PHASE 2] Using fallback data\")\n        pairs = [(\"আমি কল বন্ধ করেছি।\", \"I turned off the tap.\")]\n\n    if \"MemoryEfficientDataset\" not in globals():\n        raise RuntimeError(\"MemoryEfficientDataset not found - run Cell 2\")\n    \n    full_dataset = MemoryEfficientDataset(pairs, tokenizer, max_length=_MAX_LENGTH)\n    \n    total_size = len(full_dataset)\n    val_size = int(total_size * _VALIDATION_SPLIT)\n    train_size = total_size - val_size\n    \n    print(f\"[PHASE 2] Splitting dataset: train={train_size}, val={val_size}\")\n    \n    train_indices = list(range(train_size))\n    val_indices = list(range(train_size, total_size))\n    \n    train_dataset = Subset(full_dataset, train_indices)\n    val_dataset = Subset(full_dataset, val_indices)\n    \n    collate_fn = globals().get(\"safe_collate\", None)\n    \n    if \"create_optimized_dataloader\" in globals():\n        try:\n            train_loader = create_optimized_dataloader(train_dataset, batch_size=_BATCH_SIZE, shuffle=True)\n            val_loader = create_optimized_dataloader(val_dataset, batch_size=_BATCH_SIZE, shuffle=False)\n        except Exception:\n            dataloader_kwargs = {\n                'batch_size': _BATCH_SIZE,\n                'num_workers': 0,\n                'pin_memory': torch.cuda.is_available()\n            }\n            if collate_fn is not None:\n                dataloader_kwargs['collate_fn'] = collate_fn\n            \n            train_loader = DataLoader(train_dataset, shuffle=True, **dataloader_kwargs)\n            val_loader = DataLoader(val_dataset, shuffle=False, **dataloader_kwargs)\n    else:\n        dataloader_kwargs = {\n            'batch_size': _BATCH_SIZE,\n            'num_workers': 0,\n            'pin_memory': torch.cuda.is_available()\n        }\n        if collate_fn is not None:\n            dataloader_kwargs['collate_fn'] = collate_fn\n        \n        train_loader = DataLoader(train_dataset, shuffle=True, **dataloader_kwargs)\n        val_loader = DataLoader(val_dataset, shuffle=False, **dataloader_kwargs)\n\n    try:\n        print(f\"[PHASE 2] Train: {len(train_dataset)} samples, {len(train_loader)} batches\")\n        print(f\"[PHASE 2] Val: {len(val_dataset)} samples, {len(val_loader)} batches\")\n    except Exception:\n        print(\"[PHASE 2] Dataset loaded\")\n\n    del pairs\n    _safe_clear_gpu_caches()\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Data loading: {time.time() - phase_start:.2f}s\")\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 3] Initializing model...\")\n    if \"MemoryOptimizedTATNWithExplanations\" not in globals():\n        raise RuntimeError(\"Model class not found - run Cell 6\")\n\n    model_core = MemoryOptimizedTATNWithExplanations(tokenizer)\n\n    try:\n        validate_component_compatibility(model_core, tokenizer)\n    except Exception as e:\n        print(f\"[PHASE 3] ❌ Component validation failed: {e}\")\n        raise\n\n    try:\n        validate_dataset_compatibility(full_dataset, tokenizer, model_core.vocab_size)\n    except Exception as e:\n        print(f\"[PHASE 3] ❌ Dataset validation failed: {e}\")\n        raise\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 1:\n        device_ids = list(range(_NUM_GPUS))\n        print(f\"[PHASE 3] Using DataParallel on {device_ids}\")\n        model = nn.DataParallel(model_core, device_ids=device_ids)\n    else:\n        model = model_core\n\n    model = model.to(_DEVICE)\n    core_model = _get_core_model(model)\n\n    try:\n        test_model_forward_pass(model, tokenizer, _DEVICE)\n    except Exception as e:\n        print(f\"[PHASE 3] ❌ Forward pass test failed: {e}\")\n        raise\n\n    if _FREEZE_ENCODER:\n        try:\n            for p in core_model.mbart.model.encoder.parameters():\n                p.requires_grad = False\n            print(\"[PHASE 3] Encoder frozen\")\n        except Exception:\n            pass\n\n    print(f\"[PHASE 3] Model initialized and validated\")\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Model init: {time.time() - phase_start:.2f}s\")\n\n    print(\"\\n[PHASE 4] Setting up optimizers...\")\n\n    try:\n        critic_params = list(core_model.asbn.critic_parameters()) if hasattr(core_model, \"asbn\") and hasattr(core_model.asbn, \"critic_parameters\") else []\n    except Exception:\n        critic_params = []\n\n    critic_ids = {id(p) for p in critic_params}\n    base_params = [p for p in core_model.parameters() if p.requires_grad and id(p) not in critic_ids]\n    optimizer = torch.optim.AdamW(base_params, lr=_LR_NMT)\n\n    phi_optimizer = None\n    if critic_params and _ENABLE_ASBN_TRAINING:\n        phi_optimizer = torch.optim.AdamW([p for p in critic_params if p.requires_grad], lr=_LR_PHI)\n        print(f\"[PHASE 4] ASBN optimizer created ({len([p for p in critic_params if p.requires_grad])} params)\")\n    elif not _ENABLE_ASBN_TRAINING:\n        print(f\"[PHASE 4] ASBN optimizer DISABLED (training disabled)\")\n\n    print(f\"[PHASE 4] Optimizers ready\")\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 5] Training...\")\n    print(f\"  - ASBN Training: {'DISABLED' if not _ENABLE_ASBN_TRAINING else 'ENABLED'}\")\n    print(f\"  - ASBN Optimizer: {'None (ASBN disabled)' if phi_optimizer is None else 'Active'}\")\n    print(f\"  - Validation: {len(val_loader)} batches\")\n\n    trained_model = model\n    training_stats = None\n\n    if \"train_memory_efficient_tatn\" in globals():\n        try:\n            try:\n                trg = getattr(core_model, 'trg', None)\n                if trg and hasattr(trg, 'reset_statistics'):\n                    trg.reset_statistics()\n            except Exception:\n                pass\n            \n            trained_model = train_memory_efficient_tatn(\n                model,\n                tokenizer,\n                train_loader,\n                optimizer,\n                phi_optimizer=phi_optimizer,\n                epochs=_EPOCHS,\n                accumulation_steps=_ACCUMULATION_STEPS,\n                validate_every=_VALIDATION_CHECK_INTERVAL,\n                enable_validation=(_VALIDATION_CHECK_INTERVAL > 0),\n                val_loader=val_loader,\n            )\n            print(\"[PHASE 5] Training complete\")\n        except Exception as e:\n            print(f\"[PHASE 5] Training failed: {e}\")\n            trained_model = model\n    else:\n        print(\"[PHASE 5] Skipping training (function not found)\")\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Training: {time.time() - phase_start:.2f}s\")\n\n    del train_loader, val_loader, train_dataset, val_dataset, full_dataset\n    _safe_clear_gpu_caches()\n\n    core_model = _get_core_model(trained_model)\n\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 6] Discovery check...\")\n    discovery_success = False\n\n    try:\n        dscd = getattr(core_model, 'dscd', None)\n        if dscd is None:\n            print(\"[PHASE 6] No DSCD module\")\n        else:\n            print(\"[PHASE 6] Running periodic discovery check...\")\n            if hasattr(dscd, 'periodic_discovery_check'):\n                try:\n                    sig = inspect.signature(dscd.periodic_discovery_check)\n                    params = list(sig.parameters.keys())\n                    print(f\"[PHASE 6] periodic_discovery_check params: {params}\")\n\n                    total_steps = int(_EPOCHS * _NUM_SAMPLES // _BATCH_SIZE)\n\n                    if 'cluster_missing' in params:\n                        if len(params) >= 3:\n                            num_discovered = dscd.periodic_discovery_check(total_steps, _PERIODIC_DISCOVERY_FREQUENCY, cluster_missing=False)\n                        elif len(params) >= 2:\n                            num_discovered = dscd.periodic_discovery_check(total_steps, cluster_missing=False)\n                        else:\n                            num_discovered = dscd.periodic_discovery_check(cluster_missing=False)\n                    else:\n                        if len(params) >= 2:\n                            num_discovered = dscd.periodic_discovery_check(total_steps, _PERIODIC_DISCOVERY_FREQUENCY)\n                        elif len(params) >= 1:\n                            num_discovered = dscd.periodic_discovery_check(total_steps)\n                        else:\n                            num_discovered = dscd.periodic_discovery_check()\n\n                    discovery_success = True\n                    print(f\"[PHASE 6] Discovery complete: {num_discovered} homographs found\")\n                except Exception as e:\n                    print(f\"[PHASE 6] periodic_discovery_check failed: {e}\")\n                    try:\n                        if hasattr(dscd, 'discover_homographs'):\n                            num_discovered = dscd.discover_homographs()\n                            discovery_success = True\n                            print(f\"[PHASE 6] Fallback discovery: {num_discovered} homographs\")\n                        else:\n                            print(\"[PHASE 6] discover_homographs not available\")\n                    except Exception as e2:\n                        print(f\"[PHASE 6] Fallback discovery failed: {e2}\")\n            else:\n                print(\"[PHASE 6] periodic_discovery_check not available\")\n                if hasattr(dscd, 'discover_homographs'):\n                    try:\n                        num_discovered = dscd.discover_homographs()\n                        discovery_success = True\n                        print(f\"[PHASE 6] discover_homographs: {num_discovered} homographs\")\n                    except Exception as e:\n                        print(f\"[PHASE 6] discover_homographs failed: {e}\")\n\n            stores = _get_dscd_stores_safe(dscd)\n\n            def _store_size(s):\n                try:\n                    if callable(getattr(s, \"size\", None)):\n                        return int(s.size())\n                    return int(getattr(s, \"size\", 0))\n                except Exception:\n                    return 0\n\n            total_protos = sum(_store_size(store) for store in stores.values())\n            multi_sense = sum(1 for store in stores.values() if _store_size(store) >= 2)\n\n            print(\"[PHASE 6] Discovery state:\")\n            print(f\"  - Tokens: {len(stores)}\")\n            print(f\"  - Prototypes: {total_protos}\")\n            print(f\"  - Multi-sense: {multi_sense}\")\n\n            if len(stores) == 0:\n                print(\"[PHASE 6] WARNING: No prototypes created\")\n            else:\n                discovery_success = True\n    except Exception as e:\n        print(f\"[PHASE 6] Discovery failed: {e}\")\n        if _DEBUG_TIMING:\n            try:\n                traceback.print_exc()\n            except Exception:\n                pass\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Discovery: {time.time() - phase_start:.2f}s\")\n    _safe_clear_gpu_caches()\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 7] DSCD warmup...\")\n    if \"dscd_discovery_warmup\" in globals():\n        try:\n            warmup_samples = min(4000, _DSCD_WARMUP_SAMPLES)\n            print(f\"[PHASE 7] Processing {warmup_samples} warmup samples...\")\n            warmup_start = time.time()\n            dscd_discovery_warmup(trained_model, tokenizer, num_sents=warmup_samples, batch_size=64, max_len=_MAX_LENGTH)\n            warmup_duration = time.time() - warmup_start\n            print(f\"[PHASE 7] Warmup complete ({warmup_samples} samples in {warmup_duration:.1f}s)\")\n        except Exception as e:\n            print(f\"[PHASE 7] Warmup failed: {e}\")\n    else:\n        print(\"[PHASE 7] Skipping warmup (function not found)\")\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Warmup: {time.time() - phase_start:.2f}s\")\n    _safe_clear_gpu_caches()\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 8] Baseline evaluation...\")\n    baseline_metrics = None\n\n    try:\n        dscd_baseline = getattr(core_model, 'dscd', None)\n        has_prototypes = False\n\n        if dscd_baseline:\n            stores = _get_dscd_stores_safe(dscd_baseline)\n            has_prototypes = len(stores) > 0\n\n        if not has_prototypes:\n            print(\"[PHASE 8] Skipping baseline (no prototypes)\")\n        elif \"comprehensive_post_training_testing\" in globals():\n            try:\n                trg = getattr(core_model, 'trg', None)\n                if trg and hasattr(trg, 'reset_statistics'):\n                    trg.reset_statistics()\n            except Exception:\n                pass\n\n            print(\"[PHASE 8] ⚡ Running baseline with DSCD-augmented generation...\")\n            baseline_metrics = comprehensive_post_training_testing(trained_model, tokenizer, run_warmup=False)\n            baseline_success = baseline_metrics.get('success_rate_pct', 0)\n            baseline_expl = baseline_metrics.get('total_explanations', 0)\n            print(f\"[PHASE 8] Baseline: {baseline_success:.1f}% success, {baseline_expl} explanations\")\n        else:\n            print(\"[PHASE 8] Skipping baseline (function not found)\")\n    except Exception as e:\n        print(f\"[PHASE 8] Baseline failed: {e}\")\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Baseline: {time.time() - phase_start:.2f}s\")\n    _safe_clear_gpu_caches()\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 9] Post-training evaluation...\")\n    eval_results: Dict[str, Any] = {}\n\n    if \"comprehensive_post_training_testing\" in globals():\n        try:\n            try:\n                trg = getattr(core_model, 'trg', None)\n                if trg and hasattr(trg, 'reset_statistics'):\n                    trg.reset_statistics()\n            except Exception:\n                pass\n\n            print(\"[PHASE 9] ⚡ Running evaluation with DSCD-augmented generation...\")\n            eval_results = comprehensive_post_training_testing(\n                trained_model,\n                tokenizer,\n                run_warmup=False,\n                compare_baseline=(baseline_metrics is not None),\n                baseline_metrics=baseline_metrics\n            )\n            final_success = eval_results.get('success_rate_pct', 0)\n            final_expl = eval_results.get('total_explanations', 0)\n            print(f\"[PHASE 9] Evaluation: {final_success:.1f}% success, {final_expl} explanations\")\n        except Exception as e:\n            print(f\"[PHASE 9] Evaluation failed: {e}\")\n    else:\n        print(\"[PHASE 9] Skipping evaluation (function not found)\")\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Evaluation: {time.time() - phase_start:.2f}s\")\n    _safe_clear_gpu_caches()\n    if _DEBUG_TIMING:\n        phase_start = time.time()\n\n    print(\"\\n[PHASE 10] Saving checkpoint...\")\n    try:\n        os.makedirs(_CHECKPOINT_DIR, exist_ok=True)\n        was_training = getattr(core_model, \"training\", False)\n        core_model.eval()\n        try:\n            model_state = core_model.state_dict()\n            dscd_state = {}\n\n            if hasattr(core_model, 'dscd'):\n                dscd_save = core_model.dscd\n                if hasattr(dscd_save, 'state_dict'):\n                    lock = None\n                    if hasattr(dscd_save, 'buffer_lock'):\n                        lock = dscd_save.buffer_lock\n                    elif hasattr(dscd_save, 'clustering_lock'):\n                        lock = dscd_save.clustering_lock\n\n                    try:\n                        if lock:\n                            try:\n                                with lock:\n                                    dscd_state = dscd_save.state_dict()\n                            except Exception:\n                                dscd_state = dscd_save.state_dict()\n                        else:\n                            dscd_state = dscd_save.state_dict()\n                    except Exception as e:\n                        print(f\"[PHASE 10] DSCD state_dict failed: {e}\")\n                        dscd_state = {}\n\n            optimizer_state = None\n            if optimizer is not None:\n                try:\n                    optimizer_state = optimizer.state_dict()\n                    if 'state' in optimizer_state:\n                        for param_state in optimizer_state['state'].values():\n                            if isinstance(param_state, dict) and 'momentum_buffer' in param_state:\n                                try:\n                                    del param_state['momentum_buffer']\n                                except Exception:\n                                    pass\n                except Exception:\n                    optimizer_state = None\n\n            checkpoint = {\n                'model_state_dict': model_state,\n                'dscd_state': dscd_state,\n                'optimizer_state_dict': optimizer_state,\n                'training_stats': training_stats,\n                'baseline_metrics': baseline_metrics,\n                'eval_results': eval_results,\n                'discovery_success': discovery_success,\n                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n                'config': {\n                    'epochs': _EPOCHS,\n                    'batch_size': _BATCH_SIZE,\n                    'span_threshold': _SPAN_THRESHOLD,\n                    'uncertainty_threshold': _UNCERTAINTY_THRESHOLD,\n                    'discovery_frequency': _PERIODIC_DISCOVERY_FREQUENCY,\n                    'vocab_size': vocab_size,\n                    'asbn_training_enabled': _ENABLE_ASBN_TRAINING,\n                    'validation_split': _VALIDATION_SPLIT,\n                }\n            }\n            torch.save(checkpoint, _CHECKPOINT_PATH)\n\n            try:\n                import mmap\n                with open(_CHECKPOINT_PATH, 'rb') as f:\n                    with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as m:\n                        size_mb = len(m) / 1024**2\n\n                print(f\"[PHASE 10] Checkpoint saved: {_CHECKPOINT_PATH}\")\n                print(f\"  - Size: {size_mb:.2f} MB\")\n\n                try:\n                    verify_keys = torch.load(_CHECKPOINT_PATH, map_location='cpu', weights_only=False)\n                    has_model = 'model_state_dict' in verify_keys and len(verify_keys['model_state_dict']) > 0\n                    has_dscd = 'dscd_state' in verify_keys and len(verify_keys.get('dscd_state', {})) > 0\n                    print(f\"  - Model: {'OK' if has_model else 'MISSING'}\")\n                    print(f\"  - DSCD: {'OK' if has_dscd else 'MISSING'}\")\n\n                    if has_dscd:\n                        try:\n                            dscd_verify_state = verify_keys.get('dscd_state', {})\n                            num_tokens = 0\n                            if 'prototype_stores' in dscd_verify_state:\n                                num_tokens = len(dscd_verify_state['prototype_stores'])\n                            print(f\"  - DSCD tokens: {num_tokens}\")\n                        except Exception:\n                            print(f\"  - DSCD tokens: unknown\")\n\n                    del verify_keys\n                except Exception as e:\n                    print(f\"[PHASE 10] Checkpoint verification warning: {e}\")\n            except Exception:\n                print(f\"[PHASE 10] Checkpoint saved: {_CHECKPOINT_PATH}\")\n        finally:\n            if was_training:\n                try:\n                    core_model.train()\n                except Exception:\n                    pass\n    except Exception as e:\n        print(f\"[PHASE 10] Checkpoint failed: {e}\")\n        if _DEBUG_TIMING:\n            try:\n                traceback.print_exc()\n            except Exception:\n                pass\n\n    if _DEBUG_TIMING:\n        print(f\"[TIMING] Checkpoint: {time.time() - phase_start:.2f}s\")\n\n    print(\"\\n[PHASE 11] Final validation...\")\n    try:\n        dscd_ok = False\n        if hasattr(core_model, 'dscd'):\n            stores = _get_dscd_stores_safe(core_model.dscd)\n            dscd_ok = len(stores) > 0\n\n        asbn_ok = hasattr(core_model, 'asbn') and hasattr(core_model.asbn, 'forward')\n        trg_ok = hasattr(core_model, 'trg') and hasattr(core_model.trg, 'process_sentence_for_explanations')\n\n        print(f\"[PHASE 11] Component validation:\")\n        print(f\"  - DSCD: {'OK' if dscd_ok else 'MISSING'}\")\n        print(f\"  - ASBN: {'OK' if asbn_ok else 'MISSING'} {'(DISABLED)' if not _ENABLE_ASBN_TRAINING else '(ENABLED)'}\")\n        print(f\"  - TRG: {'OK' if trg_ok else 'MISSING'}\")\n\n        all_ok = dscd_ok and asbn_ok and trg_ok\n        if all_ok:\n            print(\"[PHASE 11] ✅ All components validated\")\n        else:\n            print(\"[PHASE 11] ⚠️  Some components missing\")\n    except Exception as e:\n        print(f\"[PHASE 11] Validation failed: {e}\")\n\n    pipeline_time = time.time() - pipeline_start\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"PIPELINE COMPLETE - FINAL SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"\\n[TIMING]\")\n    print(f\"  Total time: {pipeline_time:.2f}s ({pipeline_time/60:.2f} min)\")\n\n    print(f\"\\n[TRAINING]\")\n    if training_stats:\n        total_loss = training_stats.get('total_loss', [])\n        optimizer_updates = training_stats.get('optimizer_updates', 0)\n        print(f\"  Completed: {optimizer_updates} optimizer updates\")\n        if total_loss:\n            recent_loss = sum(total_loss[-100:]) / len(total_loss[-100:])\n            print(f\"  - Final loss: {recent_loss:.6f}\")\n    else:\n        print(\"  No stats available\")\n\n    print(f\"\\n[DISCOVERY]\")\n    if discovery_success:\n        print(\"  ✅ Success\")\n    else:\n        print(\"  ⚠️  Issues detected\")\n\n    print(f\"\\n[EVALUATION]\")\n    if baseline_metrics and eval_results:\n        baseline_success = baseline_metrics.get('success_rate_pct', 0)\n        final_success = eval_results.get('success_rate_pct', 0)\n        improvement = final_success - baseline_success\n\n        print(f\"  Baseline -> Final: {baseline_success:.1f}% -> {final_success:.1f}%\")\n        print(f\"  Improvement: {improvement:+.1f}%\")\n\n        baseline_dscd_stats = baseline_metrics.get('dscd_stats', {})\n        final_dscd_stats = eval_results.get('dscd_stats', {})\n\n        baseline_dscd = baseline_dscd_stats.get('multi_sense_words', 0) if isinstance(baseline_dscd_stats, dict) else 0\n        final_dscd = final_dscd_stats.get('multi_sense_words', 0) if isinstance(final_dscd_stats, dict) else 0\n\n        if baseline_dscd is not None and final_dscd is not None:\n            print(f\"  DSCD multi-sense: {baseline_dscd} -> {final_dscd}\")\n\n        baseline_asbn_stats = baseline_metrics.get('asbn_stats', {})\n        final_asbn_stats = eval_results.get('asbn_stats', {})\n\n        baseline_asbn = baseline_asbn_stats.get('domain_accuracy', 0) if isinstance(baseline_asbn_stats, dict) else 0\n        final_asbn = final_asbn_stats.get('domain_accuracy', 0) if isinstance(final_asbn_stats, dict) else 0\n\n        if baseline_asbn is not None and final_asbn is not None:\n            print(f\"  ASBN accuracy: {baseline_asbn:.2%} -> {final_asbn:.2%} {'(DISABLED)' if not _ENABLE_ASBN_TRAINING else ''}\")\n    elif eval_results:\n        print(f\"  Success rate: {eval_results.get('success_rate_pct', 0):.1f}%\")\n    else:\n        print(\"  No results\")\n\n    print(f\"\\n[CHECKPOINT]\")\n    if os.path.exists(_CHECKPOINT_PATH):\n        try:\n            size_mb = os.path.getsize(_CHECKPOINT_PATH) / 1024**2\n            print(f\"  Saved: {_CHECKPOINT_PATH}\")\n            print(f\"  - Size: {size_mb:.2f} MB\")\n        except Exception:\n            print(f\"  Saved: {_CHECKPOINT_PATH}\")\n    else:\n        print(\"  Not saved\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Usage: trained_model, tokenizer = main_pipeline()\")\n    print(\"=\" * 80)\n\n    _safe_clear_gpu_caches()\n\n    return trained_model, tokenizer\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 10: Main Pipeline (DUAL-PATH COMPATIBLE)\")\nprint(\"=\" * 80)\nprint(\"Pipeline phases:\")\nprint(\"  1. Environment initialization\")\nprint(\"  2. Tokenizer & data loading (with validation split)\")\nprint(\"  3. Model initialization & validation\")\nprint(\"  4. Optimizer setup\")\nprint(\"  5. Training (with validation dataloader)\")\nprint(\"  6. Discovery check\")\nprint(\"  7. DSCD warmup\")\nprint(\"  8. Baseline evaluation\")\nprint(\"  9. Post-training evaluation\")\nprint(\"  10. Checkpoint saving\")\nprint(\"  11. Final validation\")\nprint()\nprint(f\"Configuration:\")\nprint(f\"  - Epochs: {_EPOCHS}\")\nprint(f\"  - Batch size: {_BATCH_SIZE}\")\nprint(f\"  - Learning rates: NMT={_LR_NMT}, PHI={_LR_PHI}\")\nprint(f\"  - Span threshold: {_SPAN_THRESHOLD}\")\nprint(f\"  - Uncertainty threshold: {_UNCERTAINTY_THRESHOLD}\")\nprint(f\"  - Discovery frequency: {_PERIODIC_DISCOVERY_FREQUENCY}\")\nprint(f\"  - DSCD warmup samples: {_DSCD_WARMUP_SAMPLES}\")\nprint(f\"  - ASBN Training: {'DISABLED' if not _ENABLE_ASBN_TRAINING else 'ENABLED'}\")\nprint(f\"  - Validation split: {_VALIDATION_SPLIT:.1%}\")\nprint(f\"  - Device: {_DEVICE}\")\nprint(\"\\n✅ ALL FIXES APPLIED:\")\nprint(\"  ✅ FIX #1: Validation dataset created (10% split)\")\nprint(\"  ✅ FIX #2: val_loader passed to train_memory_efficient_tatn()\")\nprint(\"  ✅ Real validation data now used during training\")\nprint(\"  ✅ Validation metrics computed from actual validation batches\")\nprint(\"  ✅ Progress bar shows real train/val loss\")\nprint(\"==\" * 80 + \"\\n\")\n","metadata":{"id":"kEux2BVXH4J5","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:05.066690Z","iopub.execute_input":"2026-02-18T08:40:05.066985Z","iopub.status.idle":"2026-02-18T08:40:05.149976Z","shell.execute_reply.started":"2026-02-18T08:40:05.066966Z","shell.execute_reply":"2026-02-18T08:40:05.149468Z"}},"outputs":[{"name":"stdout","text":"✓ Registered safe globals for PyTorch 2.6+\n\n================================================================================\nCell 10: Main Pipeline (DUAL-PATH COMPATIBLE)\n================================================================================\nPipeline phases:\n  1. Environment initialization\n  2. Tokenizer & data loading (with validation split)\n  3. Model initialization & validation\n  4. Optimizer setup\n  5. Training (with validation dataloader)\n  6. Discovery check\n  7. DSCD warmup\n  8. Baseline evaluation\n  9. Post-training evaluation\n  10. Checkpoint saving\n  11. Final validation\n\nConfiguration:\n  - Epochs: 2\n  - Batch size: 4\n  - Learning rates: NMT=5e-05, PHI=0.0001\n  - Span threshold: 0.2\n  - Uncertainty threshold: 0.15\n  - Discovery frequency: 300\n  - DSCD warmup samples: 9000\n  - ASBN Training: ENABLED\n  - Validation split: 10.0%\n  - Device: cuda\n\n✅ ALL FIXES APPLIED:\n  ✅ FIX #1: Validation dataset created (10% split)\n  ✅ FIX #2: val_loader passed to train_memory_efficient_tatn()\n  ✅ Real validation data now used during training\n  ✅ Validation metrics computed from actual validation batches\n  ✅ Progress bar shows real train/val loss\n================================================================================================================================================================\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 11: MAIN EXECUTION WRAPPER (DUAL-PATH COMPATIBLE)\n# ===========================================================================================\nfrom datetime import datetime, timezone\nimport os\nimport traceback\nimport math\nimport sys\nimport time\nimport torch\nimport gc\n\ntry:\n    _NUM_SAMPLES = int(globals().get('NUM_SAMPLES', 30000))\n    _EPOCHS = int(globals().get('EPOCHS', 1))\n    _BATCH_SIZE = int(globals().get('BATCH_SIZE', 4))\n    _ACCUMULATION_STEPS = int(globals().get('ACCUMULATION_STEPS', 16))\n\n    raw_device = globals().get('DEVICE', \"cuda\" if torch.cuda.is_available() else \"cpu\")\n    if isinstance(raw_device, torch.device):\n        _DEVICE = raw_device\n    else:\n        _DEVICE = torch.device(str(raw_device))\n\n    _ENABLE_ASBN_TRAINING = bool(globals().get('ENABLE_ASBN_TRAINING', False))\n    _ENABLE_TRG_INFERENCE = bool(globals().get('ENABLE_TRG_INFERENCE', True))\n    _PERIODIC_DISCOVERY_FREQUENCY = int(globals().get('PERIODIC_DISCOVERY_FREQUENCY', 50))\n    _VERBOSE_LOGGING = bool(globals().get('VERBOSE_LOGGING', False))\n    _DEBUG_DISCOVERY = bool(globals().get('DEBUG_DISCOVERY', False))\n    _DEBUG_TIMING = bool(globals().get('DEBUG_TIMING', False))\n    _NUM_GPUS = int(globals().get('NUM_GPUS', torch.cuda.device_count() if torch.cuda.is_available() else 0))\n    _USE_MULTI_GPU = bool(globals().get('USE_MULTI_GPU', _NUM_GPUS > 1))\n    _SPAN_THRESHOLD = float(globals().get('SPAN_THRESHOLD', 0.20))\n    _UNCERTAINTY_THRESHOLD = float(globals().get('UNCERTAINTY_THRESHOLD', 0.15))\n    _MAX_LENGTH = int(globals().get('MAX_LENGTH', 52))\n    _SOURCE_LANGUAGE = str(globals().get('SOURCE_LANGUAGE', 'bn'))\n    _TARGET_LANGUAGE = str(globals().get('TARGET_LANGUAGE', 'en'))\n\n    raw_list = globals().get('HOMOGRAPH_REFERENCE_LIST_BN', [\"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\", \"ফল\", \"মাথা\"])\n    _HOMOGRAPH_REFERENCE_LIST_BN = set(str(w) for w in raw_list)\n    cell0_loaded = 'NUM_SAMPLES' in globals()\n\nexcept (NameError, TypeError, ValueError) as e:\n    print(f\"[EXEC] Config load error: {e}\")\n    _NUM_SAMPLES = 30000\n    _EPOCHS = 1\n    _BATCH_SIZE = 4\n    _ACCUMULATION_STEPS = 16\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _ENABLE_ASBN_TRAINING = False\n    _ENABLE_TRG_INFERENCE = True\n    _PERIODIC_DISCOVERY_FREQUENCY = 50\n    _VERBOSE_LOGGING = False\n    _DEBUG_DISCOVERY = False\n    _DEBUG_TIMING = False\n    _NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    _USE_MULTI_GPU = (_NUM_GPUS > 1)\n    _SPAN_THRESHOLD = 0.20\n    _UNCERTAINTY_THRESHOLD = 0.15\n    _MAX_LENGTH = 52\n    _SOURCE_LANGUAGE = 'bn'\n    _TARGET_LANGUAGE = 'en'\n    _HOMOGRAPH_REFERENCE_LIST_BN = {\"কল\", \"কাল\", \"পাতা\", \"ব্যাংক\", \"ফল\", \"মাথা\"}\n    cell0_loaded = False\n    print(\"[EXEC] Using fallback configuration (Cell 0 not executed)\")\n\n_CHECKPOINT_PATH = \"/kaggle/working/tatn_final.pt\"\n\n\ndef _safe_div_ceil(a: int, b: int) -> int:\n    try:\n        if isinstance(a, int) and isinstance(b, int) and b > 0:\n            return math.ceil(a / b)\n    except Exception:\n        pass\n    return 0\n\n\ndef _format_duration(seconds: float) -> str:\n    if seconds < 60:\n        return f\"{seconds:.1f}s\"\n    elif seconds < 3600:\n        return f\"{seconds/60:.1f}min\"\n    else:\n        return f\"{seconds/3600:.2f}hr\"\n\n\ndef _safe_get(d: dict, *keys, default=None):\n    if not isinstance(d, dict):\n        return default\n    result = d\n    for key in keys:\n        if not isinstance(result, dict):\n            return default\n        if key not in result:\n            return default\n        result = result[key]\n    return result if result is not None else default\n\n\ndef _get_dscd_homographs(model):\n    try:\n        core = model.module if hasattr(model, 'module') else model\n        dscd = getattr(core, 'dscd', None)\n\n        if dscd and hasattr(dscd, 'get_discovered_homographs'):\n            try:\n                return dscd.get_discovered_homographs()\n            except Exception:\n                pass\n\n        if dscd and hasattr(dscd, 'prototype_stores'):\n            homographs = set()\n\n            lock = None\n            if hasattr(dscd, 'buffer_lock'):\n                lock = dscd.buffer_lock\n            elif hasattr(dscd, 'clustering_lock'):\n                lock = dscd.clustering_lock\n\n            try:\n                if lock:\n                    try:\n                        with lock:\n                            stores = dict(dscd.prototype_stores)\n                    except Exception:\n                        stores = dict(dscd.prototype_stores)\n                else:\n                    stores = dict(dscd.prototype_stores)\n            except Exception:\n                return set()\n\n            for token, store in stores.items():\n                try:\n                    size_ok = False\n                    if hasattr(store, 'size'):\n                        size_attr = getattr(store, 'size')\n                        if callable(size_attr):\n                            try:\n                                size_val = size_attr()\n                                size_ok = int(size_val) >= 1\n                            except Exception:\n                                size_ok = False\n                        elif isinstance(size_attr, int):\n                            size_ok = size_attr >= 1\n\n                    if size_ok:\n                        clean = str(token).replace('▁', '').replace('Ġ', '').replace('##', '').strip().lower()\n                        if clean:\n                            homographs.add(clean)\n                except Exception:\n                    continue\n            return homographs\n    except Exception:\n        pass\n    return set()\n\n\ndef _safe_cleanup():\n    try:\n        if torch.cuda.is_available():\n            for i in range(torch.cuda.device_count()):\n                try:\n                    with torch.cuda.device(i):\n                        torch.cuda.empty_cache()\n                except Exception:\n                    pass\n        if gc.isenabled():\n            gc.collect()\n    except Exception:\n        pass\n\n\nif __name__ == \"__main__\":\n    print(\"=\" * 80)\n    print(\"MEMORY-OPTIMIZED TATN (DUAL-PATH COMPATIBLE)\")\n    print(\"=\" * 80)\n\n    user_login = os.getenv(\"KAGGLE_USERNAME\") or os.getenv(\"USER\") or \"manas0003\"\n    start_time = time.time()\n    now_utc = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n\n    print(f\"User: {user_login}\")\n    print(f\"Started: {now_utc}\")\n\n    print(\"\\n[CONFIGURATION]\")\n    print(f\"  Cell 0 status: {'Loaded' if cell0_loaded else 'Using fallbacks'}\")\n    print(f\"  Samples: {_NUM_SAMPLES}\")\n    print(f\"  Epochs: {_EPOCHS}\")\n    print(f\"  Batch Size: {_BATCH_SIZE}\")\n    print(f\"  Accumulation: {_ACCUMULATION_STEPS}\")\n    print(f\"  Device: {_DEVICE}\")\n    print(f\"  Multi-GPU: {'ENABLED' if _USE_MULTI_GPU else 'DISABLED'} ({_NUM_GPUS} GPUs)\")\n    print(f\"  Source language: {_SOURCE_LANGUAGE}\")\n    print(f\"  Target language: {_TARGET_LANGUAGE}\")\n    print(f\"  Span threshold: {_SPAN_THRESHOLD}\")\n    print(f\"  Uncertainty threshold: {_UNCERTAINTY_THRESHOLD}\")\n    print(f\"  Max length: {_MAX_LENGTH}\")\n    print(f\"  Discovery frequency: {_PERIODIC_DISCOVERY_FREQUENCY}\")\n\n    if _USE_MULTI_GPU and _NUM_GPUS > 0:\n        per_gpu = _safe_div_ceil(_BATCH_SIZE, _NUM_GPUS)\n        print(f\"  Batch per GPU: {per_gpu}\")\n\n    print(f\"  ASBN: {'Enabled' if _ENABLE_ASBN_TRAINING else 'Disabled'}\")\n    print(f\"  TRG: {'Enabled' if _ENABLE_TRG_INFERENCE else 'Disabled'}\")\n    print(f\"  Debug: {'Enabled' if _DEBUG_DISCOVERY else 'Disabled'}\")\n    print(\"=\" * 80)\n\n    trained_model, tokenizer = None, None\n    pipeline_success = False\n    failure_category = None\n    failure_details = \"\"\n\n    if 'main_pipeline' not in globals():\n        print(\"\\nERROR: main_pipeline not found\")\n        print(\"   -> Run Cell 10 before executing Cell 11\")\n        failure_category = \"MISSING_DEPENDENCY\"\n        failure_details = \"Cell 10 not executed\"\n    else:\n        try:\n            print(\"\\nStarting pipeline...\")\n\n            if _DEBUG_TIMING:\n                print(\"   Expected: ~15-45 min (config dependent)\")\n\n            pipeline_start = time.time()\n            trained_model, tokenizer = main_pipeline()\n            pipeline_duration = time.time() - pipeline_start\n\n            print(f\"\\nPipeline completed: {_format_duration(pipeline_duration)}\")\n            pipeline_success = True\n\n        except KeyboardInterrupt:\n            print(\"\\nInterrupted by user\")\n            failure_category = \"USER_INTERRUPT\"\n            failure_details = \"Manual stop\"\n\n        except RuntimeError as e:\n            msg = str(e).lower()\n\n            if \"tokenizer\" in msg or \"sentencepiece\" in msg:\n                print(\"\\nTokenizer error\")\n                failure_category = \"TOKENIZER_ERROR\"\n                failure_details = str(e)[:200]\n\n                print(\"\\nFix:\")\n                print(\"   ! pip install transformers==4.30.2 sentencepiece tokenizers\")\n                print(\"   Then RESTART kernel and re-run Cells 0-11\")\n\n            elif \"out of memory\" in msg:\n                print(\"\\nOut of Memory\")\n                failure_category = \"OOM_ERROR\"\n                failure_details = \"GPU OOM\"\n\n                print(\"\\nFixes:\")\n                print(\"   1. Reduce BATCH_SIZE (try 2-4)\")\n                print(\"   2. Reduce NUM_SAMPLES (try 10k-20k)\")\n                print(\"   3. Increase ACCUMULATION_STEPS (32-64)\")\n\n            else:\n                print(f\"\\nRuntime error: {type(e).__name__}\")\n                print(f\"   {str(e)[:400]}\")\n                failure_category = \"RUNTIME_ERROR\"\n                failure_details = str(e)[:200]\n\n            if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n                print(\"\\n[TRACEBACK]\")\n                try:\n                    traceback.print_exc()\n                except Exception:\n                    pass\n\n        except Exception as e:\n            print(f\"\\nUnexpected error: {type(e).__name__}\")\n            print(f\"   {str(e)[:400]}\")\n            failure_category = \"UNKNOWN_ERROR\"\n            failure_details = str(e)[:200]\n\n            if _VERBOSE_LOGGING or _DEBUG_DISCOVERY:\n                print(\"\\n[TRACEBACK]\")\n                try:\n                    traceback.print_exc()\n                except Exception:\n                    pass\n\n    checkpoint_dict = None\n\n    if pipeline_success and trained_model is not None and tokenizer is not None:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"PIPELINE SUCCEEDED\")\n        print(\"=\" * 80)\n\n        print(\"\\n[CHECKPOINT]\")\n        checkpoint_valid = False\n\n        try:\n            if os.path.exists(_CHECKPOINT_PATH):\n                size_mb = os.path.getsize(_CHECKPOINT_PATH) / (1024**2)\n                print(f\"  File: {_CHECKPOINT_PATH}\")\n                print(f\"  Size: {size_mb:.1f} MB\")\n\n                checkpoint_dict = torch.load(_CHECKPOINT_PATH, map_location='cpu', weights_only=False)\n\n                has_model = 'model_state_dict' in checkpoint_dict and len(checkpoint_dict['model_state_dict']) > 0\n                has_dscd = 'dscd_state' in checkpoint_dict and len(checkpoint_dict.get('dscd_state', {})) > 0\n\n                print(f\"  Model: {'Present' if has_model else 'MISSING'}\")\n                print(f\"  DSCD: {'Present' if has_dscd else 'MISSING'}\")\n\n                if has_dscd:\n                    try:\n                        dscd_state = checkpoint_dict['dscd_state']\n                        num_tokens = 0\n\n                        if 'prototype_stores' in dscd_state:\n                            num_tokens = len(dscd_state['prototype_stores'])\n                        elif 'prototype_stores_data' in dscd_state:\n                            num_tokens = len(dscd_state['prototype_stores_data'])\n\n                        print(f\"  Tokens: {num_tokens}\")\n\n                        if num_tokens > 0:\n                            checkpoint_valid = True\n                            print(\"  Status: VALID\")\n                        else:\n                            print(\"  Status: EMPTY DSCD\")\n                    except Exception as e:\n                        print(f\"  Status: VALIDATION ERROR ({str(e)[:50]})\")\n                else:\n                    print(\"  Status: MISSING DSCD\")\n            else:\n                print(f\"  NOT FOUND: {_CHECKPOINT_PATH}\")\n\n        except Exception as e:\n            print(f\"  Validation failed: {e}\")\n            checkpoint_dict = None\n\n        print(\"\\n[COMPONENTS]\")\n\n        try:\n            core = trained_model.module if hasattr(trained_model, 'module') else trained_model\n\n            dscd = getattr(core, 'dscd', None)\n            if dscd and hasattr(dscd, 'get_prototype_summary'):\n                try:\n                    dscd_stats = dscd.get_prototype_summary()\n                    print(\"  DSCD:\")\n                    print(f\"    - Tokens: {dscd_stats.get('total_tokens', 0)}\")\n                    print(f\"    - Prototypes: {dscd_stats.get('total_prototypes', 0)}\")\n                    print(f\"    - Homographs: {dscd_stats.get('num_homographs', 0)}\")\n                except Exception:\n                    pass\n\n            asbn = getattr(core, 'asbn', None)\n            if asbn and hasattr(asbn, 'get_detailed_stats'):\n                try:\n                    asbn_stats = asbn.get_detailed_stats()\n                    print(\"  ASBN:\")\n                    print(f\"    - Domain accuracy: {asbn_stats.get('domain_accuracy', 0):.2%} {'(DISABLED)' if not _ENABLE_ASBN_TRAINING else ''}\")\n                    if 'source_accuracy' in asbn_stats:\n                        print(f\"    - Source: {asbn_stats['source_accuracy']:.2%}\")\n                        print(f\"    - Target: {asbn_stats['target_accuracy']:.2%}\")\n                except Exception:\n                    pass\n\n            trg = getattr(core, 'trg', None)\n            if trg and hasattr(trg, 'get_statistics'):\n                try:\n                    trg_stats = trg.get_statistics()\n                    print(\"  TRG:\")\n                    print(f\"    - Explanations: {trg_stats.get('explanations_generated', 0)}\")\n                    print(f\"    - High confidence: {trg_stats.get('high_confidence_rate', 0):.1%}\")\n                    print(f\"    - DSCD homograph rate: {trg_stats.get('dscd_homograph_rate', 0):.1%}\")\n                except Exception:\n                    pass\n\n        except Exception as e:\n            print(f\"  Stats failed: {e}\")\n\n        print(\"\\n[METRICS]\")\n\n        try:\n            if checkpoint_dict is not None:\n                training_stats = checkpoint_dict.get('training_stats', {})\n                if training_stats:\n                    total_loss = training_stats.get('total_loss', [])\n                    updates = training_stats.get('optimizer_updates', 0)\n\n                    print(\"  Training:\")\n                    print(f\"    - Updates: {updates}\")\n                    if total_loss:\n                        if len(total_loss) >= 100:\n                            final = sum(total_loss[-100:]) / len(total_loss[-100:])\n                        else:\n                            final = sum(total_loss) / len(total_loss)\n                        print(f\"    - Final loss: {final:.6f}\")\n\n                eval_results = checkpoint_dict.get('eval_results', {})\n                baseline = checkpoint_dict.get('baseline_metrics', {})\n\n                if eval_results:\n                    final_success = eval_results.get('success_rate_pct', 0)\n                    total_expl = eval_results.get('total_explanations', 0)\n\n                    print(\"  Evaluation:\")\n                    if baseline:\n                        baseline_success = baseline.get('success_rate_pct', 0)\n                        improvement = final_success - baseline_success\n                        print(f\"    - Baseline -> Final: {baseline_success:.1f}% -> {final_success:.1f}%\")\n                        print(f\"    - Improvement: {improvement:+.1f}%\")\n                    else:\n                        print(f\"    - Success: {final_success:.1f}%\")\n\n                    print(f\"    - Explanations: {total_expl}\")\n\n                    quality = eval_results.get('quality_metrics', {})\n                    if quality:\n                        print(f\"    - Avg confidence: {quality.get('avg_confidence', 0):.3f}\")\n            elif os.path.exists(_CHECKPOINT_PATH):\n                print(\"  Checkpoint loaded but invalid format\")\n            else:\n                print(\"  No checkpoint available\")\n\n        except Exception as e:\n            print(f\"  Metrics failed: {e}\")\n\n        del checkpoint_dict\n        _safe_cleanup()\n\n        print(\"\\n[INFERENCE VALIDATION]\")\n        print(\"Testing disambiguation on ambiguous sentences...\")\n        print(\"-\" * 80)\n\n        inference_success = 0\n        inference_failed = 0\n        dscd_homographs_detected = set()\n        inference_times = []\n\n        dscd_homographs = _get_dscd_homographs(trained_model)\n        print(f\"DSCD discovered: {len(dscd_homographs)} homographs\")\n        if dscd_homographs and _DEBUG_DISCOVERY:\n            print(f\"  Sample: {list(dscd_homographs)[:10]}\")\n\n        test_sentences = [\n            (\"আমি কল বন্ধ করেছি।\", \"কল (tap/call)\"),\n            (\"কাল আমি বই কিনব।\", \"কাল (tomorrow/yesterday)\"),\n            (\"পাতা ঝরে পড়েছে।\", \"পাতা (leaf/page)\"),\n        ]\n\n        try:\n            if 'translate_with_explanations' not in globals():\n                print(\"translate_with_explanations not available\")\n                print(\"   -> Run Cell 8 before Cell 11\")\n            else:\n                for idx, (sentence, desc) in enumerate(test_sentences, 1):\n                    try:\n                        print(f\"\\n{idx}.  {desc}\")\n                        print(f\"   Input: {sentence}\")\n\n                        inf_start = time.time()\n\n                        res = translate_with_explanations(\n                            trained_model,\n                            tokenizer,\n                            sentence,\n                            source_lang=_SOURCE_LANGUAGE,\n                            target_lang=_TARGET_LANGUAGE,\n                            device=_DEVICE,\n                            max_length=_MAX_LENGTH,\n                            span_threshold=_SPAN_THRESHOLD,\n                            uncertainty_threshold=_UNCERTAINTY_THRESHOLD,\n                            track_stats=True\n                        )\n\n                        inf_time = time.time() - inf_start\n                        inference_times.append(inf_time)\n\n                        if isinstance(res, dict):\n                            translation = res.get('translation', 'N/A')\n                            amb_count = res.get('ambiguous_words_detected', 0)\n                            exs = res.get('explanations', []) or []\n\n                            print(f\"   Translation: {translation}\")\n                            print(f\"   Ambiguous: {amb_count}\")\n                            print(f\"   Time: {inf_time:.3f}s\")\n\n                            if exs:\n                                for exp in exs:\n                                    word = exp.get('ambiguous_word', exp.get('token', 'N/A'))\n                                    clean = str(word).replace('▁', '').replace('Ġ', '').strip().lower()\n\n                                    if clean in dscd_homographs:\n                                        dscd_homographs_detected.add(clean)\n\n                                    try:\n                                        conf = float(exp.get('confidence', 0.5))\n                                        span = float(exp.get('span', 0.0))\n                                        u = float(exp.get('uncertainty', 0.0))\n                                        print(f\"   -> '{word}': conf={conf:.3f}, s={span:.3f}, u={u:.3f}\")\n                                    except Exception:\n                                        print(f\"   -> '{word}': (no metrics)\")\n\n                                inference_success += 1\n                            else:\n                                print(\"   No explanations\")\n                                inference_success += 1\n                        else:\n                            print(\"   Unexpected format\")\n                            inference_failed += 1\n\n                        _safe_cleanup()\n\n                    except Exception as e:\n                        print(f\"   Failed: {type(e).__name__} - {str(e)[:100]}\")\n                        inference_failed += 1\n                        if _DEBUG_DISCOVERY:\n                            try:\n                                traceback.print_exc()\n                            except Exception:\n                                pass\n\n                print(\"\\n\" + \"-\" * 80)\n                print(f\"Results: {inference_success}/{len(test_sentences)} successful\")\n\n                if inference_times:\n                    avg_time = sum(inference_times) / len(inference_times)\n                    print(f\"Performance: {avg_time:.3f}s avg per sentence\")\n\n                if dscd_homographs_detected:\n                    print(f\"DSCD homographs detected: {', '.join(sorted(dscd_homographs_detected))}\")\n                else:\n                    print(\"No DSCD homographs detected\")\n                    if len(dscd_homographs) == 0:\n                        print(\"   -> DSCD has no discoveries (run warmup)\")\n                    else:\n                        print(f\"   -> Check TRG thresholds (span={_SPAN_THRESHOLD}, u={_UNCERTAINTY_THRESHOLD})\")\n\n                if 'INFERENCE_STATS' in globals():\n                    try:\n                        print(\"\\n\" + \"-\" * 80)\n                        print(\"AGGREGATED STATISTICS (from Cell 8):\")\n                        print(\"-\" * 80)\n                        INFERENCE_STATS.print_summary()\n                    except Exception as e:\n                        if _DEBUG_DISCOVERY:\n                            print(f\"Failed to print INFERENCE_STATS: {e}\")\n                else:\n                    if _DEBUG_DISCOVERY:\n                        print(\"\\nINFERENCE_STATS not available (Cell 8 not loaded)\")\n\n        except Exception as e:\n            print(f\"Validation failed: {e}\")\n            if _DEBUG_DISCOVERY:\n                try:\n                    traceback.print_exc()\n                except Exception:\n                    pass\n\n        print(\"\\n[SYSTEM TEST]\")\n\n        try:\n            core = trained_model.module if hasattr(trained_model, 'module') else trained_model\n\n            dscd_ok = hasattr(core, 'dscd') and hasattr(core.dscd, 'forward')\n            asbn_ok = hasattr(core, 'asbn') and hasattr(core.asbn, 'forward')\n            trg_ok = hasattr(core, 'trg') and hasattr(core.trg, 'process_sentence_for_explanations')\n            mbart_ok = hasattr(core, 'mbart') and hasattr(core.mbart, 'generate')\n\n            print(\"  Component status:\")\n            print(f\"    - DSCD: {'OK' if dscd_ok else 'MISSING'}\")\n            print(f\"    - ASBN: {'OK' if asbn_ok else 'MISSING'} {'(DISABLED)' if not _ENABLE_ASBN_TRAINING else ''}\")\n            print(f\"    - TRG: {'OK' if trg_ok else 'MISSING'}\")\n            print(f\"    - M2M100: {'OK' if mbart_ok else 'MISSING'}\")\n\n            all_ok = dscd_ok and asbn_ok and trg_ok and mbart_ok\n\n            if all_ok:\n                print(\"  All components operational\")\n            else:\n                print(\"  Some components missing\")\n\n        except Exception as e:\n            print(f\"  Test failed: {e}\")\n\n        print(\"\\n\" + \"=\" * 80)\n        print(\"NEXT STEPS\")\n        print(\"=\" * 80)\n\n        print(\"\\n1. Single translation:\")\n        print(f\"   result = translate_with_explanations(trained_model, tokenizer, 'আমি কল বন্ধ করেছি।', source_lang='{_SOURCE_LANGUAGE}', target_lang='{_TARGET_LANGUAGE}', device=_DEVICE, max_length={_MAX_LENGTH})\")\n\n        print(\"\\n2. Batch translation:\")\n        print(\"   for sent in sentences:\")\n        print(f\"       res = translate_with_explanations(trained_model, tokenizer, sent, source_lang='{_SOURCE_LANGUAGE}', target_lang='{_TARGET_LANGUAGE}', device=_DEVICE, max_length={_MAX_LENGTH})\")\n\n        print(\"\\n3. Load checkpoint:\")\n        print(\"   ckpt = torch.load('/kaggle/working/tatn_final.pt', weights_only=False)\")\n        print(\"   model.load_state_dict(ckpt['model_state_dict'])\")\n        print(\"   model.dscd.load_state_dict(ckpt['dscd_state'])\")\n\n        print(\"\\n4. Full evaluation:\")\n        print(\"   results = comprehensive_post_training_testing(trained_model, tokenizer)\")\n\n        print(\"\\n5. Demo:\")\n        print(\"   demonstrate_system(trained_model, tokenizer)\")\n\n        if not checkpoint_valid:\n            print(\"\\nCheckpoint needs verification - re-run Cell 10 if needed\")\n\n        print(\"\\n\" + \"=\" * 80)\n\n    else:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"PIPELINE FAILED\")\n        print(\"=\" * 80)\n\n        print(f\"\\nCategory: {failure_category or 'UNKNOWN'}\")\n        if failure_details:\n            print(f\"Details: {failure_details[:200]}\")\n\n        print(\"\\n[DIAGNOSTICS]\")\n\n        components = {\n            'Cell 0': 'NUM_SAMPLES' in globals(),\n            'Cell 1': 'reconstruct_word_spans' in globals(),\n            'Cell 2': 'MemoryEfficientDataset' in globals(),\n            'Cell 3': 'MemoryEfficientDSCDOnline' in globals(),\n            'Cell 4': 'MemoryEfficientASBNModule' in globals(),\n            'Cell 5': 'CompleteTRGWithExplanations' in globals(),\n            'Cell 6': 'MemoryOptimizedTATNWithExplanations' in globals(),\n            'Cell 7': 'train_memory_efficient_tatn' in globals(),\n            'Cell 8': 'translate_with_explanations' in globals(),\n            'Cell 9': 'comprehensive_post_training_testing' in globals(),\n            'Cell 10': 'main_pipeline' in globals(),\n        }\n\n        all_present = True\n        for comp, present in components.items():\n            status = \"OK\" if present else \"MISSING\"\n            print(f\"  {status} {comp}\")\n            if not present:\n                all_present = False\n\n        print(\"\\n[RECOVERY]\")\n\n        if failure_category == \"MISSING_DEPENDENCY\":\n            print(\"\\n-> Run Cells 0-10 in sequence, then re-run Cell 11\")\n\n        elif failure_category == \"TOKENIZER_ERROR\":\n            print(\"\\n-> Install dependencies:\")\n            print(\"  ! pip install transformers==4.30.2 sentencepiece tokenizers\")\n            print(\"  Then RESTART kernel and re-run Cells 0-11\")\n\n        elif failure_category == \"OOM_ERROR\":\n            print(\"\\n-> Reduce memory in Cell 0:\")\n            print(\"  BATCH_SIZE = 2\")\n            print(\"  NUM_SAMPLES = 15000\")\n            print(\"  ACCUMULATION_STEPS = 32\")\n            print(\"  Then re-run Cells 0-11\")\n\n        elif failure_category == \"RUNTIME_ERROR\":\n            print(\"\\n-> Enable debug in Cell 0:\")\n            print(\"  VERBOSE_LOGGING = True\")\n            print(\"  DEBUG_DISCOVERY = True\")\n            print(\"  Then re-run Cell 11 for details\")\n\n        elif failure_category == \"USER_INTERRUPT\":\n            print(\"\\n-> Check checkpoint exists:\")\n            print(f\"  os.path.exists('{_CHECKPOINT_PATH}')\")\n            print(\"  If yes, can load and skip training\")\n            print(\"  If no, re-run Cell 11\")\n\n        else:\n            print(\"\\n-> General steps:\")\n            print(\"  1. Enable DEBUG in Cell 0\")\n            print(\"  2. Re-run Cells 0-11\")\n            print(\"  3. Check GPU: torch.cuda.is_available()\")\n            print(\"  4. Verify data loaded\")\n\n        print(\"\\n\" + \"=\" * 80)\n\n    total_duration = time.time() - start_time\n    end_utc = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"EXECUTION SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"User: {user_login}\")\n    print(f\"Started: {now_utc}\")\n    print(f\"Finished: {end_utc}\")\n    print(f\"Duration: {_format_duration(total_duration)}\")\n\n    if pipeline_success:\n        print(\"Status: SUCCESS\")\n        if 'checkpoint_valid' in locals() and checkpoint_valid:\n            print(\"Checkpoint: VALID\")\n        else:\n            print(\"Checkpoint: CHECK NEEDED\")\n    else:\n        print(f\"Status: FAILED ({failure_category or 'UNKNOWN'})\")\n\n    print(\"=\" * 80)\n\n    _safe_cleanup()\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Cell 11: Execution Wrapper (DUAL-PATH COMPATIBLE)\")\nprint(\"=\" * 80)\nprint(\"This cell:\")\nprint(\"  - Loads configuration from Cell 0\")\nprint(\"  - Executes main_pipeline() from Cell 10\")\nprint(\"  - Validates checkpoint integrity\")\nprint(\"  - Tests inference with sample sentences\")\nprint(\"  - Provides comprehensive diagnostics\")\nprint(\"  - Shows usage examples for next steps\")\nprint()\nprint(f\"Current config:\")\nprint(f\"  - Samples: {_NUM_SAMPLES}\")\nprint(f\"  - Epochs: {_EPOCHS}\")\nprint(f\"  - Batch size: {_BATCH_SIZE}\")\nprint(f\"  - Device: {_DEVICE}\")\nprint(f\"  - Multi-GPU: {_USE_MULTI_GPU}\")\nprint(f\"  - ASBN Training: {'DISABLED' if not _ENABLE_ASBN_TRAINING else 'ENABLED'}\")\nprint(f\"  - Discovery Frequency: {_PERIODIC_DISCOVERY_FREQUENCY}\")\nprint(\"\\n✅ DUAL-PATH COMPATIBILITY:\")\nprint(\"  ✅ Uses Cell 8 translate_with_explanations() (already fixed)\")\nprint(\"  ✅ Uses Cell 10 main_pipeline() (already fixed)\")\nprint(\"  ✅ No direct model.forward() calls\")\nprint(\"  ✅ Only inspection functions (no API changes)\")\nprint(\"  ✅ Fully compatible with dual-path system\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"id":"9n4Hrn1wH4J6","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T08:40:05.150771Z","iopub.execute_input":"2026-02-18T08:40:05.150965Z","iopub.status.idle":"2026-02-18T09:34:16.967028Z","shell.execute_reply.started":"2026-02-18T08:40:05.150948Z","shell.execute_reply":"2026-02-18T09:34:16.966397Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nMEMORY-OPTIMIZED TATN (DUAL-PATH COMPATIBLE)\n================================================================================\nUser: manas0003\nStarted: 2026-02-18 08:40:05 UTC\n\n[CONFIGURATION]\n  Cell 0 status: Loaded\n  Samples: 100000\n  Epochs: 2\n  Batch Size: 4\n  Accumulation: 4\n  Device: cuda\n  Multi-GPU: DISABLED (1 GPUs)\n  Source language: bn_IN\n  Target language: en_XX\n  Span threshold: 0.2\n  Uncertainty threshold: 0.15\n  Max length: 256\n  Discovery frequency: 300\n  ASBN: Enabled\n  TRG: Enabled\n  Debug: Disabled\n================================================================================\n\nStarting pipeline...\n   Expected: ~15-45 min (config dependent)\n\n================================================================================\nTATN MAIN PIPELINE (DUAL-PATH COMPATIBLE)\n================================================================================\nConfiguration:\n  - Span threshold: 0.2\n  - Uncertainty threshold: 0.15\n  - Discovery frequency: 300\n  - ASBN Training: ENABLED\n  - Epochs: 2\n  - Batch size: 4\n  - Validation split: 10.0%\n================================================================================\n[PIPELINE] Initializing environment...\n[PIPELINE] GPUs: 2\n  GPU 0: Tesla T4 (14.6 GB)\n  GPU 1: Tesla T4 (14.6 GB)\n[TIMING] Initialization: 0.57s\n\n[PHASE 1] Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ef514b42a3493b8d2f5d0390093536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f8f581411d498895824c4df1130865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e8a090045f44fd695421f37a8544cc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6906219ff6a48f0999a1c6d2506dd3b"}},"metadata":{}},{"name":"stdout","text":"[PHASE 1] Tokenizer loaded (vocab: 250054)\n[PHASE 1] Validating tokenizer vocabulary...\n[TOKENIZER-VALIDATION] Actual vocab size: 250054\n[TOKENIZER-VALIDATION] Language tokens:\n  __bn_IN__ → 3\n  __en_XX__ → 3\n[TOKENIZER-VALIDATION] ⚠️  Language token IDs differ from Cell 0:\n  Expected: bn=250028, en=250004\n  Got: bn=3, en=3\n  → Update Cell 0 with correct values\n[TOKENIZER-VALIDATION] ✅ Language tokens valid\n[TIMING] Tokenizer: 3.45s\n\n[PHASE 2] Loading data (100000 samples)...\n[CELL2] Loading up to 100000 samples from local CSV: /kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\n[CELL2] Reading CSV file...\n[CELL2] Detected src=English, tgt=Bengali: Swapping columns for bn→en task.\n[CELL2] Swap successful: src=Bengali, tgt=English\n[CELL2] Processing 100000 rows from CSV...\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 100000/100000 [00:02<00:00, 41726.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"[CELL2] Loaded 100000 pairs from CSV, skipped 0 rows\n[CELL2] Dataset vocab size: 250054\n[CELL2] Dataset initialized: 100000 valid pairs, 0 invalid, split=train\n","output_type":"stream"},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"name":"stdout","text":"[PHASE 2] Splitting dataset: train=90000, val=10000\n[CELL2] DataLoader created (train): batch_size=4, workers=0, pin_memory=False\n[CELL2] DataLoader created (train): batch_size=4, workers=0, pin_memory=False\n[PHASE 2] Train: 90000 samples, 22500 batches\n[PHASE 2] Val: 10000 samples, 2500 batches\n[TIMING] Data loading: 4.56s\n\n[PHASE 3] Initializing model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77cd9c461f944a94a1014c43dc7e8329"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf449b4c365f42bb893f287366d3cb2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6f5ba1bb92342f1ae58369f0360d42c"}},"metadata":{}},{"name":"stdout","text":"[TATN-INIT] ✅ Vocab sizes match: 250054\n\n[VALIDATION] Checking component compatibility...\n  ✅ Vocabulary: 250054\n  ✅ Model embed_dim: 1024\n  ✅ DSCD embed_dim: 1024\n  ✅ ASBN embed_dim: 1024\n  ✅ Embedding layer: dim=1024, vocab=250054\n[VALIDATION] ✅ All components compatible\n\n[VALIDATION] Checking dataset compatibility...\n  Input IDs range: [2, 250028]\n  Model vocab size: 250054\n[VALIDATION] ✅ Dataset token IDs valid\n\n[VALIDATION] Testing model forward pass...\n  [TEST 1] Testing forward pass (inference mode)...\n  ✅ Forward pass successful (dict output)\n  Keys: ['encoder_outputs', 'dscd_outputs', 'sense_augmented_embeddings', 'explanations', 'asbn_loss', 'domain_loss', 'domain_accuracy', 'ambiguity_signals']\n\n  [TEST 2] Validating DSCD-augmented generation capability...\n    ✅ DSCD embeddings: shape=torch.Size([1, 256, 1024])\n    ✅ BaseModelOutput created successfully\n\n  [TEST 3] Testing generate() with DSCD-augmented embeddings...\n    ✅ Generation successful: 'I've got to get out of here.'\n    ✅ DSCD-AUGMENTED GENERATION WORKING!\n\n[VALIDATION] ✅ Model forward pass and generation validated\n[PHASE 3] Model initialized and validated\n[TIMING] Model init: 19.85s\n\n[PHASE 4] Setting up optimizers...\n[PHASE 4] ASBN optimizer created (18 params)\n[PHASE 4] Optimizers ready\n\n[PHASE 5] Training...\n  - ASBN Training: ENABLED\n  - ASBN Optimizer: Active\n  - Validation: 2500 batches\n[TRAIN] Starting training: epochs=2, batch=4, accum_steps=4\n[TRAIN] Validation: enabled\n[TRAIN] Validation dataloader: 2500 batches\n[TRAIN] DP enabled: False, GPUs: 1, Device: cuda\n[TRAIN] Discovery frequency: 300 steps\n[TRAIN] Dual-path training: ENABLED\n[TRAIN] Checkpoints:\n  - Final: /kaggle/working/tatn_final.pt\n  - Best:  /kaggle/working/tatn_best.pt (based on validation loss)\n\n[TRAIN] ✅ Validation-based LR scheduler created:\n[TRAIN]    - Type: ReduceLROnPlateau\n[TRAIN]    - Mode: Minimize validation loss\n[TRAIN]    - Factor: 0.5 (halves LR on plateau)\n[TRAIN]    - Patience: 2 validations\n[TRAIN]    - Min LR: 1e-6\n[TRAIN]    - Initial LR: 5.00e-05\n\n[TRAIN] ✅ Early stopping enabled:\n[TRAIN]    - Patience: 3 validations without improvement\n\n[TRAIN] ✅ Best checkpoint saving enabled:\n[TRAIN]    - Path: /kaggle/working/tatn_best.pt\n\n\n================================================================================\nEPOCH 1/2 STARTED\n================================================================================\n\n[TRAIN] TRG statistics reset for epoch 1\n[TRAIN] ASBN statistics reset for epoch 1\nEpoch 1/2:   1%| | 298/22500 [01:41<2:31:05,  2.45it/s, train_loss=1.9532, val_loss=0.0000, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=2\n[DISCOVERY] Running periodic check at step 300...\nEpoch 1/2:   2%| | 398/22500 [02:18<2:25:55,  2.52it/s, train_loss=1.9649, val_loss=0.0000, rate=100.0%, disc=202, lr=5.0e-05, patience=0/3, path[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=400 loss=3.6811 clusters=3313\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     করে            42          5         0.004416       0.005469    \n2     হয়            42          5         0.007512       0.006451    \n3     এবং            42          4         0.001437       0.002349    \n4     জন্য           42          4         0.004193       0.004193    \n5     করা            41          4         0.004167       0.004258    \n------------------------------------------------------------------------------------------\nEpoch 1/2:   2%| | 498/22500 [02:54<2:26:05,  2.51it/s, train_loss=1.9347, val_loss=0.0000, rate=100.0%, disc=102, lr=5.0e-05, patience=0/3, path\n================================================================================\nLOSS SUMMARY AT STEP 500\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0084\n  - Backward Loss: 0.4875\n  - Total Batches: 250\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  4.0010\n  - Backward Loss: 0.4875\n  - Total Batches: 250\n\nCOMBINED:\n  - Total Batches: 500\n  - Optimizer Updates: 125\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 500)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.8185\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.7236 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 152])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 24.27 (from 79 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is unbelievable.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: it was then that he was arrested.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: there have been several incidents in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: best player of the year : january 2015\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 4 prototypes (counts=[15, 6, 6, 1])\n  ✗ রস - NOT FOUND\n  ✗ মারা - NOT FOUND\n  ✗ অর্থ - NOT FOUND\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✗ উত্তর - NOT FOUND\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✗ অংশ - NOT FOUND\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✗ ধরা - NOT FOUND\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✗ দাবি - NOT FOUND\n  ✗ সাড়া - NOT FOUND\n  ✗ দেখা - NOT FOUND\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✗ নাম - NOT FOUND\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 3938\n  - Total prototypes: 296\n  - Multi-sense tokens: 55\n  - Reference found: 1/42\n  - Quality Score: 1.99%\n================================================================================\n  - Quality Score: 2.0%\n  - Multi-sense tokens: 55\n  - Total prototypes: 296\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.7236\n  - BLEU Score: 24.27\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 2.0%\n  - Multi-sense tokens: 55\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n\n[BEST] Val: 3.7236, BLEU: 24.27\n\n[CHECKPOINT] ✅ Saved best model\n\nEpoch 1/2:   3%| | 598/22500 [09:58<2:31:57,  2.40it/s, train_loss=1.9606, val_loss=3.7236, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=2\n[DISCOVERY] Running periodic check at step 600...\nEpoch 1/2:   4%| | 798/22500 [11:11<2:28:55,  2.43it/s, train_loss=1.8388, val_loss=3.7236, rate=100.0%, disc=102, lr=5.0e-05, patience=0/3, path[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=800 loss=3.7434 clusters=5690\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     করে            42          5         0.004134       0.005019    \n2     হয়            42          5         0.006193       0.004042    \n3     তিনি           42          5         0.003803       0.004060    \n4     কিন্তু         42          5         0.001684       0.001944    \n5     আমি            41          4         0.000485       0.000593    \n------------------------------------------------------------------------------------------\nEpoch 1/2:   4%| | 898/22500 [11:48<2:39:36,  2.26it/s, train_loss=1.8846, val_loss=3.7236, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=2\n[DISCOVERY] Running periodic check at step 900...\nEpoch 1/2:   4%| | 998/22500 [12:25<2:30:18,  2.38it/s, train_loss=1.8882, val_loss=3.7236, rate=100.0%, disc=202, lr=5.0e-05, patience=0/3, path\n================================================================================\nLOSS SUMMARY AT STEP 1000\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0097\n  - Backward Loss: 0.4788\n  - Total Batches: 500\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.9103\n  - Backward Loss: 0.4788\n  - Total Batches: 500\n\nCOMBINED:\n  - Total Batches: 1000\n  - Optimizer Updates: 250\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 1000)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.7711\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.6368 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 16])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 17.29 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is an unbelievable cripple.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , it became a crime.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: the city has already had a lot of troubles.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: the meeting was held on kachmani.\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: premier league player of the month : september 2018\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 5 prototypes (counts=[17, 11, 12, 1, 1])\n  ✗ রস - NOT FOUND\n  ✗ মারা - NOT FOUND\n  ✗ অর্থ - NOT FOUND\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✗ উত্তর - NOT FOUND\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✗ অংশ - NOT FOUND\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✗ ধরা - NOT FOUND\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✗ দাবি - NOT FOUND\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 3 prototypes (counts=[5, 5, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 3 prototypes (counts=[5, 12, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 6627\n  - Total prototypes: 708\n  - Multi-sense tokens: 124\n  - Reference found: 3/42\n  - Quality Score: 5.03%\n================================================================================\n  - Quality Score: 5.0%\n  - Multi-sense tokens: 124\n  - Total prototypes: 708\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.6368\n  - BLEU Score: 17.29\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 5.0%\n  - Multi-sense tokens: 124\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n\n[BEST] Val: 3.6368, BLEU: 17.29\n\n[CHECKPOINT] ✅ Saved best model\n\nEpoch 1/2:   5%| | 1198/22500 [15:07<2:25:41,  2.44it/s, train_loss=1.9503, val_loss=3.6368, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=\n[DISCOVERY] Running periodic check at step 1200...\n[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=1200 loss=3.2742 clusters=7473\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     তাঁর           42          5         0.000957       0.001239    \n2     হয়            42          5         0.004346       0.004661    \n3     তিনি           42          5         0.002989       0.004046    \n4     ছিল            42          5         0.005107       0.005280    \n5     জন্য           42          5         0.005609       0.004742    \n------------------------------------------------------------------------------------------\nEpoch 1/2:   7%| | 1499/22500 [17:00<2:01:17,  2.89it/s, train_loss=1.8895, val_loss=3.6368, rate=100.0%, disc=1, lr=5.0e-05, patience=0/3, path=\n[DISCOVERY] Running periodic check at step 1500...\n\n================================================================================\nLOSS SUMMARY AT STEP 1500\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0109\n  - Backward Loss: 0.4740\n  - Total Batches: 750\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.8003\n  - Backward Loss: 0.4740\n  - Total Batches: 750\n\nCOMBINED:\n  - Total Batches: 1500\n  - Optimizer Updates: 375\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 1500)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.6536\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.5957 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 13])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 24.27 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is unbelievable.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , there was a noise.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: several incidents have occurred in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: hastegal meets kashmir\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: prairie league best player of the month : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 4 prototypes (counts=[5, 19, 14, 1])\n  ✗ রস - NOT FOUND\n  ✗ মারা - NOT FOUND\n  ✗ অর্থ - NOT FOUND\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 3 prototypes (counts=[6, 6, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✗ অংশ - NOT FOUND\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✗ ধরা - NOT FOUND\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✗ দাবি - NOT FOUND\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 4 prototypes (counts=[5, 5, 17, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 4 prototypes (counts=[6, 14, 7, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 8771\n  - Total prototypes: 1138\n  - Multi-sense tokens: 220\n  - Reference found: 4/42\n  - Quality Score: 6.72%\n================================================================================\n  - Quality Score: 6.7%\n  - Multi-sense tokens: 220\n  - Total prototypes: 1138\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.5957\n  - BLEU Score: 24.27\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 6.7%\n  - Multi-sense tokens: 220\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n\n[BEST] Val: 3.5957, BLEU: 24.27\n\n[CHECKPOINT] ✅ Saved best model\n\nEpoch 1/2:   7%| | 1599/22500 [19:09<2:06:57,  2.74it/s, train_loss=1.8897, val_loss=3.5957, rate=100.0%, disc=201, lr=5.0e-05, patience=0/3, pat[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=1600 loss=3.4754 clusters=9141\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     করা            42          5         0.004851       0.004518    \n2     রয়েছে         42          5         0.000000       0.000001    \n3     করে            41          4         0.006933       0.005874    \n4     তাঁর           41          5         0.003599       0.003174    \n5     থেকে           41          5         0.012053       0.006561    \n------------------------------------------------------------------------------------------\nEpoch 1/2:   8%| | 1798/22500 [20:25<2:27:52,  2.33it/s, train_loss=1.8560, val_loss=3.5957, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=\n[DISCOVERY] Running periodic check at step 1800...\nEpoch 1/2:   9%| | 1998/22500 [21:41<2:26:59,  2.32it/s, train_loss=1.8737, val_loss=3.5957, rate=100.0%, disc=102, lr=5.0e-05, patience=0/3, pat\n================================================================================\nLOSS SUMMARY AT STEP 2000\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0109\n  - Backward Loss: 0.4669\n  - Total Batches: 1000\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.7528\n  - Backward Loss: 0.4669\n  - Total Batches: 1000\n\nCOMBINED:\n  - Total Batches: 2000\n  - Optimizer Updates: 500\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 2000)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.5730\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.5585 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 16])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 17.29 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is an impossible one.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , it was nauseous.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: the city has been the scene of several earlier thefts.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: hattgold at meeting with kacmya\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: premier league best player of the month : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 3 prototypes (counts=[26, 11, 1])\n  ✗ রস - NOT FOUND\n  ✓ মারা - 3 prototypes (counts=[7, 14, 1])\n  ✗ অর্থ - NOT FOUND\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 4 prototypes (counts=[10, 6, 6, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✗ অংশ - NOT FOUND\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✗ ধরা - NOT FOUND\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✗ দাবি - NOT FOUND\n  ✓ সাড়া - 3 prototypes (counts=[5, 5, 1])\n  ✓ দেখা - 4 prototypes (counts=[10, 10, 16, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 5 prototypes (counts=[6, 10, 14, 6, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 10622\n  - Total prototypes: 1634\n  - Multi-sense tokens: 310\n  - Reference found: 6/42\n  - Quality Score: 9.74%\n================================================================================\n  - Quality Score: 9.7%\n  - Multi-sense tokens: 310\n  - Total prototypes: 1634\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.5585\n  - BLEU Score: 17.29\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 9.7%\n  - Multi-sense tokens: 310\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n\n[BEST] Val: 3.5585, BLEU: 17.29\n\n[CHECKPOINT] ✅ Saved best model\n\n[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=2000 loss=4.3647 clusters=10622\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     আমি            42          5         0.013931       0.011829    \n2     করা            42          5         0.005724       0.004489    \n3     এবং            42          5         0.005015       0.005398    \n4     করার           42          5         0.005448       0.005113    \n5     তবে            42          5         0.001194       0.001395    \n------------------------------------------------------------------------------------------\nEpoch 1/2:   9%| | 2099/22500 [24:16<2:05:30,  2.71it/s, train_loss=1.8690, val_loss=3.5585, rate=100.0%, disc=1, lr=5.0e-05, patience=0/3, path=\n[DISCOVERY] Running periodic check at step 2100...\nEpoch 1/2:  11%| | 2398/22500 [26:11<2:19:18,  2.40it/s, train_loss=1.8437, val_loss=3.5585, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=\n[DISCOVERY] Running periodic check at step 2400...\n[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=2400 loss=3.0383 clusters=12060\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     এটা            42          5         0.005783       0.005223    \n2     তার            42          5         0.004456       0.004251    \n3     হিসেবে         42          5         0.007118       0.007215    \n4     আমি            41          4         0.010471       0.008328    \n5     অনেক           41          4         0.000000       0.000001    \n------------------------------------------------------------------------------------------\nEpoch 1/2:  11%| | 2499/22500 [26:49<2:02:34,  2.72it/s, train_loss=1.8037, val_loss=3.5585, rate=100.0%, disc=201, lr=5.0e-05, patience=0/3, pat\n================================================================================\nLOSS SUMMARY AT STEP 2500\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0109\n  - Backward Loss: 0.4624\n  - Total Batches: 1250\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.7064\n  - Backward Loss: 0.4624\n  - Total Batches: 1250\n\nCOMBINED:\n  - Total Batches: 2500\n  - Optimizer Updates: 625\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 2500)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.5731\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.5814 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 14])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 24.27 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is surprising.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , it became nuts.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: several cases of fraud have been reported in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: meeting held on kashmir\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: best player of the year : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 4 prototypes (counts=[24, 6, 9, 1])\n  ✗ রস - NOT FOUND\n  ✗ মারা - NOT FOUND\n  ✓ অর্থ - 3 prototypes (counts=[5, 5, 1])\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 4 prototypes (counts=[16, 6, 6, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✓ অংশ - 3 prototypes (counts=[12, 15, 1])\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✗ ধরা - NOT FOUND\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✓ দাবি - 3 prototypes (counts=[13, 6, 1])\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 4 prototypes (counts=[9, 16, 10, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 5 prototypes (counts=[11, 8, 11, 10, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 12403\n  - Total prototypes: 2030\n  - Multi-sense tokens: 400\n  - Reference found: 7/42\n  - Quality Score: 11.29%\n================================================================================\n  - Quality Score: 11.3%\n  - Multi-sense tokens: 400\n  - Total prototypes: 2030\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.5814\n  - BLEU Score: 24.27\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 11.3%\n  - Multi-sense tokens: 400\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\nEpoch 1/2:  12%| | 2698/22500 [31:44<2:19:03,  2.37it/s, train_loss=1.7690, val_loss=3.5814, rate=100.0%, disc=2, lr=5.0e-05, patience=1/3, path=\n[DISCOVERY] Running periodic check at step 2700...\nEpoch 1/2:  12%| | 2799/22500 [32:22<1:58:02,  2.78it/s, train_loss=1.8333, val_loss=3.5814, rate=100.0%, disc=201, lr=5.0e-05, patience=1/3, pat[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=2800 loss=3.9281 clusters=13436\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     আমি            42          5         0.009488       0.005913    \n2     অনেক           42          5         0.000000       0.000001    \n3     থেকে           42          5         0.003467       0.004685    \n4     করা            42          5         0.007410       0.006537    \n5     তিনি           42          4         0.006511       0.004961    \n------------------------------------------------------------------------------------------\nEpoch 1/2:  13%|▏| 2998/22500 [33:37<2:25:51,  2.23it/s, train_loss=1.8028, val_loss=3.5814, rate=100.0%, disc=2, lr=5.0e-05, patience=1/3, path=\n[DISCOVERY] Running periodic check at step 3000...\n\n================================================================================\nLOSS SUMMARY AT STEP 3000\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0109\n  - Backward Loss: 0.4578\n  - Total Batches: 1500\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.6698\n  - Backward Loss: 0.4578\n  - Total Batches: 1500\n\nCOMBINED:\n  - Total Batches: 3000\n  - Optimizer Updates: 750\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 3000)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.5975\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.4974 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 14])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 24.27 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is impossible.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , he got nauseous.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: several robberies have been reported in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: meeting on kashmir\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: premier league player of the month : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 4 prototypes (counts=[25, 6, 9, 1])\n  ✗ রস - NOT FOUND\n  ✓ মারা - 3 prototypes (counts=[19, 14, 1])\n  ✓ অর্থ - 4 prototypes (counts=[5, 5, 7, 1])\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 4 prototypes (counts=[18, 6, 6, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✓ অংশ - 5 prototypes (counts=[14, 7, 7, 12, 1])\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✓ ধরা - 3 prototypes (counts=[10, 5, 1])\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✓ দাবি - 4 prototypes (counts=[8, 13, 8, 1])\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 5 prototypes (counts=[13, 10, 9, 5, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 5 prototypes (counts=[10, 7, 6, 17, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 13978\n  - Total prototypes: 2510\n  - Multi-sense tokens: 495\n  - Reference found: 9/42\n  - Quality Score: 14.27%\n================================================================================\n  - Quality Score: 14.3%\n  - Multi-sense tokens: 495\n  - Total prototypes: 2510\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.4974\n  - BLEU Score: 24.27\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 14.3%\n  - Multi-sense tokens: 495\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n\n[BEST] Val: 3.4974, BLEU: 24.27\n\n[CHECKPOINT] ✅ Saved best model\n\nEpoch 1/2:  14%|▏| 3198/22500 [36:18<2:15:48,  2.37it/s, train_loss=1.8329, val_loss=3.4974, rate=100.0%, disc=102, lr=5.0e-05, patience=0/3, pat[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=3200 loss=3.3799 clusters=14554\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     আপনি           42          5         0.000000       0.000001    \n2     মনে            42          5         0.005962       0.004937    \n3     আমি            41          4         0.007692       0.006857    \n4     এখানে          41          5         0.000958       0.000959    \n5     অনেক           41          4         0.000000       0.000001    \n------------------------------------------------------------------------------------------\nEpoch 1/2:  15%|▏| 3298/22500 [36:57<2:16:53,  2.34it/s, train_loss=1.8314, val_loss=3.4974, rate=100.0%, disc=2, lr=5.0e-05, patience=0/3, path=\n[DISCOVERY] Running periodic check at step 3300...\nEpoch 1/2:  16%|▏| 3498/22500 [38:13<2:21:19,  2.24it/s, train_loss=1.8350, val_loss=3.4974, rate=100.0%, disc=102, lr=5.0e-05, patience=0/3, pat\n================================================================================\nLOSS SUMMARY AT STEP 3500\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0110\n  - Backward Loss: 0.4613\n  - Total Batches: 1750\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.6654\n  - Backward Loss: 0.4613\n  - Total Batches: 1750\n\nCOMBINED:\n  - Total Batches: 3500\n  - Optimizer Updates: 875\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 3500)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.5867\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.5198 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 15])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 16.52 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is a very interesting one.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , it became a problem.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: there have been several cases of theft in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: crash hits throat\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: premier league's best player : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 4 prototypes (counts=[16, 15, 9, 1])\n  ✗ রস - NOT FOUND\n  ✓ মারা - 4 prototypes (counts=[22, 14, 1, 1])\n  ✓ অর্থ - 4 prototypes (counts=[5, 7, 6, 1])\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✗ মুখ - NOT FOUND\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 5 prototypes (counts=[6, 18, 7, 6, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✓ অংশ - 4 prototypes (counts=[12, 12, 12, 1])\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✓ ধরা - 3 prototypes (counts=[10, 5, 1])\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✓ দাবি - 4 prototypes (counts=[15, 13, 8, 1])\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 4 prototypes (counts=[18, 7, 12, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 4 prototypes (counts=[6, 17, 14, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✗ মান - NOT FOUND\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 15386\n  - Total prototypes: 2986\n  - Multi-sense tokens: 582\n  - Reference found: 9/42\n  - Quality Score: 14.37%\n================================================================================\n  - Quality Score: 14.4%\n  - Multi-sense tokens: 582\n  - Total prototypes: 2986\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.5198\n  - BLEU Score: 16.52\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 14.4%\n  - Multi-sense tokens: 582\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\nEpoch 1/2:  16%|▏| 3599/22500 [40:04<2:04:56,  2.52it/s, train_loss=1.8223, val_loss=3.5198, rate=100.0%, disc=1, lr=5.0e-05, patience=1/3, path=\n[DISCOVERY] Running periodic check at step 3600...\n[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=3600 loss=3.9761 clusters=15707\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     হয়            43          5         0.004934       0.004472    \n2     হয়েছে         42          5         0.010093       0.009243    \n3     তিনি           42          5         0.005038       0.004675    \n4     আমি            41          4         0.009113       0.006648    \n5     এখানে          41          5         0.003031       0.002936    \n------------------------------------------------------------------------------------------\nEpoch 1/2:  17%|▏| 3898/22500 [42:01<2:37:02,  1.97it/s, train_loss=1.7601, val_loss=3.5198, rate=100.0%, disc=2, lr=5.0e-05, patience=1/3, path=\n[DISCOVERY] Running periodic check at step 3900...\nEpoch 1/2:  18%|▏| 3998/22500 [42:40<2:27:24,  2.09it/s, train_loss=1.8703, val_loss=3.5198, rate=100.0%, disc=202, lr=5.0e-05, patience=1/3, pat\n================================================================================\nLOSS SUMMARY AT STEP 4000\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0110\n  - Backward Loss: 0.4559\n  - Total Batches: 2000\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.6579\n  - Backward Loss: 0.4559\n  - Total Batches: 2000\n\nCOMBINED:\n  - Total Batches: 4000\n  - Optimizer Updates: 1000\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 4000)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.5253\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.5118 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 14])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 20.41 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: there is one outstanding writer.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: after that , it got nasty.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: there has been a lot of crime in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: talks with kashmir\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: premier league's best player : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 4 prototypes (counts=[25, 7, 1, 1])\n  ✗ রস - NOT FOUND\n  ✓ মারা - 4 prototypes (counts=[8, 6, 23, 1])\n  ✓ অর্থ - 5 prototypes (counts=[6, 6, 13, 1, 1])\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✓ মুখ - 3 prototypes (counts=[7, 6, 1])\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 3 prototypes (counts=[13, 18, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✓ অংশ - 4 prototypes (counts=[16, 8, 12, 1])\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✗ বার - NOT FOUND\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✓ ধরা - 3 prototypes (counts=[10, 5, 1])\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✓ দাবি - 4 prototypes (counts=[19, 11, 8, 1])\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 5 prototypes (counts=[14, 7, 7, 12, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 5 prototypes (counts=[7, 17, 6, 8, 1])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✓ মান - 3 prototypes (counts=[6, 8, 1])\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 16758\n  - Total prototypes: 3472\n  - Multi-sense tokens: 677\n  - Reference found: 11/42\n  - Quality Score: 17.33%\n================================================================================\n  - Quality Score: 17.3%\n  - Multi-sense tokens: 677\n  - Total prototypes: 3472\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.5118\n  - BLEU Score: 20.41\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 17.3%\n  - Multi-sense tokens: 677\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=4000 loss=3.4633 clusters=16758\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     আমাদের         42          5         0.003336       0.005030    \n2     এখনও           42          5         0.001736       0.001702    \n3     তার            42          5         0.007834       0.005727    \n4     একজন           42          5         0.000679       0.000656    \n5     করেছিল         42          5         0.000000       0.000001    \n------------------------------------------------------------------------------------------\nEpoch 1/2:  19%|▏| 4198/22500 [45:12<2:21:06,  2.16it/s, train_loss=1.7997, val_loss=3.5118, rate=100.0%, disc=2, lr=5.0e-05, patience=2/3, path=\n[DISCOVERY] Running periodic check at step 4200...\nEpoch 1/2:  20%|▏| 4399/22500 [46:30<1:50:45,  2.72it/s, train_loss=1.7295, val_loss=3.5118, rate=100.0%, disc=101, lr=5.0e-05, patience=2/3, pat[DEBUG] GPU mem (GB):\n  GPU 0: alloc=6.85 resv=7.48\n  GPU 1: alloc=0.00 resv=0.00\n[DEBUG] step=4400 loss=3.5294 clusters=17783\n\n[CLUSTER] Top 5 clusters:\n------------------------------------------------------------------------------------------\nRank  Token          Count       Protos    Mu             Tau         \n------------------------------------------------------------------------------------------\n1     করে            42          4         0.010768       0.008105    \n2     থেকে           42          5         0.010067       0.007173    \n3     তিনি           42          4         0.006433       0.003429    \n4     আমাদের         42          5         0.002702       0.004675    \n5     এটা            42          5         0.015918       0.010800    \n------------------------------------------------------------------------------------------\nEpoch 1/2:  20%|▏| 4498/22500 [47:08<2:17:07,  2.19it/s, train_loss=1.7977, val_loss=3.5118, rate=100.0%, disc=2, lr=5.0e-05, patience=2/3, path=\n[DISCOVERY] Running periodic check at step 4500...\n\n================================================================================\nLOSS SUMMARY AT STEP 4500\n================================================================================\n\nPATH 1 (DSCD Word-Level):\n  - Forward Loss:  0.0110\n  - Backward Loss: 0.4540\n  - Total Batches: 2250\n\nPATH 2 (Translation Subword):\n  - Forward Loss:  3.6287\n  - Backward Loss: 0.4540\n  - Total Batches: 2250\n\nCOMBINED:\n  - Total Batches: 4500\n  - Optimizer Updates: 1125\n================================================================================\n\n\n================================================================================\nEPOCH 1 COMPREHENSIVE VALIDATION (Step 4500)\n================================================================================\n\n[VALIDATION] Using real validation data (2500 batches)\n--------------------------------------------------------------------------------\n[VALIDATION] Batch 0: valid_labels=42/1024\n[VALIDATION] Batch 0: Using forward_path2()\n[VALIDATION] Batch 0: outputs is Tensor, shape=torch.Size([])\n[VALIDATION] Batch 0: raw_loss=3.5132\n[VALIDATION] Batch 0: loss accepted\n[VALIDATION] Processed 5/10 batches...\n[VALIDATION] Computed avg loss: 3.5187 from 10 batches\n\n[VALIDATION] Computing BLEU score + generating 10 translations...\n--------------------------------------------------------------------------------\n[VALIDATION] Processing up to 20 batches for BLEU...\n[VALIDATION] Batch 0: batch_size=4\n[VALIDATION] Batch 0: src_texts len=4\n[VALIDATION] Generation config: beams=2, max_len=256, forced_bos=250004\n[VALIDATION] ✅ Generation successful: shape=torch.Size([4, 14])\n[VALIDATION] Collection complete: refs=80, preds=80\n[VALIDATION] ✅ BLEU Score: 24.27 (from 80 translations)\n\n[VALIDATION] ✅ Translation Examples (10 samples):\n================================================================================\n[1] SRC: তার মধ্যে একটি তো অসম্ভব চিত্তাকর্ষক।\n    PRD: one of them is unbelievable.\n    REF: of them one is astonishing.\n[2] SRC: তার পরেই নোটিস হল।\n    PRD: then the noise.\n    REF: a notification was issued thereafter.\n[3] SRC: শহরে আগেও একাধিক চুরি-ছিনতাই হয়েছে।\n    PRD: there have been several robberies in the city.\n    REF: they have committed several thefts in the city.\n[4] SRC: কাশ্মীর নিয়ে সভায় হট্টগোল\n    PRD: chattgool to discuss kashmir\n    REF: meeting on kashmir issue\n[5] SRC: প্রিমিয়ার লীগ মাসের সেরা খেলোয়াড় : জানুয়ারি ২০১৭\n    PRD: best player of the year in the premier league : january 2017\n    REF: premier league player of the month : january 2017\n================================================================================\n[VALIDATION] Processed 10 validation batches\n\n--------------------------------------------------------------------------------\n[VALIDATION] DSCD Prototype Quality Check:\n================================================================================\nDSCD-VALIDATION: Prototype Quality Check\n================================================================================\nVALIDATION: Reference Homograph Coverage\n--------------------------------------------------------------------------------\n  ✓ তারা - 3 prototypes (counts=[28, 9, 1])\n  ✗ রস - NOT FOUND\n  ✓ মারা - 4 prototypes (counts=[7, 23, 8, 1])\n  ✓ অর্থ - 4 prototypes (counts=[10, 6, 13, 1])\n  ✗ কলা - NOT FOUND\n  ✗ আসন - NOT FOUND\n  ✗ ধারা - NOT FOUND\n  ✗ হার - NOT FOUND\n  ✓ মুখ - 3 prototypes (counts=[7, 6, 1])\n  ✗ পদ - NOT FOUND\n  ✗ গান - NOT FOUND\n  ✗ কাল - NOT FOUND\n  ✗ তোলা - NOT FOUND\n  ✓ উত্তর - 4 prototypes (counts=[13, 14, 13, 1])\n  ✗ শব্দ - NOT FOUND\n  ✗ ব্যাংক - NOT FOUND\n  ✓ অংশ - 5 prototypes (counts=[12, 8, 12, 8, 1])\n  ✗ পাত্র - NOT FOUND\n  ✗ ঘর - NOT FOUND\n  ✗ জমা - NOT FOUND\n  ✗ বাঁচা - NOT FOUND\n  ✓ বার - 4 prototypes (counts=[8, 10, 1, 1])\n  ✗ পাতা - NOT FOUND\n  ✗ পড়া - NOT FOUND\n  ✗ বল - NOT FOUND\n  ✗ চলা - NOT FOUND\n  ✗ তীর - NOT FOUND\n  ✗ কল - NOT FOUND\n  ✓ ধরা - 4 prototypes (counts=[10, 6, 5, 1])\n  ✗ মন - NOT FOUND\n  ✗ পত্র - NOT FOUND\n  ✗ বসা - NOT FOUND\n  ✓ দাবি - 5 prototypes (counts=[17, 5, 8, 8, 1])\n  ✗ সাড়া - NOT FOUND\n  ✓ দেখা - 5 prototypes (counts=[9, 7, 9, 15, 1])\n  ✗ বেলা - NOT FOUND\n  ✗ চাল - NOT FOUND\n  ✓ নাম - 5 prototypes (counts=[8, 9, 7, 6, 10])\n  ✗ রাগ - NOT FOUND\n  ✗ ফল - NOT FOUND\n  ✗ মোড় - NOT FOUND\n  ✓ মান - 3 prototypes (counts=[6, 8, 1])\n--------------------------------------------------------------------------------\nVALIDATION: Summary\n  - Total tokens: 18034\n  - Total prototypes: 3858\n  - Multi-sense tokens: 766\n  - Reference found: 12/42\n  - Quality Score: 18.84%\n================================================================================\n  - Quality Score: 18.8%\n  - Multi-sense tokens: 766\n  - Total prototypes: 3858\n\n--------------------------------------------------------------------------------\n[VALIDATION] ASBN Training Statistics:\n  - Domain Loss: 0.0000\n  - Domain Accuracy: 0.00%\n  - Source Accuracy: 0.00%\n  - Target Accuracy: 0.00%\n\n--------------------------------------------------------------------------------\n[VALIDATION] TRG Explanation Statistics:\n  - Total explanations: 0\n  - High confidence rate: 0.0%\n  - DSCD homograph rate: 0.0%\n--------------------------------------------------------------------------------\n\n[VALIDATION] Summary:\n  - Translations: 0/0 successful\n  - Explanations generated: 0\n  - Avg explanation confidence: 0.000\n  - Avg validation loss: 3.5187\n  - BLEU Score: 24.27\n  - DSCD homographs explained: 0\n  - Reference homographs explained: 0\n  - DSCD Quality Score: 18.8%\n  - Multi-sense tokens: 766\n  - ASBN Domain Accuracy: 0.00%\n\n[VALIDATION] Health Warnings:\n  - No explanations generated\n  - Low DSCD quality score\n================================================================================\n\n\n[LR] Reduced: 5.00e-05 → 2.50e-05\n\n                                                                                                                                                 \n================================================================================\nEPOCH 1/2 SUMMARY\n================================================================================\n  Duration: 48.31 min\n  Avg loss: 1.872131\n  Clusters: 18034\n  Best val: 3.4974\n  Best BLEU: 24.27\n  Patience: 3/3\n================================================================================\n\n[EARLY STOP] Training stopped at epoch 2\n\n================================================================================\nTRAINING COMPLETE\n================================================================================\n\nFINAL CHECKPOINT:\n  Path: /kaggle/working/tatn_final.pt\n  Size: 7016.23 MB\n  Best val: 3.4974\n  Best BLEU: 24.27\n================================================================================\n\n[PHASE 5] Training complete\n[TIMING] Training: 2911.63s\n\n[PHASE 6] Discovery check...\n[PHASE 6] Running periodic discovery check...\n[PHASE 6] periodic_discovery_check params: ['global_step', 'frequency']\n[PHASE 6] Discovery complete: 0 homographs found\n[PHASE 6] Discovery state:\n  - Tokens: 18034\n  - Prototypes: 3858\n  - Multi-sense: 1249\n[TIMING] Discovery: 0.05s\n\n[PHASE 7] DSCD warmup...\n[PHASE 7] Processing 4000 warmup samples...\n\n================================================================================\n[WARMUP] Starting DSCD discovery warmup\n================================================================================\n[CELL2] Loading up to 4000 samples from local CSV: /kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\n[CELL2] Reading CSV file...\n[CELL2] Detected src=English, tgt=Bengali: Swapping columns for bn→en task.\n[CELL2] Swap successful: src=Bengali, tgt=English\n[CELL2] Processing 4000 rows from CSV...\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 4000/4000 [00:00<00:00, 40083.56it/s]","output_type":"stream"},{"name":"stdout","text":"[CELL2] Loaded 4000 pairs from CSV, skipped 0 rows\n\n[WARMUP] Processing 4000 sentences (batch=64)...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[WARMUP] 64/4000 (1.6%) | 22.3 sent/s | ETA 177s\n[WARMUP] 192/4000 (4.8%) | 21.6 sent/s | ETA 176s\n[WARMUP] 320/4000 (8.0%) | 20.6 sent/s | ETA 178s\n[WARMUP] 448/4000 (11.2%) | 20.6 sent/s | ETA 173s\n[WARMUP] 576/4000 (14.4%) | 21.3 sent/s | ETA 161s\n[WARMUP] 704/4000 (17.6%) | 21.5 sent/s | ETA 154s\n[WARMUP] 832/4000 (20.8%) | 21.6 sent/s | ETA 147s\n[WARMUP] 960/4000 (24.0%) | 21.9 sent/s | ETA 139s\n[WARMUP] 1088/4000 (27.2%) | 21.8 sent/s | ETA 134s\n[WARMUP] 1152/4000 (28.8%) | 20.7 sent/s | ETA 137s\n[WARMUP] 1280/4000 (32.0%) | 20.8 sent/s | ETA 131s\n[WARMUP] 1344/4000 (33.6%) | 20.9 sent/s | ETA 127s\n[WARMUP] 1472/4000 (36.8%) | 20.3 sent/s | ETA 124s\n[WARMUP] 1600/4000 (40.0%) | 20.4 sent/s | ETA 118s\n[WARMUP] 1728/4000 (43.2%) | 19.9 sent/s | ETA 114s\n[WARMUP] 1856/4000 (46.4%) | 19.6 sent/s | ETA 109s\n[WARMUP] 1984/4000 (49.6%) | 19.6 sent/s | ETA 103s\n[WARMUP] 2112/4000 (52.8%) | 19.6 sent/s | ETA 96s\n[WARMUP] 2240/4000 (56.0%) | 19.3 sent/s | ETA 91s\n[WARMUP] 2304/4000 (57.6%) | 19.1 sent/s | ETA 89s\n[WARMUP] 2432/4000 (60.8%) | 19.0 sent/s | ETA 83s\n[WARMUP] 2560/4000 (64.0%) | 19.1 sent/s | ETA 75s\n[WARMUP] 2624/4000 (65.6%) | 19.0 sent/s | ETA 73s\n[WARMUP] 2752/4000 (68.8%) | 18.8 sent/s | ETA 67s\n[WARMUP] 2880/4000 (72.0%) | 18.4 sent/s | ETA 61s\n[WARMUP] 3008/4000 (75.2%) | 18.4 sent/s | ETA 54s\n[WARMUP] 3136/4000 (78.4%) | 18.0 sent/s | ETA 48s\n[WARMUP] 3264/4000 (81.6%) | 18.0 sent/s | ETA 41s\n[WARMUP] 3392/4000 (84.8%) | 17.9 sent/s | ETA 34s\n[WARMUP] 3520/4000 (88.0%) | 17.8 sent/s | ETA 27s\n[WARMUP] 3648/4000 (91.2%) | 17.6 sent/s | ETA 20s\n[WARMUP] 3712/4000 (92.8%) | 17.5 sent/s | ETA 16s\n[WARMUP] 3776/4000 (94.4%) | 17.3 sent/s | ETA 13s\n[WARMUP] 3904/4000 (97.6%) | 17.1 sent/s | ETA 6s\n[WARMUP] 3968/4000 (99.2%) | 16.9 sent/s | ETA 2s\n\n[WARMUP] Completed in 237.4s (16.8 sent/s)\n--------------------------------------------------------------------------------\n[WARMUP] Running DSCD cleanup after warmup...\n[WARMUP] Summary:\n  - Token types: 22875\n  - Total prototypes: 4776\n  - Multi-sense tokens: 1995\n  - Multi-sense ratio: 8.7%\n\n[WARMUP] Discovered Homographs: 0\n\n[WARMUP] Reference List Comparison:\n  - Reference list: 42 words\n  - Found in DSCD: 0\n  - Coverage: 0.0%\n\n[WARMUP] WARNING: < 50% reference coverage\n================================================================================\n\n[PHASE 7] Warmup complete (4000 samples in 239.8s)\n[TIMING] Warmup: 239.79s\n\n[PHASE 8] Baseline evaluation...\n[PHASE 8] ⚡ Running baseline with DSCD-augmented generation...\n\n================================================================================\nCOMPREHENSIVE POST-TRAINING EVALUATION\n================================================================================\n[EVAL] DSCD discovered: 0 homographs\n\n[EVAL] Running 14 tests...\n--------------------------------------------------------------------------------\n\nTest 1/14: কল = tap/call\n============================================================\nInput: আমি কল বন্ধ করেছি।\nExpected: I turned off the tap\nTranslation: i shut up.\nSimilarity: 20.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'বন্ধ' @ 4\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'করেছি'.   Pattern matches learned data.   \n  2. [S>0.20] 'করেছি' @ 5\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'বন্ধ'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 2/14: কাল = tomorrow/yesterday\n============================================================\nInput: কাল আমি বই কিনব।\nExpected: Tomorrow I will buy a book\nTranslation: i will be back tomorrow.\nSimilarity: 33.3%\nAmbiguous: 1\n\nExplanations:\n  1.            'কাল' @ 1\n       conf=0.408 | U=0.408 | S=0.190\n       Chose 'sense_0' with high confidence (99.9%) based on: 'আমি'.   Pattern matches learned data.   Alternatives: 'sense_1' ...\nSuccess\n------------------------------------------------------------\n\nTest 3/14: কাল = tomorrow/yesterday\n============================================================\nInput: কাল আমি বই কিনেছিলাম।\nExpected: Yesterday I bought a book\nTranslation: i was thinking about it.\nSimilarity: 20.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'ছিলাম' @ 6\n       conf=0.649 | U=0.446 | S=0.649\n       Chose 'sense_2' with high confidence (98.3%) based on: 'limited context'.   Pattern matches learned data.   Alternatives...\n  2. [S>0.20] 'কাল' @ 1\n       conf=0.434 | U=0.434 | S=0.280\n       Chose 'sense_2' with high confidence (98.9%) based on: 'আমি'.   Pattern matches learned data.   Alternatives: 'sense_0' ...\nSuccess\n------------------------------------------------------------\n\nTest 4/14: পাতা = leaf/page\n============================================================\nInput: পাতা ঝরে পড়েছে।\nExpected: The leaf has fallen\nTranslation: the page has fallen down.\nSimilarity: 75.0%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'পড়েছে' @ 4\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'limited context'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 5/14: ব্যাংক = bank/embankment\n============================================================\nInput: তিনি ব্যাংক গেছেন।\nExpected: He went to the bank\nTranslation: he has become a banker.\nSimilarity: 20.0%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'গেছে' @ 3\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'তিনি, ব্যাংক'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 6/14: ফল = fruit/result\n============================================================\nInput: ফল খুব সুস্বাদু।\nExpected: The fruit is delicious\nTranslation: it is a very beautiful picture.\nSimilarity: 25.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'খুব' @ 3\n       conf=1.000 | U=0.835 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'limited context'.   Pattern matches learned data.   \n  2.            'বাদ' @ 6\n       conf=0.430 | U=0.430 | S=0.152\n       Chose 'sense_0' with high confidence (99.1%) based on: 'limited context'.   Pattern matches learned data.   Alternatives...\nSuccess\n------------------------------------------------------------\n\nTest 7/14: মাথা = head/top\n============================================================\nInput: মাথা ব্যথা করছে।\nExpected: Head is aching\nTranslation: he is angry.\nSimilarity: 33.3%\nAmbiguous: 1\n\nExplanations:\n  1.            'ব্য' @ 3\n       conf=0.416 | U=0.416 | S=0.190\n       Chose 'sense_0' with high confidence (99.6%) based on: 'মাথা, করছে'.   Pattern matches learned data.   Alternatives: 'se...\nSuccess\n------------------------------------------------------------\n\nTest 8/14: Multiple কল\n============================================================\nInput: কল থেকে কল এসেছে।\nExpected: A call came from the tap\nTranslation: it came from a different place.\nSimilarity: 50.0%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'এসেছে' @ 6\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'limited context'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 9/14: Multiple কাল\n============================================================\nInput: কালকে কাল মেঘ দেখা গেছে।\nExpected: Yesterday black clouds were seen\nTranslation: we met each other at the same time.\nSimilarity: 0.0%\nAmbiguous: 3\n\nExplanations:\n  1. [S>0.20] 'দেখা' @ 6\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'গেছে'.   Pattern matches learned data.   \n  2. [S>0.20] 'গেছে' @ 7\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'দেখা'.   Pattern matches learned data.   \n  3.            'কাল' @ 3\n       conf=0.418 | U=0.418 | S=0.166\n       Chose 'sense_0' with high confidence (99.7%) based on: 'কাল'.   Pattern matches learned data.   Alternatives: 'sense_1' ...\nSuccess\n------------------------------------------------------------\n\nTest 10/14: Simple\n============================================================\nInput: আজ ভাল আবহাওয়া।\nExpected: Weather is good today\nTranslation: the weather is good.\nSimilarity: 50.0%\nAmbiguous: 1\n\nExplanations:\n  1.            'ভাল' @ 2\n       conf=0.815 | U=0.815 | S=0.127\n       Selected 'sense_2' with moderate confidence (56.6%). Evidence: 'আবহাওয়া'. Some uncertainty (81.5%).   Alternatives: 'se...\nSuccess\n------------------------------------------------------------\n\nTest 11/14: Simple\n============================================================\nInput: আমি ভালো আছি।\nExpected: I am fine\nTranslation: i am fine.\nSimilarity: 66.7%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'ভালো' @ 2\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'আমি'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 12/14: Simple\n============================================================\nInput: সে খুব মিষ্টি কথা বলে।\nExpected: She speaks sweetly\nTranslation: he talks about it very well.\nSimilarity: 0.0%\nAmbiguous: 4\n\nExplanations:\n  1. [S>0.20] 'খুব' @ 2\n       conf=0.480 | U=0.480 | S=0.233\n       Chose 'sense_1' with high confidence (97.2%) based on: 'ষ্ট'.   Pattern matches learned data.   Alternatives: 'sense_2' ...\n  2.            'বলে' @ 7\n       conf=0.440 | U=0.440 | S=0.183\n       Chose 'sense_1' with high confidence (98.8%) based on: 'কথা'.   Pattern matches learned data.   Alternatives: 'sense_2' ...\n  3.            'ষ্ট' @ 4\n       conf=0.618 | U=0.618 | S=0.105\n       Chose 'sense_0' with high confidence (89.0%) based on: 'খুব, কথা'.   Pattern matches learned data.   Alternatives: 'sens...\n  4.            'কথা' @ 6\n       conf=0.854 | U=0.854 | S=0.061\n       Chose 'sense_0' with high confidence (78.2%) based on: 'ষ্ট, বলে'.   Pattern matches learned data.   Alternatives: 'sens...\nSuccess\n------------------------------------------------------------\n\nTest 13/14: Simple\n============================================================\nInput: এটা আমার বই।\nExpected: This is my book\nTranslation: this is my book.\nSimilarity: 75.0%\nAmbiguous: 1\n\nExplanations:\n  1.            'এটা' @ 1\n       conf=0.498 | U=0.498 | S=0.184\n       Chose 'sense_1' with high confidence (97.6%) based on: 'আমার'.   Pattern matches learned data.   Alternatives: 'sense_0'...\nSuccess\n------------------------------------------------------------\n\nTest 14/14: Long with multiple\n============================================================\nInput: তিনি ব্যাংকে কাজ করেন এবং ব্যাংকে বসে থাকেন।\nExpected: He works at the bank and sits on the embankment\nTranslation: he worked in banking and finance.\nSimilarity: 22.2%\nAmbiguous: 3\n\nExplanations:\n  1. [S>0.20] 'বসে' @ 9\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'ব্যাংক, থাকে'.   Pattern matches learned data.   \n  2. [S>0.20] 'থাকে' @ 10\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'বসে'.   Pattern matches learned data.   \n  3.            'কাজ' @ 4\n       conf=0.563 | U=0.563 | S=0.190\n       Chose 'sense_0' with high confidence (91.9%) based on: 'ব্যাংক, করেন, এবং'.   Pattern matches learned data.   Alternativ...\nSuccess\n------------------------------------------------------------\n\n================================================================================\nCOMPREHENSIVE EVALUATION SUMMARY\n================================================================================\n\n[TRANSLATION QUALITY]\n  Total tests: 14\n  Successful: 14\n  Success rate: 100.0%\n\n[AMBIGUITY DETECTION]\n  Total explanations: 24\n  High-span (S>0.2): 14\n  Real ambiguous: 24\n  Avg explanations/test: 1.71\n\n[EXPLANATION QUALITY]\n  Avg confidence: 0.751\n  Avg span: 0.571\n  Avg uncertainty: 0.486\n  Confidence P25/P50/P75: 0.480 / 0.854 / 1.000\n  High (>=0.65): 13\n  Medium (0.4-0.65): 11\n  Low (<0.4): 0\n\n[HOMOGRAPH DISCOVERY]\n  DSCD discovered: 0\n  Explained: 20\n  Explanation rate: 0.0%\n  Test discovery rate: 0.0%\n\n  Explained homographs (top 10):\n            'এটা': 1 x conf=0.498\n            'এসেছে': 1 x conf=1.000\n            'কথা': 1 x conf=0.854\n            'করেছি': 1 x conf=1.000\n            'কাজ': 1 x conf=0.563\n        [R] 'কাল': 3 x conf=0.420\n            'খুব': 2 x conf=0.740\n            'গেছে': 2 x conf=1.000\n            'ছিলাম': 1 x conf=0.649\n            'থাকে': 1 x conf=1.000\n\n[REFERENCE COMPARISON]\n  Reference: 42 words\n  Discovered: 0/42\n  Coverage: 0.0%\n\n[DSCD PROTOTYPES]\n  Word types: 22880\n  Multi-sense: 1998\n  Total prototypes: 4765\n  Multi-sense ratio: 8.7%\n\n[ASBN]\n  Domain accuracy: 0.00%\n  Source accuracy: 0.00%\n  Target accuracy: 0.00%\n\n[TRG]\n  Total explanations: 0\n  High confidence: 0.0%\n\n[PERFORMANCE]\n  Total time: 17.97s\n  Avg time/test: 1.28s\n\n[WARNINGS]\n  - Low explanation rate (<30%)\n  - Discovery log missing\n  - ASBN domain accuracy <50%\n================================================================================\n[TIMING] comprehensive_post_training_testing: 17.98s\n[PHASE 8] Baseline: 100.0% success, 24 explanations\n[TIMING] Baseline: 17.98s\n\n[PHASE 9] Post-training evaluation...\n[PHASE 9] ⚡ Running evaluation with DSCD-augmented generation...\n\n================================================================================\nCOMPREHENSIVE POST-TRAINING EVALUATION\n================================================================================\n[EVAL] DSCD discovered: 0 homographs\n\n[EVAL] Running 14 tests...\n--------------------------------------------------------------------------------\n\nTest 1/14: কল = tap/call\n============================================================\nInput: আমি কল বন্ধ করেছি।\nExpected: I turned off the tap\nTranslation: i shut up.\nSimilarity: 20.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'বন্ধ' @ 4\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'করেছি'.   Pattern matches learned data.   \n  2. [S>0.20] 'করেছি' @ 5\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'বন্ধ'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 2/14: কাল = tomorrow/yesterday\n============================================================\nInput: কাল আমি বই কিনব।\nExpected: Tomorrow I will buy a book\nTranslation: i will be back tomorrow.\nSimilarity: 33.3%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'কাল' @ 1\n       conf=0.409 | U=0.409 | S=0.249\n       Chose 'sense_0' with high confidence (99.9%) based on: 'আমি'.   Pattern matches learned data.   Alternatives: 'sense_1' ...\nSuccess\n------------------------------------------------------------\n\nTest 3/14: কাল = tomorrow/yesterday\n============================================================\nInput: কাল আমি বই কিনেছিলাম।\nExpected: Yesterday I bought a book\nTranslation: i was thinking about it.\nSimilarity: 20.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'ছিলাম' @ 6\n       conf=0.680 | U=0.418 | S=0.680\n       Chose 'sense_2' with high confidence (99.5%) based on: 'limited context'.   Pattern matches learned data.   Alternatives...\n  2. [S>0.20] 'কাল' @ 1\n       conf=0.768 | U=0.768 | S=0.235\n       Selected 'sense_2' with moderate confidence (61.1%). Evidence: 'আমি'. Some uncertainty (76.8%).   Alternatives: 'sense_0...\nSuccess\n------------------------------------------------------------\n\nTest 4/14: পাতা = leaf/page\n============================================================\nInput: পাতা ঝরে পড়েছে।\nExpected: The leaf has fallen\nTranslation: the page has fallen down.\nSimilarity: 75.0%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'পড়েছে' @ 4\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'limited context'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 5/14: ব্যাংক = bank/embankment\n============================================================\nInput: তিনি ব্যাংক গেছেন।\nExpected: He went to the bank\nTranslation: he is a banker.\nSimilarity: 20.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'ব্যাংক' @ 2\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'তিনি, গেছে'.   Pattern matches learned data.   \n  2. [S>0.20] 'গেছে' @ 3\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'তিনি, ব্যাংক'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 6/14: ফল = fruit/result\n============================================================\nInput: ফল খুব সুস্বাদু।\nExpected: The fruit is delicious\nTranslation: it is very beautiful.\nSimilarity: 25.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'বাদ' @ 6\n       conf=0.403 | U=0.403 | S=0.273\n       Chose 'sense_2' with high confidence (99.9%) based on: 'limited context'.   Pattern matches learned data.   Alternatives...\n  2.            'খুব' @ 3\n       conf=0.610 | U=0.610 | S=0.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'limited context'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 7/14: মাথা = head/top\n============================================================\nInput: মাথা ব্যথা করছে।\nExpected: Head is aching\nTranslation: he was shaking his head.\nSimilarity: 0.0%\nAmbiguous: 2\n\nExplanations:\n  1. [S>0.20] 'মাথা' @ 1\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'ব্য'.   Pattern matches learned data.   \n  2. [S>0.20] 'ব্য' @ 3\n       conf=0.408 | U=0.408 | S=0.218\n       Chose 'sense_2' with high confidence (99.8%) based on: 'মাথা, করছে'.   Pattern matches learned data.   Alternatives: 'se...\nSuccess\n------------------------------------------------------------\n\nTest 8/14: Multiple কল\n============================================================\nInput: কল থেকে কল এসেছে।\nExpected: A call came from the tap\nTranslation: it came from a different place.\nSimilarity: 50.0%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'এসেছে' @ 6\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'limited context'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 9/14: Multiple কাল\n============================================================\nInput: কালকে কাল মেঘ দেখা গেছে।\nExpected: Yesterday black clouds were seen\nTranslation: we met each other at the same time.\nSimilarity: 0.0%\nAmbiguous: 3\n\nExplanations:\n  1. [S>0.20] 'দেখা' @ 6\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'গেছে'.   Pattern matches learned data.   \n  2. [S>0.20] 'গেছে' @ 7\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'দেখা'.   Pattern matches learned data.   \n  3.            'কাল' @ 3\n       conf=0.436 | U=0.436 | S=0.166\n       Chose 'sense_0' with high confidence (99.3%) based on: 'কাল'.   Pattern matches learned data.   Alternatives: 'sense_1' ...\nSuccess\n------------------------------------------------------------\n\nTest 10/14: Simple\n============================================================\nInput: আজ ভাল আবহাওয়া।\nExpected: Weather is good today\nTranslation: the weather is good.\nSimilarity: 50.0%\nAmbiguous: 1\n\nExplanations:\n  1.            'ভাল' @ 2\n       conf=0.640 | U=0.640 | S=0.153\n       Chose 'sense_2' with high confidence (86.0%) based on: 'আবহাওয়া'.   Pattern matches learned data.   Alternatives: 'sens...\nSuccess\n------------------------------------------------------------\n\nTest 11/14: Simple\n============================================================\nInput: আমি ভালো আছি।\nExpected: I am fine\nTranslation: i am fine.\nSimilarity: 66.7%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'ভালো' @ 2\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'আমি'.   Pattern matches learned data.   \nSuccess\n------------------------------------------------------------\n\nTest 12/14: Simple\n============================================================\nInput: সে খুব মিষ্টি কথা বলে।\nExpected: She speaks sweetly\nTranslation: he talks about himself.\nSimilarity: 0.0%\nAmbiguous: 4\n\nExplanations:\n  1. [S>0.20] 'খুব' @ 2\n       conf=1.000 | U=0.979 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'ষ্ট'.   Pattern matches learned data.   \n  2. [S>0.20] 'বলে' @ 7\n       conf=0.416 | U=0.416 | S=0.229\n       Chose 'sense_2' with high confidence (99.6%) based on: 'কথা'.   Pattern matches learned data.   Alternatives: 'sense_0' ...\n  3. [S>0.20] 'ষ্ট' @ 4\n       conf=0.424 | U=0.424 | S=0.228\n       Chose 'sense_2' with high confidence (99.3%) based on: 'খুব, কথা'.   Pattern matches learned data.   Alternatives: 'sens...\n  4.            'কথা' @ 6\n       conf=0.697 | U=0.697 | S=0.106\n       Chose 'sense_1' with high confidence (89.1%) based on: 'ষ্ট, বলে'.   Pattern matches learned data.   Alternatives: 'sens...\nSuccess\n------------------------------------------------------------\n\nTest 13/14: Simple\n============================================================\nInput: এটা আমার বই।\nExpected: This is my book\nTranslation: this is my book.\nSimilarity: 75.0%\nAmbiguous: 1\n\nExplanations:\n  1. [S>0.20] 'এটা' @ 1\n       conf=0.460 | U=0.460 | S=0.221\n       Chose 'sense_1' with high confidence (98.7%) based on: 'আমার'.   Pattern matches learned data.   Alternatives: 'sense_0'...\nSuccess\n------------------------------------------------------------\n\nTest 14/14: Long with multiple\n============================================================\nInput: তিনি ব্যাংকে কাজ করেন এবং ব্যাংকে বসে থাকেন।\nExpected: He works at the bank and sits on the embankment\nTranslation: he worked in banking and finance.\nSimilarity: 22.2%\nAmbiguous: 3\n\nExplanations:\n  1. [S>0.20] 'বসে' @ 9\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'ব্যাংক, থাকে'.   Pattern matches learned data.   \n  2. [S>0.20] 'থাকে' @ 10\n       conf=1.000 | U=0.400 | S=1.000\n       Chose 'sense_0' with high confidence (100.0%) based on: 'বসে'.   Pattern matches learned data.   \n  3. [S>0.20] 'কাজ' @ 4\n       conf=0.420 | U=0.420 | S=0.283\n       Chose 'sense_2' with high confidence (99.4%) based on: 'ব্যাংক, করেন, এবং'.   Pattern matches learned data.   Alternativ...\nSuccess\n------------------------------------------------------------\n\n================================================================================\nCOMPREHENSIVE EVALUATION SUMMARY\n================================================================================\n\n[TRANSLATION QUALITY]\n  Total tests: 14\n  Successful: 14\n  Success rate: 100.0%\n\n[AMBIGUITY DETECTION]\n  Total explanations: 26\n  High-span (S>0.2): 22\n  Real ambiguous: 26\n  Avg explanations/test: 1.86\n\n[EXPLANATION QUALITY]\n  Avg confidence: 0.760\n  Avg span: 0.617\n  Avg uncertainty: 0.473\n  Confidence P25/P50/P75: 0.436 / 1.000 / 1.000\n  High (>=0.65): 16\n  Medium (0.4-0.65): 10\n  Low (<0.4): 0\n\n[HOMOGRAPH DISCOVERY]\n  DSCD discovered: 0\n  Explained: 22\n  Explanation rate: 0.0%\n  Test discovery rate: 0.0%\n\n  Explained homographs (top 10):\n            'এটা': 1 x conf=0.460\n            'এসেছে': 1 x conf=1.000\n            'কথা': 1 x conf=0.697\n            'করেছি': 1 x conf=1.000\n            'কাজ': 1 x conf=0.420\n        [R] 'কাল': 3 x conf=0.538\n            'খুব': 2 x conf=0.805\n            'গেছে': 2 x conf=1.000\n            'ছিলাম': 1 x conf=0.680\n            'থাকে': 1 x conf=1.000\n\n[REFERENCE COMPARISON]\n  Reference: 42 words\n  Discovered: 0/42\n  Coverage: 0.0%\n\n[DSCD PROTOTYPES]\n  Word types: 22880\n  Multi-sense: 1997\n  Total prototypes: 4761\n  Multi-sense ratio: 8.7%\n\n[ASBN]\n  Domain accuracy: 0.00%\n  Source accuracy: 0.00%\n  Target accuracy: 0.00%\n\n[TRG]\n  Total explanations: 0\n  High confidence: 0.0%\n\n[PERFORMANCE]\n  Total time: 18.81s\n  Avg time/test: 1.34s\n\n[BASELINE COMPARISON]\n  Translation: 100.0% (+0.0%)\n  Explanations: 26 (+2)\n  Confidence: 0.760 (+0.009)\n  Explanation rate: 0.0% (+0.0%)\n\n[WARNINGS]\n  - Low explanation rate (<30%)\n  - Discovery log missing\n  - ASBN domain accuracy <50%\n================================================================================\n[TIMING] comprehensive_post_training_testing: 18.82s\n[PHASE 9] Evaluation: 100.0% success, 26 explanations\n[TIMING] Evaluation: 18.82s\n\n[PHASE 10] Saving checkpoint...\n[PHASE 10] Checkpoint saved: /kaggle/working/tatn_final.pt\n  - Size: 7022.63 MB\n  - Model: OK\n  - DSCD: OK\n  - DSCD tokens: 0\n[TIMING] Checkpoint: 21.34s\n\n[PHASE 11] Final validation...\n[PHASE 11] Component validation:\n  - DSCD: OK\n  - ASBN: OK (ENABLED)\n  - TRG: OK\n[PHASE 11] ✅ All components validated\n\n================================================================================\nPIPELINE COMPLETE - FINAL SUMMARY\n================================================================================\n\n[TIMING]\n  Total time: 3240.42s (54.01 min)\n\n[TRAINING]\n  No stats available\n\n[DISCOVERY]\n  ✅ Success\n\n[EVALUATION]\n  Baseline -> Final: 100.0% -> 100.0%\n  Improvement: +0.0%\n  DSCD multi-sense: 1998 -> 1997\n  ASBN accuracy: 0.00% -> 0.00% \n\n[CHECKPOINT]\n  Saved: /kaggle/working/tatn_final.pt\n  - Size: 7022.63 MB\n\n================================================================================\nUsage: trained_model, tokenizer = main_pipeline()\n================================================================================\n\nPipeline completed: 54.0min\n\n================================================================================\nPIPELINE SUCCEEDED\n================================================================================\n\n[CHECKPOINT]\n  File: /kaggle/working/tatn_final.pt\n  Size: 7022.6 MB\n  Model: Present\n  DSCD: Present\n  Tokens: 22880\n  Status: VALID\n\n[COMPONENTS]\n  DSCD:\n    - Tokens: 22880\n    - Prototypes: 4761\n    - Homographs: 1997\n  ASBN:\n    - Domain accuracy: 0.00% \n    - Source: 0.00%\n    - Target: 0.00%\n  TRG:\n    - Explanations: 26\n    - High confidence: 96.2%\n    - DSCD homograph rate: 0.0%\n\n[METRICS]\n  Evaluation:\n    - Baseline -> Final: 100.0% -> 100.0%\n    - Improvement: +0.0%\n    - Explanations: 26\n    - Avg confidence: 0.760\n\n[INFERENCE VALIDATION]\nTesting disambiguation on ambiguous sentences...\n--------------------------------------------------------------------------------\nDSCD discovered: 0 homographs\n\n1.  কল (tap/call)\n   Input: আমি কল বন্ধ করেছি।\n   Translation: i shut up.\n   Ambiguous: 2\n   Time: 1.363s\n   -> 'বন্ধ': conf=1.000, s=1.000, u=0.400\n   -> 'করেছি': conf=1.000, s=1.000, u=0.000\n\n2.  কাল (tomorrow/yesterday)\n   Input: কাল আমি বই কিনব।\n   Translation: i will be back tomorrow.\n   Ambiguous: 0\n   Time: 1.383s\n   No explanations\n\n3.  পাতা (leaf/page)\n   Input: পাতা ঝরে পড়েছে।\n   Translation: the page has fallen down.\n   Ambiguous: 1\n   Time: 1.360s\n   -> 'পড়েছে': conf=1.000, s=1.000, u=0.000\n\n--------------------------------------------------------------------------------\nResults: 3/3 successful\nPerformance: 1.369s avg per sentence\nNo DSCD homographs detected\n   -> DSCD has no discoveries (run warmup)\n\n--------------------------------------------------------------------------------\nAGGREGATED STATISTICS (from Cell 8):\n--------------------------------------------------------------------------------\n\n================================================================================\nINFERENCE STATISTICS SUMMARY\n================================================================================\nTotal inferences: 3\nSuccess rate: 100.0%\nTotal explanations: 3\nExplanations per inference: 1.00\nUnique tokens explained: 3\nDiversity ratio: 100.00%\nAvg confidence: 1.000\nHigh confidence rate: 100.0%\nAvg span: 1.000\nAvg uncertainty: 0.133\n================================================================================\n\n\n[SYSTEM TEST]\n  Component status:\n    - DSCD: OK\n    - ASBN: OK \n    - TRG: OK\n    - M2M100: OK\n  All components operational\n\n================================================================================\nNEXT STEPS\n================================================================================\n\n1. Single translation:\n   result = translate_with_explanations(trained_model, tokenizer, 'আমি কল বন্ধ করেছি।', source_lang='bn_IN', target_lang='en_XX', device=_DEVICE, max_length=256)\n\n2. Batch translation:\n   for sent in sentences:\n       res = translate_with_explanations(trained_model, tokenizer, sent, source_lang='bn_IN', target_lang='en_XX', device=_DEVICE, max_length=256)\n\n3. Load checkpoint:\n   ckpt = torch.load('/kaggle/working/tatn_final.pt', weights_only=False)\n   model.load_state_dict(ckpt['model_state_dict'])\n   model.dscd.load_state_dict(ckpt['dscd_state'])\n\n4. Full evaluation:\n   results = comprehensive_post_training_testing(trained_model, tokenizer)\n\n5. Demo:\n   demonstrate_system(trained_model, tokenizer)\n\n================================================================================\n\n================================================================================\nEXECUTION SUMMARY\n================================================================================\nUser: manas0003\nStarted: 2026-02-18 08:40:05 UTC\nFinished: 2026-02-18 09:34:16 UTC\nDuration: 54.2min\nStatus: SUCCESS\nCheckpoint: VALID\n================================================================================\n\n================================================================================\nCell 11: Execution Wrapper (DUAL-PATH COMPATIBLE)\n================================================================================\nThis cell:\n  - Loads configuration from Cell 0\n  - Executes main_pipeline() from Cell 10\n  - Validates checkpoint integrity\n  - Tests inference with sample sentences\n  - Provides comprehensive diagnostics\n  - Shows usage examples for next steps\n\nCurrent config:\n  - Samples: 100000\n  - Epochs: 2\n  - Batch size: 4\n  - Device: cuda\n  - Multi-GPU: False\n  - ASBN Training: ENABLED\n  - Discovery Frequency: 300\n\n✅ DUAL-PATH COMPATIBILITY:\n  ✅ Uses Cell 8 translate_with_explanations() (already fixed)\n  ✅ Uses Cell 10 main_pipeline() (already fixed)\n  ✅ No direct model.forward() calls\n  ✅ Only inspection functions (no API changes)\n  ✅ Fully compatible with dual-path system\n================================================================================\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ==============================================================================\n# CELL 12: TRANSLATION TEST WITH AMBIGUOUS WORD DETECTION & SENSE DISAMBIGUATION\n# FIXED: robust tokenizer lang resolution and small robustness improvements\n# ==============================================================================\nimport os\nimport time\nimport json\nimport traceback\nfrom typing import Dict, List, Tuple, Optional, Any\nfrom collections import defaultdict\nimport torch\nimport torch.nn.functional as F\nimport gc\nimport pandas as pd\n\ntry:\n    _DEVICE = DEVICE if isinstance(DEVICE, torch.device) else torch.device(str(DEVICE)) if isinstance(DEVICE, str) else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\n    _TARGET_LANGUAGE = str(TARGET_LANGUAGE)\n    _VERBOSE_LOGGING = bool(VERBOSE_LOGGING)\n    _DEBUG_DISCOVERY = bool(DEBUG_DISCOVERY)\nexcept Exception:\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = \"bn_IN\"\n    _TARGET_LANGUAGE = \"en_XX\"\n    _VERBOSE_LOGGING = False\n    _DEBUG_DISCOVERY = False\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CELL 12: TRANSLATION TEST WITH SENSE DISAMBIGUATION\")\nprint(\"=\" * 80)\nprint(f\"Device: {_DEVICE}\")\nprint(f\"Translation: {_SOURCE_LANGUAGE} → {_TARGET_LANGUAGE}\")\nprint(\"=\" * 80 + \"\\n\")\n\n\n# ==============================================================================\n# STEP 1: DEFINE TEST SENTENCES WITH EXPECTED TRANSLATIONS\n# ==============================================================================\nTEST_SENTENCES = [\n    {\"id\": 1, \"input\": \"আমি ব্যাংকে টাকা জমা করি।\", \"expected\": \"I deposit money in the bank.\", \"ambiguous_words\": [\"ব্যাংক\"], \"expected_senses\": {\"ব্যাংক\": \"financial institution\"}},\n    {\"id\": 2, \"input\": \"নদীর ব্যাংকে অনেক গাছ আছে।\", \"expected\": \"There are many trees on the river bank.\", \"ambiguous_words\": [\"ব্যাংক\"], \"expected_senses\": {\"ব্যাংক\": \"riverbank/embankment\"}},\n    {\"id\": 3, \"input\": \"কাল আমি বাজারে যাব।\", \"expected\": \"I will go to the market tomorrow.\", \"ambiguous_words\": [\"কাল\"], \"expected_senses\": {\"কাল\": \"tomorrow\"}},\n    {\"id\": 4, \"input\": \"কাল অন্ধকার রাত ছিল।\", \"expected\": \"It was a dark black night.\", \"ambiguous_words\": [\"কাল\"], \"expected_senses\": {\"কাল\": \"black/dark\"}},\n    {\"id\": 5, \"input\": \"গাছের পাতা সবুজ।\", \"expected\": \"The leaves of the tree are green.\", \"ambiguous_words\": [\"পাতা\"], \"expected_senses\": {\"পাতা\": \"leaf\"}},\n    {\"id\": 6, \"input\": \"বই পাতা উল্টাও।\", \"expected\": \"Turn the pages of the book.\", \"ambiguous_words\": [\"পাতা\"], \"expected_senses\": {\"পাতা\": \"page\"}},\n    {\"id\": 7, \"input\": \"ফুটবল খেলায় বল লাথি মারা হয়।\", \"expected\": \"In football, the ball is kicked.\", \"ambiguous_words\": [\"বল\"], \"expected_senses\": {\"বল\": \"ball\"}},\n    {\"id\": 8, \"input\": \"আমার বল বেশি তাই আমি জিতব।\", \"expected\": \"My strength is more so I will win.\", \"ambiguous_words\": [\"বল\"], \"expected_senses\": {\"বল\": \"strength/force\"}},\n    {\"id\": 9, \"input\": \"চোরকে ধরা হয়েছে।\", \"expected\": \"The thief has been caught.\", \"ambiguous_words\": [\"ধরা\"], \"expected_senses\": {\"ধরা\": \"caught\"}},\n    {\"id\": 10, \"input\": \"আকাশে চাঁদ ধরা দিয়েছে।\", \"expected\": \"The moon has appeared in the sky.\", \"ambiguous_words\": [\"ধরা\"], \"expected_senses\": {\"ধরা\": \"appeared\"}},\n    {\"id\": 11, \"input\": \"সে খুব মিষ্টি কথা বলে।\", \"expected\": \"She speaks very sweetly.\", \"ambiguous_words\": [\"কথা\"], \"expected_senses\": {\"কথা\": \"words/speech\"}},\n    {\"id\": 12, \"input\": \"তিনি ব্যাংকে কাজ করেন এবং নদীর ব্যাংকে বসে থাকেন।\", \"expected\": \"He works at the bank and sits on the river bank.\", \"ambiguous_words\": [\"ব্যাংক\", \"ব্যাংক\"], \"expected_senses\": {\"ব্যাংক_1\": \"financial institution\", \"ব্যাংক_2\": \"riverbank\"}},\n    {\"id\": 13, \"input\": \"কাল কালো মেঘ ছিল।\", \"expected\": \"Yesterday there were black clouds.\", \"ambiguous_words\": [\"কাল\"], \"expected_senses\": {\"কাল\": \"yesterday\"}},\n]\n\nprint(f\"[STEP 1] Loaded {len(TEST_SENTENCES)} test sentences\")\n\n\n# ==============================================================================\n# STEP 2: LOAD TRAINED MODEL AND PROTOTYPES (robust tokenizer lang resolution)\n# ==============================================================================\nMODEL_CHECKPOINT_PATH = \"/kaggle/working/tatn_final.pt\"\nPROTOTYPE_DIR = \"/kaggle/working/tatn_final.ptprototypes/\"\n\nmodel = None\ntokenizer = None\nprototypes_data = {}\n\ndef _resolve_tokenizer_lang(tokenizer, lang_code: str) -> Optional[str]:\n    \"\"\"\n    Try to resolve best matching language key for tokenizer.\n    Tries variants: original, strip region (before '_' or '-'), only first 2 letters, etc.\n    Returns the chosen key (string) or None if none found.\n    \"\"\"\n    if not lang_code or not isinstance(lang_code, str):\n        return None\n\n    candidates = []\n    # raw\n    candidates.append(lang_code)\n    # strip after underscore/hyphen\n    if \"_\" in lang_code:\n        candidates.append(lang_code.split(\"_\")[0])\n        candidates.append(lang_code.replace(\"_\", \"-\"))\n    if \"-\" in lang_code:\n        candidates.append(lang_code.split(\"-\")[0])\n        candidates.append(lang_code.replace(\"-\", \"_\"))\n    # 2-letter ISO\n    if len(lang_code) >= 2:\n        candidates.append(lang_code[:2])\n\n    # final unique order-preserving\n    seen = set()\n    candidates = [c for c in candidates if c not in seen and not seen.add(c)]\n\n    # Try tokenizer-specific maps\n    try:\n        # check lang_code_to_id (MBART / MBART50)\n        if hasattr(tokenizer, \"lang_code_to_id\") and isinstance(tokenizer.lang_code_to_id, dict):\n            for c in candidates:\n                if c in tokenizer.lang_code_to_id:\n                    return c\n    except Exception:\n        pass\n\n    try:\n        # check lang_code_to_token (M2M100)\n        if hasattr(tokenizer, \"lang_code_to_token\") and isinstance(tokenizer.lang_code_to_token, dict):\n            for c in candidates:\n                if c in tokenizer.lang_code_to_token:\n                    return c\n    except Exception:\n        pass\n\n    try:\n        # get_lang_id fallback\n        if hasattr(tokenizer, \"get_lang_id\"):\n            for c in candidates:\n                try:\n                    lid = tokenizer.get_lang_id(c)\n                    if lid is not None and int(lid) >= 0:\n                        return c\n                except Exception:\n                    continue\n    except Exception:\n        pass\n\n    return None\n\ndef _set_tokenizer_langs_safe(tokenizer, src_lang: str, tgt_lang: str):\n    \"\"\"\n    Set tokenizer.src_lang and tokenizer.tgt_lang if possible, using _resolve_tokenizer_lang.\n    Returns tuple (resolved_src, resolved_tgt).\n    \"\"\"\n    resolved_src = _resolve_tokenizer_lang(tokenizer, src_lang)\n    resolved_tgt = _resolve_tokenizer_lang(tokenizer, tgt_lang)\n\n    if resolved_src:\n        try:\n            # try assignment; some tokenizers update special tokens on set\n            tokenizer.src_lang = resolved_src\n        except Exception:\n            # try alternate setter naming\n            try:\n                if hasattr(tokenizer, \"set_src_lang_special_tokens\"):\n                    tokenizer.set_src_lang_special_tokens(resolved_src)\n            except Exception:\n                pass\n\n    if resolved_tgt:\n        try:\n            tokenizer.tgt_lang = resolved_tgt\n        except Exception:\n            try:\n                if hasattr(tokenizer, \"set_tgt_lang_special_tokens\"):\n                    tokenizer.set_tgt_lang_special_tokens(resolved_tgt)\n            except Exception:\n                pass\n\n    return resolved_src, resolved_tgt\n\n\ntry:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"[STEP 2] Loading Trained Model...\")\n    print(\"=\" * 80)\n\n    if not os.path.exists(MODEL_CHECKPOINT_PATH):\n        available_models = [f for f in os.listdir(\"/kaggle/working/tatn_final.pt\") if f.endswith('.pt')]\n        print(f\"❌ Model not found: {MODEL_CHECKPOINT_PATH}\")\n        print(f\"📂 Available models in /kaggle/working/tatn_final.pt:\")\n        for model_file in available_models:\n            print(f\"   - {model_file}\")\n        raise FileNotFoundError(f\"Model checkpoint not found: {MODEL_CHECKPOINT_PATH}\\nAvailable models: {available_models}\")\n\n    print(f\"📂 Loading from: {MODEL_CHECKPOINT_PATH}\")\n    checkpoint = torch.load(MODEL_CHECKPOINT_PATH, map_location=_DEVICE, weights_only=False)\n    print(f\"✅ Checkpoint loaded successfully\")\n    print(f\"   Keys in checkpoint: {list(checkpoint.keys())}\")\n\n    # --- Tokenizer\n    if \"tokenizer\" in checkpoint and checkpoint[\"tokenizer\"] is not None:\n        tokenizer = checkpoint[\"tokenizer\"]\n        print(\"✅ Tokenizer loaded from checkpoint\")\n        # Try to set tokenizer languages safely (best-effort)\n        resolved_src, resolved_tgt = _set_tokenizer_langs_safe(tokenizer, _SOURCE_LANGUAGE, _TARGET_LANGUAGE)\n        print(f\"   Tokenizer language mapping (from checkpoint): src={resolved_src}, tgt={resolved_tgt}\")\n    else:\n        # Fallback: attempt to load a compatible tokenizer. Many training configs use mBART or M2M100.\n        from transformers import M2M100Tokenizer, MBart50TokenizerFast, MBartTokenizerFast\n        tokenizer_loaded = False\n        load_errors = []\n\n        # Try MBART50 first (most common in this repo)\n        try:\n            tok = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n            tokenizer = tok\n            tokenizer_loaded = True\n            print(\"⚠️  Tokenizer fallback: loaded MBart50TokenizerFast\")\n        except Exception as e:\n            load_errors.append((\"MBart50TokenizerFast\", str(e)))\n\n        # Try MBartTokenizerFast\n        if not tokenizer_loaded:\n            try:\n                tok = MBartTokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n                tokenizer = tok\n                tokenizer_loaded = True\n                print(\"⚠️  Tokenizer fallback: loaded MBartTokenizerFast\")\n            except Exception as e:\n                load_errors.append((\"MBartTokenizerFast\", str(e)))\n\n        # Try M2M100\n        if not tokenizer_loaded:\n            try:\n                tok = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n                tokenizer = tok\n                tokenizer_loaded = True\n                print(\"⚠️  Tokenizer fallback: loaded M2M100Tokenizer\")\n            except Exception as e:\n                load_errors.append((\"M2M100Tokenizer\", str(e)))\n\n        if not tokenizer_loaded:\n            print(\"❌ Could not load any fallback tokenizer. Errors:\")\n            for name, err in load_errors:\n                print(f\"   - {name}: {err}\")\n            raise RuntimeError(\"No fallback tokenizer available\")\n\n        # Now try to set language codes robustly\n        resolved_src, resolved_tgt = _set_tokenizer_langs_safe(tokenizer, _SOURCE_LANGUAGE, _TARGET_LANGUAGE)\n        print(f\"   Tokenizer language mapping (fallback): src={resolved_src}, tgt={resolved_tgt}\")\n\n        # If we didn't resolve either lang, try direct conservative fallback: strip region suffixes\n        if not resolved_src:\n            alt_src = _SOURCE_LANGUAGE.split(\"_\")[0] if \"_\" in _SOURCE_LANGUAGE else _SOURCE_LANGUAGE\n            try:\n                tokenizer.src_lang = alt_src\n                resolved_src = alt_src\n                print(f\"   Forcing tokenizer.src_lang -> {alt_src}\")\n            except Exception:\n                pass\n        if not resolved_tgt:\n            alt_tgt = _TARGET_LANGUAGE.split(\"_\")[0] if \"_\" in _TARGET_LANGUAGE else _TARGET_LANGUAGE\n            try:\n                tokenizer.tgt_lang = alt_tgt\n                resolved_tgt = alt_tgt\n                print(f\"   Forcing tokenizer.tgt_lang -> {alt_tgt}\")\n            except Exception:\n                pass\n\n    # --- Model state\n    if \"model\" in checkpoint:\n        model_state = checkpoint[\"model\"]\n    elif \"model_state_dict\" in checkpoint:\n        model_state = checkpoint[\"model_state_dict\"]\n    else:\n        raise ValueError(f\"No model state found in checkpoint. Keys: {list(checkpoint.keys())}\")\n\n    try:\n        TATNModelClass = globals().get(\"MemoryOptimizedTATNWithExplanations\") or globals().get(\"TATNModelWithDSCDAndASBN\")\n        if TATNModelClass is None:\n            raise RuntimeError(\"TATN model class not found. Run Cell 6 first.\")\n\n        print(f\"🔧 Initializing model...\")\n        model = TATNModelClass(tokenizer)\n\n        print(f\"🔧 Loading model state...\")\n        # attempt strict=False to allow mismatches\n        load_res = model.load_state_dict(model_state, strict=False)\n        # load_state_dict returns nothing or dict depending on implementation; handle both\n        try:\n            missing_keys = load_res.missing_keys if hasattr(load_res, 'missing_keys') else (load_res[0] if isinstance(load_res, tuple) else [])\n            unexpected_keys = load_res.unexpected_keys if hasattr(load_res, 'unexpected_keys') else (load_res[1] if isinstance(load_res, tuple) else [])\n        except Exception:\n            missing_keys, unexpected_keys = [], []\n\n        if missing_keys:\n            print(f\"⚠️  Missing keys: {len(missing_keys)}\")\n            if len(missing_keys) <= 10:\n                for key in missing_keys:\n                    print(f\"   - {key}\")\n\n        if unexpected_keys:\n            print(f\"⚠️  Unexpected keys: {len(unexpected_keys)}\")\n            if len(unexpected_keys) <= 10:\n                for key in unexpected_keys[:10]:\n                    print(f\"   - {key}\")\n            else:\n                print(f\"   ... and {len(unexpected_keys) - 10} more\")\n\n        model.to(_DEVICE)\n        model.eval()\n        print(f\"✅ Model loaded successfully\")\n        try:\n            dev = next(model.parameters()).device\n        except Exception:\n            dev = _DEVICE\n        print(f\"   Device: {dev}\")\n        print(f\"   Global step: {checkpoint.get('global_step', checkpoint.get('step', 'unknown'))}\")\n        print(f\"   Epoch: {checkpoint.get('epoch', 'unknown')}\")\n\n    except Exception as e:\n        print(f\"❌ Failed to load model: {e}\")\n        traceback.print_exc()\n        raise\n\n    # --- DSCD prototypes loading (unchanged logic but safe)\n    try:\n        print(f\"\\n[STEP 2.1] Loading DSCD Prototypes...\")\n        print(f\"🔍 Searching for prototypes in checkpoint...\")\n\n        if \"dscd_state\" in checkpoint:\n            dscd_state = checkpoint[\"dscd_state\"]\n            print(f\"   ✓ Found 'dscd_state' key\")\n            print(f\"   Type: {type(dscd_state)}\")\n\n            # Look for prototype_stores_data first\n            if isinstance(dscd_state, dict) and \"prototype_stores_data\" in dscd_state:\n                prototype_stores_raw = dscd_state[\"prototype_stores_data\"]\n                print(f\"\\n   ✓ Found 'prototype_stores_data' key!\")\n                print(f\"   Total tokens: {len(prototype_stores_raw) if isinstance(prototype_stores_raw, dict) else 'N/A'}\")\n\n                if isinstance(prototype_stores_raw, dict) and len(prototype_stores_raw) > 0:\n                    # Extract multi-sense prototypes; fallback to single-sense if none multi\n                    valid_prototypes = {}\n                    single_sense_count = 0\n                    for token, proto_list in prototype_stores_raw.items():\n                        if isinstance(proto_list, list):\n                            if len(proto_list) >= 2:\n                                valid_prototypes[token] = proto_list\n                            elif len(proto_list) == 1:\n                                single_sense_count += 1\n\n                    if len(valid_prototypes) == 0:\n                        # fallback: load all\n                        valid_prototypes = prototype_stores_raw.copy()\n\n                    # inject into model if possible\n                    if hasattr(model, 'dscd'):\n                        try:\n                            model.dscd._prototype_stores = valid_prototypes\n                            print(f\"\\n✅ Injected {len(valid_prototypes)} prototypes into model.dscd._prototype_stores\")\n                        except Exception:\n                            pass\n\n                    # prepare prototypes_data for use\n                    for token, proto_list in list(valid_prototypes.items())[:2000]:\n                        clean_token = token.replace('▁', '').strip()\n                        num_senses = len(proto_list) if isinstance(proto_list, list) else 0\n                        prototypes_data[clean_token] = {\n                            \"token\": token,\n                            \"num_senses\": num_senses,\n                            \"prototypes\": proto_list\n                        }\n\n            elif isinstance(dscd_state, dict) and \"_prototype_stores\" in dscd_state:\n                prototype_stores = dscd_state[\"_prototype_stores\"]\n                print(f\"   ✓ Found '_prototype_stores' key\")\n                if isinstance(prototype_stores, dict) and len(prototype_stores) > 0:\n                    if hasattr(model, 'dscd'):\n                        try:\n                            model.dscd._prototype_stores = prototype_stores\n                            print(f\"✅ Injected prototypes into model.dscd._prototype_stores\")\n                        except Exception:\n                            pass\n                    for token, proto_list in list(prototype_stores.items())[:2000]:\n                        clean_token = token.replace('▁', '').strip()\n                        prototypes_data[clean_token] = {\n                            \"token\": token,\n                            \"num_senses\": len(proto_list) if isinstance(proto_list, list) else 0,\n                            \"prototypes\": proto_list\n                        }\n            else:\n                print(f\"⚠️  No prototype keys found in dscd_state\")\n        else:\n            print(f\"⚠️  No 'dscd_state' key in checkpoint\")\n\n        # fallback: if model has dscd._prototype_stores\n        if not prototypes_data and hasattr(model, 'dscd') and hasattr(model.dscd, '_prototype_stores'):\n            try:\n                prototype_stores = model.dscd._prototype_stores\n                if isinstance(prototype_stores, dict) and len(prototype_stores) > 0:\n                    for token, proto_list in list(prototype_stores.items())[:2000]:\n                        clean_token = token.replace('▁', '').strip()\n                        prototypes_data[clean_token] = {\n                            \"token\": token,\n                            \"num_senses\": len(proto_list) if isinstance(proto_list, list) else 0,\n                            \"prototypes\": proto_list\n                        }\n                    print(f\"\\n✅ Found prototypes in model.dscd._prototype_stores: {len(prototype_stores)}\")\n            except Exception:\n                pass\n\n        # fallback: try load from PROTOTYPE_DIR file\n        if not prototypes_data and os.path.exists(PROTOTYPE_DIR):\n            proto_file = os.path.join(PROTOTYPE_DIR, \"dscd_prototypes.pt\")\n            if os.path.exists(proto_file):\n                try:\n                    loaded_protos = torch.load(proto_file, map_location=_DEVICE, weights_only=False)\n                    if isinstance(loaded_protos, dict) and len(loaded_protos) > 0:\n                        for token, proto_list in loaded_protos.items():\n                            clean_token = token.replace('▁', '').strip()\n                            prototypes_data[clean_token] = {\n                                \"token\": token,\n                                \"num_senses\": len(proto_list) if isinstance(proto_list, list) else 0,\n                                \"prototypes\": proto_list\n                            }\n                        if hasattr(model, 'dscd'):\n                            try:\n                                model.dscd._prototype_stores = loaded_protos\n                            except Exception:\n                                pass\n                        print(f\"✅ Loaded {len(prototypes_data)} prototypes from file\")\n                except Exception as e:\n                    print(f\"⚠️  Could not load prototype file: {e}\")\n\n        print(f\"\\n{'='*80}\")\n        if not prototypes_data:\n            print(f\"❌ CRITICAL: No prototypes found!\")\n            print(f\"\\n⚠️  Cell 12 will run WITHOUT prototypes\")\n            print(f\"   Translations will work, but:\")\n            print(f\"   - No homograph detection\")\n            print(f\"   - No sense disambiguation\")\n        else:\n            print(f\"✅ PROTOTYPE LOADING COMPLETE!\")\n            print(f\"   Total prototypes loaded: {len(prototypes_data)}\")\n            avg_senses = sum(p[\"num_senses\"] for p in prototypes_data.values()) / len(prototypes_data)\n            print(f\"   Average prototypes per token: {avg_senses:.1f}\")\n            multi_sense = sum(1 for p in prototypes_data.values() if p[\"num_senses\"] >= 2)\n            single_sense = sum(1 for p in prototypes_data.values() if p[\"num_senses\"] == 1)\n            print(f\"   Multi-sense tokens (≥2): {multi_sense}\")\n            print(f\"   Single-sense tokens (=1): {single_sense}\")\n            print(f\"   Ready for disambiguation!\")\n        print(f\"{'='*80}\\n\")\n\n    except Exception as e:\n        print(f\"\\n❌ FAILED TO LOAD PROTOTYPES: {e}\")\n        traceback.print_exc()\n\nexcept Exception as e:\n    print(f\"\\n❌ FAILED TO LOAD MODEL: {e}\")\n    traceback.print_exc()\n    print(\"\\nPlease ensure:\")\n    print(\"  1. Cell 0-11 have been run\")\n    print(\"  2. Training completed successfully\")\n    print(\"  3. Model checkpoint exists at:\", MODEL_CHECKPOINT_PATH)\n    raise\n\n\n# ==============================================================================\n# STEP 3: HELPER FUNCTIONS\n# ==============================================================================\ndef compute_similarity(text1: str, text2: str) -> float:\n    \"\"\"Compute word-level Jaccard similarity between two texts\"\"\"\n    words1 = set(str(text1).lower().split())\n    words2 = set(str(text2).lower().split())\n\n    if not words1 and not words2:\n        return 100.0\n    if not words1 or not words2:\n        return 0.0\n\n    intersection = len(words1 & words2)\n    union = len(words1 | words2)\n\n    return (intersection / union) * 100.0\n\n\ndef find_sense_from_prototypes(word: str, embedding: torch.Tensor, prototypes_data: Dict) -> Optional[Dict]:\n    \"\"\"Find which sense the word belongs to based on prototype similarity\"\"\"\n    if word not in prototypes_data:\n        return None\n\n    proto_info = prototypes_data[word]\n    proto_list = proto_info.get(\"prototypes\", [])\n\n    if not proto_list or not isinstance(proto_list, list):\n        return None\n\n    best_sense_idx = -1\n    best_similarity = -1.0\n    similarities = []\n\n    try:\n        # Ensure embedding is on CPU or GPU; compute normalized embedding on its device\n        emb_device = embedding.device if hasattr(embedding, \"device\") else _DEVICE\n        embedding_norm = F.normalize(embedding.flatten().unsqueeze(0).to(emb_device), dim=1)\n\n        for sense_idx, proto in enumerate(proto_list):\n            if isinstance(proto, dict) and \"centroid\" in proto:\n                centroid = proto[\"centroid\"]\n            elif isinstance(proto, torch.Tensor):\n                centroid = proto\n            else:\n                continue\n\n            # move centroid to embedding device for correct similarity calculation\n            try:\n                centroid = centroid.to(embedding_norm.device)\n            except Exception:\n                pass\n\n            centroid_norm = F.normalize(centroid.flatten().unsqueeze(0), dim=1)\n            similarity = F.cosine_similarity(embedding_norm, centroid_norm).item()\n            similarities.append(similarity)\n\n            if similarity > best_similarity:\n                best_similarity = similarity\n                best_sense_idx = sense_idx\n\n        if best_sense_idx >= 0:\n            return {\n                \"sense_index\": best_sense_idx,\n                \"similarity\": best_similarity,\n                \"num_senses\": len(proto_list),\n                \"all_similarities\": similarities\n            }\n\n    except Exception:\n        pass\n\n    return None\n\n\ndef translate_with_analysis(\n    sentence: str,\n    model,\n    tokenizer,\n    prototypes_data: Dict,\n    max_length: int = 128\n) -> Dict[str, Any]:\n    \"\"\"Translate sentence and analyze ambiguous words\"\"\"\n    result = {\n        \"input\": sentence,\n        \"translation\": \"\",\n        \"ambiguous_detections\": [],\n        \"sense_disambiguations\": [],\n        \"explanations\": [],\n        \"error\": None\n    }\n\n    try:\n        # set tokenizer source language if available (best-effort)\n        try:\n            # many tokenizers accept src_lang attribute (MBART/M2M)\n            tokenizer.src_lang = getattr(tokenizer, \"src_lang\", getattr(tokenizer, \"language\", None)) or tokenizer.src_lang\n        except Exception:\n            pass\n\n        inputs = tokenizer(\n            sentence,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=max_length\n        )\n\n        input_ids = inputs[\"input_ids\"].to(_DEVICE)\n        attention_mask = inputs[\"attention_mask\"].to(_DEVICE)\n\n        with torch.no_grad():\n            # forward should return encoder outputs and DSCD outputs in some dict form\n            forward_outputs = model.forward(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                src_texts=[sentence],\n                labels=None,\n                # model-specific flags - adapt if your model expects different args\n                use_dscd=True,\n                use_asbn=False,\n                return_dict=True\n            )\n\n            encoder_outputs = None\n            dscd_outputs = {}\n            explanations = []\n\n            if isinstance(forward_outputs, dict):\n                encoder_outputs = forward_outputs.get(\"encoder_outputs\") or forward_outputs.get(\"encoder_last_hidden_state\") or forward_outputs.get(\"last_hidden_state\")\n                dscd_outputs = forward_outputs.get(\"dscd_outputs\", forward_outputs.get(\"dscd\", {})) or {}\n                explanations = forward_outputs.get(\"explanations\", [[]])[0] if forward_outputs.get(\"explanations\") is not None else []\n                result[\"explanations\"] = explanations\n            else:\n                # model-specific: if object-like outputs, try attributes (robust)\n                try:\n                    encoder_outputs = getattr(forward_outputs, \"encoder_last_hidden_state\", None) or getattr(forward_outputs, \"last_hidden_state\", None)\n                except Exception:\n                    encoder_outputs = forward_outputs\n\n            # tokens & DSCD signals\n            tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().tolist())\n            uncertainties = dscd_outputs.get(\"uncertainties\", [[]])[0] if dscd_outputs else []\n            span_preds = dscd_outputs.get(\"span_preds\", [[]])[0] if dscd_outputs else []\n            h_augmented = dscd_outputs.get(\"h_augmented\") if dscd_outputs else None\n\n            for idx, token in enumerate(tokens):\n                clean_token = token.replace('▁', '').replace('##', '').strip()\n                if len(clean_token) < 1:\n                    continue\n\n                try:\n                    unc_val = uncertainties[idx] if idx < len(uncertainties) else 0.0\n                    if isinstance(unc_val, torch.Tensor):\n                        uncertainty = float(unc_val.item())\n                    else:\n                        uncertainty = float(unc_val)\n                except Exception:\n                    uncertainty = 0.0\n\n                try:\n                    span_val = span_preds[idx] if idx < len(span_preds) else 0.0\n                    if isinstance(span_val, torch.Tensor):\n                        span = float(span_val.item())\n                    else:\n                        span = float(span_val)\n                except Exception:\n                    span = 0.0\n\n                is_in_prototypes = clean_token in prototypes_data\n\n                if uncertainty > 0.10 or span > 0.10 or is_in_prototypes:\n                    detection = {\n                        \"word\": clean_token,\n                        \"token\": token,\n                        \"position\": idx,\n                        \"uncertainty\": uncertainty,\n                        \"span\": span,\n                        \"is_homograph\": is_in_prototypes\n                    }\n\n                    if is_in_prototypes and h_augmented is not None:\n                        try:\n                            # h_augmented expected shape: (batch, seq_len, hidden)\n                            embedding = h_augmented[0, idx, :].detach()\n                            sense_info = find_sense_from_prototypes(clean_token, embedding, prototypes_data)\n                            if sense_info:\n                                detection[\"sense_info\"] = sense_info\n                                result[\"sense_disambiguations\"].append({\n                                    \"word\": clean_token,\n                                    \"selected_sense\": sense_info[\"sense_index\"],\n                                    \"confidence\": sense_info[\"similarity\"],\n                                    \"num_senses\": sense_info[\"num_senses\"],\n                                    \"reason\": f\"Matched sense {sense_info['sense_index']+1}/{sense_info['num_senses']} with {sense_info['similarity']:.1%} confidence\"\n                                })\n                        except Exception:\n                            pass\n\n                    result[\"ambiguous_detections\"].append(detection)\n\n        # prepare for generation: set target language safe (best-effort)\n        try:\n            tokenizer.tgt_lang = getattr(tokenizer, \"tgt_lang\", getattr(tokenizer, \"language\", None)) or tokenizer.tgt_lang\n        except Exception:\n            pass\n\n        # Use core.mbart.generate if model wraps MBART; otherwise try model.generate\n        generated = None\n        try:\n            # If encoder_outputs came as tensor or BaseModelOutput, pass accordingly\n            if hasattr(model, \"mbart\") and hasattr(model.mbart, \"generate\"):\n                # many wrappers expect encoder_outputs as BaseModelOutput with last_hidden_state\n                enc_out = None\n                if isinstance(encoder_outputs, dict) and \"last_hidden_state\" in encoder_outputs:\n                    enc_out = encoder_outputs\n                elif hasattr(encoder_outputs, \"last_hidden_state\"):\n                    enc_out = encoder_outputs\n                else:\n                    # try to wrap if tensor\n                    try:\n                        enc_out = BaseModelOutput(last_hidden_state=encoder_outputs)\n                    except Exception:\n                        enc_out = None\n\n                generated = model.mbart.generate(\n                    input_ids=None if enc_out is not None else input_ids,\n                    encoder_outputs=enc_out,\n                    attention_mask=attention_mask,\n                    max_length=max_length,\n                    num_beams=5,\n                    early_stopping=True,\n                )\n            else:\n                # fallback to wrapper generate\n                generated = model.generate(\n                    input_ids=None,\n                    attention_mask=attention_mask,\n                    encoder_outputs=encoder_outputs,\n                    max_length=max_length,\n                    num_beams=5,\n                    early_stopping=True,\n                )\n        except Exception as e:\n            # store generation failure but still continue\n            result[\"error\"] = f\"Generation failed: {type(e).__name__}: {e}\"\n            traceback.print_exc()\n            return result\n\n        try:\n            # decode generated ids\n            if generated is not None:\n                gen_ids = generated[0] if isinstance(generated, (list, tuple)) else generated[0]\n                gen_ids = gen_ids.detach().cpu().tolist() if hasattr(gen_ids, \"detach\") else gen_ids\n                translation = tokenizer.decode(gen_ids, skip_special_tokens=True)\n            else:\n                translation = \"\"\n            result[\"translation\"] = translation\n        except Exception:\n            try:\n                result[\"translation\"] = tokenizer.decode(generated[0], skip_special_tokens=True)\n            except Exception:\n                result[\"translation\"] = \"\"\n\n    except Exception as e:\n        result[\"error\"] = str(e)\n        result[\"translation\"] = \"[ERROR]\"\n        traceback.print_exc()\n\n    return result\n\n\n# ==============================================================================\n# STEP 4: RUN TRANSLATION TESTS\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"[STEP 4] Running Translation Tests...\")\nprint(\"=\" * 80 + \"\\n\")\n\nall_results = []\n\nfor test_case in TEST_SENTENCES:\n    print(f\"\\n{'='*60}\")\n    print(f\"TEST {test_case['id']}/{len(TEST_SENTENCES)}\")\n    print(f\"{'='*60}\")\n\n    print(f\"\\n📝 INPUT ({_SOURCE_LANGUAGE}):\")\n    print(f\"   {test_case['input']}\")\n\n    print(f\"\\n🎯 EXPECTED ({_TARGET_LANGUAGE}):\")\n    print(f\"   {test_case['expected']}\")\n\n    result = translate_with_analysis(\n        test_case['input'],\n        model,\n        tokenizer,\n        prototypes_data,\n        max_length=128\n    )\n\n    if result[\"error\"]:\n        print(f\"\\n❌ ERROR: {result['error']}\")\n        similarity = 0.0\n    else:\n        print(f\"\\n🤖 TRANSLATION ({_TARGET_LANGUAGE}):\")\n        print(f\"   {result['translation']}\")\n\n        similarity = compute_similarity(result[\"translation\"], test_case[\"expected\"])\n        print(f\"\\n📊 SIMILARITY: {similarity:.1f}%\")\n\n        if similarity >= 70:\n            print(f\"   ✅ EXCELLENT\")\n        elif similarity >= 50:\n            print(f\"   ✓ GOOD\")\n        elif similarity >= 30:\n            print(f\"   ~ ACCEPTABLE\")\n        else:\n            print(f\"   ❌ NEEDS IMPROVEMENT\")\n\n    num_ambiguous = len(result[\"ambiguous_detections\"])\n    print(f\"\\n🔍 AMBIGUOUS WORDS DETECTED: {num_ambiguous}\")\n\n    if num_ambiguous > 0:\n        for detection in result[\"ambiguous_detections\"]:\n            word = detection[\"word\"]\n            uncertainty = detection[\"uncertainty\"]\n            span = detection[\"span\"]\n            is_homograph = detection[\"is_homograph\"]\n\n            marker = \"🟢\" if is_homograph else \"🟡\"\n            status = \"HOMOGRAPH\" if is_homograph else \"uncertain\"\n\n            print(f\"\\n   {marker} '{word}' ({status})\")\n            print(f\"      Uncertainty: {uncertainty:.3f}\")\n            print(f\"      Span: {span:.3f}\")\n\n            if \"sense_info\" in detection:\n                sense_info = detection[\"sense_info\"]\n                print(f\"      ✓ SENSE DETECTED: {sense_info['sense_index']+1}/{sense_info['num_senses']}\")\n                print(f\"      ✓ CONFIDENCE: {sense_info['similarity']:.1%}\")\n\n                if len(sense_info.get('all_similarities', [])) > 1:\n                    print(f\"      All similarities: {[f'{s:.2f}' for s in sense_info['all_similarities']]}\")\n\n    if len(result[\"sense_disambiguations\"]) > 0:\n        print(f\"\\n💡 SENSE DISAMBIGUATION:\")\n        for disamb in result[\"sense_disambiguations\"]:\n            print(f\"   ✓ '{disamb['word']}': {disamb['reason']}\")\n\n    if len(result[\"explanations\"]) > 0:\n        print(f\"\\n📖 EXPLANATIONS ({len(result['explanations'])}):\")\n        for i, exp in enumerate(result[\"explanations\"][:3], 1):\n            if isinstance(exp, dict):\n                word = exp.get('token', 'unknown')\n                explanation = exp.get('explanation', 'N/A')\n                print(f\"   {i}. {word}: {explanation}\")\n\n    result[\"test_id\"] = test_case[\"id\"]\n    result[\"expected\"] = test_case[\"expected\"]\n    result[\"similarity\"] = similarity\n    all_results.append(result)\n\n    print(f\"\\n{'='*60}\\n\")\n\n\n# ==============================================================================\n# STEP 5: SUMMARY REPORT\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"[STEP 5] SUMMARY REPORT\")\nprint(\"=\" * 80)\n\ntotal_tests = len(all_results)\nsuccessful_tests = sum(1 for r in all_results if r[\"error\"] is None)\navg_similarity = sum(r[\"similarity\"] for r in all_results) / total_tests if total_tests > 0 else 0.0\ntotal_ambiguous = sum(len(r[\"ambiguous_detections\"]) for r in all_results)\ntotal_disambiguations = sum(len(r[\"sense_disambiguations\"]) for r in all_results)\ntotal_explanations = sum(len(r[\"explanations\"]) for r in all_results)\n\nprint(f\"\\n📊 TRANSLATION QUALITY:\")\nprint(f\"   Total tests: {total_tests}\")\nprint(f\"   Successful: {successful_tests} ({successful_tests/total_tests*100:.1f}%)\")\nprint(f\"   Average similarity: {avg_similarity:.1f}%\")\n\nprint(f\"\\n🔍 AMBIGUITY DETECTION:\")\nprint(f\"   Total ambiguous words detected: {total_ambiguous}\")\nprint(f\"   Average per sentence: {total_ambiguous/total_tests:.1f}\")\n\nprint(f\"\\n💡 SENSE DISAMBIGUATION:\")\nprint(f\"   Total disambiguations: {total_disambiguations}\")\nprint(f\"   Coverage: {total_disambiguations/total_ambiguous*100:.1f}%\" if total_ambiguous > 0 else \"   Coverage: N/A\")\n\nprint(f\"\\n📖 EXPLANATIONS:\")\nprint(f\"   Total explanations: {total_explanations}\")\nprint(f\"   Average per sentence: {total_explanations/total_tests:.1f}\")\n\nhomograph_coverage = {}\nfor test_case in TEST_SENTENCES:\n    for ambig_word in test_case.get(\"ambiguous_words\", []):\n        if ambig_word not in homograph_coverage:\n            homograph_coverage[ambig_word] = {\"expected\": 0, \"detected\": 0}\n        homograph_coverage[ambig_word][\"expected\"] += 1\n\nfor result in all_results:\n    for detection in result[\"ambiguous_detections\"]:\n        word = detection[\"word\"]\n        if word in homograph_coverage:\n            homograph_coverage[word][\"detected\"] += 1\n\nprint(f\"\\n🎯 HOMOGRAPH DETECTION ACCURACY:\")\nfor word, stats in homograph_coverage.items():\n    detection_rate = stats[\"detected\"] / stats[\"expected\"] * 100 if stats[\"expected\"] > 0 else 0\n    marker = \"✅\" if detection_rate >= 80 else \"⚠️\" if detection_rate >= 50 else \"❌\"\n    print(f\"   {marker} {word}: {stats['detected']}/{stats['expected']} ({detection_rate:.0f}%)\")\n\nprint(f\"\\n🔬 PROTOTYPE STATISTICS:\")\nif prototypes_data:\n    print(f\"   Total prototypes loaded: {len(prototypes_data)}\")\n    avg_senses = sum(p[\"num_senses\"] for p in prototypes_data.values()) / len(prototypes_data)\n    print(f\"   Average prototypes per token: {avg_senses:.1f}\")\n    multi_sense = sum(1 for p in prototypes_data.values() if p[\"num_senses\"] >= 2)\n    single_sense = sum(1 for p in prototypes_data.values() if p[\"num_senses\"] == 1)\n    print(f\"   Multi-sense tokens (≥2): {multi_sense}\")\n    print(f\"   Single-sense tokens (=1): {single_sense}\")\n\n    if multi_sense > 0:\n        print(f\"\\n   Sample multi-sense prototypes:\")\n        count = 0\n        for word, info in prototypes_data.items():\n            if info[\"num_senses\"] >= 2:\n                print(f\"      {word}: {info['num_senses']} senses\")\n                count += 1\n                if count >= 5:\n                    break\nelse:\n    print(f\"   ⚠️  No prototypes loaded\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CELL 12: TRANSLATION TEST COMPLETE\")\nprint(\"=\" * 80)\nprint(f\"\\n✅ Execution completed (note: errors may be reported above)\")\n\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"id":"oDQGVh5w_oAx","execution":{"iopub.status.busy":"2026-02-18T09:34:16.968566Z","iopub.execute_input":"2026-02-18T09:34:16.968839Z","iopub.status.idle":"2026-02-18T09:34:42.085879Z","shell.execute_reply.started":"2026-02-18T09:34:16.968817Z","shell.execute_reply":"2026-02-18T09:34:42.085290Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCELL 12: TRANSLATION TEST WITH SENSE DISAMBIGUATION\n================================================================================\nDevice: cuda\nTranslation: bn_IN → en_XX\n================================================================================\n\n[STEP 1] Loaded 13 test sentences\n\n================================================================================\n[STEP 2] Loading Trained Model...\n================================================================================\n📂 Loading from: /kaggle/working/tatn_final.pt\n✅ Checkpoint loaded successfully\n   Keys in checkpoint: ['model_state_dict', 'dscd_state', 'optimizer_state_dict', 'training_stats', 'baseline_metrics', 'eval_results', 'discovery_success', 'timestamp', 'config']\n⚠️  Tokenizer fallback: loaded MBart50TokenizerFast\n   Tokenizer language mapping (fallback): src=bn_IN, tgt=en_XX\n🔧 Initializing model...\n[TATN-INIT] ✅ Vocab sizes match: 250054\n🔧 Loading model state...\n⚠️  Unexpected keys: 4\n   - dscd.prototype_stores_data\n   - dscd.discovered_homographs\n   - trg.dscd_module.prototype_stores_data\n   - trg.dscd_module.discovered_homographs\n✅ Model loaded successfully\n   Device: cuda:0\n   Global step: unknown\n   Epoch: unknown\n\n[STEP 2.1] Loading DSCD Prototypes...\n🔍 Searching for prototypes in checkpoint...\n   ✓ Found 'dscd_state' key\n   Type: <class 'collections.OrderedDict'>\n\n   ✓ Found 'prototype_stores_data' key!\n   Total tokens: 22880\n\n✅ Injected 22880 prototypes into model.dscd._prototype_stores\n\n================================================================================\n✅ PROTOTYPE LOADING COMPLETE!\n   Total prototypes loaded: 2000\n   Average prototypes per token: 0.0\n   Multi-sense tokens (≥2): 0\n   Single-sense tokens (=1): 0\n   Ready for disambiguation!\n================================================================================\n\n\n================================================================================\n[STEP 4] Running Translation Tests...\n================================================================================\n\n\n============================================================\nTEST 1/13\n============================================================\n\n📝 INPUT (bn_IN):\n   আমি ব্যাংকে টাকা জমা করি।\n\n🎯 EXPECTED (en_XX):\n   I deposit money in the bank.\n\n🤖 TRANSLATION (en_XX):\n   i have to do it. i have to do it.\n\n📊 SIMILARITY: 10.0%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 4\n\n   🟢 'আমি' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'ব্যাংক' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'টাকা' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'করি' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 2/13\n============================================================\n\n📝 INPUT (bn_IN):\n   নদীর ব্যাংকে অনেক গাছ আছে।\n\n🎯 EXPECTED (en_XX):\n   There are many trees on the river bank.\n\n🤖 TRANSLATION (en_XX):\n   there are a number of rivers in the country.\n\n📊 SIMILARITY: 21.4%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 3\n\n   🟢 'ব্যাংক' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'অনেক' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'আছে' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 3/13\n============================================================\n\n📝 INPUT (bn_IN):\n   কাল আমি বাজারে যাব।\n\n🎯 EXPECTED (en_XX):\n   I will go to the market tomorrow.\n\n🤖 TRANSLATION (en_XX):\n   i want to go to the market. i want to go shopping.\n\n📊 SIMILARITY: 40.0%\n   ~ ACCEPTABLE\n\n🔍 AMBIGUOUS WORDS DETECTED: 2\n\n   🟢 'কাল' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'আমি' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 4/13\n============================================================\n\n📝 INPUT (bn_IN):\n   কাল অন্ধকার রাত ছিল।\n\n🎯 EXPECTED (en_XX):\n   It was a dark black night.\n\n🤖 TRANSLATION (en_XX):\n   it was a night of darkness.\n\n📊 SIMILARITY: 33.3%\n   ~ ACCEPTABLE\n\n🔍 AMBIGUOUS WORDS DETECTED: 3\n\n   🟢 'কাল' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'রাত' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'ছিল' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 5/13\n============================================================\n\n📝 INPUT (bn_IN):\n   গাছের পাতা সবুজ।\n\n🎯 EXPECTED (en_XX):\n   The leaves of the tree are green.\n\n🤖 TRANSLATION (en_XX):\n   the tree is green.\n\n📊 SIMILARITY: 42.9%\n   ~ ACCEPTABLE\n\n🔍 AMBIGUOUS WORDS DETECTED: 0\n\n============================================================\n\n\n============================================================\nTEST 6/13\n============================================================\n\n📝 INPUT (bn_IN):\n   বই পাতা উল্টাও।\n\n🎯 EXPECTED (en_XX):\n   Turn the pages of the book.\n\n🤖 TRANSLATION (en_XX):\n   back to the original page.\n\n📊 SIMILARITY: 11.1%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 0\n\n============================================================\n\n\n============================================================\nTEST 7/13\n============================================================\n\n📝 INPUT (bn_IN):\n   ফুটবল খেলায় বল লাথি মারা হয়।\n\n🎯 EXPECTED (en_XX):\n   In football, the ball is kicked.\n\n🤖 TRANSLATION (en_XX):\n   he said that he was injured in the accident.\n\n📊 SIMILARITY: 16.7%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 3\n\n   🟢 'খেলা' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'মারা' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'হয়' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 8/13\n============================================================\n\n📝 INPUT (bn_IN):\n   আমার বল বেশি তাই আমি জিতব।\n\n🎯 EXPECTED (en_XX):\n   My strength is more so I will win.\n\n🤖 TRANSLATION (en_XX):\n   i want to win. i want to win.\n\n📊 SIMILARITY: 20.0%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 4\n\n   🟢 'আমার' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'বেশি' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'তাই' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'আমি' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 9/13\n============================================================\n\n📝 INPUT (bn_IN):\n   চোরকে ধরা হয়েছে।\n\n🎯 EXPECTED (en_XX):\n   The thief has been caught.\n\n🤖 TRANSLATION (en_XX):\n   he was arrested by the police.\n\n📊 SIMILARITY: 10.0%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 1\n\n   🟢 'হয়েছে' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 10/13\n============================================================\n\n📝 INPUT (bn_IN):\n   আকাশে চাঁদ ধরা দিয়েছে।\n\n🎯 EXPECTED (en_XX):\n   The moon has appeared in the sky.\n\n🤖 TRANSLATION (en_XX):\n   the sky is cloudy with clouds.\n\n📊 SIMILARITY: 9.1%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 1\n\n   🟢 'দিয়েছে' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 11/13\n============================================================\n\n📝 INPUT (bn_IN):\n   সে খুব মিষ্টি কথা বলে।\n\n🎯 EXPECTED (en_XX):\n   She speaks very sweetly.\n\n🤖 TRANSLATION (en_XX):\n   he said that he is very proud of himself.\n\n📊 SIMILARITY: 9.1%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 3\n\n   🟢 'খুব' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'কথা' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'বলে' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 12/13\n============================================================\n\n📝 INPUT (bn_IN):\n   তিনি ব্যাংকে কাজ করেন এবং নদীর ব্যাংকে বসে থাকেন।\n\n🎯 EXPECTED (en_XX):\n   He works at the bank and sits on the river bank.\n\n🤖 TRANSLATION (en_XX):\n   he worked in banking and finance. he also worked in banking and finance.\n\n📊 SIMILARITY: 13.3%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 7\n\n   🟢 'তিনি' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'ব্যাংক' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'কাজ' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'করেন' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'এবং' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'ব্যাংক' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'থাকে' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n============================================================\nTEST 13/13\n============================================================\n\n📝 INPUT (bn_IN):\n   কাল কালো মেঘ ছিল।\n\n🎯 EXPECTED (en_XX):\n   Yesterday there were black clouds.\n\n🤖 TRANSLATION (en_XX):\n   there was a slight rainfall in the afternoon and a slight rain in the evening.\n\n📊 SIMILARITY: 6.7%\n   ❌ NEEDS IMPROVEMENT\n\n🔍 AMBIGUOUS WORDS DETECTED: 2\n\n   🟢 'কাল' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n   🟢 'ছিল' (HOMOGRAPH)\n      Uncertainty: 0.000\n      Span: 0.000\n\n============================================================\n\n\n================================================================================\n[STEP 5] SUMMARY REPORT\n================================================================================\n\n📊 TRANSLATION QUALITY:\n   Total tests: 13\n   Successful: 13 (100.0%)\n   Average similarity: 18.7%\n\n🔍 AMBIGUITY DETECTION:\n   Total ambiguous words detected: 33\n   Average per sentence: 2.5\n\n💡 SENSE DISAMBIGUATION:\n   Total disambiguations: 0\n   Coverage: 0.0%\n\n📖 EXPLANATIONS:\n   Total explanations: 0\n   Average per sentence: 0.0\n\n🎯 HOMOGRAPH DETECTION ACCURACY:\n   ✅ ব্যাংক: 4/4 (100%)\n   ✅ কাল: 3/3 (100%)\n   ❌ পাতা: 0/2 (0%)\n   ❌ বল: 0/2 (0%)\n   ❌ ধরা: 0/2 (0%)\n   ✅ কথা: 1/1 (100%)\n\n🔬 PROTOTYPE STATISTICS:\n   Total prototypes loaded: 2000\n   Average prototypes per token: 0.0\n   Multi-sense tokens (≥2): 0\n   Single-sense tokens (=1): 0\n\n================================================================================\nCELL 12: TRANSLATION TEST COMPLETE\n================================================================================\n\n✅ Execution completed (note: errors may be reported above)\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"135"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# ==============================================================================\n# CELL 13: MEMORY CLEANUP + BLEU & CHRF++ & COMET EVALUATION (MBART-50)\n# ==============================================================================\nimport os\nimport sys\nimport time\nimport csv\nimport gc\nfrom typing import List, Dict, Tuple, Optional, Any\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nimport torch\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CELL 13: EVALUATION WITH MEMORY MANAGEMENT (MBART-50)\")\nprint(\"=\" * 80)\n\n\n# ==============================================================================\n# SECTION 1: MEMORY CLEANUP\n# ==============================================================================\nprint(\"\\n[SECTION 1] Memory Cleanup...\")\nprint(\"-\" * 80)\n\n\nif torch.cuda.is_available():\n    try:\n        initial_allocated = torch.cuda.memory_allocated(0) / 1024**3\n        initial_reserved = torch.cuda.memory_reserved(0) / 1024**3\n        print(f\"📊 BEFORE CLEANUP:\")\n        print(f\"   Allocated: {initial_allocated:.2f} GB\")\n        print(f\"   Reserved: {initial_reserved:.2f} GB\")\n    except Exception:\n        pass\n\n\n# Delete common large variables from global scope to reduce memory pressure\nvariables_to_delete = [\n    'model', 'tatn_model',\n    'tokenizer',\n    'optimizer', 'scheduler',\n    'train_dataloader', 'val_dataloader',\n    'checkpoint', 'model_state',\n    'training_args', 'trainer',\n    'dscd_outputs', 'asbn_outputs', 'trg_outputs',\n    'encoder_outputs', 'forward_outputs',\n    'prototypes_data', 'all_results',\n    'result', 'test_case',\n    'baseline_model', 'baseline_tokenizer', 'baseline_translations'\n]\n\n\ndeleted_count = 0\nfor var_name in variables_to_delete:\n    if var_name in globals():\n        try:\n            del globals()[var_name]\n            deleted_count += 1\n        except Exception:\n            pass\n\n\nprint(f\"✓ Attempted to delete {deleted_count} variables\")\n\n\n# Force garbage collection\ngc.collect()\nprint(f\"✓ Python garbage collection invoked\")\n\n\n# Clear CUDA cache\nif torch.cuda.is_available():\n    try:\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n        print(f\"✓ CUDA cache cleared\")\n        final_allocated = torch.cuda.memory_allocated(0) / 1024**3\n        final_reserved = torch.cuda.memory_reserved(0) / 1024**3\n        print(f\"\\n📊 AFTER CLEANUP:\")\n        print(f\"   Allocated: {final_allocated:.2f} GB\")\n        print(f\"   Reserved: {final_reserved:.2f} GB\")\n        try:\n            print(f\"   Memory freed: {initial_allocated - final_allocated:.2f} GB allocated, {initial_reserved - final_reserved:.2f} GB reserved\")\n        except Exception:\n            pass\n    except Exception:\n        pass\n\n\nprint(\"\\n✅ Memory cleanup complete - Ready for evaluation\")\nprint(\"=\" * 80)\n\n\n# ==============================================================================\n# SECTION 2: SETUP AND IMPORTS\n# ==============================================================================\nprint(\"\\n[SECTION 2] Setup and Imports...\")\nprint(\"-\" * 80)\n\n\ntry:\n    import sacrebleu\n    print(f\"✅ sacrebleu version: {sacrebleu.__version__}\")\nexcept Exception:\n    print(\"⚠️  sacrebleu not available — attempting install...\")\n    import subprocess\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"sacrebleu\"])\n    import sacrebleu\n    print(f\"✅ sacrebleu version: {sacrebleu.__version__}\")\n\n\n# Install COMET (official Unbabel package)\ntry:\n    from comet import download_model, load_from_checkpoint\n    print(f\"✅ unbabel-comet already installed\")\nexcept Exception:\n    print(\"⚠️  unbabel-comet not available — installing...\")\n    import subprocess\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"unbabel-comet\"])\n    from comet import download_model, load_from_checkpoint\n    print(f\"✅ unbabel-comet installed successfully\")\n\n\ntry:\n    _DEVICE = DEVICE if isinstance(DEVICE, torch.device) else torch.device(str(DEVICE)) if isinstance(DEVICE, str) else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\n    _TARGET_LANGUAGE = str(TARGET_LANGUAGE)\n    _MAX_LENGTH = int(MAX_LENGTH)\n    _EVAL_BATCH_SIZE = int(EVAL_BATCH_SIZE) if \"EVAL_BATCH_SIZE\" in globals() else 4\n    _EVAL_NUM_BEAMS = int(EVAL_NUM_BEAMS) if \"EVAL_NUM_BEAMS\" in globals() else 5\nexcept Exception:\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = \"bn_IN\"\n    _TARGET_LANGUAGE = \"en_XX\"\n    _MAX_LENGTH = 256\n    _EVAL_BATCH_SIZE = 4\n    _EVAL_NUM_BEAMS = 8\n\n\nprint(f\"✅ Configuration loaded\")\nprint(f\"   Device: {_DEVICE}\")\nprint(f\"   Direction: {_SOURCE_LANGUAGE} → {_TARGET_LANGUAGE}\")\nprint(f\"   Max length: {_MAX_LENGTH}\")\nprint(f\"   Batch size: {_EVAL_BATCH_SIZE}\")\nprint(f\"   Num beams: {_EVAL_NUM_BEAMS}\")\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 3: LOAD DATASET (5K SAMPLES)\n# ==============================================================================\nDATASET_PATH = \"/kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\"\nNUM_EVAL_SAMPLES = 5000\n\n\nprint(f\"\\n[SECTION 3] Loading Dataset...\")\nprint(\"-\" * 80)\nprint(f\"Path: {DATASET_PATH}\")\nprint(f\"Samples: {NUM_EVAL_SAMPLES}\")\n\n\nif not os.path.exists(DATASET_PATH):\n    raise FileNotFoundError(f\"Dataset not found: {DATASET_PATH}\")\n\n\ntry:\n    df = pd.read_csv(DATASET_PATH, nrows=NUM_EVAL_SAMPLES)\n    print(f\"✅ Loaded {len(df)} rows\")\n    print(f\"   Columns: {list(df.columns)}\")\n\n\n    # CRITICAL: Swap columns since dataset has src=English, tgt=Bengali\n    # But we need src=Bengali, tgt=English for bn→en translation\n    if 'src' in df.columns and 'tgt' in df.columns:\n        print(f\"\\n⚠️  SWAPPING COLUMNS:\")\n        print(f\"   Dataset has: src=English, tgt=Bengali\")\n        print(f\"   We need: src=Bengali, tgt=English\")\n\n\n        # Swap the columns\n        df_eval = pd.DataFrame({\n            'src': df['tgt'].values,  # Bengali becomes source\n            'tgt': df['src'].values   # English becomes target\n        })\n\n\n        print(f\"\\n✅ After swap:\")\n        print(f\"   src: {_SOURCE_LANGUAGE} (Bengali)\")\n        print(f\"   tgt: {_TARGET_LANGUAGE} (English)\")\n        print(f\"\\n   Sample 1:\")\n        print(f\"      SRC (bn): {df_eval['src'].iloc[0][:80]}...\")\n        print(f\"      TGT (en): {df_eval['tgt'].iloc[0][:80]}...\")\n\n\n    elif 'source' in df.columns and 'target' in df.columns:\n        df_eval = df.rename(columns={'source': 'src', 'target': 'tgt'})\n        df_eval = pd.DataFrame({\n            'src': df_eval['tgt'].values,\n            'tgt': df_eval['src'].values\n        })\n    else:\n        raise ValueError(f\"Unexpected columns: {list(df.columns)}\")\n\n\n    sources = df_eval['src'].tolist()\n    references = df_eval['tgt'].tolist()\n\n\n    # Free up memory\n    del df, df_eval\n    gc.collect()\n\n\n    print(f\"\\n✅ Prepared {len(sources)} samples for evaluation\")\n    print(\"=\" * 80)\n\n\nexcept Exception as e:\n    print(f\"❌ Failed to load dataset: {e}\")\n    raise\n\n\n\n# ==============================================================================\n# SECTION 4: LOAD TRAINED TATN MODEL (MBART-50)\n# ==============================================================================\nMODEL_CHECKPOINT_PATH = \"/kaggle/working/tatn_final.pt\"\n\n\nprint(f\"\\n[SECTION 4] Loading Trained TATN Model (mBART-50)...\")\nprint(\"-\" * 80)\nprint(f\"Path: {MODEL_CHECKPOINT_PATH}\")\n\n\nif not os.path.exists(MODEL_CHECKPOINT_PATH):\n    raise FileNotFoundError(f\"Model checkpoint not found: {MODEL_CHECKPOINT_PATH}\")\n\n\ntry:\n    # Load checkpoint to CPU first to avoid OOM\n    print(f\"📂 Loading checkpoint to CPU...\")\n    checkpoint = torch.load(MODEL_CHECKPOINT_PATH, map_location='cpu', weights_only=False)\n    print(f\"✅ Checkpoint loaded to CPU\")\n\n\n    # CRITICAL FIX: Use MBart50Tokenizer for mBART-50 model\n    if \"tokenizer\" in checkpoint:\n        tokenizer = checkpoint[\"tokenizer\"]\n        print(f\"✅ Tokenizer loaded from checkpoint\")\n    else:\n        from transformers import MBart50Tokenizer  # ← FIXED: Use MBart50Tokenizer\n        tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50\")\n        print(f\"✅ MBart50Tokenizer loaded from pretrained\")\n\n\n    # Set language codes (correct for mBART-50)\n    tokenizer.src_lang = _SOURCE_LANGUAGE  # \"bn_IN\"\n    tokenizer.tgt_lang = _TARGET_LANGUAGE  # \"en_XX\"\n    print(f\"✅ Language codes set: {_SOURCE_LANGUAGE} → {_TARGET_LANGUAGE}\")\n\n\n    TATNModelClass = globals().get(\"MemoryOptimizedTATNWithExplanations\") or globals().get(\"TATNModelWithDSCDAndASBN\")\n    if TATNModelClass is None:\n        raise RuntimeError(\"TATN model class not found. Run Cell 6 first.\")\n\n\n    print(f\"🔧 Initializing TATN model...\")\n    tatn_model = TATNModelClass(tokenizer)\n\n\n    if \"model\" in checkpoint:\n        model_state = checkpoint[\"model\"]\n    elif \"model_state_dict\" in checkpoint:\n        model_state = checkpoint[\"model_state_dict\"]\n    else:\n        raise ValueError(\"No model state found in checkpoint\")\n\n\n    print(f\"🔧 Loading model weights (strict=False)...\")\n    tatn_model.load_state_dict(model_state, strict=False)\n\n\n    # Free checkpoint memory before moving to GPU\n    try:\n        del model_state\n    except Exception:\n        pass\n    if 'dscd_state' in checkpoint:\n        try:\n            del checkpoint['dscd_state']\n        except Exception:\n            pass\n    try:\n        del checkpoint\n    except Exception:\n        pass\n    gc.collect()\n    torch.cuda.empty_cache()\n\n\n    print(f\"🔧 Moving model to {_DEVICE}...\")\n    tatn_model.to(_DEVICE)\n    tatn_model.eval()\n\n\n    print(f\"✅ TATN model loaded successfully\")\n    try:\n        print(f\"   Device: {next(tatn_model.parameters()).device}\")\n    except Exception:\n        pass\n\n\n    if torch.cuda.is_available():\n        try:\n            allocated = torch.cuda.memory_allocated(0) / 1024**3\n            print(f\"   GPU memory: {allocated:.2f} GB\")\n        except Exception:\n            pass\n\n\n    print(\"=\" * 80)\n\n\nexcept Exception as e:\n    print(f\"❌ Failed to load TATN model: {e}\")\n    import traceback\n    traceback.print_exc()\n    raise\n\n\n\n# ==============================================================================\n# SECTION 6: TRANSLATION FUNCTION (TATN only)\n# ==============================================================================\ndef translate_batch_tatn(\n    sentences: List[str],\n    model,\n    tokenizer,\n    max_length: int = 128,\n    num_beams: int = 5,\n) -> List[str]:\n    \"\"\"Translate batch using TATN model\"\"\"\n    try:\n        tokenizer.src_lang = _SOURCE_LANGUAGE\n        inputs = tokenizer(\n            sentences,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=max_length\n        )\n\n\n        input_ids = inputs[\"input_ids\"].to(_DEVICE)\n        attention_mask = inputs[\"attention_mask\"].to(_DEVICE)\n\n\n        with torch.no_grad():\n            forward_outputs = model.forward(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=None,\n                use_dscd=True,\n                use_asbn=False,\n                return_dict=True\n            )\n\n\n            if isinstance(forward_outputs, dict):\n                encoder_outputs = forward_outputs.get(\"encoder_outputs\")\n            else:\n                encoder_outputs = forward_outputs\n\n\n            tokenizer.tgt_lang = _TARGET_LANGUAGE\n\n\n            generated = model.generate(\n                input_ids=None,\n                attention_mask=attention_mask,\n                encoder_outputs=encoder_outputs,\n                max_length=max_length,\n                num_beams=num_beams,\n                early_stopping=True,\n                forced_bos_token_id=tokenizer.lang_code_to_id.get(\n                    _TARGET_LANGUAGE,\n                    getattr(tokenizer, \"eos_token_id\", None)\n                ),\n            )\n\n\n            translations = tokenizer.batch_decode(generated, skip_special_tokens=True)\n\n\n            # Clean up batch memory\n            try:\n                del input_ids, attention_mask, generated, encoder_outputs\n            except Exception:\n                pass\n            if isinstance(forward_outputs, dict):\n                try:\n                    del forward_outputs\n                except Exception:\n                    pass\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n\n\n            return translations\n\n\n    except Exception as e:\n        print(f\"⚠️  Batch translation failed: {e}\")\n        return [\"[ERROR]\"] * len(sentences)\n\n\n\n# ==============================================================================\n# SECTION 7: EVALUATE TATN MODEL\n# ==============================================================================\nprint(f\"\\n[SECTION 7] Evaluating TATN Model...\")\nprint(\"-\" * 80)\nprint(f\"Translating {len(sources)} samples...\")\n\n\ntatn_translations = []\nstart_time = time.time()\n\n\nfor i in range(0, len(sources), _EVAL_BATCH_SIZE):\n    batch_sources = sources[i:i + _EVAL_BATCH_SIZE]\n    batch_translations = translate_batch_tatn(\n        batch_sources,\n        tatn_model,\n        tokenizer,\n        max_length=_MAX_LENGTH,\n        num_beams=_EVAL_NUM_BEAMS\n    )\n    tatn_translations.extend(batch_translations)\n\n\n    if (i + _EVAL_BATCH_SIZE) % 200 == 0 or (i + _EVAL_BATCH_SIZE) >= len(sources):\n        elapsed = time.time() - start_time\n        processed = min(i + _EVAL_BATCH_SIZE, len(sources))\n        speed = processed / elapsed if elapsed > 0 else 0\n        eta = (len(sources) - processed) / speed if speed > 0 else 0\n\n\n        if torch.cuda.is_available():\n            try:\n                mem_gb = torch.cuda.memory_allocated(0) / 1024**3\n                print(f\"   Progress: {processed}/{len(sources)} ({processed/len(sources)*100:.1f}%) | \"\n                      f\"Speed: {speed:.1f} samples/s | ETA: {eta/60:.1f} min | GPU: {mem_gb:.2f}GB\")\n            except Exception:\n                print(f\"   Progress: {processed}/{len(sources)} ({processed/len(sources)*100:.1f}%) | \"\n                      f\"Speed: {speed:.1f} samples/s | ETA: {eta/60:.1f} min\")\n        else:\n            print(f\"   Progress: {processed}/{len(sources)} ({processed/len(sources)*100:.1f}%) | \"\n                  f\"Speed: {speed:.1f} samples/s | ETA: {eta/60:.1f} min\")\n\n\nelapsed_tatn = time.time() - start_time\n\n\nprint(f\"\\n✅ TATN translation complete\")\nprint(f\"   Time: {elapsed_tatn:.1f}s ({elapsed_tatn/60:.2f} min)\")\nprint(f\"   Speed: {len(sources)/elapsed_tatn:.2f} samples/s\")\n\n\n# ==============================================================================\n# SECTION 8: COMPUTE BLEU & CHRF++ SCORES\n# ==============================================================================\nprint(f\"\\n[SECTION 8] Computing BLEU & ChrF++ Scores...\")\nprint(\"-\" * 80)\n\ntry:\n    tatn_bleu = sacrebleu.corpus_bleu(tatn_translations, [references])\n    tatn_chrf = sacrebleu.corpus_chrf(tatn_translations, [references])\n\n    tatn_bleu_score = tatn_bleu.score\n    tatn_chrf_score = tatn_chrf.score\n\n    print(f\"✅ BLEU computed: {tatn_bleu_score:.2f}\")\n    print(f\"✅ ChrF++ computed: {tatn_chrf_score:.2f}\")\nexcept Exception as e:\n    print(f\"⚠️  sacrebleu computation failed: {e}\")\n    tatn_bleu_score = 0.0\n    tatn_chrf_score = 0.0\n\nprint(\"=\" * 80)\n\n\n# ==============================================================================\n# SECTION 9: COMPUTE COMET SCORE (OFFICIAL UNBABEL IMPLEMENTATION)\n# ==============================================================================\nprint(f\"\\n[SECTION 9] Computing COMET Score...\")\nprint(\"-\" * 80)\n\ntry:\n    # Step 1: Download COMET model (official Unbabel model)\n    print(f\"📥 Downloading COMET model: Unbabel/wmt22-comet-da...\")\n    comet_model_path = download_model(\"Unbabel/wmt22-comet-da\")\n    print(f\"✅ Model downloaded: {comet_model_path}\")\n\n    # Step 2: Load COMET model from checkpoint\n    print(f\"🔧 Loading COMET model...\")\n    comet_model = load_from_checkpoint(comet_model_path)\n    print(f\"✅ COMET model loaded successfully\")\n\n    # Step 3: Prepare data in COMET format (list of dicts)\n    print(f\"📋 Preparing data for COMET evaluation...\")\n    comet_data = []\n    for src, mt, ref in zip(sources, tatn_translations, references):\n        comet_data.append({\n            \"src\": src,\n            \"mt\": mt,\n            \"ref\": ref\n        })\n    print(f\"✅ Prepared {len(comet_data)} samples\")\n\n    # Step 4: Run COMET prediction\n    print(f\"🚀 Running COMET evaluation...\")\n    print(f\"   Batch size: 8\")\n    print(f\"   GPUs: {1 if torch.cuda.is_available() else 0}\")\n\n    comet_output = comet_model.predict(\n        comet_data,\n        batch_size=8,\n        gpus=1 if torch.cuda.is_available() else 0\n    )\n\n    # Step 5: Extract scores\n    tatn_comet_score = comet_output.system_score  # Corpus-level score\n    tatn_comet_segment_scores = comet_output.scores  # Segment-level scores (list)\n\n    print(f\"\\n✅ COMET evaluation complete\")\n    print(f\"   System score: {tatn_comet_score:.4f}\")\n    print(f\"   Segment scores: {len(tatn_comet_segment_scores)} samples\")\n    print(f\"   Score range: [{min(tatn_comet_segment_scores):.4f}, {max(tatn_comet_segment_scores):.4f}]\")\n\n    # Clean up COMET model to free memory\n    try:\n        del comet_model, comet_data, comet_output\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        print(f\"✅ COMET model memory freed\")\n    except Exception:\n        pass\n\nexcept Exception as e:\n    print(f\"⚠️  COMET evaluation failed: {e}\")\n    import traceback\n    traceback.print_exc()\n    tatn_comet_score = 0.0\n    tatn_comet_segment_scores = [0.0] * len(sources)\n\nprint(\"=\" * 80)\n\n\n# ==============================================================================\n# SECTION 10: FINAL SUMMARY\n# ==============================================================================\nprint(f\"\\n[SECTION 10] FINAL EVALUATION SUMMARY\")\nprint(\"=\" * 80)\n\nprint(f\"\\n📊 TATN MODEL SCORES:\")\nprint(f\"   BLEU:   {tatn_bleu_score:.2f}\")\nprint(f\"   ChrF++: {tatn_chrf_score:.2f}\")\nprint(f\"   COMET:  {tatn_comet_score:.4f}\")\nprint(f\"\\n   Samples evaluated: {len(sources)}\")\nprint(f\"   Translation time: {elapsed_tatn/60:.2f} minutes\")\nprint(f\"   Speed: {len(sources)/elapsed_tatn:.2f} samples/second\")\n\nprint(\"=\" * 80)\n\n\n# ==============================================================================\n# SECTION 11: SAMPLE TRANSLATIONS\n# ==============================================================================\nprint(f\"\\n[SECTION 11] Sample Translations\")\nprint(\"=\" * 80)\n\n\nnum_samples = min(5, len(sources))\nfor i in range(num_samples):\n    print(f\"\\n{'='*60}\")\n    print(f\"SAMPLE {i+1}/{num_samples}\")\n    print(f\"{'='*60}\")\n    print(f\"\\n📝 Source ({_SOURCE_LANGUAGE}):\")\n    print(f\"   {sources[i]}\")\n    print(f\"\\n🎯 Reference ({_TARGET_LANGUAGE}):\")\n    print(f\"   {references[i]}\")\n    print(f\"\\n🤖 TATN Translation:\")\n    print(f\"   {tatn_translations[i]}\")\n    print(f\"\\n📊 COMET Segment Score: {tatn_comet_segment_scores[i]:.4f}\")\n\n\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 12: SAVE RESULTS\n# ==============================================================================\nprint(f\"\\n[SECTION 12] Saving Results...\")\nprint(\"=\" * 80)\n\n\nresults_dir = \"/kaggle/working/\"\nos.makedirs(results_dir, exist_ok=True)\n\n\n# Save summary with COMET\nsummary_file = os.path.join(results_dir, \"evaluation_summary.csv\")\nsummary_data = {\n    \"Model\": [\"TATN\"],\n    \"BLEU\": [tatn_bleu_score],\n    \"ChrF++\": [tatn_chrf_score],\n    \"COMET\": [tatn_comet_score],\n    \"Num_Samples\": [len(sources)],\n}\nsummary_df = pd.DataFrame(summary_data)\nsummary_df.to_csv(summary_file, index=False)\nprint(f\"✅ Summary saved: {summary_file}\")\n\n\n# Save detailed results with COMET segment scores\ndetailed_file = os.path.join(results_dir, \"evaluation_detailed.csv\")\ndetailed_data = {\n    \"source\": sources,\n    \"reference\": references,\n    \"tatn_translation\": tatn_translations,\n    \"comet_score\": tatn_comet_segment_scores,\n}\ndetailed_df = pd.DataFrame(detailed_data)\ndetailed_df.to_csv(detailed_file, index=False)\nprint(f\"✅ Detailed results saved: {detailed_file}\")\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CELL 13: EVALUATION COMPLETE\")\nprint(\"=\" * 80)\n\n\nprint(f\"\\n📊 FINAL SCORES:\")\nprint(f\"   BLEU:   {tatn_bleu_score:.2f}\")\nprint(f\"   ChrF++: {tatn_chrf_score:.2f}\")\nprint(f\"   COMET:  {tatn_comet_score:.4f}\")\n\n\nprint(f\"\\n✅ Results saved to:\")\nprint(f\"   - {summary_file}\")\nprint(f\"   - {detailed_file}\")\n\n\nprint(\"=\" * 80 + \"\\n\")\n\n\n# Final cleanup\ntry:\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\nexcept Exception:\n    pass\ngc.collect()\n","metadata":{"trusted":true,"id":"ITFJEXIW_oAy","execution":{"iopub.status.busy":"2026-02-18T09:34:42.087018Z","iopub.execute_input":"2026-02-18T09:34:42.087248Z","execution_failed":"2026-02-18T11:45:42.578Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCELL 13: EVALUATION WITH MEMORY MANAGEMENT (MBART-50)\n================================================================================\n\n[SECTION 1] Memory Cleanup...\n--------------------------------------------------------------------------------\n📊 BEFORE CLEANUP:\n   Allocated: 11.43 GB\n   Reserved: 11.47 GB\n✓ Attempted to delete 8 variables\n✓ Python garbage collection invoked\n✓ CUDA cache cleared\n\n📊 AFTER CLEANUP:\n   Allocated: 2.31 GB\n   Reserved: 2.35 GB\n   Memory freed: 9.11 GB allocated, 9.12 GB reserved\n\n✅ Memory cleanup complete - Ready for evaluation\n================================================================================\n\n[SECTION 2] Setup and Imports...\n--------------------------------------------------------------------------------\n✅ sacrebleu version: 2.6.0\n⚠️  unbabel-comet not available — installing...\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\na2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\njaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\njax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"✅ unbabel-comet installed successfully\n✅ Configuration loaded\n   Device: cuda\n   Direction: bn_IN → en_XX\n   Max length: 256\n   Batch size: 8\n   Num beams: 5\n================================================================================\n\n[SECTION 3] Loading Dataset...\n--------------------------------------------------------------------------------\nPath: /kaggle/input/datasets/manas00000003/sam-dataset/bn_en_qe0.6_adequacy_filtered_500000_1000000.csv\nSamples: 5000\n✅ Loaded 5000 rows\n   Columns: ['idx', 'src', 'tgt', 'qe_score']\n\n⚠️  SWAPPING COLUMNS:\n   Dataset has: src=English, tgt=Bengali\n   We need: src=Bengali, tgt=English\n\n✅ After swap:\n   src: bn_IN (Bengali)\n   tgt: en_XX (English)\n\n   Sample 1:\n      SRC (bn): ভিডিওটি দেখতে এই লিঙ্কে ক্লিক করুন:...\n      TGT (en): Click on the link below to view the video:...\n\n✅ Prepared 5000 samples for evaluation\n================================================================================\n\n[SECTION 4] Loading Trained TATN Model (mBART-50)...\n--------------------------------------------------------------------------------\nPath: /kaggle/working/tatn_final.pt\n📂 Loading checkpoint to CPU...\n✅ Checkpoint loaded to CPU\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e12d11893424e7b805ac05e3daa9791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b13d40bba1d84a6399621def34f0ed81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce74605ad4a4ef39881344660ce4ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c94b9ab8dd4f4751a5a6fc32435102f3"}},"metadata":{}},{"name":"stdout","text":"✅ MBart50Tokenizer loaded from pretrained\n✅ Language codes set: bn_IN → en_XX\n🔧 Initializing TATN model...\n[TATN-INIT] ✅ Vocab sizes match: 250054\n🔧 Loading model weights (strict=False)...\n🔧 Moving model to cuda...\n✅ TATN model loaded successfully\n   Device: cuda:0\n   GPU memory: 4.60 GB\n================================================================================\n\n[SECTION 7] Evaluating TATN Model...\n--------------------------------------------------------------------------------\nTranslating 5000 samples...\n   Progress: 200/5000 (4.0%) | Speed: 0.5 samples/s | ETA: 167.4 min | GPU: 4.60GB\n   Progress: 400/5000 (8.0%) | Speed: 0.5 samples/s | ETA: 146.3 min | GPU: 4.60GB\n   Progress: 600/5000 (12.0%) | Speed: 0.6 samples/s | ETA: 131.5 min | GPU: 4.60GB\n   Progress: 800/5000 (16.0%) | Speed: 0.6 samples/s | ETA: 123.0 min | GPU: 4.60GB\n   Progress: 1000/5000 (20.0%) | Speed: 0.6 samples/s | ETA: 113.0 min | GPU: 4.60GB\n   Progress: 1200/5000 (24.0%) | Speed: 0.6 samples/s | ETA: 107.0 min | GPU: 4.60GB\n   Progress: 1400/5000 (28.0%) | Speed: 0.6 samples/s | ETA: 102.5 min | GPU: 4.60GB\n   Progress: 1600/5000 (32.0%) | Speed: 0.6 samples/s | ETA: 96.0 min | GPU: 4.60GB\n   Progress: 1800/5000 (36.0%) | Speed: 0.6 samples/s | ETA: 91.0 min | GPU: 4.60GB\n   Progress: 2000/5000 (40.0%) | Speed: 0.6 samples/s | ETA: 86.6 min | GPU: 4.60GB\n   Progress: 2200/5000 (44.0%) | Speed: 0.6 samples/s | ETA: 81.2 min | GPU: 4.60GB\n   Progress: 2400/5000 (48.0%) | Speed: 0.6 samples/s | ETA: 75.1 min | GPU: 4.60GB\n   Progress: 2600/5000 (52.0%) | Speed: 0.6 samples/s | ETA: 69.0 min | GPU: 4.60GB\n   Progress: 2800/5000 (56.0%) | Speed: 0.6 samples/s | ETA: 63.6 min | GPU: 4.60GB\n   Progress: 3000/5000 (60.0%) | Speed: 0.6 samples/s | ETA: 58.2 min | GPU: 4.60GB\n   Progress: 3200/5000 (64.0%) | Speed: 0.6 samples/s | ETA: 52.7 min | GPU: 4.60GB\n   Progress: 3400/5000 (68.0%) | Speed: 0.6 samples/s | ETA: 46.4 min | GPU: 4.60GB\n   Progress: 3600/5000 (72.0%) | Speed: 0.6 samples/s | ETA: 40.6 min | GPU: 4.60GB\n   Progress: 3800/5000 (76.0%) | Speed: 0.6 samples/s | ETA: 34.9 min | GPU: 4.60GB\n   Progress: 4000/5000 (80.0%) | Speed: 0.6 samples/s | ETA: 29.4 min | GPU: 4.60GB\n   Progress: 4200/5000 (84.0%) | Speed: 0.6 samples/s | ETA: 23.5 min | GPU: 4.60GB\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# CELL 13: MEMORY CLEANUP + BLEU & CHRF++ & COMET EVALUATION (MBART-50)\n# ==============================================================================\nimport os\nimport sys\nimport time\nimport csv\nimport gc\nfrom typing import List, Dict, Tuple, Optional, Any\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nimport torch\n\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CELL 13: EVALUATION WITH MEMORY MANAGEMENT (MBART-50)\")\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 1: MEMORY CLEANUP\n# ==============================================================================\nprint(\"\\n[SECTION 1] Memory Cleanup...\")\nprint(\"-\" * 80)\n\n\n\nif torch.cuda.is_available():\n    try:\n        initial_allocated = torch.cuda.memory_allocated(0) / 1024**3\n        initial_reserved = torch.cuda.memory_reserved(0) / 1024**3\n        print(f\"📊 BEFORE CLEANUP:\")\n        print(f\"   Allocated: {initial_allocated:.2f} GB\")\n        print(f\"   Reserved: {initial_reserved:.2f} GB\")\n    except Exception:\n        pass\n\n\n\n# Delete common large variables from global scope to reduce memory pressure\nvariables_to_delete = [\n    'model', 'tatn_model',\n    'tokenizer',\n    'optimizer', 'scheduler',\n    'train_dataloader', 'val_dataloader',\n    'checkpoint', 'model_state',\n    'training_args', 'trainer',\n    'dscd_outputs', 'asbn_outputs', 'trg_outputs',\n    'encoder_outputs', 'forward_outputs',\n    'prototypes_data', 'all_results',\n    'result', 'test_case',\n    'baseline_model', 'baseline_tokenizer', 'baseline_translations'\n]\n\n\n\ndeleted_count = 0\nfor var_name in variables_to_delete:\n    if var_name in globals():\n        try:\n            del globals()[var_name]\n            deleted_count += 1\n        except Exception:\n            pass\n\n\n\nprint(f\"✓ Attempted to delete {deleted_count} variables\")\n\n\n\n# Force garbage collection\ngc.collect()\nprint(f\"✓ Python garbage collection invoked\")\n\n\n\n# Clear CUDA cache\nif torch.cuda.is_available():\n    try:\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n        print(f\"✓ CUDA cache cleared\")\n        final_allocated = torch.cuda.memory_allocated(0) / 1024**3\n        final_reserved = torch.cuda.memory_reserved(0) / 1024**3\n        print(f\"\\n📊 AFTER CLEANUP:\")\n        print(f\"   Allocated: {final_allocated:.2f} GB\")\n        print(f\"   Reserved: {final_reserved:.2f} GB\")\n        try:\n            print(f\"   Memory freed: {initial_allocated - final_allocated:.2f} GB allocated, {initial_reserved - final_reserved:.2f} GB reserved\")\n        except Exception:\n            pass\n    except Exception:\n        pass\n\n\n\nprint(\"\\n✅ Memory cleanup complete - Ready for evaluation\")\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 2: SETUP AND IMPORTS\n# ==============================================================================\nprint(\"\\n[SECTION 2] Setup and Imports...\")\nprint(\"-\" * 80)\n\n\n\ntry:\n    import sacrebleu\n    print(f\"✅ sacrebleu version: {sacrebleu.__version__}\")\nexcept Exception:\n    print(\"⚠️  sacrebleu not available — attempting install...\")\n    import subprocess\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"sacrebleu\"])\n    import sacrebleu\n    print(f\"✅ sacrebleu version: {sacrebleu.__version__}\")\n\n\n\n# Install COMET (official Unbabel package)\ntry:\n    from comet import download_model, load_from_checkpoint\n    print(f\"✅ unbabel-comet already installed\")\nexcept Exception:\n    print(\"⚠️  unbabel-comet not available — installing...\")\n    import subprocess\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"unbabel-comet\"])\n    from comet import download_model, load_from_checkpoint\n    print(f\"✅ unbabel-comet installed successfully\")\n\n\n\ntry:\n    _DEVICE = DEVICE if isinstance(DEVICE, torch.device) else torch.device(str(DEVICE)) if isinstance(DEVICE, str) else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = str(SOURCE_LANGUAGE)\n    _TARGET_LANGUAGE = str(TARGET_LANGUAGE)\n    _MAX_LENGTH = int(MAX_LENGTH)\n    _EVAL_BATCH_SIZE = int(EVAL_BATCH_SIZE) if \"EVAL_BATCH_SIZE\" in globals() else 4\n    _EVAL_NUM_BEAMS = int(EVAL_NUM_BEAMS) if \"EVAL_NUM_BEAMS\" in globals() else 5\nexcept Exception:\n    _DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _SOURCE_LANGUAGE = \"bn_IN\"\n    _TARGET_LANGUAGE = \"en_XX\"\n    _MAX_LENGTH = 256\n    _EVAL_BATCH_SIZE = 4\n    _EVAL_NUM_BEAMS = 8\n\n\n\nprint(f\"✅ Configuration loaded\")\nprint(f\"   Device: {_DEVICE}\")\nprint(f\"   Direction: {_SOURCE_LANGUAGE} → {_TARGET_LANGUAGE}\")\nprint(f\"   Max length: {_MAX_LENGTH}\")\nprint(f\"   Batch size: {_EVAL_BATCH_SIZE}\")\nprint(f\"   Num beams: {_EVAL_NUM_BEAMS}\")\nprint(\"=\" * 80)\n\n\n\n\n# ==============================================================================\n# SECTION 3: LOAD NTREX DATASET (TEXT FILES)\n# ==============================================================================\n# CRITICAL: Your files have src=English, ref=Bengali\n# But we need src=Bengali, tgt=English for bn→en translation\nBENGALI_FILE = \"/content/drive/MyDrive/paper_dataset/ntrex_ref_ben.txt\"  # Bengali (reference)\nENGLISH_FILE = \"/content/drive/MyDrive/paper_dataset/ntrex_src_eng.txt\"  # English (source)\n\n\n\nprint(f\"\\n[SECTION 3] Loading NTREX Dataset...\")\nprint(\"-\" * 80)\nprint(f\"Bengali file: {BENGALI_FILE}\")\nprint(f\"English file: {ENGLISH_FILE}\")\n\n\n\n# Check files exist\nif not os.path.exists(BENGALI_FILE):\n    raise FileNotFoundError(f\"Bengali file not found: {BENGALI_FILE}\")\nif not os.path.exists(ENGLISH_FILE):\n    raise FileNotFoundError(f\"English file not found: {ENGLISH_FILE}\")\n\n\n\ntry:\n    # Load Bengali sentences (these become SOURCE for bn→en)\n    with open(BENGALI_FILE, 'r', encoding='utf-8') as f:\n        bengali_sentences = [line.strip() for line in f if line.strip()]\n\n    # Load English sentences (these become REFERENCE for bn→en)\n    with open(ENGLISH_FILE, 'r', encoding='utf-8') as f:\n        english_sentences = [line.strip() for line in f if line.strip()]\n\n    print(f\"✅ Loaded {len(bengali_sentences)} Bengali sentences\")\n    print(f\"✅ Loaded {len(english_sentences)} English sentences\")\n\n    # Verify same length\n    if len(bengali_sentences) != len(english_sentences):\n        raise ValueError(f\"Mismatch: {len(bengali_sentences)} Bengali vs {len(english_sentences)} English\")\n\n    # ASSIGN CORRECTLY FOR bn→en TRANSLATION\n    sources = bengali_sentences      # Bengali is SOURCE\n    references = english_sentences   # English is REFERENCE (target)\n\n    print(f\"\\n✅ Dataset prepared for bn→en translation:\")\n    print(f\"   Source (Bengali): {len(sources)} sentences\")\n    print(f\"   Reference (English): {len(references)} sentences\")\n\n    print(f\"\\n   Sample 1:\")\n    print(f\"      SRC (bn): {sources[0][:80]}...\")\n    print(f\"      REF (en): {references[0][:80]}...\")\n\n    if len(sources) > 1:\n        print(f\"\\n   Sample 2:\")\n        print(f\"      SRC (bn): {sources[1][:80]}...\")\n        print(f\"      REF (en): {references[1][:80]}...\")\n\n    print(\"=\" * 80)\n\nexcept Exception as e:\n    print(f\"❌ Failed to load dataset: {e}\")\n    raise\n\n\n\n\n# ==============================================================================\n# SECTION 4: LOAD TRAINED TATN MODEL (MBART-50)\n# ==============================================================================\nMODEL_CHECKPOINT_PATH = \"/kaggle/working/tatn_final.pt\"\n\n\n\nprint(f\"\\n[SECTION 4] Loading Trained TATN Model (mBART-50)...\")\nprint(\"-\" * 80)\nprint(f\"Path: {MODEL_CHECKPOINT_PATH}\")\n\n\n\nif not os.path.exists(MODEL_CHECKPOINT_PATH):\n    raise FileNotFoundError(f\"Model checkpoint not found: {MODEL_CHECKPOINT_PATH}\")\n\n\n\ntry:\n    # Load checkpoint to CPU first to avoid OOM\n    print(f\"📂 Loading checkpoint to CPU...\")\n    checkpoint = torch.load(MODEL_CHECKPOINT_PATH, map_location='cpu', weights_only=False)\n    print(f\"✅ Checkpoint loaded to CPU\")\n\n\n\n    # CRITICAL FIX: Use MBart50Tokenizer for mBART-50 model\n    if \"tokenizer\" in checkpoint:\n        tokenizer = checkpoint[\"tokenizer\"]\n        print(f\"✅ Tokenizer loaded from checkpoint\")\n    else:\n        from transformers import MBart50Tokenizer  # ← FIXED: Use MBart50Tokenizer\n        tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50\")\n        print(f\"✅ MBart50Tokenizer loaded from pretrained\")\n\n\n\n    # Set language codes (correct for mBART-50)\n    tokenizer.src_lang = _SOURCE_LANGUAGE  # \"bn_IN\"\n    tokenizer.tgt_lang = _TARGET_LANGUAGE  # \"en_XX\"\n    print(f\"✅ Language codes set: {_SOURCE_LANGUAGE} → {_TARGET_LANGUAGE}\")\n\n\n\n    TATNModelClass = globals().get(\"MemoryOptimizedTATNWithExplanations\") or globals().get(\"TATNModelWithDSCDAndASBN\")\n    if TATNModelClass is None:\n        raise RuntimeError(\"TATN model class not found. Run Cell 6 first.\")\n\n\n\n    print(f\"🔧 Initializing TATN model...\")\n    tatn_model = TATNModelClass(tokenizer)\n\n\n\n    if \"model\" in checkpoint:\n        model_state = checkpoint[\"model\"]\n    elif \"model_state_dict\" in checkpoint:\n        model_state = checkpoint[\"model_state_dict\"]\n    else:\n        raise ValueError(\"No model state found in checkpoint\")\n\n\n\n    print(f\"🔧 Loading model weights (strict=False)...\")\n    tatn_model.load_state_dict(model_state, strict=False)\n\n\n\n    # Free checkpoint memory before moving to GPU\n    try:\n        del model_state\n    except Exception:\n        pass\n    if 'dscd_state' in checkpoint:\n        try:\n            del checkpoint['dscd_state']\n        except Exception:\n            pass\n    try:\n        del checkpoint\n    except Exception:\n        pass\n    gc.collect()\n    torch.cuda.empty_cache()\n\n\n\n    print(f\"🔧 Moving model to {_DEVICE}...\")\n    tatn_model.to(_DEVICE)\n    tatn_model.eval()\n\n\n\n    print(f\"✅ TATN model loaded successfully\")\n    try:\n        print(f\"   Device: {next(tatn_model.parameters()).device}\")\n    except Exception:\n        pass\n\n\n\n    if torch.cuda.is_available():\n        try:\n            allocated = torch.cuda.memory_allocated(0) / 1024**3\n            print(f\"   GPU memory: {allocated:.2f} GB\")\n        except Exception:\n            pass\n\n\n\n    print(\"=\" * 80)\n\n\n\nexcept Exception as e:\n    print(f\"❌ Failed to load TATN model: {e}\")\n    import traceback\n    traceback.print_exc()\n    raise\n\n\n\n\n# ==============================================================================\n# SECTION 6: TRANSLATION FUNCTION (TATN only)\n# ==============================================================================\ndef translate_batch_tatn(\n    sentences: List[str],\n    model,\n    tokenizer,\n    max_length: int = 128,\n    num_beams: int = 5,\n) -> List[str]:\n    \"\"\"Translate batch using TATN model\"\"\"\n    try:\n        tokenizer.src_lang = _SOURCE_LANGUAGE\n        inputs = tokenizer(\n            sentences,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=max_length\n        )\n\n\n\n        input_ids = inputs[\"input_ids\"].to(_DEVICE)\n        attention_mask = inputs[\"attention_mask\"].to(_DEVICE)\n\n\n\n        with torch.no_grad():\n            forward_outputs = model.forward(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=None,\n                use_dscd=True,\n                use_asbn=False,\n                return_dict=True\n            )\n\n\n\n            if isinstance(forward_outputs, dict):\n                encoder_outputs = forward_outputs.get(\"encoder_outputs\")\n            else:\n                encoder_outputs = forward_outputs\n\n\n\n            tokenizer.tgt_lang = _TARGET_LANGUAGE\n\n\n\n            generated = model.generate(\n                input_ids=None,\n                attention_mask=attention_mask,\n                encoder_outputs=encoder_outputs,\n                max_length=max_length,\n                num_beams=num_beams,\n                early_stopping=True,\n                forced_bos_token_id=tokenizer.lang_code_to_id.get(\n                    _TARGET_LANGUAGE,\n                    getattr(tokenizer, \"eos_token_id\", None)\n                ),\n            )\n\n\n\n            translations = tokenizer.batch_decode(generated, skip_special_tokens=True)\n\n\n\n            # Clean up batch memory\n            try:\n                del input_ids, attention_mask, generated, encoder_outputs\n            except Exception:\n                pass\n            if isinstance(forward_outputs, dict):\n                try:\n                    del forward_outputs\n                except Exception:\n                    pass\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n\n\n\n            return translations\n\n\n\n    except Exception as e:\n        print(f\"⚠️  Batch translation failed: {e}\")\n        return [\"[ERROR]\"] * len(sentences)\n\n\n\n\n# ==============================================================================\n# SECTION 7: EVALUATE TATN MODEL\n# ==============================================================================\nprint(f\"\\n[SECTION 7] Evaluating TATN Model...\")\nprint(\"-\" * 80)\nprint(f\"Translating {len(sources)} samples...\")\n\n\n\ntatn_translations = []\nstart_time = time.time()\n\n\n\nfor i in range(0, len(sources), _EVAL_BATCH_SIZE):\n    batch_sources = sources[i:i + _EVAL_BATCH_SIZE]\n    batch_translations = translate_batch_tatn(\n        batch_sources,\n        tatn_model,\n        tokenizer,\n        max_length=_MAX_LENGTH,\n        num_beams=_EVAL_NUM_BEAMS\n    )\n    tatn_translations.extend(batch_translations)\n\n\n\n    if (i + _EVAL_BATCH_SIZE) % 200 == 0 or (i + _EVAL_BATCH_SIZE) >= len(sources):\n        elapsed = time.time() - start_time\n        processed = min(i + _EVAL_BATCH_SIZE, len(sources))\n        speed = processed / elapsed if elapsed > 0 else 0\n        eta = (len(sources) - processed) / speed if speed > 0 else 0\n\n\n\n        if torch.cuda.is_available():\n            try:\n                mem_gb = torch.cuda.memory_allocated(0) / 1024**3\n                print(f\"   Progress: {processed}/{len(sources)} ({processed/len(sources)*100:.1f}%) | \"\n                      f\"Speed: {speed:.1f} samples/s | ETA: {eta/60:.1f} min | GPU: {mem_gb:.2f}GB\")\n            except Exception:\n                print(f\"   Progress: {processed}/{len(sources)} ({processed/len(sources)*100:.1f}%) | \"\n                      f\"Speed: {speed:.1f} samples/s | ETA: {eta/60:.1f} min\")\n        else:\n            print(f\"   Progress: {processed}/{len(sources)} ({processed/len(sources)*100:.1f}%) | \"\n                  f\"Speed: {speed:.1f} samples/s | ETA: {eta/60:.1f} min\")\n\n\n\nelapsed_tatn = time.time() - start_time\n\n\n\nprint(f\"\\n✅ TATN translation complete\")\nprint(f\"   Time: {elapsed_tatn:.1f}s ({elapsed_tatn/60:.2f} min)\")\nprint(f\"   Speed: {len(sources)/elapsed_tatn:.2f} samples/s\")\n\n\n\n# ==============================================================================\n# SECTION 8: COMPUTE BLEU & CHRF++ SCORES\n# ==============================================================================\nprint(f\"\\n[SECTION 8] Computing BLEU & ChrF++ Scores...\")\nprint(\"-\" * 80)\n\n\ntry:\n    tatn_bleu = sacrebleu.corpus_bleu(tatn_translations, [references])\n    tatn_chrf = sacrebleu.corpus_chrf(tatn_translations, [references])\n\n\n    tatn_bleu_score = tatn_bleu.score\n    tatn_chrf_score = tatn_chrf.score\n\n\n    print(f\"✅ BLEU computed: {tatn_bleu_score:.2f}\")\n    print(f\"✅ ChrF++ computed: {tatn_chrf_score:.2f}\")\nexcept Exception as e:\n    print(f\"⚠️  sacrebleu computation failed: {e}\")\n    tatn_bleu_score = 0.0\n    tatn_chrf_score = 0.0\n\n\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 9: COMPUTE COMET SCORE (OFFICIAL UNBABEL IMPLEMENTATION)\n# ==============================================================================\nprint(f\"\\n[SECTION 9] Computing COMET Score...\")\nprint(\"-\" * 80)\n\n\ntry:\n    # Step 1: Download COMET model (official Unbabel model)\n    print(f\"📥 Downloading COMET model: Unbabel/wmt22-comet-da...\")\n    comet_model_path = download_model(\"Unbabel/wmt22-comet-da\")\n    print(f\"✅ Model downloaded: {comet_model_path}\")\n\n\n    # Step 2: Load COMET model from checkpoint\n    print(f\"🔧 Loading COMET model...\")\n    comet_model = load_from_checkpoint(comet_model_path)\n    print(f\"✅ COMET model loaded successfully\")\n\n\n    # Step 3: Prepare data in COMET format (list of dicts)\n    print(f\"📋 Preparing data for COMET evaluation...\")\n    comet_data = []\n    for src, mt, ref in zip(sources, tatn_translations, references):\n        comet_data.append({\n            \"src\": src,\n            \"mt\": mt,\n            \"ref\": ref\n        })\n    print(f\"✅ Prepared {len(comet_data)} samples\")\n\n\n    # Step 4: Run COMET prediction\n    print(f\"🚀 Running COMET evaluation...\")\n    print(f\"   Batch size: 8\")\n    print(f\"   GPUs: {1 if torch.cuda.is_available() else 0}\")\n\n\n    comet_output = comet_model.predict(\n        comet_data,\n        batch_size=8,\n        gpus=1 if torch.cuda.is_available() else 0\n    )\n\n\n    # Step 5: Extract scores\n    tatn_comet_score = comet_output.system_score  # Corpus-level score\n    tatn_comet_segment_scores = comet_output.scores  # Segment-level scores (list)\n\n\n    print(f\"\\n✅ COMET evaluation complete\")\n    print(f\"   System score: {tatn_comet_score:.4f}\")\n    print(f\"   Segment scores: {len(tatn_comet_segment_scores)} samples\")\n    print(f\"   Score range: [{min(tatn_comet_segment_scores):.4f}, {max(tatn_comet_segment_scores):.4f}]\")\n\n\n    # Clean up COMET model to free memory\n    try:\n        del comet_model, comet_data, comet_output\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        print(f\"✅ COMET model memory freed\")\n    except Exception:\n        pass\n\n\nexcept Exception as e:\n    print(f\"⚠️  COMET evaluation failed: {e}\")\n    import traceback\n    traceback.print_exc()\n    tatn_comet_score = 0.0\n    tatn_comet_segment_scores = [0.0] * len(sources)\n\n\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 10: FINAL SUMMARY\n# ==============================================================================\nprint(f\"\\n[SECTION 10] FINAL EVALUATION SUMMARY\")\nprint(\"=\" * 80)\n\n\nprint(f\"\\n📊 TATN MODEL SCORES:\")\nprint(f\"   BLEU:   {tatn_bleu_score:.2f}\")\nprint(f\"   ChrF++: {tatn_chrf_score:.2f}\")\nprint(f\"   COMET:  {tatn_comet_score:.4f}\")\nprint(f\"\\n   Samples evaluated: {len(sources)}\")\nprint(f\"   Translation time: {elapsed_tatn/60:.2f} minutes\")\nprint(f\"   Speed: {len(sources)/elapsed_tatn:.2f} samples/second\")\n\n\nprint(\"=\" * 80)\n\n\n\n# ==============================================================================\n# SECTION 11: SAMPLE TRANSLATIONS\n# ==============================================================================\nprint(f\"\\n[SECTION 11] Sample Translations\")\nprint(\"=\" * 80)\n\n\n\nnum_samples = min(5, len(sources))\nfor i in range(num_samples):\n    print(f\"\\n{'='*60}\")\n    print(f\"SAMPLE {i+1}/{num_samples}\")\n    print(f\"{'='*60}\")\n    print(f\"\\n📝 Source ({_SOURCE_LANGUAGE}):\")\n    print(f\"   {sources[i]}\")\n    print(f\"\\n🎯 Reference ({_TARGET_LANGUAGE}):\")\n    print(f\"   {references[i]}\")\n    print(f\"\\n🤖 TATN Translation:\")\n    print(f\"   {tatn_translations[i]}\")\n    print(f\"\\n📊 COMET Segment Score: {tatn_comet_segment_scores[i]:.4f}\")\n\n\n\nprint(\"=\" * 80)\n\n\n\n\n# ==============================================================================\n# SECTION 12: SAVE RESULTS\n# ==============================================================================\nprint(f\"\\n[SECTION 12] Saving Results...\")\nprint(\"-\" * 80)\n\n\n\nresults_dir = \"/content/drive/MyDrive/paper_dataset/\"\nos.makedirs(results_dir, exist_ok=True)\n\n\n\n# Save summary with COMET\nsummary_file = os.path.join(results_dir, \"ntrex_evaluation_summary.csv\")\nsummary_data = {\n    \"Model\": [\"TATN\"],\n    \"BLEU\": [tatn_bleu_score],\n    \"ChrF++\": [tatn_chrf_score],\n    \"COMET\": [tatn_comet_score],\n    \"Num_Samples\": [len(sources)],\n}\nsummary_df = pd.DataFrame(summary_data)\nsummary_df.to_csv(summary_file, index=False)\nprint(f\"✅ Summary saved: {summary_file}\")\n\n\n\n# Save detailed results with COMET segment scores\ndetailed_file = os.path.join(results_dir, \"ntrex_evaluation_detailed.csv\")\ndetailed_data = {\n    \"source\": sources,\n    \"reference\": references,\n    \"tatn_translation\": tatn_translations,\n    \"comet_score\": tatn_comet_segment_scores,\n}\ndetailed_df = pd.DataFrame(detailed_data)\ndetailed_df.to_csv(detailed_file, index=False)\nprint(f\"✅ Detailed results saved: {detailed_file}\")\n\n\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CELL 13: EVALUATION COMPLETE\")\nprint(\"=\" * 80)\n\n\n\nprint(f\"\\n📊 FINAL SCORES:\")\nprint(f\"   BLEU:   {tatn_bleu_score:.2f}\")\nprint(f\"   ChrF++: {tatn_chrf_score:.2f}\")\nprint(f\"   COMET:  {tatn_comet_score:.4f}\")\n\n\n\nprint(f\"\\n✅ Results saved to:\")\nprint(f\"   - {summary_file}\")\nprint(f\"   - {detailed_file}\")\n\n\n\nprint(\"=\" * 80 + \"\\n\")\n\n\n\n# Final cleanup\ntry:\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\nexcept Exception:\n    pass\ngc.collect()\n","metadata":{"id":"QDxrLqB0Vjps","trusted":true,"execution":{"execution_failed":"2026-02-18T11:45:42.578Z"}},"outputs":[],"execution_count":null}]}